{
  "total_guides": 284,
  "guides_by_complexity": {
    "intermediate": 120,
    "advanced": 156,
    "beginner": 8
  },
  "guides_by_use_case": {
    "Chain Dependencies": [
      {
        "guide_id": "35455dea07d1",
        "title": "Chain Dependencies",
        "overview": "Workflow: Test chain of dependencies.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.dependency_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ae8eb210",
            "test_name": "test_chain_dependencies",
            "category": "workflow",
            "code": "'Test chain of dependencies.'\nself.analyzer.analyze_file('main.py', 'import utils', 'Python')\nself.analyzer.analyze_file('utils.py', 'import helpers', 'Python')\nself.analyzer.analyze_file('helpers.py', '', 'Python')\ngraph = self.analyzer.build_graph()\nself.assertEqual(graph.number_of_nodes(), 3)",
            "language": "Python",
            "description": "Workflow: Test chain of dependencies.",
            "expected_behavior": "self.assertEqual(graph.number_of_nodes(), 3)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
            "line_start": 208,
            "line_end": 217,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.dependency_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test chain of dependencies.'",
            "description": "'Test chain of dependencies.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "self.analyzer.analyze_file('main.py', 'import utils', 'Python')",
            "description": "Call self.analyzer.analyze_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "self.analyzer.analyze_file('utils.py', 'import helpers', 'Python')",
            "description": "Call self.analyzer.analyze_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.analyzer.analyze_file('helpers.py', '', 'Python')",
            "description": "Call self.analyzer.analyze_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "graph = self.analyzer.build_graph()",
            "description": "Assign graph = self.analyzer.build_graph(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(graph.number_of_nodes(), 3)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chain Dependencies",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_dependency_analyzer.py:208"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scrape Parser Creates Subparser": [
      {
        "guide_id": "3be0db480f23",
        "title": "Scrape Parser Creates Subparser",
        "overview": "Workflow: Test that ScrapeParser creates valid subparser.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e01a676e",
            "test_name": "test_scrape_parser_creates_subparser",
            "category": "workflow",
            "code": "'Test that ScrapeParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\nscrape_parser = ScrapeParser()\nsubparser = scrape_parser.create_parser(subparsers)\nassert subparser is not None\nassert scrape_parser.name == 'scrape'\nassert scrape_parser.help == 'Scrape documentation website'",
            "language": "Python",
            "description": "Workflow: Test that ScrapeParser creates valid subparser.",
            "expected_behavior": "assert scrape_parser.help == 'Scrape documentation website'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 72,
            "line_end": 82,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that ScrapeParser creates valid subparser.'",
            "description": "'Test that ScrapeParser creates valid subparser.'",
            "expected_result": null,
            "verification": "assert subparser is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert scrape_parser.name == 'scrape'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers()",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": "assert scrape_parser.help == 'Scrape documentation website'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "scrape_parser = ScrapeParser()",
            "description": "Assign scrape_parser = ScrapeParser(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "subparser = scrape_parser.create_parser(subparsers)",
            "description": "Assign subparser = scrape_parser.create_parser(...)",
            "expected_result": null,
            "verification": "assert subparser is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scrape Parser Creates Subparser",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_cli_parsers.py:72"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Github Parser Creates Subparser": [
      {
        "guide_id": "41ef2cbefcb5",
        "title": "Github Parser Creates Subparser",
        "overview": "Workflow: Test that GitHubParser creates valid subparser.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "04c400c9",
            "test_name": "test_github_parser_creates_subparser",
            "category": "workflow",
            "code": "'Test that GitHubParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\ngithub_parser = GitHubParser()\nsubparser = github_parser.create_parser(subparsers)\nassert subparser is not None\nassert github_parser.name == 'github'",
            "language": "Python",
            "description": "Workflow: Test that GitHubParser creates valid subparser.",
            "expected_behavior": "assert github_parser.name == 'github'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 84,
            "line_end": 93,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that GitHubParser creates valid subparser.'",
            "description": "'Test that GitHubParser creates valid subparser.'",
            "expected_result": null,
            "verification": "assert subparser is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert github_parser.name == 'github'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers()",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "github_parser = GitHubParser()",
            "description": "Assign github_parser = GitHubParser(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "subparser = github_parser.create_parser(subparsers)",
            "description": "Assign subparser = github_parser.create_parser(...)",
            "expected_result": null,
            "verification": "assert subparser is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Github Parser Creates Subparser",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_cli_parsers.py:84"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Package Parser Creates Subparser": [
      {
        "guide_id": "5828ca734e15",
        "title": "Package Parser Creates Subparser",
        "overview": "Workflow: Test that PackageParser creates valid subparser.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4a3afacf",
            "test_name": "test_package_parser_creates_subparser",
            "category": "workflow",
            "code": "'Test that PackageParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\npackage_parser = PackageParser()\nsubparser = package_parser.create_parser(subparsers)\nassert subparser is not None\nassert package_parser.name == 'package'",
            "language": "Python",
            "description": "Workflow: Test that PackageParser creates valid subparser.",
            "expected_behavior": "assert package_parser.name == 'package'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 95,
            "line_end": 104,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that PackageParser creates valid subparser.'",
            "description": "'Test that PackageParser creates valid subparser.'",
            "expected_result": null,
            "verification": "assert subparser is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert package_parser.name == 'package'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers()",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_parser = PackageParser()",
            "description": "Assign package_parser = PackageParser(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "subparser = package_parser.create_parser(subparsers)",
            "description": "Assign subparser = package_parser.create_parser(...)",
            "expected_result": null,
            "verification": "assert subparser is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Package Parser Creates Subparser",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_cli_parsers.py:95"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Register Parsers Creates All Subcommands": [
      {
        "guide_id": "d35258a3778e",
        "title": "Register Parsers Creates All Subcommands",
        "overview": "Workflow: Test that register_parsers creates all 19 subcommands.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "1d07962e",
            "test_name": "test_register_parsers_creates_all_subcommands",
            "category": "workflow",
            "code": "'Test that register_parsers creates all 19 subcommands.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nregister_parsers(subparsers)\ntest_commands = ['config --show', 'scrape --config test.json', 'github --repo owner/repo', 'package output/test/', 'upload test.zip', 'analyze --directory .', 'enhance output/test/', 'estimate test.json']\nfor cmd in test_commands:\n    args = main_parser.parse_args(cmd.split())\n    assert args.command is not None",
            "language": "Python",
            "description": "Workflow: Test that register_parsers creates all 19 subcommands.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 106,
            "line_end": 128,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that register_parsers creates all 19 subcommands.'",
            "description": "'Test that register_parsers creates all 19 subcommands.'",
            "expected_result": null,
            "verification": "assert args.command is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers(dest='command')",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "register_parsers(subparsers)",
            "description": "Call register_parsers()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "test_commands = ['config --show', 'scrape --config test.json', 'github --repo owner/repo', 'package output/test/', 'upload test.zip', 'analyze --directory .', 'enhance output/test/', 'estimate test.json']",
            "description": "Assign test_commands = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "args = main_parser.parse_args(cmd.split())",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.command is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Register Parsers Creates All Subcommands",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_cli_parsers.py:106"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scrape Parser Arguments": [
      {
        "guide_id": "4f1b5f83ed73",
        "title": "Scrape Parser Arguments",
        "overview": "Workflow: Test ScrapeParser has correct arguments.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9ab8ad64",
            "test_name": "test_scrape_parser_arguments",
            "category": "workflow",
            "code": "'Test ScrapeParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nscrape_parser = ScrapeParser()\nscrape_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['scrape', '--config', 'test.json'])\nassert args.command == 'scrape'\nassert args.config == 'test.json'\nargs = main_parser.parse_args(['scrape', '--config', 'test.json', '--max-pages', '100'])\nassert args.max_pages == 100\nargs = main_parser.parse_args(['scrape', '--enhance'])\nassert args.enhance is True",
            "language": "Python",
            "description": "Workflow: Test ScrapeParser has correct arguments.",
            "expected_behavior": "assert args.enhance is True",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 134,
            "line_end": 151,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test ScrapeParser has correct arguments.'",
            "description": "'Test ScrapeParser has correct arguments.'",
            "expected_result": null,
            "verification": "assert args.command == 'scrape'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert args.config == 'test.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers(dest='command')",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": "assert args.max_pages == 100",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "scrape_parser = ScrapeParser()",
            "description": "Assign scrape_parser = ScrapeParser(...)",
            "expected_result": null,
            "verification": "assert args.enhance is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "scrape_parser.create_parser(subparsers)",
            "description": "Call scrape_parser.create_parser()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "args = main_parser.parse_args(['scrape', '--config', 'test.json'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.command == 'scrape'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "args = main_parser.parse_args(['scrape', '--config', 'test.json', '--max-pages', '100'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.max_pages == 100",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "args = main_parser.parse_args(['scrape', '--enhance'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.enhance is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scrape Parser Arguments",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_cli_parsers.py:134"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Github Parser Arguments": [
      {
        "guide_id": "ec8bec88404b",
        "title": "Github Parser Arguments",
        "overview": "Workflow: Test GitHubParser has correct arguments.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ee30eed2",
            "test_name": "test_github_parser_arguments",
            "category": "workflow",
            "code": "'Test GitHubParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\ngithub_parser = GitHubParser()\ngithub_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['github', '--repo', 'owner/repo'])\nassert args.command == 'github'\nassert args.repo == 'owner/repo'\nargs = main_parser.parse_args(['github', '--repo', 'owner/repo', '--non-interactive'])\nassert args.non_interactive is True",
            "language": "Python",
            "description": "Workflow: Test GitHubParser has correct arguments.",
            "expected_behavior": "assert args.non_interactive is True",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 153,
            "line_end": 166,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test GitHubParser has correct arguments.'",
            "description": "'Test GitHubParser has correct arguments.'",
            "expected_result": null,
            "verification": "assert args.command == 'github'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert args.repo == 'owner/repo'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers(dest='command')",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": "assert args.non_interactive is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "github_parser = GitHubParser()",
            "description": "Assign github_parser = GitHubParser(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "github_parser.create_parser(subparsers)",
            "description": "Call github_parser.create_parser()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "args = main_parser.parse_args(['github', '--repo', 'owner/repo'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.command == 'github'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "args = main_parser.parse_args(['github', '--repo', 'owner/repo', '--non-interactive'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.non_interactive is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Github Parser Arguments",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_cli_parsers.py:153"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Package Parser Arguments": [
      {
        "guide_id": "a8bd303ec0a3",
        "title": "Package Parser Arguments",
        "overview": "Workflow: Test PackageParser has correct arguments.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "485bdd9c",
            "test_name": "test_package_parser_arguments",
            "category": "workflow",
            "code": "'Test PackageParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\npackage_parser = PackageParser()\npackage_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['package', 'output/test/'])\nassert args.command == 'package'\nassert args.skill_directory == 'output/test/'\nargs = main_parser.parse_args(['package', 'output/test/', '--target', 'gemini'])\nassert args.target == 'gemini'\nargs = main_parser.parse_args(['package', 'output/test/', '--no-open'])\nassert args.no_open is True",
            "language": "Python",
            "description": "Workflow: Test PackageParser has correct arguments.",
            "expected_behavior": "assert args.no_open is True",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 168,
            "line_end": 184,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test PackageParser has correct arguments.'",
            "description": "'Test PackageParser has correct arguments.'",
            "expected_result": null,
            "verification": "assert args.command == 'package'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert args.skill_directory == 'output/test/'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers(dest='command')",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": "assert args.target == 'gemini'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_parser = PackageParser()",
            "description": "Assign package_parser = PackageParser(...)",
            "expected_result": null,
            "verification": "assert args.no_open is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "package_parser.create_parser(subparsers)",
            "description": "Call package_parser.create_parser()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "args = main_parser.parse_args(['package', 'output/test/'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.command == 'package'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "args = main_parser.parse_args(['package', 'output/test/', '--target', 'gemini'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.target == 'gemini'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "args = main_parser.parse_args(['package', 'output/test/', '--no-open'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.no_open is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Package Parser Arguments",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_cli_parsers.py:168"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Analyze Parser Arguments": [
      {
        "guide_id": "5c714bd9ad6e",
        "title": "Analyze Parser Arguments",
        "overview": "Workflow: Test AnalyzeParser has correct arguments.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "argparse",
          "pytest",
          "skill_seekers.cli.parsers",
          "skill_seekers.cli.parsers.scrape_parser",
          "skill_seekers.cli.parsers.github_parser",
          "skill_seekers.cli.parsers.package_parser",
          "skill_seekers.cli.parsers.analyze_parser"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c475f8f2",
            "test_name": "test_analyze_parser_arguments",
            "category": "workflow",
            "code": "'Test AnalyzeParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nfrom skill_seekers.cli.parsers.analyze_parser import AnalyzeParser\nanalyze_parser = AnalyzeParser()\nanalyze_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['analyze', '--directory', '.'])\nassert args.command == 'analyze'\nassert args.directory == '.'\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--quick'])\nassert args.quick is True\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nassert args.comprehensive is True\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--skip-patterns'])\nassert args.skip_patterns is True",
            "language": "Python",
            "description": "Workflow: Test AnalyzeParser has correct arguments.",
            "expected_behavior": "assert args.skip_patterns is True",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
            "line_start": 186,
            "line_end": 207,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "argparse",
              "pytest",
              "skill_seekers.cli.parsers",
              "skill_seekers.cli.parsers.scrape_parser",
              "skill_seekers.cli.parsers.github_parser",
              "skill_seekers.cli.parsers.package_parser",
              "skill_seekers.cli.parsers.analyze_parser"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test AnalyzeParser has correct arguments.'",
            "description": "'Test AnalyzeParser has correct arguments.'",
            "expected_result": null,
            "verification": "assert args.command == 'analyze'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "main_parser = argparse.ArgumentParser()",
            "description": "Assign main_parser = argparse.ArgumentParser(...)",
            "expected_result": null,
            "verification": "assert args.directory == '.'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "subparsers = main_parser.add_subparsers(dest='command')",
            "description": "Assign subparsers = main_parser.add_subparsers(...)",
            "expected_result": null,
            "verification": "assert args.quick is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "analyze_parser = AnalyzeParser()",
            "description": "Assign analyze_parser = AnalyzeParser(...)",
            "expected_result": null,
            "verification": "assert args.comprehensive is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "analyze_parser.create_parser(subparsers)",
            "description": "Call analyze_parser.create_parser()",
            "expected_result": null,
            "verification": "assert args.skip_patterns is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "args = main_parser.parse_args(['analyze', '--directory', '.'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.command == 'analyze'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "args = main_parser.parse_args(['analyze', '--directory', '.', '--quick'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.quick is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "args = main_parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.comprehensive is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "args = main_parser.parse_args(['analyze', '--directory', '.', '--skip-patterns'])",
            "description": "Assign args = main_parser.parse_args(...)",
            "expected_result": null,
            "verification": "assert args.skip_patterns is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Analyze Parser Arguments",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_cli_parsers.py:186"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Init Loads Data": [
      {
        "guide_id": "908b1476c0fc",
        "title": "Init Loads Data",
        "overview": "Workflow: Test that converter loads data file on initialization",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "datetime",
          "pathlib",
          "unittest.mock",
          "github",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a8c7065c",
            "test_name": "test_init_loads_data",
            "category": "workflow",
            "code": "'Test that converter loads data file on initialization'\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter.__init__') as mock_init:\n    mock_init.return_value = None\n    converter = self.GitHubToSkillConverter(config)\n    converter.data_file = str(self.data_file)\n    converter.data = converter._load_data()\n    self.assertIn('repo_info', converter.data)\n    self.assertEqual(converter.data['repo_info']['name'], 'react')",
            "language": "Python",
            "description": "Workflow: Test that converter loads data file on initialization",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
            "line_start": 596,
            "line_end": 608,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "datetime",
              "pathlib",
              "unittest.mock",
              "github",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that converter loads data file on initialization'",
            "description": "'Test that converter loads data file on initialization'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "mock_init.return_value = None",
            "description": "Assign mock_init.return_value = None",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter = self.GitHubToSkillConverter(config)",
            "description": "Assign converter = self.GitHubToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter.data_file = str(self.data_file)",
            "description": "Assign converter.data_file = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.data = converter._load_data()",
            "description": "Assign converter.data = converter._load_data(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('repo_info', converter.data)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(converter.data['repo_info']['name'], 'react')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Init Loads Data",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_github_scraper.py:596"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Skill Creates Directory Structure": [
      {
        "guide_id": "ecf7c22b2833",
        "title": "Build Skill Creates Directory Structure",
        "overview": "Workflow: Test that build_skill creates proper directory structure",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "datetime",
          "pathlib",
          "unittest.mock",
          "github",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bf61f1d8",
            "test_name": "test_build_skill_creates_directory_structure",
            "category": "workflow",
            "code": "'Test that build_skill creates proper directory structure'\ndata_file_path = self.output_dir / 'test_github_data.json'\nwith open(data_file_path, 'w') as f:\n    json.dump(self.mock_data, f)\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter._load_data') as mock_load:\n    mock_load.return_value = self.mock_data\n    converter = self.GitHubToSkillConverter(config)\n    converter.skill_dir = str(self.output_dir / 'test_skill')\n    converter.data = self.mock_data\n    converter.build_skill()\n    skill_dir = Path(converter.skill_dir)\n    self.assertTrue(skill_dir.exists())\n    self.assertTrue((skill_dir / 'SKILL.md').exists())\n    self.assertTrue((skill_dir / 'references').exists())",
            "language": "Python",
            "description": "Workflow: Test that build_skill creates proper directory structure",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
            "line_start": 610,
            "line_end": 633,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "datetime",
              "pathlib",
              "unittest.mock",
              "github",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that build_skill creates proper directory structure'",
            "description": "'Test that build_skill creates proper directory structure'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "data_file_path = self.output_dir / 'test_github_data.json'",
            "description": "Assign data_file_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "json.dump(self.mock_data, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "mock_load.return_value = self.mock_data",
            "description": "Assign mock_load.return_value = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter = self.GitHubToSkillConverter(config)",
            "description": "Assign converter = self.GitHubToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "converter.skill_dir = str(self.output_dir / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "converter.data = self.mock_data",
            "description": "Assign converter.data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "skill_dir = Path(converter.skill_dir)",
            "description": "Assign skill_dir = Path(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue(skill_dir.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertTrue((skill_dir / 'SKILL.md').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertTrue((skill_dir / 'references').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Skill Creates Directory Structure",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_github_scraper.py:610"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Invalid Repo Name": [
      {
        "guide_id": "713d0e2ae559",
        "title": "Invalid Repo Name",
        "overview": "Workflow: Test handling of invalid repository name",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "datetime",
          "pathlib",
          "unittest.mock",
          "github",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper",
          "skill_seekers.cli.github_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5528a4b0",
            "test_name": "test_invalid_repo_name",
            "category": "workflow",
            "code": "'Test handling of invalid repository name'\nconfig = {'repo': 'invalid_repo_format', 'name': 'test', 'github_token': None}\nwith patch('skill_seekers.cli.github_scraper.Github'):\n    scraper = self.GitHubScraper(config)\n    scraper.repo = None\n    scraper.github.get_repo = Mock(side_effect=GithubException(404, 'Not found'))\n    with self.assertRaises(ValueError) as context:\n        scraper._fetch_repository()\n    self.assertIn('Repository not found', str(context.exception))",
            "language": "Python",
            "description": "Workflow: Test handling of invalid repository name",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
            "line_start": 980,
            "line_end": 993,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "datetime",
              "pathlib",
              "unittest.mock",
              "github",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper",
              "skill_seekers.cli.github_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test handling of invalid repository name'",
            "description": "'Test handling of invalid repository name'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'repo': 'invalid_repo_format', 'name': 'test', 'github_token': None}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraper = self.GitHubScraper(config)",
            "description": "Assign scraper = self.GitHubScraper(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "scraper.repo = None",
            "description": "Assign scraper.repo = None",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "scraper.github.get_repo = Mock(side_effect=GithubException(404, 'Not found'))",
            "description": "Assign scraper.github.get_repo = Mock(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIn('Repository not found', str(context.exception))",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "scraper._fetch_repository()",
            "description": "Call scraper._fetch_repository()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Invalid Repo Name",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_github_scraper.py:980"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Github Workflows Reference Correct Paths": [
      {
        "guide_id": "c316a486c9e3",
        "title": "Github Workflows Reference Correct Paths",
        "overview": "Workflow: Test that GitHub workflows reference correct MCP paths",
        "complexity_level": "beginner",
        "prerequisites": [],
        "required_imports": [
          "re",
          "subprocess",
          "pathlib",
          "pytest",
          "re",
          "re",
          "os"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5bbe62dc",
            "test_name": "test_github_workflows_reference_correct_paths",
            "category": "workflow",
            "code": "'Test that GitHub workflows reference correct MCP paths'\nworkflow_file = Path('.github/workflows/tests.yml')\nif workflow_file.exists():\n    with open(workflow_file) as f:\n        content = f.read()\n    assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
            "language": "Python",
            "description": "Workflow: Test that GitHub workflows reference correct MCP paths",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
            "line_start": 200,
            "line_end": 210,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "re",
              "subprocess",
              "pathlib",
              "pytest",
              "re",
              "re",
              "os"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that GitHub workflows reference correct MCP paths'",
            "description": "'Test that GitHub workflows reference correct MCP paths'",
            "expected_result": null,
            "verification": "assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "workflow_file = Path('.github/workflows/tests.yml')",
            "description": "Assign workflow_file = Path(...)",
            "expected_result": null,
            "verification": "assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Github Workflows Reference Correct Paths",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_setup_scripts.py:200"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Flask Framework Detection From Imports": [
      {
        "guide_id": "e8a544094a84",
        "title": "Flask Framework Detection From Imports",
        "overview": "Workflow: Test that Flask is detected from import statements (Issue #239).",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.codebase_scraper",
          "sys",
          "skill_seekers.cli.codebase_scraper",
          "sys",
          "skill_seekers.cli.codebase_scraper",
          "sys"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "3627d120",
            "test_name": "test_flask_framework_detection_from_imports",
            "category": "workflow",
            "code": "'Test that Flask is detected from import statements (Issue #239).'\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / '__init__.py').write_text('from flask import Flask\\napp = Flask(__name__)')\n(app_dir / 'routes.py').write_text(\"from flask import render_template\\nfrom app import app\\n\\n@app.route('/')\\ndef index():\\n    return render_template('index.html')\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none', '--skip-patterns', '--skip-test-examples', '--skip-how-to-guides', '--skip-config-patterns', '--skip-docs']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nself.assertTrue(arch_file.exists(), 'Architecture file should be created')\nwith open(arch_file) as f:\n    arch_data = json.load(f)\nself.assertIn('frameworks_detected', arch_data)\nself.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
            "language": "Python",
            "description": "Workflow: Test that Flask is detected from import statements (Issue #239).",
            "expected_behavior": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
            "line_start": 31,
            "line_end": 85,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.codebase_scraper",
              "sys",
              "skill_seekers.cli.codebase_scraper",
              "sys",
              "skill_seekers.cli.codebase_scraper",
              "sys"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that Flask is detected from import statements (Issue #239).'",
            "description": "'Test that Flask is detected from import statements (Issue #239).'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "app_dir = self.test_project / 'app'",
            "description": "Assign app_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "app_dir.mkdir()",
            "description": "Call app_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(app_dir / '__init__.py').write_text('from flask import Flask\\napp = Flask(__name__)')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "(app_dir / 'routes.py').write_text(\"from flask import render_template\\nfrom app import app\\n\\n@app.route('/')\\ndef index():\\n    return render_template('index.html')\\n\")",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "old_argv = sys.argv",
            "description": "Assign old_argv = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "arch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'",
            "description": "Assign arch_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(arch_file.exists(), 'Architecture file should be created')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('frameworks_detected', arch_data)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none', '--skip-patterns', '--skip-test-examples', '--skip-how-to-guides', '--skip-config-patterns', '--skip-docs']",
            "description": "Assign sys.argv = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "scraper_main()",
            "description": "Call scraper_main()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "sys.argv = old_argv",
            "description": "Assign sys.argv = old_argv",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "arch_data = json.load(f)",
            "description": "Assign arch_data = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Flask Framework Detection From Imports",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_framework_detection.py:31"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Files With Imports Are Included": [
      {
        "guide_id": "72325028bc67",
        "title": "Files With Imports Are Included",
        "overview": "Workflow: Test that files with only imports are included in analysis (Issue #239).",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.codebase_scraper",
          "sys",
          "skill_seekers.cli.codebase_scraper",
          "sys",
          "skill_seekers.cli.codebase_scraper",
          "sys"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "94b9c455",
            "test_name": "test_files_with_imports_are_included",
            "category": "workflow",
            "code": "'Test that files with only imports are included in analysis (Issue #239).'\n(self.test_project / 'imports_only.py').write_text('import django\\nfrom flask import Flask\\nimport requests')\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\ncode_analysis = self.output_dir / 'code_analysis.json'\nself.assertTrue(code_analysis.exists(), 'Code analysis file should exist')\nwith open(code_analysis) as f:\n    analysis_data = json.load(f)\nself.assertGreater(len(analysis_data['files']), 0, 'Files with imports should be included')\nimport_file = next((f for f in analysis_data['files'] if 'imports_only.py' in f['file']), None)\nself.assertIsNotNone(import_file, 'Import-only file should be in analysis')\nself.assertIn('imports', import_file, 'Imports should be extracted')\nself.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')\nself.assertIn('django', import_file['imports'], 'Django import should be captured')\nself.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
            "language": "Python",
            "description": "Workflow: Test that files with only imports are included in analysis (Issue #239).",
            "expected_behavior": "self.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
            "line_start": 87,
            "line_end": 135,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.codebase_scraper",
              "sys",
              "skill_seekers.cli.codebase_scraper",
              "sys",
              "skill_seekers.cli.codebase_scraper",
              "sys"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that files with only imports are included in analysis (Issue #239).'",
            "description": "'Test that files with only imports are included in analysis (Issue #239).'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "(self.test_project / 'imports_only.py').write_text('import django\\nfrom flask import Flask\\nimport requests')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "old_argv = sys.argv",
            "description": "Assign old_argv = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_analysis = self.output_dir / 'code_analysis.json'",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(code_analysis.exists(), 'Code analysis file should exist')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertGreater(len(analysis_data['files']), 0, 'Files with imports should be included')",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "import_file = next((f for f in analysis_data['files'] if 'imports_only.py' in f['file']), None)",
            "description": "Assign import_file = next(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIsNotNone(import_file, 'Import-only file should be in analysis')",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('imports', import_file, 'Imports should be extracted')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('django', import_file['imports'], 'Django import should be captured')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']",
            "description": "Assign sys.argv = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "scraper_main()",
            "description": "Call scraper_main()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "sys.argv = old_argv",
            "description": "Assign sys.argv = old_argv",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "analysis_data = json.load(f)",
            "description": "Assign analysis_data = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Files With Imports Are Included",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_framework_detection.py:87"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "No False Positive Frameworks": [
      {
        "guide_id": "5261066f942b",
        "title": "No False Positive Frameworks",
        "overview": "Workflow: Test that framework detection doesn't produce false positives (Issue #239).",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.codebase_scraper",
          "sys",
          "skill_seekers.cli.codebase_scraper",
          "sys",
          "skill_seekers.cli.codebase_scraper",
          "sys"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e8ebe64b",
            "test_name": "test_no_false_positive_frameworks",
            "category": "workflow",
            "code": "\"Test that framework detection doesn't produce false positives (Issue #239).\"\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / 'utils.py').write_text(\"def my_function():\\n    return 'hello'\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nif arch_file.exists():\n    with open(arch_file) as f:\n        arch_data = json.load(f)\n    frameworks = arch_data.get('frameworks_detected', [])\n    self.assertNotIn('Flask', frameworks, 'Should not detect Flask without imports')\n    for fw in ['ASP.NET', 'Rails', 'Laravel']:\n        self.assertNotIn(fw, frameworks, f'Should not detect {fw} without real evidence')",
            "language": "Python",
            "description": "Workflow: Test that framework detection doesn't produce false positives (Issue #239).",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
            "line_start": 137,
            "line_end": 179,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.codebase_scraper",
              "sys",
              "skill_seekers.cli.codebase_scraper",
              "sys",
              "skill_seekers.cli.codebase_scraper",
              "sys"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test that framework detection doesn't produce false positives (Issue #239).\"",
            "description": "\"Test that framework detection doesn't produce false positives (Issue #239).\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "app_dir = self.test_project / 'app'",
            "description": "Assign app_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "app_dir.mkdir()",
            "description": "Call app_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(app_dir / 'utils.py').write_text(\"def my_function():\\n    return 'hello'\\n\")",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "old_argv = sys.argv",
            "description": "Assign old_argv = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "arch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'",
            "description": "Assign arch_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']",
            "description": "Assign sys.argv = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "scraper_main()",
            "description": "Call scraper_main()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "sys.argv = old_argv",
            "description": "Assign sys.argv = old_argv",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "frameworks = arch_data.get('frameworks_detected', [])",
            "description": "Assign frameworks = arch_data.get(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertNotIn('Flask', frameworks, 'Should not detect Flask without imports')",
            "description": "Call self.assertNotIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "arch_data = json.load(f)",
            "description": "Assign arch_data = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertNotIn(fw, frameworks, f'Should not detect {fw} without real evidence')",
            "description": "Call self.assertNotIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "No False Positive Frameworks",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_framework_detection.py:137"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Unified Format": [
      {
        "guide_id": "1b63857d3d29",
        "title": "Detect Unified Format",
        "overview": "Workflow: Test unified format detection and legacy rejection",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e893a84b",
            "test_name": "test_detect_unified_format",
            "category": "workflow",
            "code": "'Test unified format detection and legacy rejection'\nimport json\nimport tempfile\nunified_config = {'name': 'test', 'description': 'Test skill', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nlegacy_config = {'name': 'test', 'description': 'Test skill', 'base_url': 'https://example.com'}\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    json.dump(unified_config, f)\n    config_path = f.name\ntry:\n    validator = ConfigValidator(config_path)\n    assert validator.is_unified\n    validator.validate()\nfinally:\n    os.unlink(config_path)\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    json.dump(legacy_config, f)\n    config_path = f.name\ntry:\n    validator = ConfigValidator(config_path)\n    assert validator.is_unified\n    with pytest.raises(ValueError, match='LEGACY CONFIG FORMAT DETECTED'):\n        validator.validate()\nfinally:\n    os.unlink(config_path)",
            "language": "Python",
            "description": "Workflow: Test unified format detection and legacy rejection",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 29,
            "line_end": 66,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test unified format detection and legacy rejection'",
            "description": "'Test unified format detection and legacy rejection'",
            "expected_result": null,
            "verification": "assert validator.is_unified",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "unified_config = {'name': 'test', 'description': 'Test skill', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}",
            "description": "Assign unified_config = value",
            "expected_result": null,
            "verification": "assert validator.is_unified",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "legacy_config = {'name': 'test', 'description': 'Test skill', 'base_url': 'https://example.com'}",
            "description": "Assign legacy_config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "json.dump(unified_config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config_path = f.name",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "validator = ConfigValidator(config_path)",
            "description": "Assign validator = ConfigValidator(...)",
            "expected_result": null,
            "verification": "assert validator.is_unified",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "validator.validate()",
            "description": "Call validator.validate()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "os.unlink(config_path)",
            "description": "Call os.unlink()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "json.dump(legacy_config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "config_path = f.name",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "validator = ConfigValidator(config_path)",
            "description": "Assign validator = ConfigValidator(...)",
            "expected_result": null,
            "verification": "assert validator.is_unified",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "os.unlink(config_path)",
            "description": "Call os.unlink()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "validator.validate()",
            "description": "Call validator.validate()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Unified Format",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_unified.py:29"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Needs Api Merge": [
      {
        "guide_id": "da92791621ef",
        "title": "Needs Api Merge",
        "overview": "Workflow: Test API merge detection",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [
          "api_client"
        ],
        "workflows": [
          {
            "example_id": "1f45a493",
            "test_name": "test_needs_api_merge",
            "category": "workflow",
            "code": "'Test API merge detection'\nconfig_needs_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com', 'extract_api': True}, {'type': 'github', 'repo': 'user/repo', 'include_code': True}]}\nvalidator = ConfigValidator(config_needs_merge)\nassert validator.needs_api_merge()\nconfig_no_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nvalidator = ConfigValidator(config_no_merge)\nassert not validator.needs_api_merge()",
            "language": "Python",
            "description": "Workflow: Test API merge detection",
            "expected_behavior": "assert not validator.needs_api_merge()",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 99,
            "line_end": 122,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test API merge detection'",
            "description": "'Test API merge detection'",
            "expected_result": null,
            "verification": "assert validator.needs_api_merge()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config_needs_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com', 'extract_api': True}, {'type': 'github', 'repo': 'user/repo', 'include_code': True}]}",
            "description": "Assign config_needs_merge = value",
            "expected_result": null,
            "verification": "assert not validator.needs_api_merge()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "validator = ConfigValidator(config_needs_merge)",
            "description": "Assign validator = ConfigValidator(...)",
            "expected_result": null,
            "verification": "assert validator.needs_api_merge()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config_no_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}",
            "description": "Assign config_no_merge = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "validator = ConfigValidator(config_no_merge)",
            "description": "Assign validator = ConfigValidator(...)",
            "expected_result": null,
            "verification": "assert not validator.needs_api_merge()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Needs Api Merge",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_unified.py:99"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Missing In Docs": [
      {
        "guide_id": "2887aaadf6b5",
        "title": "Detect Missing In Docs",
        "overview": "Workflow: Test detection of APIs missing in documentation",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a5be4d48",
            "test_name": "test_detect_missing_in_docs",
            "category": "workflow",
            "code": "'Test detection of APIs missing in documentation'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'documented_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'undocumented_func', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_missing_in_docs()\nassert len(conflicts) > 0\nassert any((c.type == 'missing_in_docs' for c in conflicts))\nassert any((c.api_name == 'undocumented_func' for c in conflicts))",
            "language": "Python",
            "description": "Workflow: Test detection of APIs missing in documentation",
            "expected_behavior": "assert any((c.api_name == 'undocumented_func' for c in conflicts))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 152,
            "line_end": 190,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of APIs missing in documentation'",
            "description": "'Test detection of APIs missing in documentation'",
            "expected_result": null,
            "verification": "assert len(conflicts) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'documented_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert any((c.type == 'missing_in_docs' for c in conflicts))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'undocumented_func', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert any((c.api_name == 'undocumented_func' for c in conflicts))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector._find_missing_in_docs()",
            "description": "Assign conflicts = detector._find_missing_in_docs(...)",
            "expected_result": null,
            "verification": "assert len(conflicts) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Missing In Docs",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_unified.py:152"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Missing In Code": [
      {
        "guide_id": "7b59118bfab5",
        "title": "Detect Missing In Code",
        "overview": "Workflow: Test detection of APIs missing in code",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f213a2d1",
            "test_name": "test_detect_missing_in_code",
            "category": "workflow",
            "code": "'Test detection of APIs missing in code'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'obsolete_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': []}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_missing_in_code()\nassert len(conflicts) > 0\nassert any((c.type == 'missing_in_code' for c in conflicts))\nassert any((c.api_name == 'obsolete_func' for c in conflicts))",
            "language": "Python",
            "description": "Workflow: Test detection of APIs missing in code",
            "expected_behavior": "assert any((c.api_name == 'obsolete_func' for c in conflicts))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 193,
            "line_end": 217,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of APIs missing in code'",
            "description": "'Test detection of APIs missing in code'",
            "expected_result": null,
            "verification": "assert len(conflicts) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'obsolete_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert any((c.type == 'missing_in_code' for c in conflicts))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': []}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert any((c.api_name == 'obsolete_func' for c in conflicts))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector._find_missing_in_code()",
            "description": "Assign conflicts = detector._find_missing_in_code(...)",
            "expected_result": null,
            "verification": "assert len(conflicts) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Missing In Code",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_unified.py:193"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Signature Mismatch": [
      {
        "guide_id": "28f994940ed9",
        "title": "Detect Signature Mismatch",
        "overview": "Workflow: Test detection of signature mismatches",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "fd49d2de",
            "test_name": "test_detect_signature_mismatch",
            "category": "workflow",
            "code": "'Test detection of signature mismatches'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'func', 'parameters': [{'name': 'x', 'type_hint': 'int'}, {'name': 'y', 'type_hint': 'bool', 'default': 'False'}], 'return_type': 'str'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_signature_mismatches()\nassert len(conflicts) > 0\nassert any((c.type == 'signature_mismatch' for c in conflicts))\nassert any((c.api_name == 'func' for c in conflicts))",
            "language": "Python",
            "description": "Workflow: Test detection of signature mismatches",
            "expected_behavior": "assert any((c.api_name == 'func' for c in conflicts))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 220,
            "line_end": 261,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of signature mismatches'",
            "description": "'Test detection of signature mismatches'",
            "expected_result": null,
            "verification": "assert len(conflicts) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert any((c.type == 'signature_mismatch' for c in conflicts))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'func', 'parameters': [{'name': 'x', 'type_hint': 'int'}, {'name': 'y', 'type_hint': 'bool', 'default': 'False'}], 'return_type': 'str'}]}]}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert any((c.api_name == 'func' for c in conflicts))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector._find_signature_mismatches()",
            "description": "Assign conflicts = detector._find_signature_mismatches(...)",
            "expected_result": null,
            "verification": "assert len(conflicts) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Signature Mismatch",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_unified.py:220"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Rule Based Merge Docs Only": [
      {
        "guide_id": "61d729216fc9",
        "title": "Rule Based Merge Docs Only",
        "overview": "Workflow: Test rule-based merge for docs-only APIs",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5e0faf15",
            "test_name": "test_rule_based_merge_docs_only",
            "category": "workflow",
            "code": "'Test rule-based merge for docs-only APIs'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'docs_only_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': []}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'docs_only_api' in merged['apis']\nassert merged['apis']['docs_only_api']['status'] == 'docs_only'",
            "language": "Python",
            "description": "Workflow: Test rule-based merge for docs-only APIs",
            "expected_behavior": "assert merged['apis']['docs_only_api']['status'] == 'docs_only'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 294,
            "line_end": 321,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test rule-based merge for docs-only APIs'",
            "description": "'Test rule-based merge for docs-only APIs'",
            "expected_result": null,
            "verification": "assert 'apis' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'docs_only_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert 'docs_only_api' in merged['apis']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': []}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert merged['apis']['docs_only_api']['status'] == 'docs_only'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector.detect_all_conflicts()",
            "description": "Assign conflicts = detector.detect_all_conflicts(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "merged = merger.merge_all()",
            "description": "Assign merged = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert 'apis' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Rule Based Merge Docs Only",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_unified.py:294"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Rule Based Merge Code Only": [
      {
        "guide_id": "7359cbc1cfbe",
        "title": "Rule Based Merge Code Only",
        "overview": "Workflow: Test rule-based merge for code-only APIs",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ee3da183",
            "test_name": "test_rule_based_merge_code_only",
            "category": "workflow",
            "code": "'Test rule-based merge for code-only APIs'\ndocs_data = {'pages': []}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'code_only_api', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'code_only_api' in merged['apis']\nassert merged['apis']['code_only_api']['status'] == 'code_only'",
            "language": "Python",
            "description": "Workflow: Test rule-based merge for code-only APIs",
            "expected_behavior": "assert merged['apis']['code_only_api']['status'] == 'code_only'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 324,
            "line_end": 352,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test rule-based merge for code-only APIs'",
            "description": "'Test rule-based merge for code-only APIs'",
            "expected_result": null,
            "verification": "assert 'apis' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': []}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert 'code_only_api' in merged['apis']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'code_only_api', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert merged['apis']['code_only_api']['status'] == 'code_only'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector.detect_all_conflicts()",
            "description": "Assign conflicts = detector.detect_all_conflicts(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "merged = merger.merge_all()",
            "description": "Assign merged = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert 'apis' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Rule Based Merge Code Only",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_unified.py:324"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Rule Based Merge Matched": [
      {
        "guide_id": "afa88306920c",
        "title": "Rule Based Merge Matched",
        "overview": "Workflow: Test rule-based merge for matched APIs",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "42fb31d7",
            "test_name": "test_rule_based_merge_matched",
            "category": "workflow",
            "code": "'Test rule-based merge for matched APIs'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type_hint': 'int'}], 'return_type': 'str'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'matched_api' in merged['apis']\nassert merged['apis']['matched_api']['status'] == 'matched'",
            "language": "Python",
            "description": "Workflow: Test rule-based merge for matched APIs",
            "expected_behavior": "assert merged['apis']['matched_api']['status'] == 'matched'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 355,
            "line_end": 396,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test rule-based merge for matched APIs'",
            "description": "'Test rule-based merge for matched APIs'",
            "expected_result": null,
            "verification": "assert 'apis' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert 'matched_api' in merged['apis']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type_hint': 'int'}], 'return_type': 'str'}]}]}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert merged['apis']['matched_api']['status'] == 'matched'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector.detect_all_conflicts()",
            "description": "Assign conflicts = detector.detect_all_conflicts(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "merged = merger.merge_all()",
            "description": "Assign merged = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert 'apis' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Rule Based Merge Matched",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_unified.py:355"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Merge Summary": [
      {
        "guide_id": "337a1b9f6b2f",
        "title": "Merge Summary",
        "overview": "Workflow: Test merge summary statistics",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "20f90863",
            "test_name": "test_merge_summary",
            "category": "workflow",
            "code": "'Test merge summary statistics'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'api1', 'parameters': [], 'return_type': 'str'}, {'name': 'api2', 'parameters': [], 'return_type': 'int'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'api3', 'parameters': [], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'summary' in merged\nassert merged['summary']['total_apis'] == 3\nassert merged['summary']['docs_only'] == 2\nassert merged['summary']['code_only'] == 1",
            "language": "Python",
            "description": "Workflow: Test merge summary statistics",
            "expected_behavior": "assert merged['summary']['code_only'] == 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 399,
            "line_end": 430,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test merge summary statistics'",
            "description": "'Test merge summary statistics'",
            "expected_result": null,
            "verification": "assert 'summary' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'api1', 'parameters': [], 'return_type': 'str'}, {'name': 'api2', 'parameters': [], 'return_type': 'int'}]}]}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert merged['summary']['total_apis'] == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'api3', 'parameters': [], 'return_type': 'bool'}]}]}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert merged['summary']['docs_only'] == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "detector = ConflictDetector(docs_data, github_data)",
            "description": "Assign detector = ConflictDetector(...)",
            "expected_result": null,
            "verification": "assert merged['summary']['code_only'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = detector.detect_all_conflicts()",
            "description": "Assign conflicts = detector.detect_all_conflicts(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "merged = merger.merge_all()",
            "description": "Assign merged = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert 'summary' in merged",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Merge Summary",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_unified.py:399"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Skill Builder Basic": [
      {
        "guide_id": "ef9dbc3ab78d",
        "title": "Skill Builder Basic",
        "overview": "Workflow: Test basic skill building",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "tempfile",
          "pathlib",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_skill_builder",
          "json",
          "tempfile"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "819b98bf",
            "test_name": "test_skill_builder_basic",
            "category": "workflow",
            "code": "'Test basic skill building'\nconfig = {'name': 'test_skill', 'description': 'Test skill description', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nscraped_data = {'documentation': {'pages': [], 'data_file': '/tmp/test.json'}}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    builder = UnifiedSkillBuilder(config, scraped_data)\n    builder.skill_dir = tmpdir\n    builder._generate_skill_md()\n    skill_md = Path(tmpdir) / 'SKILL.md'\n    assert skill_md.exists()\n    content = skill_md.read_text()\n    assert 'test_skill' in content.lower()\n    assert 'Test skill description' in content",
            "language": "Python",
            "description": "Workflow: Test basic skill building",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
            "line_start": 438,
            "line_end": 461,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "tempfile",
              "pathlib",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_skill_builder",
              "json",
              "tempfile"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic skill building'",
            "description": "'Test basic skill building'",
            "expected_result": null,
            "verification": "assert skill_md.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'description': 'Test skill description', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert 'test_skill' in content.lower()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'documentation': {'pages': [], 'data_file': '/tmp/test.json'}}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": "assert 'Test skill description' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder.skill_dir = tmpdir",
            "description": "Assign builder.skill_dir = tmpdir",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "builder._generate_skill_md()",
            "description": "Call builder._generate_skill_md()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "skill_md = Path(tmpdir) / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": "assert skill_md.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = skill_md.read_text()",
            "description": "Assign content = skill_md.read_text(...)",
            "expected_result": null,
            "verification": "assert 'test_skill' in content.lower()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Skill Builder Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_unified.py:438"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Format Skill Md": [
      {
        "guide_id": "89861b3d5d97",
        "title": "Format Skill Md",
        "overview": "Workflow: Test formatting SKILL.md as Qdrant points.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bccba00b",
            "test_name": "test_format_skill_md",
            "category": "workflow",
            "code": "'Test formatting SKILL.md as Qdrant points.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for Qdrant format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert 'collection_name' in result\nassert 'points' in result\nassert 'config' in result\nassert len(result['points']) == 3\nfor point in result['points']:\n    assert 'id' in point\n    assert 'vector' in point\n    assert 'payload' in point\n    payload = point['payload']\n    assert 'content' in payload\n    assert payload['source'] == 'test_skill'\n    assert payload['version'] == '1.0.0'\n    assert 'category' in payload\n    assert 'file' in payload\n    assert 'type' in payload\ncategories = {point['payload']['category'] for point in result['points']}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
            "language": "Python",
            "description": "Workflow: Test formatting SKILL.md as Qdrant points.",
            "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
            "line_start": 23,
            "line_end": 69,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test formatting SKILL.md as Qdrant points.'",
            "description": "'Test formatting SKILL.md as Qdrant points.'",
            "expected_result": null,
            "verification": "assert 'collection_name' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": "assert 'points' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": "assert 'config' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_md = skill_dir / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": "assert len(result['points']) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_md.write_text('# Test Skill\\n\\nThis is a test skill for Qdrant format.')",
            "description": "Call skill_md.write_text()",
            "expected_result": null,
            "verification": "assert 'id' in point",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "refs_dir = skill_dir / 'references'",
            "description": "Assign refs_dir = value",
            "expected_result": null,
            "verification": "assert 'vector' in point",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "refs_dir.mkdir()",
            "description": "Call refs_dir.mkdir()",
            "expected_result": null,
            "verification": "assert 'payload' in point",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert 'content' in payload",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert payload['source'] == 'test_skill'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "adaptor = get_adaptor('qdrant')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert payload['version'] == '1.0.0'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": "assert 'category' in payload",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
            "description": "Assign points_json = adaptor.format_skill_md(...)",
            "expected_result": null,
            "verification": "assert 'file' in payload",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "result = json.loads(points_json)",
            "description": "Assign result = json.loads(...)",
            "expected_result": null,
            "verification": "assert 'type' in payload",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "categories = {point['payload']['category'] for point in result['points']}",
            "description": "Assign categories = value",
            "expected_result": null,
            "verification": "assert 'overview' in categories",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "payload = point['payload']",
            "description": "Assign payload = value",
            "expected_result": null,
            "verification": "assert 'getting started' in categories or 'api' in categories",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Format Skill Md",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_qdrant_adaptor.py:23"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Package Creates Json": [
      {
        "guide_id": "864b2b61b4de",
        "title": "Package Creates Json",
        "overview": "Workflow: Test packaging skill into JSON file.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f9fcbe20",
            "test_name": "test_package_creates_json",
            "category": "workflow",
            "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('qdrant')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'qdrant' in output_path.name\nwith open(output_path) as f:\n    result = json.load(f)\nassert isinstance(result, dict)\nassert 'points' in result\nassert len(result['points']) > 0\nassert 'id' in result['points'][0]\nassert 'payload' in result['points'][0]",
            "language": "Python",
            "description": "Workflow: Test packaging skill into JSON file.",
            "expected_behavior": "assert 'payload' in result['points'][0]",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
            "line_start": 71,
            "line_end": 95,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test packaging skill into JSON file.'",
            "description": "'Test packaging skill into JSON file.'",
            "expected_result": null,
            "verification": "assert output_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": "assert output_path.suffix == '.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": "assert 'qdrant' in output_path.name",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert isinstance(result, dict)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "adaptor = get_adaptor('qdrant')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert 'points' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "output_path = adaptor.package(skill_dir, tmp_path)",
            "description": "Assign output_path = adaptor.package(...)",
            "expected_result": null,
            "verification": "assert len(result['points']) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "result = json.load(f)",
            "description": "Assign result = json.load(...)",
            "expected_result": null,
            "verification": "assert 'id' in result['points'][0]",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Package Creates Json",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_qdrant_adaptor.py:71"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Package Output Filename": [
      {
        "guide_id": "d43f20c7e5e7",
        "title": "Package Output Filename",
        "overview": "Workflow: Test package output filename generation.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "baec8673",
            "test_name": "test_package_output_filename",
            "category": "workflow",
            "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('qdrant')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-qdrant.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'qdrant' in output_path.name",
            "language": "Python",
            "description": "Workflow: Test package output filename generation.",
            "expected_behavior": "assert 'qdrant' in output_path.name",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
            "line_start": 97,
            "line_end": 112,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test package output filename generation.'",
            "description": "'Test package output filename generation.'",
            "expected_result": null,
            "verification": "assert output_path.name == 'react-qdrant.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'react'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": "assert output_path.suffix == '.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": "assert 'qdrant' in output_path.name",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "adaptor = get_adaptor('qdrant')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "output_path = adaptor.package(skill_dir, tmp_path)",
            "description": "Assign output_path = adaptor.package(...)",
            "expected_result": null,
            "verification": "assert output_path.name == 'react-qdrant.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "output_path = adaptor.package(skill_dir, tmp_path / 'test.zip')",
            "description": "Assign output_path = adaptor.package(...)",
            "expected_result": null,
            "verification": "assert output_path.suffix == '.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Package Output Filename",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_qdrant_adaptor.py:97"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Empty Skill Directory": [
      {
        "guide_id": "730bac34a020",
        "title": "Empty Skill Directory",
        "overview": "Workflow: Test handling of empty skill directory.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ca3d402d",
            "test_name": "test_empty_skill_directory",
            "category": "workflow",
            "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert 'points' in result\nassert result['points'] == []",
            "language": "Python",
            "description": "Workflow: Test handling of empty skill directory.",
            "expected_behavior": "assert result['points'] == []",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
            "line_start": 153,
            "line_end": 166,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test handling of empty skill directory.'",
            "description": "'Test handling of empty skill directory.'",
            "expected_result": null,
            "verification": "assert 'points' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'empty_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": "assert result['points'] == []",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "adaptor = get_adaptor('qdrant')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "metadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
            "description": "Assign points_json = adaptor.format_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "result = json.loads(points_json)",
            "description": "Assign result = json.loads(...)",
            "expected_result": null,
            "verification": "assert 'points' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Empty Skill Directory",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_qdrant_adaptor.py:153"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "References Only": [
      {
        "guide_id": "ea38d1f6af4b",
        "title": "References Only",
        "overview": "Workflow: Test skill with references but no SKILL.md.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "8566ae4f",
            "test_name": "test_references_only",
            "category": "workflow",
            "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert len(result['points']) == 1\nassert result['points'][0]['payload']['category'] == 'test'\nassert result['points'][0]['payload']['type'] == 'reference'",
            "language": "Python",
            "description": "Workflow: Test skill with references but no SKILL.md.",
            "expected_behavior": "assert result['points'][0]['payload']['type'] == 'reference'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
            "line_start": 168,
            "line_end": 185,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test skill with references but no SKILL.md.'",
            "description": "'Test skill with references but no SKILL.md.'",
            "expected_result": null,
            "verification": "assert len(result['points']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'refs_only'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": "assert result['points'][0]['payload']['category'] == 'test'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": "assert result['points'][0]['payload']['type'] == 'reference'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "refs_dir = skill_dir / 'references'",
            "description": "Assign refs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "refs_dir.mkdir()",
            "description": "Call refs_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "adaptor = get_adaptor('qdrant')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "metadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
            "description": "Assign points_json = adaptor.format_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "result = json.loads(points_json)",
            "description": "Assign result = json.loads(...)",
            "expected_result": null,
            "verification": "assert len(result['points']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "References Only",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_qdrant_adaptor.py:168"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Temp Git Repo": [
      {
        "guide_id": "23bde6202e31",
        "title": "Temp Git Repo",
        "overview": "Workflow: Create a temporary git repository with sample configs.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7428f5fa",
            "test_name": "temp_git_repo",
            "category": "workflow",
            "code": "'Create a temporary git repository with sample configs.'\nrepo_dir = tempfile.mkdtemp(prefix='ss_repo_')\nrepo = git.Repo.init(repo_dir)\nconfigs = {'react.json': {'name': 'react', 'description': 'React framework for UIs', 'base_url': 'https://react.dev/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {'getting_started': ['learn', 'start'], 'api': ['reference', 'api']}, 'rate_limit': 0.5, 'max_pages': 100}, 'vue.json': {'name': 'vue', 'description': 'Vue.js progressive framework', 'base_url': 'https://vuejs.org/', 'selectors': {'main_content': 'main', 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 50}, 'django.json': {'name': 'django', 'description': 'Django web framework', 'base_url': 'https://docs.djangoproject.com/', 'selectors': {'main_content': \"div[role='main']\", 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 200}}\nfor filename, config_data in configs.items():\n    config_path = Path(repo_dir) / filename\n    with open(config_path, 'w') as f:\n        json.dump(config_data, f, indent=2)\nrepo.index.add(['*.json'])\nrepo.index.commit('Initial commit with sample configs')\nyield (repo_dir, repo)\nshutil.rmtree(repo_dir, ignore_errors=True)",
            "language": "Python",
            "description": "Workflow: Create a temporary git repository with sample configs.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 51,
            "line_end": 105,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "pytest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Create a temporary git repository with sample configs.'",
            "description": "'Create a temporary git repository with sample configs.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "repo_dir = tempfile.mkdtemp(prefix='ss_repo_')",
            "description": "Assign repo_dir = tempfile.mkdtemp(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo = git.Repo.init(repo_dir)",
            "description": "Assign repo = git.Repo.init(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "configs = {'react.json': {'name': 'react', 'description': 'React framework for UIs', 'base_url': 'https://react.dev/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {'getting_started': ['learn', 'start'], 'api': ['reference', 'api']}, 'rate_limit': 0.5, 'max_pages': 100}, 'vue.json': {'name': 'vue', 'description': 'Vue.js progressive framework', 'base_url': 'https://vuejs.org/', 'selectors': {'main_content': 'main', 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 50}, 'django.json': {'name': 'django', 'description': 'Django web framework', 'base_url': 'https://docs.djangoproject.com/', 'selectors': {'main_content': \"div[role='main']\", 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 200}}",
            "description": "Assign configs = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "repo.index.add(['*.json'])",
            "description": "Call repo.index.add()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "repo.index.commit('Initial commit with sample configs')",
            "description": "Call repo.index.commit()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "yield (repo_dir, repo)",
            "description": "yield (repo_dir, repo)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "shutil.rmtree(repo_dir, ignore_errors=True)",
            "description": "Call shutil.rmtree()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "config_path = Path(repo_dir) / filename",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "json.dump(config_data, f, indent=2)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Temp Git Repo",
        "tags": [
          "pytest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_git_sources_e2e.py:51"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Workflow Direct Git Url": [
      {
        "guide_id": "c85d3079c25c",
        "title": "E2E Workflow Direct Git Url",
        "overview": "Workflow: E2E Test 1: Direct git URL workflow (no source registration)\n\nSteps:\n1. Clone repository via direct git URL\n2. List available configs\n3. Fetch specific config\n4. Verify config content",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b0071f7e",
            "test_name": "test_e2e_workflow_direct_git_url",
            "category": "workflow",
            "code": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-direct', git_url=git_url, branch='master')\nassert repo_path.exists()\nassert (repo_path / '.git').exists()\nconfigs = git_repo.find_configs(repo_path)\nassert len(configs) == 3\nconfig_names = [c.stem for c in configs]\nassert set(config_names) == {'react', 'vue', 'django'}\nconfig = git_repo.get_config(repo_path, 'react')\nassert config['name'] == 'react'\nassert config['description'] == 'React framework for UIs'\nassert config['base_url'] == 'https://react.dev/'\nassert 'selectors' in config\nassert 'categories' in config\nassert config['max_pages'] == 100",
            "language": "Python",
            "description": "Workflow: E2E Test 1: Direct git URL workflow (no source registration)\n\nSteps:\n1. Clone repository via direct git URL\n2. List available configs\n3. Fetch specific config\n4. Verify config content",
            "expected_behavior": "assert config['max_pages'] == 100",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 107,
            "line_end": 148,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '",
            "description": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '",
            "expected_result": null,
            "verification": "assert repo_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert (repo_path / '.git').exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert len(configs) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": "assert set(config_names) == {'react', 'vue', 'django'}",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
            "description": "Assign git_repo = GitConfigRepo(...)",
            "expected_result": null,
            "verification": "assert config['name'] == 'react'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "repo_path = git_repo.clone_or_pull(source_name='test-direct', git_url=git_url, branch='master')",
            "description": "Assign repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": "assert config['description'] == 'React framework for UIs'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "configs = git_repo.find_configs(repo_path)",
            "description": "Assign configs = git_repo.find_configs(...)",
            "expected_result": null,
            "verification": "assert config['base_url'] == 'https://react.dev/'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "config_names = [c.stem for c in configs]",
            "description": "Assign config_names = value",
            "expected_result": null,
            "verification": "assert 'selectors' in config",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "config = git_repo.get_config(repo_path, 'react')",
            "description": "Assign config = git_repo.get_config(...)",
            "expected_result": null,
            "verification": "assert 'categories' in config",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Workflow Direct Git Url",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_git_sources_e2e.py:107"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Workflow With Source Registration": [
      {
        "guide_id": "5b7515179249",
        "title": "E2E Workflow With Source Registration",
        "overview": "Workflow: E2E Test 2: Complete workflow with source registration\n\nSteps:\n1. Add source to registry\n2. List sources\n3. Get source details\n4. Clone via source name\n5. Fetch config\n6. Update source (re-add with different priority)\n7. Remove source\n8. Verify removal",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "98f1ba4a",
            "test_name": "test_e2e_workflow_with_source_registration",
            "category": "workflow",
            "code": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nsource_manager = SourceManager(config_dir=config_dir)\nsource = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=10)\nassert source['name'] == 'team-configs'\nassert source['git_url'] == git_url\nassert source['type'] == 'custom'\nassert source['branch'] == 'master'\nassert source['priority'] == 10\nassert source['enabled'] is True\nsources = source_manager.list_sources()\nassert len(sources) == 1\nassert sources[0]['name'] == 'team-configs'\nretrieved_source = source_manager.get_source('team-configs')\nassert retrieved_source['git_url'] == git_url\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name=source['name'], git_url=source['git_url'], branch=source['branch'])\nassert repo_path.exists()\nconfig = git_repo.get_config(repo_path, 'vue')\nassert config['name'] == 'vue'\nassert config['base_url'] == 'https://vuejs.org/'\nupdated_source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=5)\nassert updated_source['priority'] == 5\nremoved = source_manager.remove_source('team-configs')\nassert removed is True\nsources = source_manager.list_sources()\nassert len(sources) == 0\nwith pytest.raises(KeyError, match=\"Source 'team-configs' not found\"):\n    source_manager.get_source('team-configs')",
            "language": "Python",
            "description": "Workflow: E2E Test 2: Complete workflow with source registration\n\nSteps:\n1. Add source to registry\n2. List sources\n3. Get source details\n4. Clone via source name\n5. Fetch config\n6. Update source (re-add with different priority)\n7. Remove source\n8. Verify removal",
            "expected_behavior": "assert len(sources) == 0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 150,
            "line_end": 223,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '",
            "description": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '",
            "expected_result": null,
            "verification": "assert source['name'] == 'team-configs'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert source['git_url'] == git_url",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert source['type'] == 'custom'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": "assert source['branch'] == 'master'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "source_manager = SourceManager(config_dir=config_dir)",
            "description": "Assign source_manager = SourceManager(...)",
            "expected_result": null,
            "verification": "assert source['priority'] == 10",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=10)",
            "description": "Assign source = source_manager.add_source(...)",
            "expected_result": null,
            "verification": "assert source['enabled'] is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "sources = source_manager.list_sources()",
            "description": "Assign sources = source_manager.list_sources(...)",
            "expected_result": null,
            "verification": "assert len(sources) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "retrieved_source = source_manager.get_source('team-configs')",
            "description": "Assign retrieved_source = source_manager.get_source(...)",
            "expected_result": null,
            "verification": "assert sources[0]['name'] == 'team-configs'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
            "description": "Assign git_repo = GitConfigRepo(...)",
            "expected_result": null,
            "verification": "assert retrieved_source['git_url'] == git_url",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "repo_path = git_repo.clone_or_pull(source_name=source['name'], git_url=source['git_url'], branch=source['branch'])",
            "description": "Assign repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": "assert repo_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "config = git_repo.get_config(repo_path, 'vue')",
            "description": "Assign config = git_repo.get_config(...)",
            "expected_result": null,
            "verification": "assert config['name'] == 'vue'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "updated_source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=5)",
            "description": "Assign updated_source = source_manager.add_source(...)",
            "expected_result": null,
            "verification": "assert config['base_url'] == 'https://vuejs.org/'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "removed = source_manager.remove_source('team-configs')",
            "description": "Assign removed = source_manager.remove_source(...)",
            "expected_result": null,
            "verification": "assert updated_source['priority'] == 5",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "sources = source_manager.list_sources()",
            "description": "Assign sources = source_manager.list_sources(...)",
            "expected_result": null,
            "verification": "assert removed is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "source_manager.get_source('team-configs')",
            "description": "Call source_manager.get_source()",
            "expected_result": null,
            "verification": "assert len(sources) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Workflow With Source Registration",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_git_sources_e2e.py:150"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Multiple Sources Priority Resolution": [
      {
        "guide_id": "5ef70de4b9e9",
        "title": "E2E Multiple Sources Priority Resolution",
        "overview": "Workflow: E2E Test 3: Multiple sources with priority resolution\n\nSteps:\n1. Add multiple sources with different priorities\n2. Verify sources are sorted by priority\n3. Enable/disable sources\n4. List enabled sources only",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c77e4d8d",
            "test_name": "test_e2e_multiple_sources_priority_resolution",
            "category": "workflow",
            "code": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nsource_manager = SourceManager(config_dir=config_dir)\nsource_manager.add_source(name='low-priority', git_url=git_url, priority=100)\nsource_manager.add_source(name='high-priority', git_url=git_url, priority=1)\nsource_manager.add_source(name='medium-priority', git_url=git_url, priority=50)\nsources = source_manager.list_sources()\nassert len(sources) == 3\nassert sources[0]['name'] == 'high-priority'\nassert sources[1]['name'] == 'medium-priority'\nassert sources[2]['name'] == 'low-priority'\nsource_manager.add_source(name='high-priority', git_url=git_url, priority=1, enabled=False)\nenabled_sources = source_manager.list_sources(enabled_only=True)\nassert len(enabled_sources) == 2\nassert all((s['enabled'] for s in enabled_sources))\nassert 'high-priority' not in [s['name'] for s in enabled_sources]",
            "language": "Python",
            "description": "Workflow: E2E Test 3: Multiple sources with priority resolution\n\nSteps:\n1. Add multiple sources with different priorities\n2. Verify sources are sorted by priority\n3. Enable/disable sources\n4. List enabled sources only",
            "expected_behavior": "assert 'high-priority' not in [s['name'] for s in enabled_sources]",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 225,
            "line_end": 260,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '",
            "description": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '",
            "expected_result": null,
            "verification": "assert len(sources) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert sources[0]['name'] == 'high-priority'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert sources[1]['name'] == 'medium-priority'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": "assert sources[2]['name'] == 'low-priority'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "source_manager = SourceManager(config_dir=config_dir)",
            "description": "Assign source_manager = SourceManager(...)",
            "expected_result": null,
            "verification": "assert len(enabled_sources) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "source_manager.add_source(name='low-priority', git_url=git_url, priority=100)",
            "description": "Call source_manager.add_source()",
            "expected_result": null,
            "verification": "assert all((s['enabled'] for s in enabled_sources))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "source_manager.add_source(name='high-priority', git_url=git_url, priority=1)",
            "description": "Call source_manager.add_source()",
            "expected_result": null,
            "verification": "assert 'high-priority' not in [s['name'] for s in enabled_sources]",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "source_manager.add_source(name='medium-priority', git_url=git_url, priority=50)",
            "description": "Call source_manager.add_source()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "sources = source_manager.list_sources()",
            "description": "Assign sources = source_manager.list_sources(...)",
            "expected_result": null,
            "verification": "assert len(sources) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "source_manager.add_source(name='high-priority', git_url=git_url, priority=1, enabled=False)",
            "description": "Call source_manager.add_source()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "enabled_sources = source_manager.list_sources(enabled_only=True)",
            "description": "Assign enabled_sources = source_manager.list_sources(...)",
            "expected_result": null,
            "verification": "assert len(enabled_sources) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Multiple Sources Priority Resolution",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_git_sources_e2e.py:225"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Pull Existing Repository": [
      {
        "guide_id": "207e9ccdf9d1",
        "title": "E2E Pull Existing Repository",
        "overview": "Workflow: E2E Test 4: Pull updates from existing repository\n\nSteps:\n1. Clone repository\n2. Add new commit to original repo\n3. Pull updates\n4. Verify new config is available",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9313eeac",
            "test_name": "test_e2e_pull_existing_repository",
            "category": "workflow",
            "code": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master')\ninitial_configs = git_repo.find_configs(repo_path)\nassert len(initial_configs) == 3\nnew_config = {'name': 'fastapi', 'description': 'FastAPI framework', 'base_url': 'https://fastapi.tiangolo.com/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 150}\nnew_config_path = Path(repo_dir) / 'fastapi.json'\nwith open(new_config_path, 'w') as f:\n    json.dump(new_config, f, indent=2)\nrepo.index.add(['fastapi.json'])\nrepo.index.commit('Add FastAPI config')\nupdated_repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master', force_refresh=False)\nupdated_configs = git_repo.find_configs(updated_repo_path)\nassert len(updated_configs) == 4\nfastapi_config = git_repo.get_config(updated_repo_path, 'fastapi')\nassert fastapi_config['name'] == 'fastapi'\nassert fastapi_config['max_pages'] == 150",
            "language": "Python",
            "description": "Workflow: E2E Test 4: Pull updates from existing repository\n\nSteps:\n1. Clone repository\n2. Add new commit to original repo\n3. Pull updates\n4. Verify new config is available",
            "expected_behavior": "assert fastapi_config['max_pages'] == 150",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 262,
            "line_end": 319,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '",
            "description": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '",
            "expected_result": null,
            "verification": "assert len(initial_configs) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert len(updated_configs) == 4",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert fastapi_config['name'] == 'fastapi'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": "assert fastapi_config['max_pages'] == 150",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
            "description": "Assign git_repo = GitConfigRepo(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master')",
            "description": "Assign repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "initial_configs = git_repo.find_configs(repo_path)",
            "description": "Assign initial_configs = git_repo.find_configs(...)",
            "expected_result": null,
            "verification": "assert len(initial_configs) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "new_config = {'name': 'fastapi', 'description': 'FastAPI framework', 'base_url': 'https://fastapi.tiangolo.com/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 150}",
            "description": "Assign new_config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "new_config_path = Path(repo_dir) / 'fastapi.json'",
            "description": "Assign new_config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "repo.index.add(['fastapi.json'])",
            "description": "Call repo.index.add()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "repo.index.commit('Add FastAPI config')",
            "description": "Call repo.index.commit()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "updated_repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master', force_refresh=False)",
            "description": "Assign updated_repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "updated_configs = git_repo.find_configs(updated_repo_path)",
            "description": "Assign updated_configs = git_repo.find_configs(...)",
            "expected_result": null,
            "verification": "assert len(updated_configs) == 4",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "fastapi_config = git_repo.get_config(updated_repo_path, 'fastapi')",
            "description": "Assign fastapi_config = git_repo.get_config(...)",
            "expected_result": null,
            "verification": "assert fastapi_config['name'] == 'fastapi'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "json.dump(new_config, f, indent=2)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Pull Existing Repository",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_git_sources_e2e.py:262"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Force Refresh": [
      {
        "guide_id": "30a7346dfa8e",
        "title": "E2E Force Refresh",
        "overview": "Workflow: E2E Test 5: Force refresh (delete and re-clone)\n\nSteps:\n1. Clone repository\n2. Modify local cache manually\n3. Force refresh\n4. Verify cache was reset",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "704093e0",
            "test_name": "test_e2e_force_refresh",
            "category": "workflow",
            "code": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master')\ncorrupt_file = repo_path / 'CORRUPTED.txt'\nwith open(corrupt_file, 'w') as f:\n    f.write('This file should not exist after refresh')\nassert corrupt_file.exists()\nrefreshed_repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master', force_refresh=True)\nassert not corrupt_file.exists()\nconfigs = git_repo.find_configs(refreshed_repo_path)\nassert len(configs) == 3",
            "language": "Python",
            "description": "Workflow: E2E Test 5: Force refresh (delete and re-clone)\n\nSteps:\n1. Clone repository\n2. Modify local cache manually\n3. Force refresh\n4. Verify cache was reset",
            "expected_behavior": "assert len(configs) == 3",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 321,
            "line_end": 360,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '",
            "description": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '",
            "expected_result": null,
            "verification": "assert corrupt_file.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert not corrupt_file.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert len(configs) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
            "description": "Assign git_repo = GitConfigRepo(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master')",
            "description": "Assign repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "corrupt_file = repo_path / 'CORRUPTED.txt'",
            "description": "Assign corrupt_file = value",
            "expected_result": null,
            "verification": "assert corrupt_file.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "refreshed_repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master', force_refresh=True)",
            "description": "Assign refreshed_repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": "assert not corrupt_file.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "configs = git_repo.find_configs(refreshed_repo_path)",
            "description": "Assign configs = git_repo.find_configs(...)",
            "expected_result": null,
            "verification": "assert len(configs) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "f.write('This file should not exist after refresh')",
            "description": "Call f.write()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Force Refresh",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_git_sources_e2e.py:321"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Config Not Found": [
      {
        "guide_id": "ae876e1427a0",
        "title": "E2E Config Not Found",
        "overview": "Workflow: E2E Test 6: Error handling - config not found\n\nSteps:\n1. Clone repository\n2. Try to fetch non-existent config\n3. Verify helpful error message with suggestions",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "879de16a",
            "test_name": "test_e2e_config_not_found",
            "category": "workflow",
            "code": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-not-found', git_url=git_url, branch='master')\nwith pytest.raises(FileNotFoundError) as exc_info:\n    git_repo.get_config(repo_path, 'nonexistent')\nerror_msg = str(exc_info.value)\nassert 'nonexistent.json' in error_msg\nassert 'not found' in error_msg\nassert 'react' in error_msg\nassert 'vue' in error_msg\nassert 'django' in error_msg",
            "language": "Python",
            "description": "Workflow: E2E Test 6: Error handling - config not found\n\nSteps:\n1. Clone repository\n2. Try to fetch non-existent config\n3. Verify helpful error message with suggestions",
            "expected_behavior": "assert 'django' in error_msg",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 362,
            "line_end": 392,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '",
            "description": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '",
            "expected_result": null,
            "verification": "assert 'nonexistent.json' in error_msg",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert 'not found' in error_msg",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert 'react' in error_msg",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": "assert 'vue' in error_msg",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
            "description": "Assign git_repo = GitConfigRepo(...)",
            "expected_result": null,
            "verification": "assert 'django' in error_msg",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "repo_path = git_repo.clone_or_pull(source_name='test-not-found', git_url=git_url, branch='master')",
            "description": "Assign repo_path = git_repo.clone_or_pull(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "error_msg = str(exc_info.value)",
            "description": "Assign error_msg = str(...)",
            "expected_result": null,
            "verification": "assert 'nonexistent.json' in error_msg",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "git_repo.get_config(repo_path, 'nonexistent')",
            "description": "Call git_repo.get_config()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Config Not Found",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_git_sources_e2e.py:362"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Invalid Git Url": [
      {
        "guide_id": "cff856a62f38",
        "title": "E2E Invalid Git Url",
        "overview": "Workflow: E2E Test 7: Error handling - invalid git URL\n\nSteps:\n1. Try to clone with invalid URL\n2. Verify validation error",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7a766988",
            "test_name": "test_e2e_invalid_git_url",
            "category": "workflow",
            "code": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '\ncache_dir, config_dir = temp_dirs\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\ninvalid_urls = ['', 'not-a-url', 'ftp://invalid.com/repo.git', \"javascript:alert('xss')\"]\nfor invalid_url in invalid_urls:\n    with pytest.raises(ValueError, match='Invalid git URL'):\n        git_repo.clone_or_pull(source_name='test-invalid', git_url=invalid_url, branch='master')",
            "language": "Python",
            "description": "Workflow: E2E Test 7: Error handling - invalid git URL\n\nSteps:\n1. Try to clone with invalid URL\n2. Verify validation error",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 394,
            "line_end": 412,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '",
            "description": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
            "description": "Assign git_repo = GitConfigRepo(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "invalid_urls = ['', 'not-a-url', 'ftp://invalid.com/repo.git', \"javascript:alert('xss')\"]",
            "description": "Assign invalid_urls = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "git_repo.clone_or_pull(source_name='test-invalid', git_url=invalid_url, branch='master')",
            "description": "Call git_repo.clone_or_pull()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Invalid Git Url",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_git_sources_e2e.py:394"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Source Name Validation": [
      {
        "guide_id": "5cbfaadf0c4d",
        "title": "E2E Source Name Validation",
        "overview": "Workflow: E2E Test 8: Error handling - invalid source names\n\nSteps:\n1. Try to add sources with invalid names\n2. Verify validation errors",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "dc3326f6",
            "test_name": "test_e2e_source_name_validation",
            "category": "workflow",
            "code": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '\ncache_dir, config_dir = temp_dirs\nsource_manager = SourceManager(config_dir=config_dir)\ninvalid_names = ['', 'name with spaces', 'name/with/slashes', 'name@with@symbols', 'name.with.dots', '123-only-numbers-start-is-ok', 'name!exclamation']\nvalid_git_url = 'https://github.com/test/repo.git'\nfor invalid_name in invalid_names[:-2]:\n    if invalid_name == '123-only-numbers-start-is-ok':\n        continue\n    with pytest.raises(ValueError, match='Invalid source name'):\n        source_manager.add_source(name=invalid_name, git_url=valid_git_url)",
            "language": "Python",
            "description": "Workflow: E2E Test 8: Error handling - invalid source names\n\nSteps:\n1. Try to add sources with invalid names\n2. Verify validation errors",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 414,
            "line_end": 442,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '",
            "description": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "source_manager = SourceManager(config_dir=config_dir)",
            "description": "Assign source_manager = SourceManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "invalid_names = ['', 'name with spaces', 'name/with/slashes', 'name@with@symbols', 'name.with.dots', '123-only-numbers-start-is-ok', 'name!exclamation']",
            "description": "Assign invalid_names = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "valid_git_url = 'https://github.com/test/repo.git'",
            "description": "Assign valid_git_url = 'https://github.com/test/repo.git'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "source_manager.add_source(name=invalid_name, git_url=valid_git_url)",
            "description": "Call source_manager.add_source()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Source Name Validation",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_git_sources_e2e.py:414"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Registry Persistence": [
      {
        "guide_id": "85a89d8c798a",
        "title": "E2E Registry Persistence",
        "overview": "Workflow: E2E Test 9: Registry persistence across instances\n\nSteps:\n1. Add source with one SourceManager instance\n2. Create new SourceManager instance\n3. Verify source persists\n4. Modify source with new instance\n5. Verify changes persist",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "pathlib",
          "git",
          "pytest",
          "skill_seekers.mcp.git_repo",
          "skill_seekers.mcp.source_manager",
          "mcp",
          "mcp.types",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server",
          "skill_seekers.mcp.server"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4b861a9f",
            "test_name": "test_e2e_registry_persistence",
            "category": "workflow",
            "code": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nmanager1 = SourceManager(config_dir=config_dir)\nmanager1.add_source(name='persistent-source', git_url=git_url, priority=25)\nmanager2 = SourceManager(config_dir=config_dir)\nsources = manager2.list_sources()\nassert len(sources) == 1\nassert sources[0]['name'] == 'persistent-source'\nassert sources[0]['priority'] == 25\nmanager2.add_source(name='persistent-source', git_url=git_url, priority=50)\nmanager3 = SourceManager(config_dir=config_dir)\nsource = manager3.get_source('persistent-source')\nassert source['priority'] == 50",
            "language": "Python",
            "description": "Workflow: E2E Test 9: Registry persistence across instances\n\nSteps:\n1. Add source with one SourceManager instance\n2. Create new SourceManager instance\n3. Verify source persists\n4. Modify source with new instance\n5. Verify changes persist",
            "expected_behavior": "assert source['priority'] == 50",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
            "line_start": 444,
            "line_end": 483,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "pathlib",
              "git",
              "pytest",
              "skill_seekers.mcp.git_repo",
              "skill_seekers.mcp.source_manager",
              "mcp",
              "mcp.types",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server",
              "skill_seekers.mcp.server"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '",
            "description": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '",
            "expected_result": null,
            "verification": "assert len(sources) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache_dir, config_dir = temp_dirs",
            "description": "Assign unknown = temp_dirs",
            "expected_result": null,
            "verification": "assert sources[0]['name'] == 'persistent-source'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir, repo = temp_git_repo",
            "description": "Assign unknown = temp_git_repo",
            "expected_result": null,
            "verification": "assert sources[0]['priority'] == 25",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "git_url = f'file://{repo_dir}'",
            "description": "Assign git_url = value",
            "expected_result": null,
            "verification": "assert source['priority'] == 50",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "manager1 = SourceManager(config_dir=config_dir)",
            "description": "Assign manager1 = SourceManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "manager1.add_source(name='persistent-source', git_url=git_url, priority=25)",
            "description": "Call manager1.add_source()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "manager2 = SourceManager(config_dir=config_dir)",
            "description": "Assign manager2 = SourceManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "sources = manager2.list_sources()",
            "description": "Assign sources = manager2.list_sources(...)",
            "expected_result": null,
            "verification": "assert len(sources) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "manager2.add_source(name='persistent-source', git_url=git_url, priority=50)",
            "description": "Call manager2.add_source()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "manager3 = SourceManager(config_dir=config_dir)",
            "description": "Assign manager3 = SourceManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "source = manager3.get_source('persistent-source')",
            "description": "Assign source = manager3.get_source(...)",
            "expected_result": null,
            "verification": "assert source['priority'] == 50",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Registry Persistence",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_git_sources_e2e.py:444"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "With Configs Prefix": [
      {
        "guide_id": "6c01f82338af",
        "title": "With Configs Prefix",
        "overview": "Workflow: Test resolution with configs/ prefix.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "unittest.mock",
          "httpx",
          "pytest",
          "skill_seekers.cli.config_fetcher",
          "os",
          "os"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c2beb8b6",
            "test_name": "test_with_configs_prefix",
            "category": "workflow",
            "code": "'Test resolution with configs/ prefix.'\nconfigs_dir = tmp_path / 'configs'\nconfigs_dir.mkdir()\nconfig_file = configs_dir / 'test.json'\nconfig_file.write_text('{\"name\": \"test\"}')\nimport os\noriginal_cwd = os.getcwd()\ntry:\n    os.chdir(tmp_path)\n    result = resolve_config_path('test.json', auto_fetch=False)\n    assert result is not None\n    assert result.exists()\n    assert result.name == 'test.json'\nfinally:\n    os.chdir(original_cwd)",
            "language": "Python",
            "description": "Workflow: Test resolution with configs/ prefix.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
            "line_start": 239,
            "line_end": 258,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "httpx",
              "pytest",
              "skill_seekers.cli.config_fetcher",
              "os",
              "os"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test resolution with configs/ prefix.'",
            "description": "'Test resolution with configs/ prefix.'",
            "expected_result": null,
            "verification": "assert result is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "configs_dir = tmp_path / 'configs'",
            "description": "Assign configs_dir = value",
            "expected_result": null,
            "verification": "assert result.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "configs_dir.mkdir()",
            "description": "Call configs_dir.mkdir()",
            "expected_result": null,
            "verification": "assert result.name == 'test.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config_file = configs_dir / 'test.json'",
            "description": "Assign config_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config_file.write_text('{\"name\": \"test\"}')",
            "description": "Call config_file.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "original_cwd = os.getcwd()",
            "description": "Assign original_cwd = os.getcwd(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "os.chdir(tmp_path)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "result = resolve_config_path('test.json', auto_fetch=False)",
            "description": "Assign result = resolve_config_path(...)",
            "expected_result": null,
            "verification": "assert result is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "os.chdir(original_cwd)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "With Configs Prefix",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_config_fetcher.py:239"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Config Name Normalization": [
      {
        "guide_id": "9e22cb477351",
        "title": "Config Name Normalization",
        "overview": "Workflow: Test various config name formats.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "unittest.mock",
          "httpx",
          "pytest",
          "skill_seekers.cli.config_fetcher",
          "os",
          "os"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "347d551e",
            "test_name": "test_config_name_normalization",
            "category": "workflow",
            "code": "'Test various config name formats.'\nconfigs_dir = tmp_path / 'configs'\nconfigs_dir.mkdir()\nconfig_file = configs_dir / 'react.json'\nconfig_file.write_text('{\"name\": \"react\"}')\nimport os\noriginal_cwd = os.getcwd()\ntry:\n    os.chdir(tmp_path)\n    test_cases = ['react.json', 'configs/react.json']\n    for config_name in test_cases:\n        result = resolve_config_path(config_name, auto_fetch=False)\n        assert result is not None, f'Failed for {config_name}'\n        assert result.exists()\n        assert result.name == 'react.json'\nfinally:\n    os.chdir(original_cwd)",
            "language": "Python",
            "description": "Workflow: Test various config name formats.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
            "line_start": 290,
            "line_end": 312,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "httpx",
              "pytest",
              "skill_seekers.cli.config_fetcher",
              "os",
              "os"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test various config name formats.'",
            "description": "'Test various config name formats.'",
            "expected_result": null,
            "verification": "assert result is not None, f'Failed for {config_name}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "configs_dir = tmp_path / 'configs'",
            "description": "Assign configs_dir = value",
            "expected_result": null,
            "verification": "assert result.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "configs_dir.mkdir()",
            "description": "Call configs_dir.mkdir()",
            "expected_result": null,
            "verification": "assert result.name == 'react.json'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config_file = configs_dir / 'react.json'",
            "description": "Assign config_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config_file.write_text('{\"name\": \"react\"}')",
            "description": "Call config_file.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "original_cwd = os.getcwd()",
            "description": "Assign original_cwd = os.getcwd(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "os.chdir(tmp_path)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "test_cases = ['react.json', 'configs/react.json']",
            "description": "Assign test_cases = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "os.chdir(original_cwd)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "result = resolve_config_path(config_name, auto_fetch=False)",
            "description": "Assign result = resolve_config_path(...)",
            "expected_result": null,
            "verification": "assert result is not None, f'Failed for {config_name}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Config Name Normalization",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_config_fetcher.py:290"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Classify Files": [
      {
        "guide_id": "2353c5b4be0f",
        "title": "Classify Files",
        "overview": "Workflow: Test classify_files separates code and docs correctly.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c3fda686",
            "test_name": "test_classify_files",
            "category": "workflow",
            "code": "'Test classify_files separates code and docs correctly.'\n(tmp_path / 'src').mkdir()\n(tmp_path / 'src' / 'main.py').write_text(\"print('hello')\")\n(tmp_path / 'src' / 'utils.js').write_text('function(){}')\n(tmp_path / 'docs').mkdir()\n(tmp_path / 'README.md').write_text('# README')\n(tmp_path / 'docs' / 'guide.md').write_text('# Guide')\n(tmp_path / 'docs' / 'api.rst').write_text('API')\n(tmp_path / 'node_modules').mkdir()\n(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')\nfetcher = GitHubThreeStreamFetcher('https://github.com/test/repo')\ncode_files, doc_files = fetcher.classify_files(tmp_path)\ncode_paths = [f.name for f in code_files]\nassert 'main.py' in code_paths\nassert 'utils.js' in code_paths\nassert 'lib.js' not in code_paths\ndoc_paths = [f.name for f in doc_files]\nassert 'README.md' in doc_paths\nassert 'guide.md' in doc_paths\nassert 'api.rst' in doc_paths",
            "language": "Python",
            "description": "Workflow: Test classify_files separates code and docs correctly.",
            "expected_behavior": "assert 'api.rst' in doc_paths",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
            "line_start": 105,
            "line_end": 133,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test classify_files separates code and docs correctly.'",
            "description": "'Test classify_files separates code and docs correctly.'",
            "expected_result": null,
            "verification": "assert 'main.py' in code_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "(tmp_path / 'src').mkdir()",
            "description": "Call unknown.mkdir()",
            "expected_result": null,
            "verification": "assert 'utils.js' in code_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "(tmp_path / 'src' / 'main.py').write_text(\"print('hello')\")",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert 'lib.js' not in code_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(tmp_path / 'src' / 'utils.js').write_text('function(){}')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert 'README.md' in doc_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "(tmp_path / 'docs').mkdir()",
            "description": "Call unknown.mkdir()",
            "expected_result": null,
            "verification": "assert 'guide.md' in doc_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(tmp_path / 'README.md').write_text('# README')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert 'api.rst' in doc_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "(tmp_path / 'docs' / 'guide.md').write_text('# Guide')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "(tmp_path / 'docs' / 'api.rst').write_text('API')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "(tmp_path / 'node_modules').mkdir()",
            "description": "Call unknown.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "fetcher = GitHubThreeStreamFetcher('https://github.com/test/repo')",
            "description": "Assign fetcher = GitHubThreeStreamFetcher(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "code_files, doc_files = fetcher.classify_files(tmp_path)",
            "description": "Assign unknown = fetcher.classify_files(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "code_paths = [f.name for f in code_files]",
            "description": "Assign code_paths = value",
            "expected_result": null,
            "verification": "assert 'main.py' in code_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "doc_paths = [f.name for f in doc_files]",
            "description": "Assign doc_paths = value",
            "expected_result": null,
            "verification": "assert 'README.md' in doc_paths",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Classify Files",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_github_fetcher.py:105"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Python With Confidence": [
      {
        "guide_id": "268eb4dbbcba",
        "title": "Detect Python With Confidence",
        "overview": "Workflow: Test Python detection returns language and confidence",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5932c544",
            "test_name": "test_detect_python_with_confidence",
            "category": "workflow",
            "code": "'Test Python detection returns language and confidence'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"def hello():\\n    print('world')\\n    return True\"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'python')\nself.assertGreater(confidence, 0.4)\nself.assertLessEqual(confidence, 1.0)",
            "language": "Python",
            "description": "Workflow: Test Python detection returns language and confidence",
            "expected_behavior": "self.assertLessEqual(confidence, 1.0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 40,
            "line_end": 54,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Python detection returns language and confidence'",
            "description": "'Test Python detection returns language and confidence'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = \"def hello():\\n    print('world')\\n    return True\"",
            "description": "Assign code = \"def hello():\\n    print('world')\\n    return True\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'python')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.4)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertLessEqual(confidence, 1.0)",
            "description": "Call self.assertLessEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Python With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:40"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Javascript With Confidence": [
      {
        "guide_id": "a5def7288dd7",
        "title": "Detect Javascript With Confidence",
        "overview": "Workflow: Test JavaScript detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5942f5df",
            "test_name": "test_detect_javascript_with_confidence",
            "category": "workflow",
            "code": "'Test JavaScript detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'javascript')\nself.assertGreater(confidence, 0.5)",
            "language": "Python",
            "description": "Workflow: Test JavaScript detection",
            "expected_behavior": "self.assertGreater(confidence, 0.5)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 56,
            "line_end": 69,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test JavaScript detection'",
            "description": "'Test JavaScript detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"",
            "description": "Assign code = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'javascript')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.5)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Javascript With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:56"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Cpp With Confidence": [
      {
        "guide_id": "758d02dcc573",
        "title": "Detect Cpp With Confidence",
        "overview": "Workflow: Test C++ detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b50ed04d",
            "test_name": "test_detect_cpp_with_confidence",
            "category": "workflow",
            "code": "'Test C++ detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'cpp')\nself.assertGreater(confidence, 0.5)",
            "language": "Python",
            "description": "Workflow: Test C++ detection",
            "expected_behavior": "self.assertGreater(confidence, 0.5)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 71,
            "line_end": 84,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test C++ detection'",
            "description": "'Test C++ detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'",
            "description": "Assign code = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'cpp')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.5)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Cpp With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:71"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Unknown Low Confidence": [
      {
        "guide_id": "fd9108a8328f",
        "title": "Detect Unknown Low Confidence",
        "overview": "Workflow: Test unknown language returns low confidence",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "705db234",
            "test_name": "test_detect_unknown_low_confidence",
            "category": "workflow",
            "code": "'Test unknown language returns low confidence'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = 'this is not code at all just plain text'\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'unknown')\nself.assertLess(confidence, 0.3)",
            "language": "Python",
            "description": "Workflow: Test unknown language returns low confidence",
            "expected_behavior": "self.assertLess(confidence, 0.3)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 86,
            "line_end": 99,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test unknown language returns low confidence'",
            "description": "'Test unknown language returns low confidence'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = 'this is not code at all just plain text'",
            "description": "Assign code = 'this is not code at all just plain text'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'unknown')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertLess(confidence, 0.3)",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Unknown Low Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:86"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Scss With Confidence": [
      {
        "guide_id": "1e1172bdb310",
        "title": "Detect Scss With Confidence",
        "overview": "Workflow: Test SCSS detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "956a066a",
            "test_name": "test_detect_scss_with_confidence",
            "category": "workflow",
            "code": "'Test SCSS detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'scss')\nself.assertGreater(confidence, 0.8)",
            "language": "Python",
            "description": "Workflow: Test SCSS detection",
            "expected_behavior": "self.assertGreater(confidence, 0.8)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 122,
            "line_end": 148,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test SCSS detection'",
            "description": "'Test SCSS detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '",
            "description": "Assign code = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'scss')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.8)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Scss With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:122"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Dart With Confidence": [
      {
        "guide_id": "12afd0dc31a5",
        "title": "Detect Dart With Confidence",
        "overview": "Workflow: Test Dart detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bb83a4b1",
            "test_name": "test_detect_dart_with_confidence",
            "category": "workflow",
            "code": "'Test Dart detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'dart')\nself.assertGreater(confidence, 0.6)",
            "language": "Python",
            "description": "Workflow: Test Dart detection",
            "expected_behavior": "self.assertGreater(confidence, 0.6)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 150,
            "line_end": 172,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Dart detection'",
            "description": "'Test Dart detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"",
            "description": "Assign code = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'dart')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.6)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Dart With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:150"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Scala With Confidence": [
      {
        "guide_id": "9494e2522bde",
        "title": "Detect Scala With Confidence",
        "overview": "Workflow: Test Scala detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f88a839c",
            "test_name": "test_detect_scala_with_confidence",
            "category": "workflow",
            "code": "'Test Scala detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'scala')\nself.assertGreater(confidence, 0.7)",
            "language": "Python",
            "description": "Workflow: Test Scala detection",
            "expected_behavior": "self.assertGreater(confidence, 0.7)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 174,
            "line_end": 195,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Scala detection'",
            "description": "'Test Scala detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '",
            "description": "Assign code = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'scala')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.7)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Scala With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:174"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Sass With Confidence": [
      {
        "guide_id": "0148d4bd9b07",
        "title": "Detect Sass With Confidence",
        "overview": "Workflow: Test SASS detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "981c2491",
            "test_name": "test_detect_sass_with_confidence",
            "category": "workflow",
            "code": "'Test SASS detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'sass')\nself.assertGreater(confidence, 0.8)",
            "language": "Python",
            "description": "Workflow: Test SASS detection",
            "expected_behavior": "self.assertGreater(confidence, 0.8)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 197,
            "line_end": 220,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test SASS detection'",
            "description": "'Test SASS detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '",
            "description": "Assign code = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'sass')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.8)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Sass With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:197"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Elixir With Confidence": [
      {
        "guide_id": "5a9546a12556",
        "title": "Detect Elixir With Confidence",
        "overview": "Workflow: Test Elixir detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b0934b21",
            "test_name": "test_detect_elixir_with_confidence",
            "category": "workflow",
            "code": "'Test Elixir detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'elixir')\nself.assertGreater(confidence, 0.8)",
            "language": "Python",
            "description": "Workflow: Test Elixir detection",
            "expected_behavior": "self.assertGreater(confidence, 0.8)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 222,
            "line_end": 250,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Elixir detection'",
            "description": "'Test Elixir detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '",
            "description": "Assign code = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'elixir')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.8)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Elixir With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:222"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Lua With Confidence": [
      {
        "guide_id": "0e6e748e9dda",
        "title": "Detect Lua With Confidence",
        "overview": "Workflow: Test Lua detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "skill_seekers.cli.pdf_extractor_poc",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz",
          "unittest.mock",
          "fitz"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "cfaed997",
            "test_name": "test_detect_lua_with_confidence",
            "category": "workflow",
            "code": "'Test Lua detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'lua')\nself.assertGreater(confidence, 0.7)",
            "language": "Python",
            "description": "Workflow: Test Lua detection",
            "expected_behavior": "self.assertGreater(confidence, 0.7)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
            "line_start": 252,
            "line_end": 275,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "skill_seekers.cli.pdf_extractor_poc",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz",
              "unittest.mock",
              "fitz"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Lua detection'",
            "description": "'Test Lua detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
            "description": "Assign extractor.language_detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '",
            "description": "Assign code = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "language, confidence = extractor.detect_language_from_code(code)",
            "description": "Assign unknown = extractor.detect_language_from_code(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(language, 'lua')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(confidence, 0.7)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Lua With Confidence",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_extractor.py:252"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Router Generator Init": [
      {
        "guide_id": "ecebc0d6f331",
        "title": "Router Generator Init",
        "overview": "Workflow: Test router generator initialization.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "84956d78",
            "test_name": "test_router_generator_init",
            "category": "workflow",
            "code": "'Test router generator initialization.'\nconfig1 = {'name': 'test-oauth', 'description': 'OAuth authentication', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth']}}\nconfig2 = {'name': 'test-async', 'description': 'Async operations', 'base_url': 'https://example.com', 'categories': {'async': ['async', 'await']}}\nconfig_path1 = tmp_path / 'config1.json'\nconfig_path2 = tmp_path / 'config2.json'\nwith open(config_path1, 'w') as f:\n    json.dump(config1, f)\nwith open(config_path2, 'w') as f:\n    json.dump(config2, f)\ngenerator = RouterGenerator([str(config_path1), str(config_path2)])\nassert generator.router_name == 'test'\nassert len(generator.configs) == 2\nassert generator.github_streams is None",
            "language": "Python",
            "description": "Workflow: Test router generator initialization.",
            "expected_behavior": "assert generator.github_streams is None",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 20,
            "line_end": 49,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test router generator initialization.'",
            "description": "'Test router generator initialization.'",
            "expected_result": null,
            "verification": "assert generator.router_name == 'test'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config1 = {'name': 'test-oauth', 'description': 'OAuth authentication', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth']}}",
            "description": "Assign config1 = value",
            "expected_result": null,
            "verification": "assert len(generator.configs) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config2 = {'name': 'test-async', 'description': 'Async operations', 'base_url': 'https://example.com', 'categories': {'async': ['async', 'await']}}",
            "description": "Assign config2 = value",
            "expected_result": null,
            "verification": "assert generator.github_streams is None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config_path1 = tmp_path / 'config1.json'",
            "description": "Assign config_path1 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config_path2 = tmp_path / 'config2.json'",
            "description": "Assign config_path2 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "generator = RouterGenerator([str(config_path1), str(config_path2)])",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert generator.router_name == 'test'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "json.dump(config1, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "json.dump(config2, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Router Generator Init",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:20"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Infer Router Name": [
      {
        "guide_id": "e50d5b87da10",
        "title": "Infer Router Name",
        "overview": "Workflow: Test router name inference from sub-skill names.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f7ccecdf",
            "test_name": "test_infer_router_name",
            "category": "workflow",
            "code": "'Test router name inference from sub-skill names.'\nconfig1 = {'name': 'fastmcp-oauth', 'base_url': 'https://example.com'}\nconfig2 = {'name': 'fastmcp-async', 'base_url': 'https://example.com'}\nconfig_path1 = tmp_path / 'config1.json'\nconfig_path2 = tmp_path / 'config2.json'\nwith open(config_path1, 'w') as f:\n    json.dump(config1, f)\nwith open(config_path2, 'w') as f:\n    json.dump(config2, f)\ngenerator = RouterGenerator([str(config_path1), str(config_path2)])\nassert generator.router_name == 'fastmcp'",
            "language": "Python",
            "description": "Workflow: Test router name inference from sub-skill names.",
            "expected_behavior": "assert generator.router_name == 'fastmcp'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 51,
            "line_end": 66,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test router name inference from sub-skill names.'",
            "description": "'Test router name inference from sub-skill names.'",
            "expected_result": null,
            "verification": "assert generator.router_name == 'fastmcp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config1 = {'name': 'fastmcp-oauth', 'base_url': 'https://example.com'}",
            "description": "Assign config1 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config2 = {'name': 'fastmcp-async', 'base_url': 'https://example.com'}",
            "description": "Assign config2 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config_path1 = tmp_path / 'config1.json'",
            "description": "Assign config_path1 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config_path2 = tmp_path / 'config2.json'",
            "description": "Assign config_path2 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "generator = RouterGenerator([str(config_path1), str(config_path2)])",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert generator.router_name == 'fastmcp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "json.dump(config1, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "json.dump(config2, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Infer Router Name",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:51"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Routing Keywords Basic": [
      {
        "guide_id": "2d7e4e660265",
        "title": "Extract Routing Keywords Basic",
        "overview": "Workflow: Test basic keyword extraction without GitHub.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "997a58df",
            "test_name": "test_extract_routing_keywords_basic",
            "category": "workflow",
            "code": "'Test basic keyword extraction without GitHub.'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth'], 'tokens': ['token', 'jwt']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nrouting = generator.extract_routing_keywords()\nassert 'test-oauth' in routing\nkeywords = routing['test-oauth']\nassert 'authentication' in keywords\nassert 'tokens' in keywords\nassert 'oauth' in keywords",
            "language": "Python",
            "description": "Workflow: Test basic keyword extraction without GitHub.",
            "expected_behavior": "assert 'oauth' in keywords",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 68,
            "line_end": 87,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic keyword extraction without GitHub.'",
            "description": "'Test basic keyword extraction without GitHub.'",
            "expected_result": null,
            "verification": "assert 'test-oauth' in routing",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth'], 'tokens': ['token', 'jwt']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert 'authentication' in keywords",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert 'tokens' in keywords",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generator = RouterGenerator([str(config_path)])",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert 'oauth' in keywords",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "routing = generator.extract_routing_keywords()",
            "description": "Assign routing = generator.extract_routing_keywords(...)",
            "expected_result": null,
            "verification": "assert 'test-oauth' in routing",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "keywords = routing['test-oauth']",
            "description": "Assign keywords = value",
            "expected_result": null,
            "verification": "assert 'authentication' in keywords",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Routing Keywords Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:68"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Router With Github Metadata": [
      {
        "guide_id": "e0d85dde39fa",
        "title": "Router With Github Metadata",
        "overview": "Workflow: Test router generator with GitHub metadata.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "dc5ba794",
            "test_name": "test_router_with_github_metadata",
            "category": "workflow",
            "code": "'Test router generator with GitHub metadata.'\nconfig = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://github.com/test/repo', 'categories': {'oauth': ['oauth', 'auth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test Project\\n\\nA test OAuth library.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'OAuth helper'}, common_problems=[{'title': 'OAuth fails on redirect', 'number': 42, 'state': 'open', 'comments': 15, 'labels': ['bug', 'oauth']}], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 20}, {'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nassert generator.github_metadata is not None\nassert generator.github_metadata['stars'] == 1234\nassert generator.github_docs is not None\nassert generator.github_docs['readme'].startswith('# Test Project')\nassert generator.github_issues is not None",
            "language": "Python",
            "description": "Workflow: Test router generator with GitHub metadata.",
            "expected_behavior": "assert generator.github_issues is not None",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 93,
            "line_end": 139,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test router generator with GitHub metadata.'",
            "description": "'Test router generator with GitHub metadata.'",
            "expected_result": null,
            "verification": "assert generator.github_metadata is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://github.com/test/repo', 'categories': {'oauth': ['oauth', 'auth']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert generator.github_metadata['stars'] == 1234",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert generator.github_docs is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": "assert generator.github_docs['readme'].startswith('# Test Project')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme='# Test Project\\n\\nA test OAuth library.', contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": "assert generator.github_issues is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'OAuth helper'}, common_problems=[{'title': 'OAuth fails on redirect', 'number': 42, 'state': 'open', 'comments': 15, 'labels': ['bug', 'oauth']}], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 20}, {'label': 'bug', 'count': 10}])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert generator.github_metadata is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Router With Github Metadata",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:93"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Keywords With Github Labels": [
      {
        "guide_id": "f035e38c4bac",
        "title": "Extract Keywords With Github Labels",
        "overview": "Workflow: Test keyword extraction with GitHub issue labels (2x weight).",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "23b763ea",
            "test_name": "test_extract_keywords_with_github_labels",
            "category": "workflow",
            "code": "'Test keyword extraction with GitHub issue labels (2x weight).'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth', 'auth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 50}, {'label': 'authentication', 'count': 30}, {'label': 'bug', 'count': 20}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nrouting = generator.extract_routing_keywords()\nkeywords = routing['test-oauth']\noauth_count = keywords.count('oauth')\nassert oauth_count >= 4",
            "language": "Python",
            "description": "Workflow: Test keyword extraction with GitHub issue labels (2x weight).",
            "expected_behavior": "assert oauth_count >= 4",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 141,
            "line_end": 174,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test keyword extraction with GitHub issue labels (2x weight).'",
            "description": "'Test keyword extraction with GitHub issue labels (2x weight).'",
            "expected_result": null,
            "verification": "assert oauth_count >= 4",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth', 'auth']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme=None, contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={}, common_problems=[], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 50}, {'label': 'authentication', 'count': 30}, {'label': 'bug', 'count': 20}])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "routing = generator.extract_routing_keywords()",
            "description": "Assign routing = generator.extract_routing_keywords(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "keywords = routing['test-oauth']",
            "description": "Assign keywords = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "oauth_count = keywords.count('oauth')",
            "description": "Assign oauth_count = keywords.count(...)",
            "expected_result": null,
            "verification": "assert oauth_count >= 4",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Keywords With Github Labels",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_generate_router_github.py:141"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Skill Md With Github": [
      {
        "guide_id": "706f151e5034",
        "title": "Generate Skill Md With Github",
        "overview": "Workflow: Test SKILL.md generation with GitHub metadata.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "31845373",
            "test_name": "test_generate_skill_md_with_github",
            "category": "workflow",
            "code": "'Test SKILL.md generation with GitHub metadata.'\nconfig = {'name': 'test-oauth', 'description': 'OAuth authentication skill', 'base_url': 'https://github.com/test/oauth', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# OAuth Library\\n\\nQuick start: Install with pip install oauth', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 5000, 'forks': 200, 'language': 'Python', 'description': 'OAuth 2.0 library'}, common_problems=[{'title': 'Redirect URI mismatch', 'number': 100, 'state': 'open', 'comments': 25, 'labels': ['bug', 'oauth']}, {'title': 'Token refresh fails', 'number': 95, 'state': 'open', 'comments': 18, 'labels': ['oauth']}], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nskill_md = generator.generate_skill_md()\nassert '\u2b50 5,000' in skill_md\nassert 'Python' in skill_md\nassert 'OAuth 2.0 library' in skill_md\nassert '## Quick Start' in skill_md\nassert 'OAuth Library' in skill_md\nassert '## Common Issues' in skill_md or '## Examples' in skill_md\nassert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
            "language": "Python",
            "description": "Workflow: Test SKILL.md generation with GitHub metadata.",
            "expected_behavior": "assert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 176,
            "line_end": 241,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test SKILL.md generation with GitHub metadata.'",
            "description": "'Test SKILL.md generation with GitHub metadata.'",
            "expected_result": null,
            "verification": "assert '\u2b50 5,000' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-oauth', 'description': 'OAuth authentication skill', 'base_url': 'https://github.com/test/oauth', 'categories': {'oauth': ['oauth']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert 'Python' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert 'OAuth 2.0 library' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": "assert '## Quick Start' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme='# OAuth Library\\n\\nQuick start: Install with pip install oauth', contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": "assert 'OAuth Library' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={'stars': 5000, 'forks': 200, 'language': 'Python', 'description': 'OAuth 2.0 library'}, common_problems=[{'title': 'Redirect URI mismatch', 'number': 100, 'state': 'open', 'comments': 25, 'labels': ['bug', 'oauth']}, {'title': 'Token refresh fails', 'number': 95, 'state': 'open', 'comments': 18, 'labels': ['oauth']}], known_solutions=[], top_labels=[])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": "assert '## Common Issues' in skill_md or '## Examples' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": "assert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "skill_md = generator.generate_skill_md()",
            "description": "Assign skill_md = generator.generate_skill_md(...)",
            "expected_result": null,
            "verification": "assert '\u2b50 5,000' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Skill Md With Github",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:176"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Skill Md Without Github": [
      {
        "guide_id": "af430b496a48",
        "title": "Generate Skill Md Without Github",
        "overview": "Workflow: Test SKILL.md generation without GitHub (backward compat).",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2f9ec2e1",
            "test_name": "test_generate_skill_md_without_github",
            "category": "workflow",
            "code": "'Test SKILL.md generation without GitHub (backward compat).'\nconfig = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nskill_md = generator.generate_skill_md()\nassert '\u2b50' not in skill_md\nassert 'Repository Info' not in skill_md\nassert 'Quick Start (from README)' not in skill_md\nassert 'Common Issues (from GitHub)' not in skill_md\nassert 'When to Use This Skill' in skill_md\nassert 'How It Works' in skill_md",
            "language": "Python",
            "description": "Workflow: Test SKILL.md generation without GitHub (backward compat).",
            "expected_behavior": "assert 'How It Works' in skill_md",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 244,
            "line_end": 269,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test SKILL.md generation without GitHub (backward compat).'",
            "description": "'Test SKILL.md generation without GitHub (backward compat).'",
            "expected_result": null,
            "verification": "assert '\u2b50' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert 'Repository Info' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert 'Quick Start (from README)' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generator = RouterGenerator([str(config_path)])",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert 'Common Issues (from GitHub)' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_md = generator.generate_skill_md()",
            "description": "Assign skill_md = generator.generate_skill_md(...)",
            "expected_result": null,
            "verification": "assert 'When to Use This Skill' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": "assert 'How It Works' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Skill Md Without Github",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_generate_router_github.py:244"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Subskill Issues Section": [
      {
        "guide_id": "6a2dffb9ece1",
        "title": "Generate Subskill Issues Section",
        "overview": "Workflow: Test generation of issues section for sub-skills.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2b19ef0b",
            "test_name": "test_generate_subskill_issues_section",
            "category": "workflow",
            "code": "'Test generation of issues section for sub-skills.'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth redirect fails', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token expiration issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth']}], known_solutions=[{'title': 'Fixed OAuth flow', 'number': 40, 'state': 'closed', 'comments': 10, 'labels': ['oauth']}], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nissues_section = generator.generate_subskill_issues_section('test-oauth', ['oauth'])\nassert 'Common Issues (from GitHub)' in issues_section\nassert 'OAuth redirect fails' in issues_section\nassert 'Issue #50' in issues_section\nassert '20 comments' in issues_section\nassert '\ud83d\udd34' in issues_section\nassert '\u2705' in issues_section",
            "language": "Python",
            "description": "Workflow: Test generation of issues section for sub-skills.",
            "expected_behavior": "assert '\u2705' in issues_section",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 275,
            "line_end": 332,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test generation of issues section for sub-skills.'",
            "description": "'Test generation of issues section for sub-skills.'",
            "expected_result": null,
            "verification": "assert 'Common Issues (from GitHub)' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert 'OAuth redirect fails' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert 'Issue #50' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": "assert '20 comments' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme=None, contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": "assert '\ud83d\udd34' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth redirect fails', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token expiration issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth']}], known_solutions=[{'title': 'Fixed OAuth flow', 'number': 40, 'state': 'closed', 'comments': 10, 'labels': ['oauth']}], top_labels=[])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": "assert '\u2705' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "issues_section = generator.generate_subskill_issues_section('test-oauth', ['oauth'])",
            "description": "Assign issues_section = generator.generate_subskill_issues_section(...)",
            "expected_result": null,
            "verification": "assert 'Common Issues (from GitHub)' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Subskill Issues Section",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:275"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Subskill Issues No Matches": [
      {
        "guide_id": "ffe278705782",
        "title": "Generate Subskill Issues No Matches",
        "overview": "Workflow: Test issues section when no issues match the topic.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "11694666",
            "test_name": "test_generate_subskill_issues_no_matches",
            "category": "workflow",
            "code": "'Test issues section when no issues match the topic.'\nconfig = {'name': 'test-async', 'base_url': 'https://example.com', 'categories': {'async': ['async']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth fails', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['oauth']}], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nissues_section = generator.generate_subskill_issues_section('test-async', ['async'])\nassert 'Common Issues (from GitHub)' in issues_section\nassert 'Other' in issues_section\nassert 'OAuth fails' in issues_section",
            "language": "Python",
            "description": "Workflow: Test issues section when no issues match the topic.",
            "expected_behavior": "assert 'OAuth fails' in issues_section",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
            "line_start": 334,
            "line_end": 373,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test issues section when no issues match the topic.'",
            "description": "'Test issues section when no issues match the topic.'",
            "expected_result": null,
            "verification": "assert 'Common Issues (from GitHub)' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-async', 'base_url': 'https://example.com', 'categories': {'async': ['async']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert 'Other' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert 'OAuth fails' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme=None, contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth fails', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['oauth']}], known_solutions=[], top_labels=[])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "issues_section = generator.generate_subskill_issues_section('test-async', ['async'])",
            "description": "Assign issues_section = generator.generate_subskill_issues_section(...)",
            "expected_result": null,
            "verification": "assert 'Common Issues (from GitHub)' in issues_section",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Subskill Issues No Matches",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_generate_router_github.py:334"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Subdirectory Per Source": [
      {
        "guide_id": "66920b680749",
        "title": "Creates Subdirectory Per Source",
        "overview": "Workflow: Test that each doc source gets its own subdirectory.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5295fab3",
            "test_name": "test_creates_subdirectory_per_source",
            "category": "workflow",
            "code": "'Test that each doc source gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_docs_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'source_a', 'base_url': 'https://a.com', 'total_pages': 5, 'refs_dir': refs_dir1}, {'source_id': 'source_b', 'base_url': 'https://b.com', 'total_pages': 3, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\ndocs_dir = os.path.join(builder.skill_dir, 'references', 'documentation')\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_a')))\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
            "language": "Python",
            "description": "Workflow: Test that each doc source gets its own subdirectory.",
            "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 103,
            "line_end": 139,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that each doc source gets its own subdirectory.'",
            "description": "'Test that each doc source gets its own subdirectory.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "refs_dir1 = os.path.join(self.temp_dir, 'refs1')",
            "description": "Assign refs_dir1 = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "refs_dir2 = os.path.join(self.temp_dir, 'refs2')",
            "description": "Assign refs_dir2 = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "os.makedirs(refs_dir1)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "os.makedirs(refs_dir2)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "config = {'name': 'test_docs_refs', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "scraped_data = {'documentation': [{'source_id': 'source_a', 'base_url': 'https://a.com', 'total_pages': 5, 'refs_dir': refs_dir1}, {'source_id': 'source_b', 'base_url': 'https://b.com', 'total_pages': 3, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "builder._generate_docs_references(scraped_data['documentation'])",
            "description": "Call builder._generate_docs_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "docs_dir = os.path.join(builder.skill_dir, 'references', 'documentation')",
            "description": "Assign docs_dir = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_a')))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Subdirectory Per Source",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_multi_source.py:103"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Index Per Source": [
      {
        "guide_id": "55ad11cdceda",
        "title": "Creates Index Per Source",
        "overview": "Workflow: Test that each source subdirectory has its own index.md.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "457c3874",
            "test_name": "test_creates_index_per_source",
            "category": "workflow",
            "code": "'Test that each source subdirectory has its own index.md.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir = os.path.join(self.temp_dir, 'refs')\nos.makedirs(refs_dir)\nconfig = {'name': 'test_source_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'my_source', 'base_url': 'https://example.com', 'total_pages': 10, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nsource_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'my_source', 'index.md')\nself.assertTrue(os.path.exists(source_index))\nwith open(source_index) as f:\n    content = f.read()\n    self.assertIn('my_source', content)\n    self.assertIn('https://example.com', content)",
            "language": "Python",
            "description": "Workflow: Test that each source subdirectory has its own index.md.",
            "expected_behavior": "self.assertTrue(os.path.exists(source_index))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 141,
            "line_end": 174,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that each source subdirectory has its own index.md.'",
            "description": "'Test that each source subdirectory has its own index.md.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "refs_dir = os.path.join(self.temp_dir, 'refs')",
            "description": "Assign refs_dir = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "os.makedirs(refs_dir)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config = {'name': 'test_source_index', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "scraped_data = {'documentation': [{'source_id': 'my_source', 'base_url': 'https://example.com', 'total_pages': 10, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "builder._generate_docs_references(scraped_data['documentation'])",
            "description": "Call builder._generate_docs_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "source_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'my_source', 'index.md')",
            "description": "Assign source_index = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(os.path.exists(source_index))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('my_source', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('https://example.com', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Index Per Source",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_multi_source.py:141"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Main Index Listing All Sources": [
      {
        "guide_id": "9052d7085f07",
        "title": "Creates Main Index Listing All Sources",
        "overview": "Workflow: Test that main index.md lists all documentation sources.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "514fd982",
            "test_name": "test_creates_main_index_listing_all_sources",
            "category": "workflow",
            "code": "'Test that main index.md lists all documentation sources.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_main_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'docs_one', 'base_url': 'https://one.com', 'total_pages': 10, 'refs_dir': refs_dir1}, {'source_id': 'docs_two', 'base_url': 'https://two.com', 'total_pages': 20, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nmain_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'index.md')\nself.assertTrue(os.path.exists(main_index))\nwith open(main_index) as f:\n    content = f.read()\n    self.assertIn('docs_one', content)\n    self.assertIn('docs_two', content)\n    self.assertIn('2 documentation sources', content)",
            "language": "Python",
            "description": "Workflow: Test that main index.md lists all documentation sources.",
            "expected_behavior": "self.assertTrue(os.path.exists(main_index))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 176,
            "line_end": 216,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that main index.md lists all documentation sources.'",
            "description": "'Test that main index.md lists all documentation sources.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "refs_dir1 = os.path.join(self.temp_dir, 'refs1')",
            "description": "Assign refs_dir1 = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "refs_dir2 = os.path.join(self.temp_dir, 'refs2')",
            "description": "Assign refs_dir2 = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "os.makedirs(refs_dir1)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "os.makedirs(refs_dir2)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "config = {'name': 'test_main_index', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "scraped_data = {'documentation': [{'source_id': 'docs_one', 'base_url': 'https://one.com', 'total_pages': 10, 'refs_dir': refs_dir1}, {'source_id': 'docs_two', 'base_url': 'https://two.com', 'total_pages': 20, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "builder._generate_docs_references(scraped_data['documentation'])",
            "description": "Call builder._generate_docs_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "main_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'index.md')",
            "description": "Assign main_index = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue(os.path.exists(main_index))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertIn('docs_one', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "self.assertIn('docs_two', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "self.assertIn('2 documentation sources', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Main Index Listing All Sources",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_multi_source.py:176"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Copies Reference Files To Source Dir": [
      {
        "guide_id": "4fe17849c2f4",
        "title": "Copies Reference Files To Source Dir",
        "overview": "Workflow: Test that reference files are copied to source subdirectory.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "15a9374c",
            "test_name": "test_copies_reference_files_to_source_dir",
            "category": "workflow",
            "code": "'Test that reference files are copied to source subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir = os.path.join(self.temp_dir, 'refs')\nos.makedirs(refs_dir)\nwith open(os.path.join(refs_dir, 'api.md'), 'w') as f:\n    f.write('# API Reference')\nwith open(os.path.join(refs_dir, 'guide.md'), 'w') as f:\n    f.write('# User Guide')\nconfig = {'name': 'test_copy_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'test_source', 'base_url': 'https://test.com', 'total_pages': 5, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nsource_dir = os.path.join(builder.skill_dir, 'references', 'documentation', 'test_source')\nself.assertTrue(os.path.exists(os.path.join(source_dir, 'api.md')))\nself.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
            "language": "Python",
            "description": "Workflow: Test that reference files are copied to source subdirectory.",
            "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 218,
            "line_end": 251,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that reference files are copied to source subdirectory.'",
            "description": "'Test that reference files are copied to source subdirectory.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "refs_dir = os.path.join(self.temp_dir, 'refs')",
            "description": "Assign refs_dir = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "os.makedirs(refs_dir)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config = {'name': 'test_copy_refs', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "scraped_data = {'documentation': [{'source_id': 'test_source', 'base_url': 'https://test.com', 'total_pages': 5, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "builder._generate_docs_references(scraped_data['documentation'])",
            "description": "Call builder._generate_docs_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "source_dir = os.path.join(builder.skill_dir, 'references', 'documentation', 'test_source')",
            "description": "Assign source_dir = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'api.md')))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "f.write('# API Reference')",
            "description": "Call f.write()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "f.write('# User Guide')",
            "description": "Call f.write()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Copies Reference Files To Source Dir",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_multi_source.py:218"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Subdirectory Per Repo": [
      {
        "guide_id": "b086b95a74ac",
        "title": "Creates Subdirectory Per Repo",
        "overview": "Workflow: Test that each GitHub repo gets its own subdirectory.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5f9cac6a",
            "test_name": "test_creates_subdirectory_per_repo",
            "category": "workflow",
            "code": "'Test that each GitHub repo gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_github_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'org/repo1', 'repo_id': 'org_repo1', 'data': {'readme': '# Repo 1', 'issues': [], 'releases': [], 'repo_info': {}}}, {'repo': 'org/repo2', 'repo_id': 'org_repo2', 'data': {'readme': '# Repo 2', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\ngithub_dir = os.path.join(builder.skill_dir, 'references', 'github')\nself.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo1')))\nself.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
            "language": "Python",
            "description": "Workflow: Test that each GitHub repo gets its own subdirectory.",
            "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 269,
            "line_end": 297,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that each GitHub repo gets its own subdirectory.'",
            "description": "'Test that each GitHub repo gets its own subdirectory.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_github_refs', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'org/repo1', 'repo_id': 'org_repo1', 'data': {'readme': '# Repo 1', 'issues': [], 'releases': [], 'repo_info': {}}}, {'repo': 'org/repo2', 'repo_id': 'org_repo2', 'data': {'readme': '# Repo 2', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder._generate_github_references(scraped_data['github'])",
            "description": "Call builder._generate_github_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "github_dir = os.path.join(builder.skill_dir, 'references', 'github')",
            "description": "Assign github_dir = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo1')))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Subdirectory Per Repo",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_multi_source.py:269"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Readme Per Repo": [
      {
        "guide_id": "abd1ee27b606",
        "title": "Creates Readme Per Repo",
        "overview": "Workflow: Test that README.md is created for each repo.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "80ec31f0",
            "test_name": "test_creates_readme_per_repo",
            "category": "workflow",
            "code": "'Test that README.md is created for each repo.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_readme', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'test/myrepo', 'repo_id': 'test_myrepo', 'data': {'readme': '# My Repository\\n\\nDescription here.', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nreadme_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_myrepo', 'README.md')\nself.assertTrue(os.path.exists(readme_path))\nwith open(readme_path) as f:\n    content = f.read()\n    self.assertIn('test/myrepo', content)",
            "language": "Python",
            "description": "Workflow: Test that README.md is created for each repo.",
            "expected_behavior": "self.assertTrue(os.path.exists(readme_path))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 299,
            "line_end": 332,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that README.md is created for each repo.'",
            "description": "'Test that README.md is created for each repo.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_readme', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'test/myrepo', 'repo_id': 'test_myrepo', 'data': {'readme': '# My Repository\\n\\nDescription here.', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder._generate_github_references(scraped_data['github'])",
            "description": "Call builder._generate_github_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "readme_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_myrepo', 'README.md')",
            "description": "Assign readme_path = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(os.path.exists(readme_path))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('test/myrepo', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Readme Per Repo",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_multi_source.py:299"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Issues File When Issues Exist": [
      {
        "guide_id": "4edc4bb41b7d",
        "title": "Creates Issues File When Issues Exist",
        "overview": "Workflow: Test that issues.md is created when repo has issues.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "665633ca",
            "test_name": "test_creates_issues_file_when_issues_exist",
            "category": "workflow",
            "code": "'Test that issues.md is created when repo has issues.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_issues', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'data': {'readme': '# Repo', 'issues': [{'number': 1, 'title': 'Bug report', 'state': 'open', 'labels': ['bug'], 'url': 'https://github.com/test/repo/issues/1'}, {'number': 2, 'title': 'Feature request', 'state': 'closed', 'labels': ['enhancement'], 'url': 'https://github.com/test/repo/issues/2'}], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nissues_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_repo', 'issues.md')\nself.assertTrue(os.path.exists(issues_path))\nwith open(issues_path) as f:\n    content = f.read()\n    self.assertIn('Bug report', content)\n    self.assertIn('Feature request', content)",
            "language": "Python",
            "description": "Workflow: Test that issues.md is created when repo has issues.",
            "expected_behavior": "self.assertTrue(os.path.exists(issues_path))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 334,
            "line_end": 383,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that issues.md is created when repo has issues.'",
            "description": "'Test that issues.md is created when repo has issues.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_issues', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'data': {'readme': '# Repo', 'issues': [{'number': 1, 'title': 'Bug report', 'state': 'open', 'labels': ['bug'], 'url': 'https://github.com/test/repo/issues/1'}, {'number': 2, 'title': 'Feature request', 'state': 'closed', 'labels': ['enhancement'], 'url': 'https://github.com/test/repo/issues/2'}], 'releases': [], 'repo_info': {}}}], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder._generate_github_references(scraped_data['github'])",
            "description": "Call builder._generate_github_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "issues_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_repo', 'issues.md')",
            "description": "Assign issues_path = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(os.path.exists(issues_path))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('Bug report', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('Feature request', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Issues File When Issues Exist",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_multi_source.py:334"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Main Index Listing All Repos": [
      {
        "guide_id": "e14e4e206a91",
        "title": "Creates Main Index Listing All Repos",
        "overview": "Workflow: Test that main index.md lists all GitHub repositories.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "262c48dd",
            "test_name": "test_creates_main_index_listing_all_repos",
            "category": "workflow",
            "code": "'Test that main index.md lists all GitHub repositories.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_github_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'org/first', 'repo_id': 'org_first', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 100}}}, {'repo': 'org/second', 'repo_id': 'org_second', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 50}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nmain_index = os.path.join(builder.skill_dir, 'references', 'github', 'index.md')\nself.assertTrue(os.path.exists(main_index))\nwith open(main_index) as f:\n    content = f.read()\n    self.assertIn('org/first', content)\n    self.assertIn('org/second', content)\n    self.assertIn('2 GitHub repositories', content)",
            "language": "Python",
            "description": "Workflow: Test that main index.md lists all GitHub repositories.",
            "expected_behavior": "self.assertTrue(os.path.exists(main_index))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 385,
            "line_end": 428,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that main index.md lists all GitHub repositories.'",
            "description": "'Test that main index.md lists all GitHub repositories.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_github_index', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'org/first', 'repo_id': 'org_first', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 100}}}, {'repo': 'org/second', 'repo_id': 'org_second', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 50}}}], 'pdf': []}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder._generate_github_references(scraped_data['github'])",
            "description": "Call builder._generate_github_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "main_index = os.path.join(builder.skill_dir, 'references', 'github', 'index.md')",
            "description": "Assign main_index = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(os.path.exists(main_index))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('org/first', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('org/second', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('2 GitHub repositories', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Main Index Listing All Repos",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_multi_source.py:385"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Creates Pdf Index With Count": [
      {
        "guide_id": "d1636799cf57",
        "title": "Creates Pdf Index With Count",
        "overview": "Workflow: Test that PDF index shows correct document count.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "tempfile",
          "unittest",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "faf6c58e",
            "test_name": "test_creates_pdf_index_with_count",
            "category": "workflow",
            "code": "'Test that PDF index shows correct document count.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_pdf', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [], 'pdf': [{'path': '/path/to/doc1.pdf'}, {'path': '/path/to/doc2.pdf'}, {'path': '/path/to/doc3.pdf'}]}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_pdf_references(scraped_data['pdf'])\npdf_index = os.path.join(builder.skill_dir, 'references', 'pdf', 'index.md')\nself.assertTrue(os.path.exists(pdf_index))\nwith open(pdf_index) as f:\n    content = f.read()\n    self.assertIn('3 PDF document', content)",
            "language": "Python",
            "description": "Workflow: Test that PDF index shows correct document count.",
            "expected_behavior": "self.assertTrue(os.path.exists(pdf_index))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
            "line_start": 446,
            "line_end": 470,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "tempfile",
              "unittest",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that PDF index shows correct document count.'",
            "description": "'Test that PDF index shows correct document count.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_pdf', 'description': 'Test', 'sources': []}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'documentation': [], 'github': [], 'pdf': [{'path': '/path/to/doc1.pdf'}, {'path': '/path/to/doc2.pdf'}, {'path': '/path/to/doc3.pdf'}]}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder._generate_pdf_references(scraped_data['pdf'])",
            "description": "Call builder._generate_pdf_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "pdf_index = os.path.join(builder.skill_dir, 'references', 'pdf', 'index.md')",
            "description": "Assign pdf_index = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(os.path.exists(pdf_index))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('3 PDF document', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Creates Pdf Index With Count",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_multi_source.py:446"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Bootstrap Script Runs": [
      {
        "guide_id": "8fa83cb98c73",
        "title": "Bootstrap Script Runs",
        "overview": "Workflow: Test that bootstrap script runs successfully.\n\nNote: This test is slow as it runs full codebase analysis.\nRun with: pytest -m slow",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "subprocess",
          "pathlib",
          "pytest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7e0f2c67",
            "test_name": "test_bootstrap_script_runs",
            "category": "workflow",
            "code": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '\nscript = project_root / 'scripts' / 'bootstrap_skill.sh'\nresult = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=600)\nassert result.returncode == 0, f'Script failed: {result.stderr}'\noutput_dir = project_root / 'output' / 'skill-seekers'\nassert output_dir.exists(), 'Output directory should be created'\nskill_md = output_dir / 'SKILL.md'\nassert skill_md.exists(), 'SKILL.md should be created'\ncontent = skill_md.read_text()\nassert '## Prerequisites' in content, 'SKILL.md should have header prepended'\nassert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
            "language": "Python",
            "description": "Workflow: Test that bootstrap script runs successfully.\n\nNote: This test is slow as it runs full codebase analysis.\nRun with: pytest -m slow",
            "expected_behavior": "assert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill.py",
            "line_start": 54,
            "line_end": 84,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: project_root",
            "tags": [
              "pytest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "subprocess",
              "pathlib",
              "pytest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '",
            "description": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '",
            "expected_result": null,
            "verification": "assert result.returncode == 0, f'Script failed: {result.stderr}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "script = project_root / 'scripts' / 'bootstrap_skill.sh'",
            "description": "Assign script = value",
            "expected_result": null,
            "verification": "assert output_dir.exists(), 'Output directory should be created'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=600)",
            "description": "Assign result = subprocess.run(...)",
            "expected_result": null,
            "verification": "assert skill_md.exists(), 'SKILL.md should be created'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_dir = project_root / 'output' / 'skill-seekers'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": "assert '## Prerequisites' in content, 'SKILL.md should have header prepended'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_md = output_dir / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": "assert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "content = skill_md.read_text()",
            "description": "Assign content = skill_md.read_text(...)",
            "expected_result": null,
            "verification": "assert '## Prerequisites' in content, 'SKILL.md should have header prepended'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Bootstrap Script Runs",
        "tags": [
          "pytest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_bootstrap_skill.py:54"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Deduplicate Urls": [
      {
        "guide_id": "cd14c83d134e",
        "title": "Deduplicate Urls",
        "overview": "Workflow: Test that duplicate URLs are removed.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "unittest",
          "skill_seekers.cli.doc_scraper",
          "skill_seekers.cli.doc_scraper",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.llms_txt_parser",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c75ec58f",
            "test_name": "test_deduplicate_urls",
            "category": "workflow",
            "code": "'Test that duplicate URLs are removed.'\nfrom skill_seekers.cli.llms_txt_parser import LlmsTxtParser\ncontent = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'\nparser = LlmsTxtParser(content)\nurls = parser.extract_urls()\ncount = sum((1 for u in urls if u == 'https://example.com/doc.md'))\nself.assertEqual(count, 1)",
            "language": "Python",
            "description": "Workflow: Test that duplicate URLs are removed.",
            "expected_behavior": "self.assertEqual(count, 1)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
            "line_start": 273,
            "line_end": 287,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "unittest",
              "skill_seekers.cli.doc_scraper",
              "skill_seekers.cli.doc_scraper",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.llms_txt_parser",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that duplicate URLs are removed.'",
            "description": "'Test that duplicate URLs are removed.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "content = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'",
            "description": "Assign content = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "parser = LlmsTxtParser(content)",
            "description": "Assign parser = LlmsTxtParser(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "urls = parser.extract_urls()",
            "description": "Assign urls = parser.extract_urls(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "count = sum((1 for u in urls if u == 'https://example.com/doc.md'))",
            "description": "Assign count = sum(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(count, 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Deduplicate Urls",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_markdown_parsing.py:273"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cache Set And Get": [
      {
        "guide_id": "b73f4313da2b",
        "title": "Cache Set And Get",
        "overview": "Workflow: Test setting and getting cached values",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "io",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "unittest.mock",
          "fitz",
          "pytesseract",
          "PIL",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "os",
          "pdf_extractor_poc"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0d478cf7",
            "test_name": "test_cache_set_and_get",
            "category": "workflow",
            "code": "'Test setting and getting cached values'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ntest_data = {'page': 1, 'text': 'cached content'}\nextractor.set_cached('page_1', test_data)\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached, test_data)",
            "language": "Python",
            "description": "Workflow: Test setting and getting cached values",
            "expected_behavior": "self.assertEqual(cached, test_data)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
            "line_start": 339,
            "line_end": 352,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "io",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "unittest.mock",
              "fitz",
              "pytesseract",
              "PIL",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "os",
              "pdf_extractor_poc"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test setting and getting cached values'",
            "description": "'Test setting and getting cached values'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor._cache = {}",
            "description": "Assign extractor._cache = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "extractor.use_cache = True",
            "description": "Assign extractor.use_cache = True",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "test_data = {'page': 1, 'text': 'cached content'}",
            "description": "Assign test_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "extractor.set_cached('page_1', test_data)",
            "description": "Call extractor.set_cached()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "cached = extractor.get_cached('page_1')",
            "description": "Assign cached = extractor.get_cached(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(cached, test_data)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cache Set And Get",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_advanced_features.py:339"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cache Miss": [
      {
        "guide_id": "c17c0a1e0de9",
        "title": "Cache Miss",
        "overview": "Workflow: Test cache miss returns None",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "io",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "unittest.mock",
          "fitz",
          "pytesseract",
          "PIL",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "os",
          "pdf_extractor_poc"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "79af8725",
            "test_name": "test_cache_miss",
            "category": "workflow",
            "code": "'Test cache miss returns None'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ncached = extractor.get_cached('nonexistent_key')\nself.assertIsNone(cached)",
            "language": "Python",
            "description": "Workflow: Test cache miss returns None",
            "expected_behavior": "self.assertIsNone(cached)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
            "line_start": 354,
            "line_end": 362,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "io",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "unittest.mock",
              "fitz",
              "pytesseract",
              "PIL",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "os",
              "pdf_extractor_poc"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test cache miss returns None'",
            "description": "'Test cache miss returns None'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor._cache = {}",
            "description": "Assign extractor._cache = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "extractor.use_cache = True",
            "description": "Assign extractor.use_cache = True",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "cached = extractor.get_cached('nonexistent_key')",
            "description": "Assign cached = extractor.get_cached(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIsNone(cached)",
            "description": "Call self.assertIsNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cache Miss",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_pdf_advanced_features.py:354"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cache Disabled": [
      {
        "guide_id": "30cae67ea4d2",
        "title": "Cache Disabled",
        "overview": "Workflow: Test caching can be disabled",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "io",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "unittest.mock",
          "fitz",
          "pytesseract",
          "PIL",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "os",
          "pdf_extractor_poc"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4908a829",
            "test_name": "test_cache_disabled",
            "category": "workflow",
            "code": "'Test caching can be disabled'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = False\nextractor.set_cached('page_1', {'data': 'test'})\nself.assertEqual(len(extractor._cache), 0)\ncached = extractor.get_cached('page_1')\nself.assertIsNone(cached)",
            "language": "Python",
            "description": "Workflow: Test caching can be disabled",
            "expected_behavior": "self.assertIsNone(cached)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
            "line_start": 364,
            "line_end": 378,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "io",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "unittest.mock",
              "fitz",
              "pytesseract",
              "PIL",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "os",
              "pdf_extractor_poc"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test caching can be disabled'",
            "description": "'Test caching can be disabled'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor._cache = {}",
            "description": "Assign extractor._cache = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "extractor.use_cache = False",
            "description": "Assign extractor.use_cache = False",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "extractor.set_cached('page_1', {'data': 'test'})",
            "description": "Call extractor.set_cached()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(len(extractor._cache), 0)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "cached = extractor.get_cached('page_1')",
            "description": "Assign cached = extractor.get_cached(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIsNone(cached)",
            "description": "Call self.assertIsNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cache Disabled",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_advanced_features.py:364"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cache Overwrite": [
      {
        "guide_id": "a3781a3b27ca",
        "title": "Cache Overwrite",
        "overview": "Workflow: Test cache can be overwritten",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "io",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "unittest.mock",
          "fitz",
          "pytesseract",
          "PIL",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "pdf_extractor_poc",
          "os",
          "pdf_extractor_poc"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "33222edf",
            "test_name": "test_cache_overwrite",
            "category": "workflow",
            "code": "'Test cache can be overwritten'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\nextractor.set_cached('page_1', {'version': 1})\nextractor.set_cached('page_1', {'version': 2})\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached['version'], 2)",
            "language": "Python",
            "description": "Workflow: Test cache can be overwritten",
            "expected_behavior": "self.assertEqual(cached['version'], 2)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
            "line_start": 380,
            "line_end": 395,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "io",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "unittest.mock",
              "fitz",
              "pytesseract",
              "PIL",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "pdf_extractor_poc",
              "os",
              "pdf_extractor_poc"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test cache can be overwritten'",
            "description": "'Test cache can be overwritten'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
            "description": "Assign extractor = self.PDFExtractor.__new__(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "extractor._cache = {}",
            "description": "Assign extractor._cache = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "extractor.use_cache = True",
            "description": "Assign extractor.use_cache = True",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "extractor.set_cached('page_1', {'version': 1})",
            "description": "Call extractor.set_cached()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "extractor.set_cached('page_1', {'version': 2})",
            "description": "Call extractor.set_cached()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "cached = extractor.get_cached('page_1')",
            "description": "Assign cached = extractor.get_cached(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(cached['version'], 2)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cache Overwrite",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_advanced_features.py:380"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "No Config No Logging": [
      {
        "guide_id": "85e020d575ca",
        "title": "No Config No Logging",
        "overview": "Workflow: Test that default mode doesn't log exclude_dirs messages.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "unittest",
          "unittest.mock",
          "skill_seekers.cli.github_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "addec59a",
            "test_name": "test_no_config_no_logging",
            "category": "workflow",
            "code": "\"Test that default mode doesn't log exclude_dirs messages.\"\nconfig = {'repo': 'owner/repo'}\n_scraper = GitHubScraper(config)\ninfo_calls = [str(call) for call in mock_logger.info.call_args_list]\nwarning_calls = [str(call) for call in mock_logger.warning.call_args_list]\nexclude_info = [c for c in info_calls if 'directory exclusion' in c]\nexclude_warnings = [c for c in warning_calls if 'directory exclusion' in c]\nself.assertEqual(len(exclude_info), 0)\nself.assertEqual(len(exclude_warnings), 0)",
            "language": "Python",
            "description": "Workflow: Test that default mode doesn't log exclude_dirs messages.",
            "expected_behavior": "self.assertEqual(len(exclude_warnings), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
            "line_start": 299,
            "line_end": 314,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_logger, _mock_github",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "unittest",
              "unittest.mock",
              "skill_seekers.cli.github_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test that default mode doesn't log exclude_dirs messages.\"",
            "description": "\"Test that default mode doesn't log exclude_dirs messages.\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'repo': 'owner/repo'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "_scraper = GitHubScraper(config)",
            "description": "Assign _scraper = GitHubScraper(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "info_calls = [str(call) for call in mock_logger.info.call_args_list]",
            "description": "Assign info_calls = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "warning_calls = [str(call) for call in mock_logger.warning.call_args_list]",
            "description": "Assign warning_calls = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "exclude_info = [c for c in info_calls if 'directory exclusion' in c]",
            "description": "Assign exclude_info = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "exclude_warnings = [c for c in warning_calls if 'directory exclusion' in c]",
            "description": "Assign exclude_warnings = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(len(exclude_info), 0)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertEqual(len(exclude_warnings), 0)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "No Config No Logging",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_excluded_dirs_config.py:299"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Full Metadata": [
      {
        "guide_id": "53f2f5730d1f",
        "title": "Full Metadata",
        "overview": "Workflow: Test metadata with all fields",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "unittest",
          "skill_seekers.cli.adaptors"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2110f28e",
            "test_name": "test_full_metadata",
            "category": "workflow",
            "code": "'Test metadata with all fields'\nmetadata = SkillMetadata(name='react', description='React documentation', version='2.5.0', author='Test Author', tags=['react', 'javascript', 'web'])\nself.assertEqual(metadata.name, 'react')\nself.assertEqual(metadata.description, 'React documentation')\nself.assertEqual(metadata.version, '2.5.0')\nself.assertEqual(metadata.author, 'Test Author')\nself.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
            "language": "Python",
            "description": "Workflow: Test metadata with all fields",
            "expected_behavior": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
            "line_start": 30,
            "line_end": 44,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "unittest",
              "skill_seekers.cli.adaptors"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test metadata with all fields'",
            "description": "'Test metadata with all fields'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "metadata = SkillMetadata(name='react', description='React documentation', version='2.5.0', author='Test Author', tags=['react', 'javascript', 'web'])",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "self.assertEqual(metadata.name, 'react')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(metadata.description, 'React documentation')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(metadata.version, '2.5.0')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(metadata.author, 'Test Author')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Full Metadata",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_base.py:30"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect From Html Swift Class": [
      {
        "guide_id": "841726a5e139",
        "title": "Detect From Html Swift Class",
        "overview": "Workflow: Test HTML element with Swift CSS class",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "75ea9c0c",
            "test_name": "test_detect_from_html_swift_class",
            "category": "workflow",
            "code": "'Test HTML element with Swift CSS class'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-swift\">let x = 5</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'let x = 5')\nassert lang == 'swift'\nassert confidence == 1.0",
            "language": "Python",
            "description": "Workflow: Test HTML element with Swift CSS class",
            "expected_behavior": "assert confidence == 1.0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 44,
            "line_end": 53,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test HTML element with Swift CSS class'",
            "description": "'Test HTML element with Swift CSS class'",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence == 1.0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "html = '<code class=\"language-swift\">let x = 5</code>'",
            "description": "Assign html = '<code class=\"language-swift\">let x = 5</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "soup = BeautifulSoup(html, 'html.parser')",
            "description": "Assign soup = BeautifulSoup(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "elem = soup.find('code')",
            "description": "Assign elem = soup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "lang, confidence = detector.detect_from_html(elem, 'let x = 5')",
            "description": "Assign unknown = detector.detect_from_html(...)",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect From Html Swift Class",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:44"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Viewcontroller Lifecycle": [
      {
        "guide_id": "7a25e90d4eba",
        "title": "Viewcontroller Lifecycle",
        "overview": "Workflow: Test UIViewController lifecycle methods",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "601881a3",
            "test_name": "test_viewcontroller_lifecycle",
            "category": "workflow",
            "code": "'Test UIViewController lifecycle methods'\ndetector = LanguageDetector()\ncode = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.9",
            "language": "Python",
            "description": "Workflow: Test UIViewController lifecycle methods",
            "expected_behavior": "assert confidence >= 0.9",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 342,
            "line_end": 365,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test UIViewController lifecycle methods'",
            "description": "'Test UIViewController lifecycle methods'",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.9",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '",
            "description": "Assign code = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Viewcontroller Lifecycle",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:342"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Nsviewcontroller Lifecycle": [
      {
        "guide_id": "e4ea7daca24a",
        "title": "Nsviewcontroller Lifecycle",
        "overview": "Workflow: Test NSViewController lifecycle methods",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5942a2f1",
            "test_name": "test_nsviewcontroller_lifecycle",
            "category": "workflow",
            "code": "'Test NSViewController lifecycle methods'\ndetector = LanguageDetector()\ncode = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.9",
            "language": "Python",
            "description": "Workflow: Test NSViewController lifecycle methods",
            "expected_behavior": "assert confidence >= 0.9",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 468,
            "line_end": 491,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test NSViewController lifecycle methods'",
            "description": "'Test NSViewController lifecycle methods'",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.9",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '",
            "description": "Assign code = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Nsviewcontroller Lifecycle",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:468"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "High Confidence Full App": [
      {
        "guide_id": "5d91d6addac9",
        "title": "High Confidence Full App",
        "overview": "Workflow: Test complete SwiftUI app (high confidence expected)",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "16e54dc7",
            "test_name": "test_high_confidence_full_app",
            "category": "workflow",
            "code": "'Test complete SwiftUI app (high confidence expected)'\ndetector = LanguageDetector()\ncode = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.95",
            "language": "Python",
            "description": "Workflow: Test complete SwiftUI app (high confidence expected)",
            "expected_behavior": "assert confidence >= 0.95",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 960,
            "line_end": 1002,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete SwiftUI app (high confidence expected)'",
            "description": "'Test complete SwiftUI app (high confidence expected)'",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.95",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '",
            "description": "Assign code = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'swift'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "High Confidence Full App",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:960"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Swift Vs Similar Languages": [
      {
        "guide_id": "50a88b1d5eb3",
        "title": "Swift Vs Similar Languages",
        "overview": "Workflow: Test Swift doesn't false-positive for similar syntax in other languages.\n\nCritical for avoiding misclassification of:\n- Go: 'func', ':=' short declaration\n- Rust: 'fn', 'let mut', struct\n- TypeScript: 'let', 'const', type annotations with ':'\n\nThese languages share keywords or syntax patterns with Swift,\nso detection must use unique Swift patterns (guard let, @State, etc.)",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "89e4c403",
            "test_name": "test_swift_vs_similar_languages",
            "category": "workflow",
            "code": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"\ndetector = LanguageDetector()\ngo_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '\nlang, _ = detector.detect_from_code(go_code)\nassert lang == 'go', f\"Expected 'go', got '{lang}'\"\nrust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '\nlang, _ = detector.detect_from_code(rust_code)\nassert lang == 'rust', f\"Expected 'rust', got '{lang}'\"\nts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"\nlang, _ = detector.detect_from_code(ts_code)\nassert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
            "language": "Python",
            "description": "Workflow: Test Swift doesn't false-positive for similar syntax in other languages.\n\nCritical for avoiding misclassification of:\n- Go: 'func', ':=' short declaration\n- Rust: 'fn', 'let mut', struct\n- TypeScript: 'let', 'const', type annotations with ':'\n\nThese languages share keywords or syntax patterns with Swift,\nso detection must use unique Swift patterns (guard let, @State, etc.)",
            "expected_behavior": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 1004,
            "line_end": 1054,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"",
            "description": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"",
            "expected_result": null,
            "verification": "assert lang == 'go', f\"Expected 'go', got '{lang}'\"",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert lang == 'rust', f\"Expected 'rust', got '{lang}'\"",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "go_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '",
            "description": "Assign go_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '",
            "expected_result": null,
            "verification": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, _ = detector.detect_from_code(go_code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'go', f\"Expected 'go', got '{lang}'\"",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "rust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '",
            "description": "Assign rust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "lang, _ = detector.detect_from_code(rust_code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'rust', f\"Expected 'rust', got '{lang}'\"",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "ts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"",
            "description": "Assign ts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "lang, _ = detector.detect_from_code(ts_code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Swift Vs Similar Languages",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_swift_detection.py:1004"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Malformed Regex Patterns Are Skipped": [
      {
        "guide_id": "2d632e98ebbf",
        "title": "Malformed Regex Patterns Are Skipped",
        "overview": "Workflow: Test that invalid regex patterns are logged and skipped without crashing",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7b4ca31c",
            "test_name": "test_malformed_regex_patterns_are_skipped",
            "category": "workflow",
            "code": "'Test that invalid regex patterns are logged and skipped without crashing'\nfrom unittest.mock import patch\nfrom skill_seekers.cli.language_detector import LanguageDetector\nwith patch('skill_seekers.cli.language_detector.logger') as mock_logger:\n    import skill_seekers.cli.language_detector as ld_module\n    original_patterns = ld_module.LANGUAGE_PATTERNS.copy()\n    try:\n        ld_module.LANGUAGE_PATTERNS['test_malformed'] = [('(?P<invalid)', 5), ('valid_pattern', 3)]\n        _detector = LanguageDetector()\n        assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'\n    finally:\n        ld_module.LANGUAGE_PATTERNS = original_patterns",
            "language": "Python",
            "description": "Workflow: Test that invalid regex patterns are logged and skipped without crashing",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 1289,
            "line_end": 1321,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that invalid regex patterns are logged and skipped without crashing'",
            "description": "'Test that invalid regex patterns are logged and skipped without crashing'",
            "expected_result": null,
            "verification": "assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "original_patterns = ld_module.LANGUAGE_PATTERNS.copy()",
            "description": "Assign original_patterns = ld_module.LANGUAGE_PATTERNS.copy(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "ld_module.LANGUAGE_PATTERNS['test_malformed'] = [('(?P<invalid)', 5), ('valid_pattern', 3)]",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "_detector = LanguageDetector()",
            "description": "Assign _detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "ld_module.LANGUAGE_PATTERNS = original_patterns",
            "description": "Assign ld_module.LANGUAGE_PATTERNS = original_patterns",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Malformed Regex Patterns Are Skipped",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:1289"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Empty Swift Patterns Handled Gracefully": [
      {
        "guide_id": "6e47d258aa05",
        "title": "Empty Swift Patterns Handled Gracefully",
        "overview": "Workflow: Test that empty SWIFT_PATTERNS dict doesn't crash detection",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "45643623",
            "test_name": "test_empty_swift_patterns_handled_gracefully",
            "category": "workflow",
            "code": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"\nimport sys\nfrom unittest.mock import patch\nfor mod in list(sys.modules.keys()):\n    if 'skill_seekers.cli' in mod:\n        del sys.modules[mod]\nwith patch.dict('sys.modules', {'skill_seekers.cli.swift_patterns': type('MockModule', (), {'SWIFT_PATTERNS': {}})}):\n    from skill_seekers.cli.language_detector import LanguageDetector\n    detector = LanguageDetector()\n    code = 'import SwiftUI\\nstruct MyView: View { }'\n    lang, confidence = detector.detect_from_code(code)\n    assert isinstance(lang, str)\n    assert isinstance(confidence, (int, float))",
            "language": "Python",
            "description": "Workflow: Test that empty SWIFT_PATTERNS dict doesn't crash detection",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 1323,
            "line_end": 1349,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"",
            "description": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"",
            "expected_result": null,
            "verification": "assert isinstance(lang, str)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert isinstance(confidence, (int, float))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = 'import SwiftUI\\nstruct MyView: View { }'",
            "description": "Assign code = 'import SwiftUI\\nstruct MyView: View { }'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert isinstance(lang, str)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Empty Swift Patterns Handled Gracefully",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:1323"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Non String Pattern Handled During Compilation": [
      {
        "guide_id": "6100791e20a9",
        "title": "Non String Pattern Handled During Compilation",
        "overview": "Workflow: Test that non-string patterns are caught during compilation",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "skill_seekers.cli.swift_patterns",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "sys",
          "unittest.mock",
          "unittest.mock",
          "skill_seekers.cli.language_detector",
          "inspect",
          "skill_seekers.cli",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "298d3cb7",
            "test_name": "test_non_string_pattern_handled_during_compilation",
            "category": "workflow",
            "code": "'Test that non-string patterns are caught during compilation'\nfrom unittest.mock import patch\nfrom skill_seekers.cli.language_detector import LanguageDetector\nwith patch('skill_seekers.cli.language_detector.logger') as mock_logger:\n    import skill_seekers.cli.language_detector as ld_module\n    original = ld_module.LANGUAGE_PATTERNS.copy()\n    try:\n        ld_module.LANGUAGE_PATTERNS['test_nonstring'] = [(None, 5)]\n        _detector = LanguageDetector()\n        assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'\n    finally:\n        ld_module.LANGUAGE_PATTERNS = original",
            "language": "Python",
            "description": "Workflow: Test that non-string patterns are caught during compilation",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
            "line_start": 1351,
            "line_end": 1378,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "skill_seekers.cli.swift_patterns",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "sys",
              "unittest.mock",
              "unittest.mock",
              "skill_seekers.cli.language_detector",
              "inspect",
              "skill_seekers.cli",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that non-string patterns are caught during compilation'",
            "description": "'Test that non-string patterns are caught during compilation'",
            "expected_result": null,
            "verification": "assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "original = ld_module.LANGUAGE_PATTERNS.copy()",
            "description": "Assign original = ld_module.LANGUAGE_PATTERNS.copy(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "ld_module.LANGUAGE_PATTERNS['test_nonstring'] = [(None, 5)]",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "_detector = LanguageDetector()",
            "description": "Assign _detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "ld_module.LANGUAGE_PATTERNS = original",
            "description": "Assign ld_module.LANGUAGE_PATTERNS = original",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Non String Pattern Handled During Compilation",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_swift_detection.py:1351"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Async Dry Run Completes": [
      {
        "guide_id": "99470dd2b670",
        "title": "Async Dry Run Completes",
        "overview": "Workflow: Test async dry run completes without errors",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "asyncio",
          "inspect",
          "os",
          "tempfile",
          "unittest",
          "unittest.mock",
          "skill_seekers.cli.doc_scraper",
          "httpx"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "301275b9",
            "test_name": "test_async_dry_run_completes",
            "category": "workflow",
            "code": "'Test async dry run completes without errors'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'async_mode': True, 'max_pages': 5}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=True)\n        with patch.object(converter, '_try_llms_txt', return_value=False):\n            converter.scrape_all()\n            self.assertTrue(converter.dry_run)\n    finally:\n        os.chdir(self.original_cwd)",
            "language": "Python",
            "description": "Workflow: Test async dry run completes without errors",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
            "line_start": 205,
            "line_end": 227,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "asyncio",
              "inspect",
              "os",
              "tempfile",
              "unittest",
              "unittest.mock",
              "skill_seekers.cli.doc_scraper",
              "httpx"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test async dry run completes without errors'",
            "description": "'Test async dry run completes without errors'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'async_mode': True, 'max_pages': 5}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "os.chdir(tmpdir)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter = DocToSkillConverter(config, dry_run=True)",
            "description": "Assign converter = DocToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "os.chdir(self.original_cwd)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.scrape_all()",
            "description": "Call converter.scrape_all()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(converter.dry_run)",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Async Dry Run Completes",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_async_scraping.py:205"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Enhance Guide Error Fallback": [
      {
        "guide_id": "e9e41d9f0aa8",
        "title": "Enhance Guide Error Fallback",
        "overview": "Workflow: Test graceful fallback on enhancement error",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.guide_enhancer",
          "subprocess"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b67909da",
            "test_name": "test_enhance_guide_error_fallback",
            "category": "workflow",
            "code": "'Test graceful fallback on enhancement error'\nenhancer = GuideEnhancer(mode='none')\nwith patch.object(enhancer, 'enhance_guide', side_effect=Exception('API error')):\n    guide_data = {'title': 'Test', 'steps': [], 'language': 'python', 'prerequisites': [], 'description': 'Test'}\n    try:\n        enhancer = GuideEnhancer(mode='none')\n        result = enhancer.enhance_guide(guide_data)\n        assert result['title'] == guide_data['title']\n    except Exception:\n        pytest.fail('Should handle errors gracefully')",
            "language": "Python",
            "description": "Workflow: Test graceful fallback on enhancement error",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
            "line_start": 444,
            "line_end": 464,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.guide_enhancer",
              "subprocess"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test graceful fallback on enhancement error'",
            "description": "'Test graceful fallback on enhancement error'",
            "expected_result": null,
            "verification": "assert result['title'] == guide_data['title']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "enhancer = GuideEnhancer(mode='none')",
            "description": "Assign enhancer = GuideEnhancer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "guide_data = {'title': 'Test', 'steps': [], 'language': 'python', 'prerequisites': [], 'description': 'Test'}",
            "description": "Assign guide_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "enhancer = GuideEnhancer(mode='none')",
            "description": "Assign enhancer = GuideEnhancer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = enhancer.enhance_guide(guide_data)",
            "description": "Assign result = enhancer.enhance_guide(...)",
            "expected_result": null,
            "verification": "assert result['title'] == guide_data['title']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "pytest.fail('Should handle errors gracefully')",
            "description": "Call pytest.fail()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Enhance Guide Error Fallback",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_guide_enhancer.py:444"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Call Claude Local Success": [
      {
        "guide_id": "72a3b1a4e84b",
        "title": "Call Claude Local Success",
        "overview": "Workflow: Test successful LOCAL mode call",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.guide_enhancer",
          "subprocess"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "df128142",
            "test_name": "test_call_claude_local_success",
            "category": "workflow",
            "code": "'Test successful LOCAL mode call'\nmock_run.return_value = MagicMock(returncode=0, stdout=json.dumps({'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}))\nenhancer = GuideEnhancer(mode='local')\nif enhancer.mode == 'local':\n    prompt = 'Test prompt'\n    result = enhancer._call_claude_local(prompt)\n    assert result is not None\n    assert mock_run.called",
            "language": "Python",
            "description": "Workflow: Test successful LOCAL mode call",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
            "line_start": 471,
            "line_end": 492,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_run",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.guide_enhancer",
              "subprocess"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test successful LOCAL mode call'",
            "description": "'Test successful LOCAL mode call'",
            "expected_result": null,
            "verification": "assert result is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "mock_run.return_value = MagicMock(returncode=0, stdout=json.dumps({'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}))",
            "description": "Assign mock_run.return_value = MagicMock(...)",
            "expected_result": null,
            "verification": "assert mock_run.called",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "enhancer = GuideEnhancer(mode='local')",
            "description": "Assign enhancer = GuideEnhancer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "prompt = 'Test prompt'",
            "description": "Assign prompt = 'Test prompt'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = enhancer._call_claude_local(prompt)",
            "description": "Assign result = enhancer._call_claude_local(...)",
            "expected_result": null,
            "verification": "assert result is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Call Claude Local Success",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_guide_enhancer.py:471"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Call Claude Local Timeout": [
      {
        "guide_id": "d5e1884297c4",
        "title": "Call Claude Local Timeout",
        "overview": "Workflow: Test LOCAL mode timeout handling",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.guide_enhancer",
          "subprocess"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4d3e542e",
            "test_name": "test_call_claude_local_timeout",
            "category": "workflow",
            "code": "'Test LOCAL mode timeout handling'\nfrom subprocess import TimeoutExpired\nmock_run.side_effect = TimeoutExpired('claude', 300)\nenhancer = GuideEnhancer(mode='local')\nif enhancer.mode == 'local':\n    prompt = 'Test prompt'\n    result = enhancer._call_claude_local(prompt)\n    assert result is None",
            "language": "Python",
            "description": "Workflow: Test LOCAL mode timeout handling",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
            "line_start": 495,
            "line_end": 506,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_run",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.guide_enhancer",
              "subprocess"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test LOCAL mode timeout handling'",
            "description": "'Test LOCAL mode timeout handling'",
            "expected_result": null,
            "verification": "assert result is None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "mock_run.side_effect = TimeoutExpired('claude', 300)",
            "description": "Assign mock_run.side_effect = TimeoutExpired(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "enhancer = GuideEnhancer(mode='local')",
            "description": "Assign enhancer = GuideEnhancer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "prompt = 'Test prompt'",
            "description": "Assign prompt = 'Test prompt'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = enhancer._call_claude_local(prompt)",
            "description": "Assign result = enhancer._call_claude_local(...)",
            "expected_result": null,
            "verification": "assert result is None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Call Claude Local Timeout",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_guide_enhancer.py:495"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parse Enhancement Response Valid Json": [
      {
        "guide_id": "ce3ce0dcf8a5",
        "title": "Parse Enhancement Response Valid Json",
        "overview": "Workflow: Test parsing valid JSON response",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.guide_enhancer",
          "subprocess"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c9fbf074",
            "test_name": "test_parse_enhancement_response_valid_json",
            "category": "workflow",
            "code": "'Test parsing valid JSON response'\nenhancer = GuideEnhancer(mode='none')\nresponse = json.dumps({'step_descriptions': [{'step_index': 0, 'explanation': 'Test', 'variations': []}], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []})\nguide_data = {'title': 'Test', 'steps': [{'description': 'Test', 'code': 'test'}], 'language': 'python'}\nresult = enhancer._parse_enhancement_response(response, guide_data)\nassert 'step_enhancements' in result\nassert len(result['step_enhancements']) == 1",
            "language": "Python",
            "description": "Workflow: Test parsing valid JSON response",
            "expected_behavior": "assert len(result['step_enhancements']) == 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
            "line_start": 560,
            "line_end": 583,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.guide_enhancer",
              "subprocess"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parsing valid JSON response'",
            "description": "'Test parsing valid JSON response'",
            "expected_result": null,
            "verification": "assert 'step_enhancements' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "enhancer = GuideEnhancer(mode='none')",
            "description": "Assign enhancer = GuideEnhancer(...)",
            "expected_result": null,
            "verification": "assert len(result['step_enhancements']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "response = json.dumps({'step_descriptions': [{'step_index': 0, 'explanation': 'Test', 'variations': []}], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []})",
            "description": "Assign response = json.dumps(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "guide_data = {'title': 'Test', 'steps': [{'description': 'Test', 'code': 'test'}], 'language': 'python'}",
            "description": "Assign guide_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = enhancer._parse_enhancement_response(response, guide_data)",
            "description": "Assign result = enhancer._parse_enhancement_response(...)",
            "expected_result": null,
            "verification": "assert 'step_enhancements' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parse Enhancement Response Valid Json",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_guide_enhancer.py:560"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parse Enhancement Response With Extra Text": [
      {
        "guide_id": "9167b09b3900",
        "title": "Parse Enhancement Response With Extra Text",
        "overview": "Workflow: Test parsing JSON embedded in text",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.guide_enhancer",
          "subprocess"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b07ea653",
            "test_name": "test_parse_enhancement_response_with_extra_text",
            "category": "workflow",
            "code": "'Test parsing JSON embedded in text'\nenhancer = GuideEnhancer(mode='none')\njson_data = {'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}\nresponse = f\"Here's the result:\\n{json.dumps(json_data)}\\nDone!\"\nguide_data = {'title': 'Test', 'steps': [], 'language': 'python'}\nresult = enhancer._parse_enhancement_response(response, guide_data)\nassert 'title' in result",
            "language": "Python",
            "description": "Workflow: Test parsing JSON embedded in text",
            "expected_behavior": "assert 'title' in result",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
            "line_start": 585,
            "line_end": 603,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.guide_enhancer",
              "subprocess"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parsing JSON embedded in text'",
            "description": "'Test parsing JSON embedded in text'",
            "expected_result": null,
            "verification": "assert 'title' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "enhancer = GuideEnhancer(mode='none')",
            "description": "Assign enhancer = GuideEnhancer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "json_data = {'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}",
            "description": "Assign json_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "response = f\"Here's the result:\\n{json.dumps(json_data)}\\nDone!\"",
            "description": "Assign response = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "guide_data = {'title': 'Test', 'steps': [], 'language': 'python'}",
            "description": "Assign guide_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "result = enhancer._parse_enhancement_response(response, guide_data)",
            "description": "Assign result = enhancer._parse_enhancement_response(...)",
            "expected_result": null,
            "verification": "assert 'title' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parse Enhancement Response With Extra Text",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_guide_enhancer.py:585"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Compare Benchmarks": [
      {
        "guide_id": "ee88de2b3fe3",
        "title": "Compare Benchmarks",
        "overview": "Workflow: Test comparing benchmarks.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "time",
          "json",
          "datetime",
          "skill_seekers.benchmark",
          "skill_seekers.benchmark.models",
          "skill_seekers.benchmark.models",
          "os",
          "skill_seekers.benchmark.models",
          "skill_seekers.benchmark.models"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "41186b80",
            "test_name": "test_compare_benchmarks",
            "category": "workflow",
            "code": "'Test comparing benchmarks.'\nrunner = BenchmarkRunner(output_dir=tmp_path)\n\ndef baseline_bench(bench):\n    with bench.timer('operation'):\n        time.sleep(0.1)\nrunner.run('baseline', baseline_bench, save=True)\nbaseline_path = list(tmp_path.glob('baseline_*.json'))[0]\n\ndef improved_bench(bench):\n    with bench.timer('operation'):\n        time.sleep(0.05)\nrunner.run('improved', improved_bench, save=True)\nimproved_path = list(tmp_path.glob('improved_*.json'))[0]\nfrom skill_seekers.benchmark.models import ComparisonReport\ncomparison = runner.compare(baseline_path, improved_path)\nassert isinstance(comparison, ComparisonReport)\nassert comparison.speedup_factor > 1.0\nassert len(comparison.improvements) > 0",
            "language": "Python",
            "description": "Workflow: Test comparing benchmarks.",
            "expected_behavior": "assert len(comparison.improvements) > 0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
            "line_start": 368,
            "line_end": 395,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "time",
              "json",
              "datetime",
              "skill_seekers.benchmark",
              "skill_seekers.benchmark.models",
              "skill_seekers.benchmark.models",
              "os",
              "skill_seekers.benchmark.models",
              "skill_seekers.benchmark.models"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test comparing benchmarks.'",
            "description": "'Test comparing benchmarks.'",
            "expected_result": null,
            "verification": "assert isinstance(comparison, ComparisonReport)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "runner = BenchmarkRunner(output_dir=tmp_path)",
            "description": "Assign runner = BenchmarkRunner(...)",
            "expected_result": null,
            "verification": "assert comparison.speedup_factor > 1.0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "runner.run('baseline', baseline_bench, save=True)",
            "description": "Call runner.run()",
            "expected_result": null,
            "verification": "assert len(comparison.improvements) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "baseline_path = list(tmp_path.glob('baseline_*.json'))[0]",
            "description": "Assign baseline_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "runner.run('improved', improved_bench, save=True)",
            "description": "Call runner.run()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "improved_path = list(tmp_path.glob('improved_*.json'))[0]",
            "description": "Assign improved_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "comparison = runner.compare(baseline_path, improved_path)",
            "description": "Assign comparison = runner.compare(...)",
            "expected_result": null,
            "verification": "assert isinstance(comparison, ComparisonReport)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "time.sleep(0.1)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "time.sleep(0.05)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Compare Benchmarks",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_benchmark.py:368"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cleanup Old": [
      {
        "guide_id": "bf9f6e872c3a",
        "title": "Cleanup Old",
        "overview": "Workflow: Test cleaning up old benchmarks.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "time",
          "json",
          "datetime",
          "skill_seekers.benchmark",
          "skill_seekers.benchmark.models",
          "skill_seekers.benchmark.models",
          "os",
          "skill_seekers.benchmark.models",
          "skill_seekers.benchmark.models"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ce3bc3cc",
            "test_name": "test_cleanup_old",
            "category": "workflow",
            "code": "'Test cleaning up old benchmarks.'\nimport os\nrunner = BenchmarkRunner(output_dir=tmp_path)\nbase_time = time.time()\nfor i in range(10):\n    filename = f'test_{i:08d}.json'\n    file_path = tmp_path / filename\n    report_data = {'name': 'test', 'started_at': datetime.utcnow().isoformat(), 'finished_at': datetime.utcnow().isoformat(), 'total_duration': 1.0, 'timings': [], 'memory': [], 'metrics': [], 'system_info': {}, 'recommendations': []}\n    with open(file_path, 'w') as f:\n        json.dump(report_data, f)\n    mtime = base_time - (10 - i) * 60\n    os.utime(file_path, (mtime, mtime))\nassert len(list(tmp_path.glob('test_*.json'))) == 10\nrunner.cleanup_old(keep_latest=3)\nremaining = list(tmp_path.glob('test_*.json'))\nassert len(remaining) == 3\nremaining_names = {f.stem for f in remaining}\nassert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
            "language": "Python",
            "description": "Workflow: Test cleaning up old benchmarks.",
            "expected_behavior": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
            "line_start": 441,
            "line_end": 484,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "time",
              "json",
              "datetime",
              "skill_seekers.benchmark",
              "skill_seekers.benchmark.models",
              "skill_seekers.benchmark.models",
              "os",
              "skill_seekers.benchmark.models",
              "skill_seekers.benchmark.models"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test cleaning up old benchmarks.'",
            "description": "'Test cleaning up old benchmarks.'",
            "expected_result": null,
            "verification": "assert len(list(tmp_path.glob('test_*.json'))) == 10",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "runner = BenchmarkRunner(output_dir=tmp_path)",
            "description": "Assign runner = BenchmarkRunner(...)",
            "expected_result": null,
            "verification": "assert len(remaining) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "base_time = time.time()",
            "description": "Assign base_time = time.time(...)",
            "expected_result": null,
            "verification": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "runner.cleanup_old(keep_latest=3)",
            "description": "Call runner.cleanup_old()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "remaining = list(tmp_path.glob('test_*.json'))",
            "description": "Assign remaining = list(...)",
            "expected_result": null,
            "verification": "assert len(remaining) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "remaining_names = {f.stem for f in remaining}",
            "description": "Assign remaining_names = value",
            "expected_result": null,
            "verification": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "filename = f'test_{i:08d}.json'",
            "description": "Assign filename = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "file_path = tmp_path / filename",
            "description": "Assign file_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "report_data = {'name': 'test', 'started_at': datetime.utcnow().isoformat(), 'finished_at': datetime.utcnow().isoformat(), 'total_duration': 1.0, 'timings': [], 'memory': [], 'metrics': [], 'system_info': {}, 'recommendations': []}",
            "description": "Assign report_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "mtime = base_time - (10 - i) * 60",
            "description": "Assign mtime = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "os.utime(file_path, (mtime, mtime))",
            "description": "Call os.utime()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "json.dump(report_data, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cleanup Old",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_benchmark.py:441"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Comparison Report Overall Improvement": [
      {
        "guide_id": "7b8e9fe4d08b",
        "title": "Comparison Report Overall Improvement",
        "overview": "Workflow: Test ComparisonReport overall_improvement property.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "time",
          "json",
          "datetime",
          "skill_seekers.benchmark",
          "skill_seekers.benchmark.models",
          "skill_seekers.benchmark.models",
          "os",
          "skill_seekers.benchmark.models",
          "skill_seekers.benchmark.models"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d6c0efdf",
            "test_name": "test_comparison_report_overall_improvement",
            "category": "workflow",
            "code": "'Test ComparisonReport overall_improvement property.'\nfrom skill_seekers.benchmark.models import ComparisonReport\nbaseline = BenchmarkReport(name='baseline', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=10.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])\ncurrent = BenchmarkReport(name='current', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=5.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])\ncomparison = ComparisonReport(name='test', baseline=baseline, current=current, improvements=[], regressions=[], speedup_factor=2.0, memory_change_mb=0.0)\nimprovement = comparison.overall_improvement\nassert '100.0% faster' in improvement\nassert '\u2705' in improvement",
            "language": "Python",
            "description": "Workflow: Test ComparisonReport overall_improvement property.",
            "expected_behavior": "assert '\u2705' in improvement",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
            "line_start": 586,
            "line_end": 627,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "time",
              "json",
              "datetime",
              "skill_seekers.benchmark",
              "skill_seekers.benchmark.models",
              "skill_seekers.benchmark.models",
              "os",
              "skill_seekers.benchmark.models",
              "skill_seekers.benchmark.models"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test ComparisonReport overall_improvement property.'",
            "description": "'Test ComparisonReport overall_improvement property.'",
            "expected_result": null,
            "verification": "assert '100.0% faster' in improvement",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "baseline = BenchmarkReport(name='baseline', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=10.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])",
            "description": "Assign baseline = BenchmarkReport(...)",
            "expected_result": null,
            "verification": "assert '\u2705' in improvement",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "current = BenchmarkReport(name='current', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=5.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])",
            "description": "Assign current = BenchmarkReport(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "comparison = ComparisonReport(name='test', baseline=baseline, current=current, improvements=[], regressions=[], speedup_factor=2.0, memory_change_mb=0.0)",
            "description": "Assign comparison = ComparisonReport(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "improvement = comparison.overall_improvement",
            "description": "Assign improvement = value",
            "expected_result": null,
            "verification": "assert '100.0% faster' in improvement",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Comparison Report Overall Improvement",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_benchmark.py:586"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Init Preserves Existing Registry": [
      {
        "guide_id": "0019b5f5a687",
        "title": "Init Preserves Existing Registry",
        "overview": "Workflow: Test that initialization doesn't overwrite existing registry.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "pytest",
          "skill_seekers.mcp.source_manager"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f6dc7925",
            "test_name": "test_init_preserves_existing_registry",
            "category": "workflow",
            "code": "\"Test that initialization doesn't overwrite existing registry.\"\nregistry_file = temp_config_dir / 'sources.json'\nexisting_data = {'version': '1.0', 'sources': [{'name': 'test', 'git_url': 'https://example.com/repo.git'}]}\nwith open(registry_file, 'w') as f:\n    json.dump(existing_data, f)\n_manager = SourceManager(config_dir=str(temp_config_dir))\nwith open(registry_file) as f:\n    data = json.load(f)\n    assert len(data['sources']) == 1",
            "language": "Python",
            "description": "Workflow: Test that initialization doesn't overwrite existing registry.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
            "line_start": 51,
            "line_end": 69,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_config_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "pytest",
              "skill_seekers.mcp.source_manager"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test that initialization doesn't overwrite existing registry.\"",
            "description": "\"Test that initialization doesn't overwrite existing registry.\"",
            "expected_result": null,
            "verification": "assert len(data['sources']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "registry_file = temp_config_dir / 'sources.json'",
            "description": "Assign registry_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "existing_data = {'version': '1.0', 'sources': [{'name': 'test', 'git_url': 'https://example.com/repo.git'}]}",
            "description": "Assign existing_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "_manager = SourceManager(config_dir=str(temp_config_dir))",
            "description": "Assign _manager = SourceManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "json.dump(existing_data, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": "assert len(data['sources']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Init Preserves Existing Registry",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_source_manager.py:51"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Add Source Full Parameters": [
      {
        "guide_id": "8f092c2de71a",
        "title": "Add Source Full Parameters",
        "overview": "Workflow: Test adding source with all parameters.",
        "complexity_level": "beginner",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "pytest",
          "skill_seekers.mcp.source_manager"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "efdb7dce",
            "test_name": "test_add_source_full_parameters",
            "category": "workflow",
            "code": "'Test adding source with all parameters.'\nsource = source_manager.add_source(name='company', git_url='https://gitlab.company.com/platform/configs.git', source_type='gitlab', token_env='CUSTOM_TOKEN', branch='develop', priority=1, enabled=False)\nassert source['name'] == 'company'\nassert source['type'] == 'gitlab'\nassert source['token_env'] == 'CUSTOM_TOKEN'\nassert source['branch'] == 'develop'\nassert source['priority'] == 1\nassert source['enabled'] is False",
            "language": "Python",
            "description": "Workflow: Test adding source with all parameters.",
            "expected_behavior": "assert source['enabled'] is False",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
            "line_start": 98,
            "line_end": 115,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "# Fixtures: source_manager",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "pytest",
              "skill_seekers.mcp.source_manager"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test adding source with all parameters.'",
            "description": "'Test adding source with all parameters.'",
            "expected_result": null,
            "verification": "assert source['name'] == 'company'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "source = source_manager.add_source(name='company', git_url='https://gitlab.company.com/platform/configs.git', source_type='gitlab', token_env='CUSTOM_TOKEN', branch='develop', priority=1, enabled=False)",
            "description": "Assign source = source_manager.add_source(...)",
            "expected_result": null,
            "verification": "assert source['type'] == 'gitlab'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Add Source Full Parameters",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_source_manager.py:98"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Sample Skill Dir": [
      {
        "guide_id": "a5d66b13a89f",
        "title": "Sample Skill Dir",
        "overview": "Workflow: Create a sample skill for integration testing.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "time",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "contextlib",
          "sys",
          "requests",
          "weaviate",
          "weaviate",
          "chromadb",
          "chromadb",
          "qdrant_client",
          "qdrant_client.models",
          "qdrant_client",
          "qdrant_client.models"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "cf3d2039",
            "test_name": "sample_skill_dir",
            "category": "workflow",
            "code": "'Create a sample skill for integration testing.'\nskill_dir = tmp_path / 'test_integration_skill'\nskill_dir.mkdir()\nskill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'\n(skill_dir / 'SKILL.md').write_text(skill_md)\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\nreferences = {'api_reference.md': '# API Reference\\n\\n## Core Functions\\n\\n### add_documents(documents, metadata)\\nAdd documents to the vector database.\\n\\n### query(text, limit=10)\\nQuery the database with semantic search.\\n\\n### delete_collection(name)\\nDelete a collection from the database.\\n', 'getting_started.md': '# Getting Started\\n\\n## Installation\\n\\n```bash\\npip install vector-db-client\\n```\\n\\n## Basic Usage\\n\\n```python\\nfrom vector_db import Client\\n\\nclient = Client(\"http://localhost:8080\")\\nclient.add_documents([\"doc1\", \"doc2\"])\\nresults = client.query(\"search query\")\\n```\\n', 'advanced_features.md': '# Advanced Features\\n\\n## Hybrid Search\\n\\nCombine keyword and vector search for better results.\\n\\n## Metadata Filtering\\n\\nFilter results based on metadata attributes.\\n\\n## Multi-modal Search\\n\\nSearch across text, images, and audio.\\n'}\nfor filename, content in references.items():\n    (refs_dir / filename).write_text(content)\nreturn skill_dir",
            "language": "Python",
            "description": "Workflow: Create a sample skill for integration testing.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
            "line_start": 29,
            "line_end": 109,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "pytest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "time",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "contextlib",
              "sys",
              "requests",
              "weaviate",
              "weaviate",
              "chromadb",
              "chromadb",
              "qdrant_client",
              "qdrant_client.models",
              "qdrant_client",
              "qdrant_client.models"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Create a sample skill for integration testing.'",
            "description": "'Create a sample skill for integration testing.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'test_integration_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'",
            "description": "Assign skill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "(skill_dir / 'SKILL.md').write_text(skill_md)",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "refs_dir = skill_dir / 'references'",
            "description": "Assign refs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "refs_dir.mkdir()",
            "description": "Call refs_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "references = {'api_reference.md': '# API Reference\\n\\n## Core Functions\\n\\n### add_documents(documents, metadata)\\nAdd documents to the vector database.\\n\\n### query(text, limit=10)\\nQuery the database with semantic search.\\n\\n### delete_collection(name)\\nDelete a collection from the database.\\n', 'getting_started.md': '# Getting Started\\n\\n## Installation\\n\\n```bash\\npip install vector-db-client\\n```\\n\\n## Basic Usage\\n\\n```python\\nfrom vector_db import Client\\n\\nclient = Client(\"http://localhost:8080\")\\nclient.add_documents([\"doc1\", \"doc2\"])\\nresults = client.query(\"search query\")\\n```\\n', 'advanced_features.md': '# Advanced Features\\n\\n## Hybrid Search\\n\\nCombine keyword and vector search for better results.\\n\\n## Metadata Filtering\\n\\nFilter results based on metadata attributes.\\n\\n## Multi-modal Search\\n\\nSearch across text, images, and audio.\\n'}",
            "description": "Assign references = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "(refs_dir / filename).write_text(content)",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Sample Skill Dir",
        "tags": [
          "pytest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_integration_adaptors.py:29"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chroma Query Filtering": [
      {
        "guide_id": "ebda02e94997",
        "title": "Chroma Query Filtering",
        "overview": "Workflow: Test metadata filtering in ChromaDB queries.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "time",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "contextlib",
          "sys",
          "requests",
          "weaviate",
          "weaviate",
          "chromadb",
          "chromadb",
          "qdrant_client",
          "qdrant_client.models",
          "qdrant_client",
          "qdrant_client.models"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a2f1403c",
            "test_name": "test_chroma_query_filtering",
            "category": "workflow",
            "code": "'Test metadata filtering in ChromaDB queries.'\ntry:\n    import chromadb\nexcept ImportError:\n    pytest.skip('chromadb not installed')\nif not check_service_available('http://localhost:8000/api/v1/heartbeat'):\n    pytest.skip('ChromaDB not running')\ntry:\n    client = chromadb.HttpClient(host='localhost', port=8000)\n    client.heartbeat()\nexcept Exception as e:\n    pytest.skip(f'Cannot connect to ChromaDB: {e}')\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='chroma_filter_test', description='Test filtering capabilities')\npackage_path = adaptor.package(sample_skill_dir, tmp_path)\nwith open(package_path) as f:\n    data = json.load(f)\ncollection_name = data['collection_name']\ntry:\n    collection = client.get_or_create_collection(name=collection_name)\n    collection.add(documents=data['documents'], metadatas=data['metadatas'], ids=data['ids'])\n    time.sleep(1)\n    results = collection.get(where={'category': 'getting started'})\n    assert len(results['documents']) > 0, 'No documents matched filter'\n    for metadata in results['metadatas']:\n        assert metadata['category'] == 'getting started', 'Filter returned wrong category'\nfinally:\n    with contextlib.suppress(Exception):\n        client.delete_collection(name=collection_name)",
            "language": "Python",
            "description": "Workflow: Test metadata filtering in ChromaDB queries.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
            "line_start": 357,
            "line_end": 403,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "time",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "contextlib",
              "sys",
              "requests",
              "weaviate",
              "weaviate",
              "chromadb",
              "chromadb",
              "qdrant_client",
              "qdrant_client.models",
              "qdrant_client",
              "qdrant_client.models"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test metadata filtering in ChromaDB queries.'",
            "description": "'Test metadata filtering in ChromaDB queries.'",
            "expected_result": null,
            "verification": "assert len(results['documents']) > 0, 'No documents matched filter'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('chroma')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert metadata['category'] == 'getting started', 'Filter returned wrong category'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "metadata = SkillMetadata(name='chroma_filter_test', description='Test filtering capabilities')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(sample_skill_dir, tmp_path)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "collection_name = data['collection_name']",
            "description": "Assign collection_name = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "pytest.skip('ChromaDB not running')",
            "description": "Call pytest.skip()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "client = chromadb.HttpClient(host='localhost', port=8000)",
            "description": "Assign client = chromadb.HttpClient(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "client.heartbeat()",
            "description": "Call client.heartbeat()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "collection = client.get_or_create_collection(name=collection_name)",
            "description": "Assign collection = client.get_or_create_collection(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "collection.add(documents=data['documents'], metadatas=data['metadatas'], ids=data['ids'])",
            "description": "Call collection.add()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "time.sleep(1)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "results = collection.get(where={'category': 'getting started'})",
            "description": "Assign results = collection.get(...)",
            "expected_result": null,
            "verification": "assert len(results['documents']) > 0, 'No documents matched filter'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "pytest.skip('chromadb not installed')",
            "description": "Call pytest.skip()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "pytest.skip(f'Cannot connect to ChromaDB: {e}')",
            "description": "Call pytest.skip()",
            "expected_result": null,
            "verification": "assert metadata['category'] == 'getting started', 'Filter returned wrong category'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "client.delete_collection(name=collection_name)",
            "description": "Call client.delete_collection()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chroma Query Filtering",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_integration_adaptors.py:357"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Factory Method Detection": [
      {
        "guide_id": "b8a6e5c0455a",
        "title": "Factory Method Detection",
        "overview": "Workflow: Test detection of create/make methods",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.pattern_recognizer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "620cefa1",
            "test_name": "test_factory_method_detection",
            "category": "workflow",
            "code": "'Test detection of create/make methods'\ncode = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Factory']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertIn('create', ' '.join(pattern.evidence).lower())",
            "language": "Python",
            "description": "Workflow: Test detection of create/make methods",
            "expected_behavior": "self.assertIn('create', ' '.join(pattern.evidence).lower())",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
            "line_start": 135,
            "line_end": 153,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.pattern_recognizer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of create/make methods'",
            "description": "'Test detection of create/make methods'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"",
            "description": "Assign code = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "report = self.recognizer.analyze_file('test.py', code, 'Python')",
            "description": "Assign report = self.recognizer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "patterns = [p for p in report.patterns if p.pattern_type == 'Factory']",
            "description": "Assign patterns = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertGreater(len(patterns), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "pattern = patterns[0]",
            "description": "Assign pattern = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('create', ' '.join(pattern.evidence).lower())",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Factory Method Detection",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pattern_recognizer.py:135"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Observer Triplet Detection": [
      {
        "guide_id": "d6e468b92136",
        "title": "Observer Triplet Detection",
        "overview": "Workflow: Test classic attach/detach/notify triplet",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.pattern_recognizer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0f757575",
            "test_name": "test_observer_triplet_detection",
            "category": "workflow",
            "code": "'Test classic attach/detach/notify triplet'\ncode = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Observer']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertGreaterEqual(pattern.confidence, 0.8)\nevidence_str = ' '.join(pattern.evidence).lower()\nself.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
            "language": "Python",
            "description": "Workflow: Test classic attach/detach/notify triplet",
            "expected_behavior": "self.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
            "line_start": 199,
            "line_end": 225,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.pattern_recognizer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test classic attach/detach/notify triplet'",
            "description": "'Test classic attach/detach/notify triplet'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'",
            "description": "Assign code = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "report = self.recognizer.analyze_file('test.py', code, 'Python')",
            "description": "Assign report = self.recognizer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "patterns = [p for p in report.patterns if p.pattern_type == 'Observer']",
            "description": "Assign patterns = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertGreater(len(patterns), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "pattern = patterns[0]",
            "description": "Assign pattern = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreaterEqual(pattern.confidence, 0.8)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "evidence_str = ' '.join(pattern.evidence).lower()",
            "description": "Assign evidence_str = unknown.join.lower(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Observer Triplet Detection",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pattern_recognizer.py:199"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Pattern Report Summary": [
      {
        "guide_id": "fdb89246a395",
        "title": "Pattern Report Summary",
        "overview": "Workflow: Test PatternReport.get_summary() method",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.pattern_recognizer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "db79e8d6",
            "test_name": "test_pattern_report_summary",
            "category": "workflow",
            "code": "'Test PatternReport.get_summary() method'\ncode = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'\nreport = self.recognizer.analyze_file('logging.py', code, 'Python')\nsummary = report.get_summary()\nself.assertIsInstance(summary, dict)\nif summary:\n    total_count = sum(summary.values())\n    self.assertGreater(total_count, 0)",
            "language": "Python",
            "description": "Workflow: Test PatternReport.get_summary() method",
            "expected_behavior": "self.assertIsInstance(summary, dict)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
            "line_start": 329,
            "line_end": 350,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.pattern_recognizer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test PatternReport.get_summary() method'",
            "description": "'Test PatternReport.get_summary() method'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'",
            "description": "Assign code = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "report = self.recognizer.analyze_file('logging.py', code, 'Python')",
            "description": "Assign report = self.recognizer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "summary = report.get_summary()",
            "description": "Assign summary = report.get_summary(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertIsInstance(summary, dict)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "total_count = sum(summary.values())",
            "description": "Assign total_count = sum(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(total_count, 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Pattern Report Summary",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pattern_recognizer.py:329"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generator Compute Hash": [
      {
        "guide_id": "db376c78a197",
        "title": "Generator Compute Hash",
        "overview": "Workflow: Test hash computation.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "tempfile",
          "pathlib",
          "unittest.mock",
          "skill_seekers.embedding.models",
          "skill_seekers.embedding.generator",
          "skill_seekers.embedding.cache",
          "numpy"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5eccf782",
            "test_name": "test_generator_compute_hash",
            "category": "workflow",
            "code": "'Test hash computation.'\nhash1 = EmbeddingGenerator.compute_hash('text1', 'model1')\nhash2 = EmbeddingGenerator.compute_hash('text1', 'model1')\nhash3 = EmbeddingGenerator.compute_hash('text2', 'model1')\nhash4 = EmbeddingGenerator.compute_hash('text1', 'model2')\nassert hash1 == hash2\nassert hash1 != hash3\nassert hash1 != hash4",
            "language": "Python",
            "description": "Workflow: Test hash computation.",
            "expected_behavior": "assert hash1 != hash4",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
            "line_start": 165,
            "line_end": 179,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "tempfile",
              "pathlib",
              "unittest.mock",
              "skill_seekers.embedding.models",
              "skill_seekers.embedding.generator",
              "skill_seekers.embedding.cache",
              "numpy"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test hash computation.'",
            "description": "'Test hash computation.'",
            "expected_result": null,
            "verification": "assert hash1 == hash2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "hash1 = EmbeddingGenerator.compute_hash('text1', 'model1')",
            "description": "Assign hash1 = EmbeddingGenerator.compute_hash(...)",
            "expected_result": null,
            "verification": "assert hash1 != hash3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "hash2 = EmbeddingGenerator.compute_hash('text1', 'model1')",
            "description": "Assign hash2 = EmbeddingGenerator.compute_hash(...)",
            "expected_result": null,
            "verification": "assert hash1 != hash4",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "hash3 = EmbeddingGenerator.compute_hash('text2', 'model1')",
            "description": "Assign hash3 = EmbeddingGenerator.compute_hash(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "hash4 = EmbeddingGenerator.compute_hash('text1', 'model2')",
            "description": "Assign hash4 = EmbeddingGenerator.compute_hash(...)",
            "expected_result": null,
            "verification": "assert hash1 == hash2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generator Compute Hash",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding.py:165"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cache Persistence": [
      {
        "guide_id": "d93527f0bc3f",
        "title": "Cache Persistence",
        "overview": "Workflow: Test cache persistence to file.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "tempfile",
          "pathlib",
          "unittest.mock",
          "skill_seekers.embedding.models",
          "skill_seekers.embedding.generator",
          "skill_seekers.embedding.cache",
          "numpy"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7c8131cf",
            "test_name": "test_cache_persistence",
            "category": "workflow",
            "code": "'Test cache persistence to file.'\nwith tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp:\n    tmp_path = tmp.name\ntry:\n    cache1 = EmbeddingCache(tmp_path)\n    cache1.set('hash1', [0.1, 0.2, 0.3], 'model1')\n    cache1.close()\n    cache2 = EmbeddingCache(tmp_path)\n    retrieved = cache2.get('hash1')\n    assert retrieved == [0.1, 0.2, 0.3]\n    cache2.close()\nfinally:\n    Path(tmp_path).unlink(missing_ok=True)",
            "language": "Python",
            "description": "Workflow: Test cache persistence to file.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
            "line_start": 349,
            "line_end": 367,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "tempfile",
              "pathlib",
              "unittest.mock",
              "skill_seekers.embedding.models",
              "skill_seekers.embedding.generator",
              "skill_seekers.embedding.cache",
              "numpy"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test cache persistence to file.'",
            "description": "'Test cache persistence to file.'",
            "expected_result": null,
            "verification": "assert retrieved == [0.1, 0.2, 0.3]",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "tmp_path = tmp.name",
            "description": "Assign tmp_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "cache1 = EmbeddingCache(tmp_path)",
            "description": "Assign cache1 = EmbeddingCache(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "cache1.set('hash1', [0.1, 0.2, 0.3], 'model1')",
            "description": "Call cache1.set()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "cache1.close()",
            "description": "Call cache1.close()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "cache2 = EmbeddingCache(tmp_path)",
            "description": "Assign cache2 = EmbeddingCache(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "retrieved = cache2.get('hash1')",
            "description": "Assign retrieved = cache2.get(...)",
            "expected_result": null,
            "verification": "assert retrieved == [0.1, 0.2, 0.3]",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "cache2.close()",
            "description": "Call cache2.close()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "Path(tmp_path).unlink(missing_ok=True)",
            "description": "Call Path.unlink()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cache Persistence",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_embedding.py:349"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Walk With Subdirectories": [
      {
        "guide_id": "32bf598aac85",
        "title": "Walk With Subdirectories",
        "overview": "Workflow: Test walking nested directory structure.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.codebase_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "00c9a61d",
            "test_name": "test_walk_with_subdirectories",
            "category": "workflow",
            "code": "'Test walking nested directory structure.'\nsrc_dir = self.root / 'src'\nsrc_dir.mkdir()\n(src_dir / 'module.py').write_text('test')\ntests_dir = self.root / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_module.py').write_text('test')\nfiles = walk_directory(self.root)\nself.assertEqual(len(files), 2)\nfilenames = [f.name for f in files]\nself.assertIn('module.py', filenames)\nself.assertIn('test_module.py', filenames)",
            "language": "Python",
            "description": "Workflow: Test walking nested directory structure.",
            "expected_behavior": "self.assertIn('test_module.py', filenames)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
            "line_start": 159,
            "line_end": 176,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.codebase_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test walking nested directory structure.'",
            "description": "'Test walking nested directory structure.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "src_dir = self.root / 'src'",
            "description": "Assign src_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "src_dir.mkdir()",
            "description": "Call src_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(src_dir / 'module.py').write_text('test')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "tests_dir = self.root / 'tests'",
            "description": "Assign tests_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "tests_dir.mkdir()",
            "description": "Call tests_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "(tests_dir / 'test_module.py').write_text('test')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "files = walk_directory(self.root)",
            "description": "Assign files = walk_directory(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertEqual(len(files), 2)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "filenames = [f.name for f in files]",
            "description": "Assign filenames = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('module.py', filenames)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('test_module.py', filenames)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Walk With Subdirectories",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_codebase_scraper.py:159"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "No Duplicate Directories Created": [
      {
        "guide_id": "8b62e02fc43c",
        "title": "No Duplicate Directories Created",
        "overview": "Workflow: Test that source directories are cleaned up after copying to references/ (Issue #279).",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.codebase_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "3c7c2450",
            "test_name": "test_no_duplicate_directories_created",
            "category": "workflow",
            "code": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'\ntest_dirs = ['documentation', 'api_reference', 'patterns']\nfor dir_name in test_dirs:\n    dir_path = self.output_dir / dir_name\n    dir_path.mkdir()\n    (dir_path / 'test.txt').write_text(f'Test content for {dir_name}')\n_generate_references(self.output_dir)\nreferences_dir = self.output_dir / 'references'\nself.assertTrue(references_dir.exists(), 'references/ should exist')\nfor dir_name in test_dirs:\n    ref_path = references_dir / dir_name\n    self.assertTrue(ref_path.exists(), f'references/{dir_name} should exist')\n    self.assertTrue((ref_path / 'test.txt').exists(), f'references/{dir_name}/test.txt should exist')\nfor dir_name in test_dirs:\n    source_path = self.output_dir / dir_name\n    self.assertFalse(source_path.exists(), f'Source directory {dir_name}/ should be cleaned up to avoid duplication')",
            "language": "Python",
            "description": "Workflow: Test that source directories are cleaned up after copying to references/ (Issue #279).",
            "expected_behavior": "self.assertTrue(references_dir.exists(), 'references/ should exist')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
            "line_start": 411,
            "line_end": 443,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.codebase_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'",
            "description": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "test_dirs = ['documentation', 'api_reference', 'patterns']",
            "description": "Assign test_dirs = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "_generate_references(self.output_dir)",
            "description": "Call _generate_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "references_dir = self.output_dir / 'references'",
            "description": "Assign references_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(references_dir.exists(), 'references/ should exist')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "dir_path = self.output_dir / dir_name",
            "description": "Assign dir_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "dir_path.mkdir()",
            "description": "Call dir_path.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "(dir_path / 'test.txt').write_text(f'Test content for {dir_name}')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "ref_path = references_dir / dir_name",
            "description": "Assign ref_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertTrue(ref_path.exists(), f'references/{dir_name} should exist')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue((ref_path / 'test.txt').exists(), f'references/{dir_name}/test.txt should exist')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "source_path = self.output_dir / dir_name",
            "description": "Assign source_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertFalse(source_path.exists(), f'Source directory {dir_name}/ should be cleaned up to avoid duplication')",
            "description": "Call self.assertFalse()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "No Duplicate Directories Created",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_codebase_scraper.py:411"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "No Disk Space Wasted": [
      {
        "guide_id": "43e332165dfa",
        "title": "No Disk Space Wasted",
        "overview": "Workflow: Test that disk space is not wasted by duplicate directories.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.codebase_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "6c4cfcff",
            "test_name": "test_no_disk_space_wasted",
            "category": "workflow",
            "code": "'Test that disk space is not wasted by duplicate directories.'\ndoc_dir = self.output_dir / 'documentation'\ndoc_dir.mkdir()\ntest_content = 'x' * 1000\n(doc_dir / 'large_file.txt').write_text(test_content)\n_generate_references(self.output_dir)\nref_doc_dir = self.output_dir / 'references' / 'documentation'\nsource_doc_dir = self.output_dir / 'documentation'\nself.assertTrue(ref_doc_dir.exists(), 'references/documentation/ should exist')\nself.assertFalse(source_doc_dir.exists(), 'Source documentation/ should not exist (cleaned up)')\nself.assertTrue((ref_doc_dir / 'large_file.txt').exists(), 'File should exist in references/')\nself.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
            "language": "Python",
            "description": "Workflow: Test that disk space is not wasted by duplicate directories.",
            "expected_behavior": "self.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
            "line_start": 445,
            "line_end": 473,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.codebase_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that disk space is not wasted by duplicate directories.'",
            "description": "'Test that disk space is not wasted by duplicate directories.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "doc_dir = self.output_dir / 'documentation'",
            "description": "Assign doc_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "doc_dir.mkdir()",
            "description": "Call doc_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "test_content = 'x' * 1000",
            "description": "Assign test_content = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "(doc_dir / 'large_file.txt').write_text(test_content)",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "_generate_references(self.output_dir)",
            "description": "Call _generate_references()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "ref_doc_dir = self.output_dir / 'references' / 'documentation'",
            "description": "Assign ref_doc_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "source_doc_dir = self.output_dir / 'documentation'",
            "description": "Assign source_doc_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(ref_doc_dir.exists(), 'references/documentation/ should exist')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertFalse(source_doc_dir.exists(), 'Source documentation/ should not exist (cleaned up)')",
            "description": "Call self.assertFalse()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue((ref_doc_dir / 'large_file.txt').exists(), 'File should exist in references/')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "No Disk Space Wasted",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_codebase_scraper.py:445"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Agent Command Claude": [
      {
        "guide_id": "dc4afac68084",
        "title": "Build Agent Command Claude",
        "overview": "Workflow: Test Claude Code command building.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "skill_seekers.cli.enhance_skill_local"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7757584e",
            "test_name": "test_build_agent_command_claude",
            "category": "workflow",
            "code": "'Test Claude Code command building.'\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='claude')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, True)\nassert cmd_parts[0] == 'claude'\nassert '--dangerously-skip-permissions' in cmd_parts\nassert prompt_file in cmd_parts\nassert uses_file is True",
            "language": "Python",
            "description": "Workflow: Test Claude Code command building.",
            "expected_behavior": "assert uses_file is True",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
            "line_start": 32,
            "line_end": 43,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "skill_seekers.cli.enhance_skill_local"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Claude Code command building.'",
            "description": "'Test Claude Code command building.'",
            "expected_result": null,
            "verification": "assert cmd_parts[0] == 'claude'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = _make_skill_dir(tmp_path)",
            "description": "Assign skill_dir = _make_skill_dir(...)",
            "expected_result": null,
            "verification": "assert '--dangerously-skip-permissions' in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='claude')",
            "description": "Assign enhancer = LocalSkillEnhancer(...)",
            "expected_result": null,
            "verification": "assert prompt_file in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "prompt_file = str(tmp_path / 'prompt.txt')",
            "description": "Assign prompt_file = str(...)",
            "expected_result": null,
            "verification": "assert uses_file is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, True)",
            "description": "Assign unknown = enhancer._build_agent_command(...)",
            "expected_result": null,
            "verification": "assert cmd_parts[0] == 'claude'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Agent Command Claude",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_enhance_skill_local.py:32"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Agent Command Codex": [
      {
        "guide_id": "9e312e137287",
        "title": "Build Agent Command Codex",
        "overview": "Workflow: Test Codex CLI command building.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "skill_seekers.cli.enhance_skill_local"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7a9d3a78",
            "test_name": "test_build_agent_command_codex",
            "category": "workflow",
            "code": "'Test Codex CLI command building.'\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='codex')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)\nassert cmd_parts[0] == 'codex'\nassert 'exec' in cmd_parts\nassert '--full-auto' in cmd_parts\nassert '--skip-git-repo-check' in cmd_parts\nassert uses_file is False",
            "language": "Python",
            "description": "Workflow: Test Codex CLI command building.",
            "expected_behavior": "assert uses_file is False",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
            "line_start": 45,
            "line_end": 57,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "skill_seekers.cli.enhance_skill_local"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Codex CLI command building.'",
            "description": "'Test Codex CLI command building.'",
            "expected_result": null,
            "verification": "assert cmd_parts[0] == 'codex'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = _make_skill_dir(tmp_path)",
            "description": "Assign skill_dir = _make_skill_dir(...)",
            "expected_result": null,
            "verification": "assert 'exec' in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='codex')",
            "description": "Assign enhancer = LocalSkillEnhancer(...)",
            "expected_result": null,
            "verification": "assert '--full-auto' in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "prompt_file = str(tmp_path / 'prompt.txt')",
            "description": "Assign prompt_file = str(...)",
            "expected_result": null,
            "verification": "assert '--skip-git-repo-check' in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)",
            "description": "Assign unknown = enhancer._build_agent_command(...)",
            "expected_result": null,
            "verification": "assert uses_file is False",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Agent Command Codex",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_enhance_skill_local.py:45"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Agent Command Custom With Placeholder": [
      {
        "guide_id": "4e2b7c899f67",
        "title": "Build Agent Command Custom With Placeholder",
        "overview": "Workflow: Test custom command with {prompt_file} placeholder.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "skill_seekers.cli.enhance_skill_local"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "75f0193a",
            "test_name": "test_build_agent_command_custom_with_placeholder",
            "category": "workflow",
            "code": "'Test custom command with {prompt_file} placeholder.'\n_allow_executable(monkeypatch, name='my-agent')\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='custom', agent_cmd='my-agent --input {prompt_file}')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)\nassert cmd_parts[0] == 'my-agent'\nassert '--input' in cmd_parts\nassert prompt_file in cmd_parts\nassert uses_file is True",
            "language": "Python",
            "description": "Workflow: Test custom command with {prompt_file} placeholder.",
            "expected_behavior": "assert uses_file is True",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
            "line_start": 59,
            "line_end": 75,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path, monkeypatch",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "skill_seekers.cli.enhance_skill_local"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test custom command with {prompt_file} placeholder.'",
            "description": "'Test custom command with {prompt_file} placeholder.'",
            "expected_result": null,
            "verification": "assert cmd_parts[0] == 'my-agent'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "_allow_executable(monkeypatch, name='my-agent')",
            "description": "Call _allow_executable()",
            "expected_result": null,
            "verification": "assert '--input' in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir = _make_skill_dir(tmp_path)",
            "description": "Assign skill_dir = _make_skill_dir(...)",
            "expected_result": null,
            "verification": "assert prompt_file in cmd_parts",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='custom', agent_cmd='my-agent --input {prompt_file}')",
            "description": "Assign enhancer = LocalSkillEnhancer(...)",
            "expected_result": null,
            "verification": "assert uses_file is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "prompt_file = str(tmp_path / 'prompt.txt')",
            "description": "Assign prompt_file = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)",
            "description": "Assign unknown = enhancer._build_agent_command(...)",
            "expected_result": null,
            "verification": "assert cmd_parts[0] == 'my-agent'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Agent Command Custom With Placeholder",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_enhance_skill_local.py:59"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Langchain No Chunking Default": [
      {
        "guide_id": "67fbe0b2ae94",
        "title": "Langchain No Chunking Default",
        "overview": "Workflow: Test that LangChain doesn't chunk by default.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "77e4d66e",
            "test_name": "test_langchain_no_chunking_default",
            "category": "workflow",
            "code": "\"Test that LangChain doesn't chunk by default.\"\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) == 2, f'Expected 2 docs, got {len(data)}'\nfor doc in data:\n    assert 'is_chunked' not in doc['metadata']\n    assert 'chunk_index' not in doc['metadata']",
            "language": "Python",
            "description": "Workflow: Test that LangChain doesn't chunk by default.",
            "expected_behavior": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 59,
            "line_end": 75,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test that LangChain doesn't chunk by default.\"",
            "description": "\"Test that LangChain doesn't chunk by default.\"",
            "expected_result": null,
            "verification": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
            "description": "Assign skill_dir = create_test_skill(...)",
            "expected_result": null,
            "verification": "assert 'is_chunked' not in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor('langchain')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert 'chunk_index' not in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(skill_dir, tmp_path)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": "assert 'is_chunked' not in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Langchain No Chunking Default",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:59"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Langchain Chunking Enabled": [
      {
        "guide_id": "f997215aef3f",
        "title": "Langchain Chunking Enabled",
        "overview": "Workflow: Test that LangChain chunks large documents when enabled.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "3e61e5d4",
            "test_name": "test_langchain_chunking_enabled",
            "category": "workflow",
            "code": "'Test that LangChain chunks large documents when enabled.'\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) > 2, f'Large doc should be chunked, got {len(data)} docs'\nchunked_docs = [doc for doc in data if doc['metadata'].get('is_chunked')]\nassert len(chunked_docs) > 0, 'Should have chunked documents'\nfor doc in chunked_docs:\n    assert 'chunk_index' in doc['metadata']\n    assert 'total_chunks' in doc['metadata']\n    assert 'chunk_id' in doc['metadata']",
            "language": "Python",
            "description": "Workflow: Test that LangChain chunks large documents when enabled.",
            "expected_behavior": "assert len(chunked_docs) > 0, 'Should have chunked documents'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 81,
            "line_end": 104,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that LangChain chunks large documents when enabled.'",
            "description": "'Test that LangChain chunks large documents when enabled.'",
            "expected_result": null,
            "verification": "assert len(data) > 2, f'Large doc should be chunked, got {len(data)} docs'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
            "description": "Assign skill_dir = create_test_skill(...)",
            "expected_result": null,
            "verification": "assert len(chunked_docs) > 0, 'Should have chunked documents'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor('langchain')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert 'chunk_index' in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": "assert 'total_chunks' in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunked_docs = [doc for doc in data if doc['metadata'].get('is_chunked')]",
            "description": "Assign chunked_docs = value",
            "expected_result": null,
            "verification": "assert 'chunk_id' in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": "assert 'chunk_index' in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Langchain Chunking Enabled",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:81"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunking Preserves Small Docs": [
      {
        "guide_id": "a1674bf74c31",
        "title": "Chunking Preserves Small Docs",
        "overview": "Workflow: Test that small documents are not chunked.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5305693f",
            "test_name": "test_chunking_preserves_small_docs",
            "category": "workflow",
            "code": "'Test that small documents are not chunked.'\nskill_dir = create_test_skill(tmp_path, large_doc=False)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) == 2, 'Small docs should not be chunked'\nfor doc in data:\n    assert 'is_chunked' not in doc['metadata']",
            "language": "Python",
            "description": "Workflow: Test that small documents are not chunked.",
            "expected_behavior": "assert len(data) == 2, 'Small docs should not be chunked'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 106,
            "line_end": 122,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that small documents are not chunked.'",
            "description": "'Test that small documents are not chunked.'",
            "expected_result": null,
            "verification": "assert len(data) == 2, 'Small docs should not be chunked'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = create_test_skill(tmp_path, large_doc=False)",
            "description": "Assign skill_dir = create_test_skill(...)",
            "expected_result": null,
            "verification": "assert 'is_chunked' not in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor('langchain')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": "assert len(data) == 2, 'Small docs should not be chunked'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": "assert 'is_chunked' not in doc['metadata']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunking Preserves Small Docs",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:106"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Preserve Code Blocks": [
      {
        "guide_id": "857202c22814",
        "title": "Preserve Code Blocks",
        "overview": "Workflow: Test code block preservation.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "12c916c2",
            "test_name": "test_preserve_code_blocks",
            "category": "workflow",
            "code": "'Test code block preservation.'\nchunker = RAGChunker(chunk_size=50, preserve_code_blocks=True)\ntext = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\nhas_code = any(('```' in chunk['page_content'] for chunk in chunks))\nassert has_code\ncode_chunks = [c for c in chunks if c['metadata']['has_code_block']]\nassert len(code_chunks) > 0",
            "language": "Python",
            "description": "Workflow: Test code block preservation.",
            "expected_behavior": "assert len(code_chunks) > 0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 85,
            "line_end": 108,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test code block preservation.'",
            "description": "'Test code block preservation.'",
            "expected_result": null,
            "verification": "assert has_code",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker(chunk_size=50, preserve_code_blocks=True)",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": "assert len(code_chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '",
            "description": "Assign text = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "chunks = chunker.chunk_document(text, {'source': 'test'})",
            "description": "Assign chunks = chunker.chunk_document(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "has_code = any(('```' in chunk['page_content'] for chunk in chunks))",
            "description": "Assign has_code = any(...)",
            "expected_result": null,
            "verification": "assert has_code",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "code_chunks = [c for c in chunks if c['metadata']['has_code_block']]",
            "description": "Assign code_chunks = value",
            "expected_result": null,
            "verification": "assert len(code_chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Preserve Code Blocks",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:85"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Maybe Chunk Content Disabled": [
      {
        "guide_id": "ccca78ab9721",
        "title": "Maybe Chunk Content Disabled",
        "overview": "Workflow: Test that _maybe_chunk_content returns single chunk when disabled.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e7e0e0d9",
            "test_name": "test_maybe_chunk_content_disabled",
            "category": "workflow",
            "code": "'Test that _maybe_chunk_content returns single chunk when disabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Test content ' * 1000\nmetadata = {'source': 'test'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=False)\nassert len(chunks) == 1\nassert chunks[0][0] == content\nassert chunks[0][1] == metadata",
            "language": "Python",
            "description": "Workflow: Test that _maybe_chunk_content returns single chunk when disabled.",
            "expected_behavior": "assert chunks[0][1] == metadata",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 225,
            "line_end": 239,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that _maybe_chunk_content returns single chunk when disabled.'",
            "description": "'Test that _maybe_chunk_content returns single chunk when disabled.'",
            "expected_result": null,
            "verification": "assert len(chunks) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = LangChainAdaptor()",
            "description": "Assign adaptor = LangChainAdaptor(...)",
            "expected_result": null,
            "verification": "assert chunks[0][0] == content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = 'Test content ' * 1000",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": "assert chunks[0][1] == metadata",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=False)",
            "description": "Assign chunks = adaptor._maybe_chunk_content(...)",
            "expected_result": null,
            "verification": "assert len(chunks) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Maybe Chunk Content Disabled",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:225"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Maybe Chunk Content Small Doc": [
      {
        "guide_id": "41deb1427e64",
        "title": "Maybe Chunk Content Small Doc",
        "overview": "Workflow: Test that small docs are not chunked even when enabled.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f61d3115",
            "test_name": "test_maybe_chunk_content_small_doc",
            "category": "workflow",
            "code": "'Test that small docs are not chunked even when enabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Small test content'\nmetadata = {'source': 'test'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512)\nassert len(chunks) == 1",
            "language": "Python",
            "description": "Workflow: Test that small docs are not chunked even when enabled.",
            "expected_behavior": "assert len(chunks) == 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 241,
            "line_end": 255,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that small docs are not chunked even when enabled.'",
            "description": "'Test that small docs are not chunked even when enabled.'",
            "expected_result": null,
            "verification": "assert len(chunks) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = LangChainAdaptor()",
            "description": "Assign adaptor = LangChainAdaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = 'Small test content'",
            "description": "Assign content = 'Small test content'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512)",
            "description": "Assign chunks = adaptor._maybe_chunk_content(...)",
            "expected_result": null,
            "verification": "assert len(chunks) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Maybe Chunk Content Small Doc",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:241"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Maybe Chunk Content Large Doc": [
      {
        "guide_id": "de5577f99cb0",
        "title": "Maybe Chunk Content Large Doc",
        "overview": "Workflow: Test that large docs are chunked when enabled.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "daf42b67",
            "test_name": "test_maybe_chunk_content_large_doc",
            "category": "workflow",
            "code": "'Test that large docs are chunked when enabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Lorem ipsum dolor sit amet. ' * 2000\nmetadata = {'source': 'test', 'file': 'test.md'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512, preserve_code_blocks=True, source_file='test.md')\nassert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'\nfor chunk_text, chunk_meta in chunks:\n    assert isinstance(chunk_text, str)\n    assert isinstance(chunk_meta, dict)\n    assert chunk_meta['is_chunked']\n    assert 'chunk_index' in chunk_meta\n    assert 'chunk_id' in chunk_meta\n    assert chunk_meta['source'] == 'test'\n    assert chunk_meta['file'] == 'test.md'",
            "language": "Python",
            "description": "Workflow: Test that large docs are chunked when enabled.",
            "expected_behavior": "assert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 257,
            "line_end": 287,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that large docs are chunked when enabled.'",
            "description": "'Test that large docs are chunked when enabled.'",
            "expected_result": null,
            "verification": "assert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = LangChainAdaptor()",
            "description": "Assign adaptor = LangChainAdaptor(...)",
            "expected_result": null,
            "verification": "assert isinstance(chunk_text, str)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = 'Lorem ipsum dolor sit amet. ' * 2000",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": "assert isinstance(chunk_meta, dict)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test', 'file': 'test.md'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": "assert chunk_meta['is_chunked']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512, preserve_code_blocks=True, source_file='test.md')",
            "description": "Assign chunks = adaptor._maybe_chunk_content(...)",
            "expected_result": null,
            "verification": "assert 'chunk_index' in chunk_meta",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Maybe Chunk Content Large Doc",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:257"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Tokens Parameter": [
      {
        "guide_id": "4646cb5e12c6",
        "title": "Chunk Tokens Parameter",
        "overview": "Workflow: Test --chunk-tokens parameter controls chunk size.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.adaptors.langchain",
          "skill_seekers.cli.package_skill",
          "skill_seekers.cli.package_skill"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "94b738fe",
            "test_name": "test_chunk_tokens_parameter",
            "category": "workflow",
            "code": "'Test --chunk-tokens parameter controls chunk size.'\nfrom skill_seekers.cli.package_skill import package_skill\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nsuccess, package_path = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=256, preserve_code_blocks=True)\nassert success\nwith open(package_path) as f:\n    data_small = json.load(f)\nsuccess, package_path2 = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=1024, preserve_code_blocks=True)\nassert success\nwith open(package_path2) as f:\n    data_large = json.load(f)\nassert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
            "language": "Python",
            "description": "Workflow: Test --chunk-tokens parameter controls chunk size.",
            "expected_behavior": "assert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
            "line_start": 318,
            "line_end": 359,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.adaptors.langchain",
              "skill_seekers.cli.package_skill",
              "skill_seekers.cli.package_skill"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test --chunk-tokens parameter controls chunk size.'",
            "description": "'Test --chunk-tokens parameter controls chunk size.'",
            "expected_result": null,
            "verification": "assert success",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
            "description": "Assign skill_dir = create_test_skill(...)",
            "expected_result": null,
            "verification": "assert success",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "success, package_path = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=256, preserve_code_blocks=True)",
            "description": "Assign unknown = package_skill(...)",
            "expected_result": null,
            "verification": "assert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "success, package_path2 = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=1024, preserve_code_blocks=True)",
            "description": "Assign unknown = package_skill(...)",
            "expected_result": null,
            "verification": "assert success",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "data_small = json.load(f)",
            "description": "Assign data_small = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "data_large = json.load(f)",
            "description": "Assign data_large = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Tokens Parameter",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_chunking_integration.py:318"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Terminal Launch Error Handling": [
      {
        "guide_id": "020c19cef7fd",
        "title": "Terminal Launch Error Handling",
        "overview": "Workflow: Test error handling when terminal launch fails.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "pathlib",
          "unittest.mock",
          "skill_seekers.cli.enhance_skill_local",
          "tempfile",
          "tempfile",
          "tempfile",
          "skill_seekers.cli.enhance_skill_local",
          "io",
          "io"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "13d01943",
            "test_name": "test_terminal_launch_error_handling",
            "category": "workflow",
            "code": "'Test error handling when terminal launch fails.'\nif sys.platform != 'darwin':\n    self.skipTest('This test only runs on macOS')\nmock_popen.side_effect = Exception('Terminal not found')\nimport tempfile\nwith tempfile.TemporaryDirectory() as tmpdir:\n    skill_dir = Path(tmpdir) / 'test_skill'\n    skill_dir.mkdir()\n    (skill_dir / 'references').mkdir()\n    (skill_dir / 'references' / 'test.md').write_text('# Test')\n    (skill_dir / 'SKILL.md').write_text('---\\nname: test\\n---\\n# Test')\n    enhancer = LocalSkillEnhancer(skill_dir)\n    from io import StringIO\n    captured_output = StringIO()\n    old_stdout = sys.stdout\n    sys.stdout = captured_output\n    result = enhancer.run(headless=False)\n    sys.stdout = old_stdout\n    self.assertFalse(result)\n    output = captured_output.getvalue()\n    self.assertIn('Error launching', output)",
            "language": "Python",
            "description": "Workflow: Test error handling when terminal launch fails.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
            "line_start": 218,
            "line_end": 256,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_popen",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "pathlib",
              "unittest.mock",
              "skill_seekers.cli.enhance_skill_local",
              "tempfile",
              "tempfile",
              "tempfile",
              "skill_seekers.cli.enhance_skill_local",
              "io",
              "io"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test error handling when terminal launch fails.'",
            "description": "'Test error handling when terminal launch fails.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "mock_popen.side_effect = Exception('Terminal not found')",
            "description": "Assign mock_popen.side_effect = Exception(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "self.skipTest('This test only runs on macOS')",
            "description": "Call self.skipTest()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_dir = Path(tmpdir) / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(skill_dir / 'references').mkdir()",
            "description": "Call unknown.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "(skill_dir / 'references' / 'test.md').write_text('# Test')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "(skill_dir / 'SKILL.md').write_text('---\\nname: test\\n---\\n# Test')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "enhancer = LocalSkillEnhancer(skill_dir)",
            "description": "Assign enhancer = LocalSkillEnhancer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "captured_output = StringIO()",
            "description": "Assign captured_output = StringIO(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "old_stdout = sys.stdout",
            "description": "Assign old_stdout = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "sys.stdout = captured_output",
            "description": "Assign sys.stdout = captured_output",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "result = enhancer.run(headless=False)",
            "description": "Assign result = enhancer.run(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "sys.stdout = old_stdout",
            "description": "Assign sys.stdout = old_stdout",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "self.assertFalse(result)",
            "description": "Call self.assertFalse()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "output = captured_output.getvalue()",
            "description": "Assign output = captured_output.getvalue(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "self.assertIn('Error launching', output)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Terminal Launch Error Handling",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_terminal_detection.py:218"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect From Html With Css Class": [
      {
        "guide_id": "604b6e6d7bd5",
        "title": "Detect From Html With Css Class",
        "overview": "Workflow: Test HTML element with CSS class",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a326d5e1",
            "test_name": "test_detect_from_html_with_css_class",
            "category": "workflow",
            "code": "'Test HTML element with CSS class'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-python\">print(\"hello\")</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'print(\"hello\")')\nassert lang == 'python'\nassert confidence == 1.0",
            "language": "Python",
            "description": "Workflow: Test HTML element with CSS class",
            "expected_behavior": "assert confidence == 1.0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
            "line_start": 77,
            "line_end": 88,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test HTML element with CSS class'",
            "description": "'Test HTML element with CSS class'",
            "expected_result": null,
            "verification": "assert lang == 'python'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence == 1.0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "html = '<code class=\"language-python\">print(\"hello\")</code>'",
            "description": "Assign html = '<code class=\"language-python\">print(\"hello\")</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "soup = BeautifulSoup(html, 'html.parser')",
            "description": "Assign soup = BeautifulSoup(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "elem = soup.find('code')",
            "description": "Assign elem = soup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "lang, confidence = detector.detect_from_html(elem, 'print(\"hello\")')",
            "description": "Assign unknown = detector.detect_from_html(...)",
            "expected_result": null,
            "verification": "assert lang == 'python'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect From Html With Css Class",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_language_detector.py:77"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect From Html With Parent Class": [
      {
        "guide_id": "a8beda260695",
        "title": "Detect From Html With Parent Class",
        "overview": "Workflow: Test parent <pre> element with CSS class",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4f01d261",
            "test_name": "test_detect_from_html_with_parent_class",
            "category": "workflow",
            "code": "'Test parent <pre> element with CSS class'\ndetector = LanguageDetector()\nhtml = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'System.out.println(\"hello\");')\nassert lang == 'java'\nassert confidence == 1.0",
            "language": "Python",
            "description": "Workflow: Test parent <pre> element with CSS class",
            "expected_behavior": "assert confidence == 1.0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
            "line_start": 90,
            "line_end": 101,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parent <pre> element with CSS class'",
            "description": "'Test parent <pre> element with CSS class'",
            "expected_result": null,
            "verification": "assert lang == 'java'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence == 1.0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "html = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'",
            "description": "Assign html = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "soup = BeautifulSoup(html, 'html.parser')",
            "description": "Assign soup = BeautifulSoup(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "elem = soup.find('code')",
            "description": "Assign elem = soup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "lang, confidence = detector.detect_from_html(elem, 'System.out.println(\"hello\");')",
            "description": "Assign unknown = detector.detect_from_html(...)",
            "expected_result": null,
            "verification": "assert lang == 'java'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect From Html With Parent Class",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_language_detector.py:90"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Unity Lifecycle Methods": [
      {
        "guide_id": "9c27829a9f8d",
        "title": "Unity Lifecycle Methods",
        "overview": "Workflow: Test Unity lifecycle method detection",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0a9a9ea2",
            "test_name": "test_unity_lifecycle_methods",
            "category": "workflow",
            "code": "'Test Unity lifecycle method detection'\ndetector = LanguageDetector()\ncode = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5",
            "language": "Python",
            "description": "Workflow: Test Unity lifecycle method detection",
            "expected_behavior": "assert confidence >= 0.5",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
            "line_start": 128,
            "line_end": 142,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Unity lifecycle method detection'",
            "description": "'Test Unity lifecycle method detection'",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.5",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '",
            "description": "Assign code = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Unity Lifecycle Methods",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_language_detector.py:128"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Unity Namespace": [
      {
        "guide_id": "e721b645377a",
        "title": "Unity Namespace",
        "overview": "Workflow: Test Unity namespace detection",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "fea31fb0",
            "test_name": "test_unity_namespace",
            "category": "workflow",
            "code": "'Test Unity namespace detection'\ndetector = LanguageDetector()\ncode = 'using UnityEngine;'\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5\ncode = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5",
            "language": "Python",
            "description": "Workflow: Test Unity namespace detection",
            "expected_behavior": "assert confidence >= 0.5",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
            "line_start": 190,
            "line_end": 209,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Unity namespace detection'",
            "description": "'Test Unity namespace detection'",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.5",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = 'using UnityEngine;'",
            "description": "Assign code = 'using UnityEngine;'",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.5",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "code = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '",
            "description": "Assign code = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Unity Namespace",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_language_detector.py:190"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Unity Full Script": [
      {
        "guide_id": "58064ee268f4",
        "title": "Unity Full Script",
        "overview": "Workflow: Test complete Unity script (high confidence expected)",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "aa0288ef",
            "test_name": "test_unity_full_script",
            "category": "workflow",
            "code": "'Test complete Unity script (high confidence expected)'\ndetector = LanguageDetector()\ncode = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.9",
            "language": "Python",
            "description": "Workflow: Test complete Unity script (high confidence expected)",
            "expected_behavior": "assert confidence >= 0.9",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
            "line_start": 256,
            "line_end": 297,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete Unity script (high confidence expected)'",
            "description": "'Test complete Unity script (high confidence expected)'",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert confidence >= 0.9",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '",
            "description": "Assign code = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lang, confidence = detector.detect_from_code(code)",
            "description": "Assign unknown = detector.detect_from_code(...)",
            "expected_result": null,
            "verification": "assert lang == 'csharp'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Unity Full Script",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_language_detector.py:256"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Backward Compatibility With Doc Scraper": [
      {
        "guide_id": "ab5381c4c49c",
        "title": "Backward Compatibility With Doc Scraper",
        "overview": "Workflow: Test that detector can be used as drop-in replacement",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "bs4",
          "skill_seekers.cli.language_detector"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "1bede1e3",
            "test_name": "test_backward_compatibility_with_doc_scraper",
            "category": "workflow",
            "code": "'Test that detector can be used as drop-in replacement'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\ncode = elem.get_text()\nlang, confidence = detector.detect_from_html(elem, code)\nassert isinstance(lang, str)\nassert isinstance(confidence, float)\nassert lang == 'python'\nassert 0.0 <= confidence <= 1.0",
            "language": "Python",
            "description": "Workflow: Test that detector can be used as drop-in replacement",
            "expected_behavior": "assert 0.0 <= confidence <= 1.0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
            "line_start": 688,
            "line_end": 705,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "bs4",
              "skill_seekers.cli.language_detector"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that detector can be used as drop-in replacement'",
            "description": "'Test that detector can be used as drop-in replacement'",
            "expected_result": null,
            "verification": "assert isinstance(lang, str)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "detector = LanguageDetector()",
            "description": "Assign detector = LanguageDetector(...)",
            "expected_result": null,
            "verification": "assert isinstance(confidence, float)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "html = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'",
            "description": "Assign html = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'",
            "expected_result": null,
            "verification": "assert lang == 'python'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "soup = BeautifulSoup(html, 'html.parser')",
            "description": "Assign soup = BeautifulSoup(...)",
            "expected_result": null,
            "verification": "assert 0.0 <= confidence <= 1.0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "elem = soup.find('code')",
            "description": "Assign elem = soup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "lang, confidence = detector.detect_from_html(elem, code)",
            "description": "Assign unknown = detector.detect_from_html(...)",
            "expected_result": null,
            "verification": "assert isinstance(lang, str)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Backward Compatibility With Doc Scraper",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_language_detector.py:688"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Local Provider Deterministic": [
      {
        "guide_id": "3c11a6471966",
        "title": "Local Provider Deterministic",
        "overview": "Workflow: Test local provider generates deterministic embeddings.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2f6a8729",
            "test_name": "test_local_provider_deterministic",
            "category": "workflow",
            "code": "'Test local provider generates deterministic embeddings.'\nprovider = LocalEmbeddingProvider(dimension=64)\ntext = 'same text'\nemb1 = provider.generate_embeddings([text])[0]\nemb2 = provider.generate_embeddings([text])[0]\nassert emb1 == emb2",
            "language": "Python",
            "description": "Workflow: Test local provider generates deterministic embeddings.",
            "expected_behavior": "assert emb1 == emb2",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 45,
            "line_end": 54,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test local provider generates deterministic embeddings.'",
            "description": "'Test local provider generates deterministic embeddings.'",
            "expected_result": null,
            "verification": "assert emb1 == emb2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "provider = LocalEmbeddingProvider(dimension=64)",
            "description": "Assign provider = LocalEmbeddingProvider(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = 'same text'",
            "description": "Assign text = 'same text'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "emb1 = provider.generate_embeddings([text])[0]",
            "description": "Assign emb1 = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "emb2 = provider.generate_embeddings([text])[0]",
            "description": "Assign emb2 = value",
            "expected_result": null,
            "verification": "assert emb1 == emb2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Local Provider Deterministic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:45"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cache Memory": [
      {
        "guide_id": "1a1efe6a58f7",
        "title": "Cache Memory",
        "overview": "Workflow: Test memory cache functionality.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a1116f14",
            "test_name": "test_cache_memory",
            "category": "workflow",
            "code": "'Test memory cache functionality.'\ncache = EmbeddingCache()\ntext = 'test text'\nmodel = 'test-model'\nembedding = [0.1, 0.2, 0.3]\ncache.set(text, model, embedding)\nretrieved = cache.get(text, model)\nassert retrieved == embedding",
            "language": "Python",
            "description": "Workflow: Test memory cache functionality.",
            "expected_behavior": "assert retrieved == embedding",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 65,
            "line_end": 77,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test memory cache functionality.'",
            "description": "'Test memory cache functionality.'",
            "expected_result": null,
            "verification": "assert retrieved == embedding",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "cache = EmbeddingCache()",
            "description": "Assign cache = EmbeddingCache(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = 'test text'",
            "description": "Assign text = 'test text'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "model = 'test-model'",
            "description": "Assign model = 'test-model'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "embedding = [0.1, 0.2, 0.3]",
            "description": "Assign embedding = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "cache.set(text, model, embedding)",
            "description": "Call cache.set()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "retrieved = cache.get(text, model)",
            "description": "Assign retrieved = cache.get(...)",
            "expected_result": null,
            "verification": "assert retrieved == embedding",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cache Memory",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_embedding_pipeline.py:65"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Pipeline Initialization": [
      {
        "guide_id": "f6c1921e5140",
        "title": "Pipeline Initialization",
        "overview": "Workflow: Test pipeline initialization.",
        "complexity_level": "beginner",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "25a65715",
            "test_name": "test_pipeline_initialization",
            "category": "workflow",
            "code": "'Test pipeline initialization.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128, batch_size=10)\npipeline = EmbeddingPipeline(config)\nassert pipeline.config == config\nassert pipeline.provider is not None\nassert pipeline.cache is not None",
            "language": "Python",
            "description": "Workflow: Test pipeline initialization.",
            "expected_behavior": "assert pipeline.cache is not None",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 125,
            "line_end": 133,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test pipeline initialization.'",
            "description": "'Test pipeline initialization.'",
            "expected_result": null,
            "verification": "assert pipeline.config == config",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=128, batch_size=10)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": "assert pipeline.provider is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": "assert pipeline.cache is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Pipeline Initialization",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_embedding_pipeline.py:125"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Pipeline Generate Batch": [
      {
        "guide_id": "b7ea572237d1",
        "title": "Pipeline Generate Batch",
        "overview": "Workflow: Test batch embedding generation.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c4af93c8",
            "test_name": "test_pipeline_generate_batch",
            "category": "workflow",
            "code": "'Test batch embedding generation.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=64, batch_size=2)\npipeline = EmbeddingPipeline(config)\ntexts = ['doc 1', 'doc 2', 'doc 3']\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert len(result.embeddings) == 3\nassert len(result.embeddings[0]) == 64\nassert result.generated_count == 3\nassert result.cached_count == 0",
            "language": "Python",
            "description": "Workflow: Test batch embedding generation.",
            "expected_behavior": "assert result.cached_count == 0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 136,
            "line_end": 148,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test batch embedding generation.'",
            "description": "'Test batch embedding generation.'",
            "expected_result": null,
            "verification": "assert len(result.embeddings) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=64, batch_size=2)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": "assert len(result.embeddings[0]) == 64",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": "assert result.generated_count == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "texts = ['doc 1', 'doc 2', 'doc 3']",
            "description": "Assign texts = value",
            "expected_result": null,
            "verification": "assert result.cached_count == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = pipeline.generate_batch(texts, show_progress=False)",
            "description": "Assign result = pipeline.generate_batch(...)",
            "expected_result": null,
            "verification": "assert len(result.embeddings) == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Pipeline Generate Batch",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:136"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Pipeline Batch Processing": [
      {
        "guide_id": "ad453b2f8bcd",
        "title": "Pipeline Batch Processing",
        "overview": "Workflow: Test large batch is processed in chunks.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "407de5a9",
            "test_name": "test_pipeline_batch_processing",
            "category": "workflow",
            "code": "'Test large batch is processed in chunks.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=16, batch_size=3)\npipeline = EmbeddingPipeline(config)\ntexts = [f'doc {i}' for i in range(10)]\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert len(result.embeddings) == 10",
            "language": "Python",
            "description": "Workflow: Test large batch is processed in chunks.",
            "expected_behavior": "assert len(result.embeddings) == 10",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 177,
            "line_end": 192,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test large batch is processed in chunks.'",
            "description": "'Test large batch is processed in chunks.'",
            "expected_result": null,
            "verification": "assert len(result.embeddings) == 10",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=16, batch_size=3)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "texts = [f'doc {i}' for i in range(10)]",
            "description": "Assign texts = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = pipeline.generate_batch(texts, show_progress=False)",
            "description": "Assign result = pipeline.generate_batch(...)",
            "expected_result": null,
            "verification": "assert len(result.embeddings) == 10",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Pipeline Batch Processing",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:177"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Validate Dimensions Valid": [
      {
        "guide_id": "37fd9bbe50ec",
        "title": "Validate Dimensions Valid",
        "overview": "Workflow: Test dimension validation with valid embeddings.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a837031b",
            "test_name": "test_validate_dimensions_valid",
            "category": "workflow",
            "code": "'Test dimension validation with valid embeddings.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128)\npipeline = EmbeddingPipeline(config)\nembeddings = [[0.1] * 128, [0.2] * 128]\nis_valid = pipeline.validate_dimensions(embeddings)\nassert is_valid",
            "language": "Python",
            "description": "Workflow: Test dimension validation with valid embeddings.",
            "expected_behavior": "assert is_valid",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 195,
            "line_end": 204,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test dimension validation with valid embeddings.'",
            "description": "'Test dimension validation with valid embeddings.'",
            "expected_result": null,
            "verification": "assert is_valid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=128)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "embeddings = [[0.1] * 128, [0.2] * 128]",
            "description": "Assign embeddings = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "is_valid = pipeline.validate_dimensions(embeddings)",
            "description": "Assign is_valid = pipeline.validate_dimensions(...)",
            "expected_result": null,
            "verification": "assert is_valid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Validate Dimensions Valid",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:195"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Validate Dimensions Invalid": [
      {
        "guide_id": "4875231c2831",
        "title": "Validate Dimensions Invalid",
        "overview": "Workflow: Test dimension validation with invalid embeddings.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d25ca695",
            "test_name": "test_validate_dimensions_invalid",
            "category": "workflow",
            "code": "'Test dimension validation with invalid embeddings.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128)\npipeline = EmbeddingPipeline(config)\nembeddings = [[0.1] * 64, [0.2] * 128]\nis_valid = pipeline.validate_dimensions(embeddings)\nassert not is_valid",
            "language": "Python",
            "description": "Workflow: Test dimension validation with invalid embeddings.",
            "expected_behavior": "assert not is_valid",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 207,
            "line_end": 217,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test dimension validation with invalid embeddings.'",
            "description": "'Test dimension validation with invalid embeddings.'",
            "expected_result": null,
            "verification": "assert not is_valid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=128)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "embeddings = [[0.1] * 64, [0.2] * 128]",
            "description": "Assign embeddings = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "is_valid = pipeline.validate_dimensions(embeddings)",
            "description": "Assign is_valid = pipeline.validate_dimensions(...)",
            "expected_result": null,
            "verification": "assert not is_valid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Validate Dimensions Invalid",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:207"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Embedding Result Metadata": [
      {
        "guide_id": "288718cc914a",
        "title": "Embedding Result Metadata",
        "overview": "Workflow: Test embedding result includes metadata.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "93a3469f",
            "test_name": "test_embedding_result_metadata",
            "category": "workflow",
            "code": "'Test embedding result includes metadata.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=256)\npipeline = EmbeddingPipeline(config)\ntexts = ['test']\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert 'provider' in result.metadata\nassert 'model' in result.metadata\nassert 'dimension' in result.metadata\nassert result.metadata['dimension'] == 256",
            "language": "Python",
            "description": "Workflow: Test embedding result includes metadata.",
            "expected_behavior": "assert result.metadata['dimension'] == 256",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 220,
            "line_end": 232,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test embedding result includes metadata.'",
            "description": "'Test embedding result includes metadata.'",
            "expected_result": null,
            "verification": "assert 'provider' in result.metadata",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=256)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": "assert 'model' in result.metadata",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": "assert 'dimension' in result.metadata",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "texts = ['test']",
            "description": "Assign texts = value",
            "expected_result": null,
            "verification": "assert result.metadata['dimension'] == 256",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = pipeline.generate_batch(texts, show_progress=False)",
            "description": "Assign result = pipeline.generate_batch(...)",
            "expected_result": null,
            "verification": "assert 'provider' in result.metadata",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Embedding Result Metadata",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:220"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cost Stats": [
      {
        "guide_id": "0032a327212e",
        "title": "Cost Stats",
        "overview": "Workflow: Test cost statistics tracking.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.embedding_pipeline"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "98b546c7",
            "test_name": "test_cost_stats",
            "category": "workflow",
            "code": "'Test cost statistics tracking.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=64)\npipeline = EmbeddingPipeline(config)\ntexts = ['doc 1', 'doc 2']\npipeline.generate_batch(texts, show_progress=False)\nstats = pipeline.get_cost_stats()\nassert 'total_requests' in stats\nassert 'cache_hits' in stats\nassert 'estimated_cost' in stats",
            "language": "Python",
            "description": "Workflow: Test cost statistics tracking.",
            "expected_behavior": "assert 'estimated_cost' in stats",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
            "line_start": 235,
            "line_end": 248,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.embedding_pipeline"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test cost statistics tracking.'",
            "description": "'Test cost statistics tracking.'",
            "expected_result": null,
            "verification": "assert 'total_requests' in stats",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=64)",
            "description": "Assign config = EmbeddingConfig(...)",
            "expected_result": null,
            "verification": "assert 'cache_hits' in stats",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "pipeline = EmbeddingPipeline(config)",
            "description": "Assign pipeline = EmbeddingPipeline(...)",
            "expected_result": null,
            "verification": "assert 'estimated_cost' in stats",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "texts = ['doc 1', 'doc 2']",
            "description": "Assign texts = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "pipeline.generate_batch(texts, show_progress=False)",
            "description": "Call pipeline.generate_batch()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "stats = pipeline.get_cost_stats()",
            "description": "Assign stats = pipeline.get_cost_stats(...)",
            "expected_result": null,
            "verification": "assert 'total_requests' in stats",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cost Stats",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_embedding_pipeline.py:235"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Categorize Issues Basic": [
      {
        "guide_id": "2675d0c07dc9",
        "title": "Categorize Issues Basic",
        "overview": "Workflow: Test basic issue categorization.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ad900c24",
            "test_name": "test_categorize_issues_basic",
            "category": "workflow",
            "code": "'Test basic issue categorization.'\nproblems = [{'title': 'OAuth setup fails', 'labels': ['bug', 'oauth'], 'number': 1, 'state': 'open', 'comments': 10}, {'title': 'Testing framework issue', 'labels': ['testing'], 'number': 2, 'state': 'open', 'comments': 5}]\nsolutions = [{'title': 'Fixed OAuth redirect', 'labels': ['oauth'], 'number': 3, 'state': 'closed', 'comments': 3}]\ntopics = ['oauth', 'testing', 'async']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized\nassert len(categorized['oauth']) == 2\nassert 'testing' in categorized\nassert len(categorized['testing']) == 1",
            "language": "Python",
            "description": "Workflow: Test basic issue categorization.",
            "expected_behavior": "assert len(categorized['testing']) == 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 24,
            "line_end": 59,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic issue categorization.'",
            "description": "'Test basic issue categorization.'",
            "expected_result": null,
            "verification": "assert 'oauth' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "problems = [{'title': 'OAuth setup fails', 'labels': ['bug', 'oauth'], 'number': 1, 'state': 'open', 'comments': 10}, {'title': 'Testing framework issue', 'labels': ['testing'], 'number': 2, 'state': 'open', 'comments': 5}]",
            "description": "Assign problems = value",
            "expected_result": null,
            "verification": "assert len(categorized['oauth']) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "solutions = [{'title': 'Fixed OAuth redirect', 'labels': ['oauth'], 'number': 3, 'state': 'closed', 'comments': 3}]",
            "description": "Assign solutions = value",
            "expected_result": null,
            "verification": "assert 'testing' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "topics = ['oauth', 'testing', 'async']",
            "description": "Assign topics = value",
            "expected_result": null,
            "verification": "assert len(categorized['testing']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
            "description": "Assign categorized = categorize_issues_by_topic(...)",
            "expected_result": null,
            "verification": "assert 'oauth' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Categorize Issues Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_merge_sources_github.py:24"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Hybrid Content Basic": [
      {
        "guide_id": "205a97313313",
        "title": "Generate Hybrid Content Basic",
        "overview": "Workflow: Test basic hybrid content generation.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "90f3d018",
            "test_name": "test_generate_hybrid_content_basic",
            "category": "workflow",
            "code": "'Test basic hybrid content generation.'\napi_data = {'apis': {'oauth_login': {'name': 'oauth_login', 'status': 'matched'}}, 'summary': {'total_apis': 1}}\ngithub_docs = {'readme': '# Project README', 'contributing': None, 'docs_files': [{'path': 'docs/oauth.md', 'content': 'OAuth guide'}]}\ngithub_insights = {'metadata': {'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'Test project'}, 'common_problems': [{'title': 'OAuth fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug']}], 'known_solutions': [{'title': 'Fixed OAuth', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], 'top_labels': [{'label': 'bug', 'count': 10}, {'label': 'enhancement', 'count': 5}]}\nconflicts = []\nhybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)\nassert 'api_reference' in hybrid\nassert 'github_context' in hybrid\nassert 'conflict_summary' in hybrid\nassert 'issue_links' in hybrid\nassert hybrid['github_context']['docs']['readme'] == '# Project README'\nassert hybrid['github_context']['docs']['docs_files_count'] == 1\nassert hybrid['github_context']['metadata']['stars'] == 1234\nassert hybrid['github_context']['metadata']['language'] == 'Python'\nassert hybrid['github_context']['issues']['common_problems_count'] == 1\nassert hybrid['github_context']['issues']['known_solutions_count'] == 1\nassert len(hybrid['github_context']['issues']['top_problems']) == 1\nassert len(hybrid['github_context']['top_labels']) == 2",
            "language": "Python",
            "description": "Workflow: Test basic hybrid content generation.",
            "expected_behavior": "assert len(hybrid['github_context']['top_labels']) == 2",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 133,
            "line_end": 194,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic hybrid content generation.'",
            "description": "'Test basic hybrid content generation.'",
            "expected_result": null,
            "verification": "assert 'api_reference' in hybrid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "api_data = {'apis': {'oauth_login': {'name': 'oauth_login', 'status': 'matched'}}, 'summary': {'total_apis': 1}}",
            "description": "Assign api_data = value",
            "expected_result": null,
            "verification": "assert 'github_context' in hybrid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_docs = {'readme': '# Project README', 'contributing': None, 'docs_files': [{'path': 'docs/oauth.md', 'content': 'OAuth guide'}]}",
            "description": "Assign github_docs = value",
            "expected_result": null,
            "verification": "assert 'conflict_summary' in hybrid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "github_insights = {'metadata': {'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'Test project'}, 'common_problems': [{'title': 'OAuth fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug']}], 'known_solutions': [{'title': 'Fixed OAuth', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], 'top_labels': [{'label': 'bug', 'count': 10}, {'label': 'enhancement', 'count': 5}]}",
            "description": "Assign github_insights = value",
            "expected_result": null,
            "verification": "assert 'issue_links' in hybrid",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = []",
            "description": "Assign conflicts = value",
            "expected_result": null,
            "verification": "assert hybrid['github_context']['docs']['readme'] == '# Project README'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "hybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)",
            "description": "Assign hybrid = generate_hybrid_content(...)",
            "expected_result": null,
            "verification": "assert hybrid['github_context']['docs']['docs_files_count'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Hybrid Content Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_merge_sources_github.py:133"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Hybrid Content With Conflicts": [
      {
        "guide_id": "992cc9e319e0",
        "title": "Generate Hybrid Content With Conflicts",
        "overview": "Workflow: Test hybrid content with conflicts.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "06f6dd43",
            "test_name": "test_generate_hybrid_content_with_conflicts",
            "category": "workflow",
            "code": "'Test hybrid content with conflicts.'\napi_data = {'apis': {}, 'summary': {}}\ngithub_docs = None\ngithub_insights = None\nconflicts = [Conflict(api_name='test_api', type='signature_mismatch', severity='medium', difference='Parameter count differs', docs_info={'parameters': ['a', 'b']}, code_info={'parameters': ['a', 'b', 'c']}), Conflict(api_name='test_api_2', type='missing_in_docs', severity='low', difference='API not documented', docs_info=None, code_info={'name': 'test_api_2'})]\nhybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)\nassert hybrid['conflict_summary']['total_conflicts'] == 2\nassert hybrid['conflict_summary']['by_type']['signature_mismatch'] == 1\nassert hybrid['conflict_summary']['by_type']['missing_in_docs'] == 1\nassert hybrid['conflict_summary']['by_severity']['medium'] == 1\nassert hybrid['conflict_summary']['by_severity']['low'] == 1",
            "language": "Python",
            "description": "Workflow: Test hybrid content with conflicts.",
            "expected_behavior": "assert hybrid['conflict_summary']['by_severity']['low'] == 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 196,
            "line_end": 228,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test hybrid content with conflicts.'",
            "description": "'Test hybrid content with conflicts.'",
            "expected_result": null,
            "verification": "assert hybrid['conflict_summary']['total_conflicts'] == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "api_data = {'apis': {}, 'summary': {}}",
            "description": "Assign api_data = value",
            "expected_result": null,
            "verification": "assert hybrid['conflict_summary']['by_type']['signature_mismatch'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_docs = None",
            "description": "Assign github_docs = None",
            "expected_result": null,
            "verification": "assert hybrid['conflict_summary']['by_type']['missing_in_docs'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "github_insights = None",
            "description": "Assign github_insights = None",
            "expected_result": null,
            "verification": "assert hybrid['conflict_summary']['by_severity']['medium'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "conflicts = [Conflict(api_name='test_api', type='signature_mismatch', severity='medium', difference='Parameter count differs', docs_info={'parameters': ['a', 'b']}, code_info={'parameters': ['a', 'b', 'c']}), Conflict(api_name='test_api_2', type='missing_in_docs', severity='low', difference='API not documented', docs_info=None, code_info={'name': 'test_api_2'})]",
            "description": "Assign conflicts = value",
            "expected_result": null,
            "verification": "assert hybrid['conflict_summary']['by_severity']['low'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "hybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)",
            "description": "Assign hybrid = generate_hybrid_content(...)",
            "expected_result": null,
            "verification": "assert hybrid['conflict_summary']['total_conflicts'] == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Hybrid Content With Conflicts",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_merge_sources_github.py:196"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Match Issues To Apis Basic": [
      {
        "guide_id": "3c0dca885171",
        "title": "Match Issues To Apis Basic",
        "overview": "Workflow: Test basic issue to API matching.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [
          "api_client"
        ],
        "workflows": [
          {
            "example_id": "4a327bf9",
            "test_name": "test_match_issues_to_apis_basic",
            "category": "workflow",
            "code": "'Test basic issue to API matching.'\napis = {'oauth_login': {'name': 'oauth_login'}, 'async_fetch': {'name': 'async_fetch'}}\nproblems = [{'title': 'OAuth login fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug', 'oauth']}]\nsolutions = [{'title': 'Fixed async fetch timeout', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['async']}]\nissue_links = _match_issues_to_apis(apis, problems, solutions)\nassert 'oauth_login' in issue_links\nassert len(issue_links['oauth_login']) == 1\nassert issue_links['oauth_login'][0]['number'] == 42\nassert 'async_fetch' in issue_links\nassert len(issue_links['async_fetch']) == 1\nassert issue_links['async_fetch'][0]['number'] == 35",
            "language": "Python",
            "description": "Workflow: Test basic issue to API matching.",
            "expected_behavior": "assert issue_links['async_fetch'][0]['number'] == 35",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 246,
            "line_end": 280,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic issue to API matching.'",
            "description": "'Test basic issue to API matching.'",
            "expected_result": null,
            "verification": "assert 'oauth_login' in issue_links",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "apis = {'oauth_login': {'name': 'oauth_login'}, 'async_fetch': {'name': 'async_fetch'}}",
            "description": "Assign apis = value",
            "expected_result": null,
            "verification": "assert len(issue_links['oauth_login']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "problems = [{'title': 'OAuth login fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug', 'oauth']}]",
            "description": "Assign problems = value",
            "expected_result": null,
            "verification": "assert issue_links['oauth_login'][0]['number'] == 42",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "solutions = [{'title': 'Fixed async fetch timeout', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['async']}]",
            "description": "Assign solutions = value",
            "expected_result": null,
            "verification": "assert 'async_fetch' in issue_links",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "issue_links = _match_issues_to_apis(apis, problems, solutions)",
            "description": "Assign issue_links = _match_issues_to_apis(...)",
            "expected_result": null,
            "verification": "assert len(issue_links['async_fetch']) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Match Issues To Apis Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_merge_sources_github.py:246"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Merger With Github Streams": [
      {
        "guide_id": "56faf7802e20",
        "title": "Merger With Github Streams",
        "overview": "Workflow: Test merger with three-stream GitHub data.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ca735931",
            "test_name": "test_merger_with_github_streams",
            "category": "workflow",
            "code": "'Test merger with three-stream GitHub data.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\nconflicts = []\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# README', contributing='# Contributing', docs_files=[{'path': 'docs/guide.md', 'content': 'Guide content'}])\ninsights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python'}, common_problems=[{'title': 'Bug 1', 'number': 1, 'state': 'open', 'comments': 10, 'labels': ['bug']}], known_solutions=[{'title': 'Fix 1', 'number': 2, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], top_labels=[{'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)\nassert merger.github_streams is not None\nassert merger.github_docs is not None\nassert merger.github_insights is not None\nassert merger.github_docs['readme'] == '# README'\nassert merger.github_insights['metadata']['stars'] == 1234",
            "language": "Python",
            "description": "Workflow: Test merger with three-stream GitHub data.",
            "expected_behavior": "assert merger.github_insights['metadata']['stars'] == 1234",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 325,
            "line_end": 357,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test merger with three-stream GitHub data.'",
            "description": "'Test merger with three-stream GitHub data.'",
            "expected_result": null,
            "verification": "assert merger.github_streams is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': []}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert merger.github_docs is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'apis': {}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert merger.github_insights is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "conflicts = []",
            "description": "Assign conflicts = value",
            "expected_result": null,
            "verification": "assert merger.github_docs['readme'] == '# README'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": "assert merger.github_insights['metadata']['stars'] == 1234",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "docs_stream = DocsStream(readme='# README', contributing='# Contributing', docs_files=[{'path': 'docs/guide.md', 'content': 'Guide content'}])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "insights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python'}, common_problems=[{'title': 'Bug 1', 'number': 1, 'state': 'open', 'comments': 10, 'labels': ['bug']}], known_solutions=[{'title': 'Fix 1', 'number': 2, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], top_labels=[{'label': 'bug', 'count': 10}])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": "assert merger.github_streams is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Merger With Github Streams",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_merge_sources_github.py:325"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Merger Merge All With Streams": [
      {
        "guide_id": "f611624daf53",
        "title": "Merger Merge All With Streams",
        "overview": "Workflow: Test merge_all() with GitHub streams.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e819cbda",
            "test_name": "test_merger_merge_all_with_streams",
            "category": "workflow",
            "code": "'Test merge_all() with GitHub streams.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\nconflicts = []\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# README', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 500}, common_problems=[], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)\nresult = merger.merge_all()\nassert 'github_context' in result\nassert 'conflict_summary' in result\nassert 'issue_links' in result\nassert result['github_context']['metadata']['stars'] == 500",
            "language": "Python",
            "description": "Workflow: Test merge_all() with GitHub streams.",
            "expected_behavior": "assert result['github_context']['metadata']['stars'] == 500",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 359,
            "line_end": 381,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test merge_all() with GitHub streams.'",
            "description": "'Test merge_all() with GitHub streams.'",
            "expected_result": null,
            "verification": "assert 'github_context' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': []}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert 'conflict_summary' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'apis': {}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert 'issue_links' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "conflicts = []",
            "description": "Assign conflicts = value",
            "expected_result": null,
            "verification": "assert result['github_context']['metadata']['stars'] == 500",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "docs_stream = DocsStream(readme='# README', contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "insights_stream = InsightsStream(metadata={'stars': 500}, common_problems=[], known_solutions=[], top_labels=[])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "result = merger.merge_all()",
            "description": "Assign result = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert 'github_context' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Merger Merge All With Streams",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_merge_sources_github.py:359"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Full Pipeline With Streams": [
      {
        "guide_id": "8a4d91b38f5a",
        "title": "Full Pipeline With Streams",
        "overview": "Workflow: Test complete pipeline with three-stream data.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "skill_seekers.cli.conflict_detector",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "01f0d76f",
            "test_name": "test_full_pipeline_with_streams",
            "category": "workflow",
            "code": "'Test complete pipeline with three-stream data.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test Project\\n\\nA test project.', contributing='# Contributing\\n\\nPull requests welcome.', docs_files=[{'path': 'docs/quickstart.md', 'content': '# Quick Start'}, {'path': 'docs/api.md', 'content': '# API Reference'}])\ninsights_stream = InsightsStream(metadata={'stars': 2500, 'forks': 123, 'language': 'Python', 'description': 'Test framework'}, common_problems=[{'title': 'Installation fails on Windows', 'number': 150, 'state': 'open', 'comments': 25, 'labels': ['bug', 'windows']}, {'title': 'Memory leak in async mode', 'number': 142, 'state': 'open', 'comments': 18, 'labels': ['bug', 'async']}], known_solutions=[{'title': 'Fixed config loading', 'number': 130, 'state': 'closed', 'comments': 8, 'labels': ['bug']}, {'title': 'Resolved OAuth timeout', 'number': 125, 'state': 'closed', 'comments': 12, 'labels': ['oauth']}], top_labels=[{'label': 'bug', 'count': 45}, {'label': 'enhancement', 'count': 20}, {'label': 'question', 'count': 15}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, [], github_streams)\nresult = merger.merge_all()\nassert 'apis' in result\nassert 'github_context' in result\ngh_context = result['github_context']\nassert gh_context['docs']['readme'] == '# Test Project\\n\\nA test project.'\nassert gh_context['docs']['contributing'] == '# Contributing\\n\\nPull requests welcome.'\nassert gh_context['docs']['docs_files_count'] == 2\nassert gh_context['metadata']['stars'] == 2500\nassert gh_context['metadata']['language'] == 'Python'\nassert gh_context['issues']['common_problems_count'] == 2\nassert gh_context['issues']['known_solutions_count'] == 2\nassert len(gh_context['issues']['top_problems']) == 2\nassert len(gh_context['issues']['top_solutions']) == 2\nassert len(gh_context['top_labels']) == 3\nassert 'conflict_summary' in result\nassert result['conflict_summary']['total_conflicts'] == 0",
            "language": "Python",
            "description": "Workflow: Test complete pipeline with three-stream data.",
            "expected_behavior": "assert result['conflict_summary']['total_conflicts'] == 0",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
            "line_start": 407,
            "line_end": 495,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "skill_seekers.cli.conflict_detector",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete pipeline with three-stream data.'",
            "description": "'Test complete pipeline with three-stream data.'",
            "expected_result": null,
            "verification": "assert 'apis' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "docs_data = {'pages': []}",
            "description": "Assign docs_data = value",
            "expected_result": null,
            "verification": "assert 'github_context' in result",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_data = {'apis': {}}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert gh_context['docs']['readme'] == '# Test Project\\n\\nA test project.'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": "assert gh_context['docs']['contributing'] == '# Contributing\\n\\nPull requests welcome.'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme='# Test Project\\n\\nA test project.', contributing='# Contributing\\n\\nPull requests welcome.', docs_files=[{'path': 'docs/quickstart.md', 'content': '# Quick Start'}, {'path': 'docs/api.md', 'content': '# API Reference'}])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": "assert gh_context['docs']['docs_files_count'] == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={'stars': 2500, 'forks': 123, 'language': 'Python', 'description': 'Test framework'}, common_problems=[{'title': 'Installation fails on Windows', 'number': 150, 'state': 'open', 'comments': 25, 'labels': ['bug', 'windows']}, {'title': 'Memory leak in async mode', 'number': 142, 'state': 'open', 'comments': 18, 'labels': ['bug', 'async']}], known_solutions=[{'title': 'Fixed config loading', 'number': 130, 'state': 'closed', 'comments': 8, 'labels': ['bug']}, {'title': 'Resolved OAuth timeout', 'number': 125, 'state': 'closed', 'comments': 12, 'labels': ['oauth']}], top_labels=[{'label': 'bug', 'count': 45}, {'label': 'enhancement', 'count': 20}, {'label': 'question', 'count': 15}])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": "assert gh_context['metadata']['stars'] == 2500",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": "assert gh_context['metadata']['language'] == 'Python'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "merger = RuleBasedMerger(docs_data, github_data, [], github_streams)",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": "assert gh_context['issues']['common_problems_count'] == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "result = merger.merge_all()",
            "description": "Assign result = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert gh_context['issues']['known_solutions_count'] == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "gh_context = result['github_context']",
            "description": "Assign gh_context = value",
            "expected_result": null,
            "verification": "assert len(gh_context['issues']['top_problems']) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Full Pipeline With Streams",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_merge_sources_github.py:407"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Benchmark Format Skill Md All Adaptors": [
      {
        "guide_id": "bfd723729c5e",
        "title": "Benchmark Format Skill Md All Adaptors",
        "overview": "Workflow: Benchmark format_skill_md across all adaptors",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "tempfile",
          "time",
          "unittest",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "03aa860a",
            "test_name": "test_benchmark_format_skill_md_all_adaptors",
            "category": "workflow",
            "code": "'Benchmark format_skill_md across all adaptors'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: format_skill_md() - All Adaptors')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nmetadata = SkillMetadata(name='benchmark', description='Benchmark test')\nplatforms = ['claude', 'gemini', 'openai', 'markdown', 'langchain', 'llama-index', 'haystack', 'weaviate', 'chroma', 'faiss', 'qdrant']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    adaptor.format_skill_md(skill_dir, metadata)\n    times = []\n    for _ in range(5):\n        start = time.perf_counter()\n        formatted = adaptor.format_skill_md(skill_dir, metadata)\n        end = time.perf_counter()\n        times.append(end - start)\n        self.assertIsInstance(formatted, str)\n        self.assertGreater(len(formatted), 0)\n    avg_time = sum(times) / len(times)\n    min_time = min(times)\n    max_time = max(times)\n    results[platform] = {'avg': avg_time, 'min': min_time, 'max': max_time}\n    print(f'{platform:15} - Avg: {avg_time * 1000:6.2f}ms | Min: {min_time * 1000:6.2f}ms | Max: {max_time * 1000:6.2f}ms')\nfor platform, metrics in results.items():\n    self.assertLess(metrics['avg'], 0.5, f\"{platform} format_skill_md too slow: {metrics['avg'] * 1000:.2f}ms\")",
            "language": "Python",
            "description": "Workflow: Benchmark format_skill_md across all adaptors",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
            "line_start": 76,
            "line_end": 139,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tempfile",
              "time",
              "unittest",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Benchmark format_skill_md across all adaptors'",
            "description": "'Benchmark format_skill_md across all adaptors'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "print('\\n' + '=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "print('BENCHMARK: format_skill_md() - All Adaptors')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "print('=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_dir = self._create_skill_with_n_references(10)",
            "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "metadata = SkillMetadata(name='benchmark', description='Benchmark test')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "platforms = ['claude', 'gemini', 'openai', 'markdown', 'langchain', 'llama-index', 'haystack', 'weaviate', 'chroma', 'faiss', 'qdrant']",
            "description": "Assign platforms = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "results = {}",
            "description": "Assign results = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "adaptor.format_skill_md(skill_dir, metadata)",
            "description": "Call adaptor.format_skill_md()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "times = []",
            "description": "Assign times = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "avg_time = sum(times) / len(times)",
            "description": "Assign avg_time = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "min_time = min(times)",
            "description": "Assign min_time = min(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "max_time = max(times)",
            "description": "Assign max_time = max(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "results[platform] = {'avg': avg_time, 'min': min_time, 'max': max_time}",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "print(f'{platform:15} - Avg: {avg_time * 1000:6.2f}ms | Min: {min_time * 1000:6.2f}ms | Max: {max_time * 1000:6.2f}ms')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "self.assertLess(metrics['avg'], 0.5, f\"{platform} format_skill_md too slow: {metrics['avg'] * 1000:.2f}ms\")",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 19,
            "code": "formatted = adaptor.format_skill_md(skill_dir, metadata)",
            "description": "Assign formatted = adaptor.format_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 20,
            "code": "end = time.perf_counter()",
            "description": "Assign end = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 21,
            "code": "times.append(end - start)",
            "description": "Call times.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 22,
            "code": "self.assertIsInstance(formatted, str)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 23,
            "code": "self.assertGreater(len(formatted), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Benchmark Format Skill Md All Adaptors",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptor_benchmarks.py:76"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Benchmark Package Operations": [
      {
        "guide_id": "f3576d17e219",
        "title": "Benchmark Package Operations",
        "overview": "Workflow: Benchmark complete package operation",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "tempfile",
          "time",
          "unittest",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2af4f94a",
            "test_name": "test_benchmark_package_operations",
            "category": "workflow",
            "code": "'Benchmark complete package operation'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: package() - Complete Operation')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nplatforms = ['claude', 'langchain', 'chroma', 'weaviate', 'faiss']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    start = time.perf_counter()\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    end = time.perf_counter()\n    elapsed = end - start\n    file_size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'time': elapsed, 'size_kb': file_size_kb}\n    print(f'{platform:15} - Time: {elapsed * 1000:7.2f}ms | Size: {file_size_kb:7.1f} KB')\n    self.assertTrue(package_path.exists())\nfor platform, metrics in results.items():\n    self.assertLess(metrics['time'], 1.0, f\"{platform} packaging too slow: {metrics['time'] * 1000:.2f}ms\")\n    self.assertLess(metrics['size_kb'], 1000, f\"{platform} package too large: {metrics['size_kb']:.1f}KB\")",
            "language": "Python",
            "description": "Workflow: Benchmark complete package operation",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
            "line_start": 141,
            "line_end": 186,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tempfile",
              "time",
              "unittest",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Benchmark complete package operation'",
            "description": "'Benchmark complete package operation'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "print('\\n' + '=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "print('BENCHMARK: package() - Complete Operation')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "print('=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_dir = self._create_skill_with_n_references(10)",
            "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "platforms = ['claude', 'langchain', 'chroma', 'weaviate', 'faiss']",
            "description": "Assign platforms = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "results = {}",
            "description": "Assign results = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "package_path = adaptor.package(skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "end = time.perf_counter()",
            "description": "Assign end = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "elapsed = end - start",
            "description": "Assign elapsed = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "file_size_kb = package_path.stat().st_size / 1024",
            "description": "Assign file_size_kb = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "results[platform] = {'time': elapsed, 'size_kb': file_size_kb}",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "print(f'{platform:15} - Time: {elapsed * 1000:7.2f}ms | Size: {file_size_kb:7.1f} KB')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "self.assertTrue(package_path.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "self.assertLess(metrics['time'], 1.0, f\"{platform} packaging too slow: {metrics['time'] * 1000:.2f}ms\")",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "self.assertLess(metrics['size_kb'], 1000, f\"{platform} package too large: {metrics['size_kb']:.1f}KB\")",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Benchmark Package Operations",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptor_benchmarks.py:141"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Benchmark Scaling With Reference Count": [
      {
        "guide_id": "767a6ec40cc6",
        "title": "Benchmark Scaling With Reference Count",
        "overview": "Workflow: Test how performance scales with reference count",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "tempfile",
          "time",
          "unittest",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "779840e9",
            "test_name": "test_benchmark_scaling_with_reference_count",
            "category": "workflow",
            "code": "'Test how performance scales with reference count'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Scaling with Reference Count')\nprint('=' * 80)\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='scaling_test', description='Scaling benchmark test')\nreference_counts = [1, 5, 10, 25, 50]\nresults = []\nprint(f\"\\n{'Refs':>4} | {'Time (ms)':>10} | {'Time/Ref':>10} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor ref_count in reference_counts:\n    skill_dir = self._create_skill_with_n_references(ref_count)\n    start = time.perf_counter()\n    formatted = adaptor.format_skill_md(skill_dir, metadata)\n    end = time.perf_counter()\n    elapsed = end - start\n    time_per_ref = elapsed / ref_count\n    json.loads(formatted)\n    size_kb = len(formatted) / 1024\n    results.append({'count': ref_count, 'time': elapsed, 'time_per_ref': time_per_ref, 'size_kb': size_kb})\n    print(f'{ref_count:4} | {elapsed * 1000:10.2f} | {time_per_ref * 1000:10.3f} | {size_kb:10.1f}')\nfirst_per_ref = results[0]['time_per_ref']\nlast_per_ref = results[-1]['time_per_ref']\nscaling_factor = last_per_ref / first_per_ref\nprint(f'\\nScaling Factor: {scaling_factor:.2f}x')\nprint(f'(Time per ref at 50 refs / Time per ref at 1 ref)')\nself.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
            "language": "Python",
            "description": "Workflow: Test how performance scales with reference count",
            "expected_behavior": "self.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
            "line_start": 188,
            "line_end": 243,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tempfile",
              "time",
              "unittest",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test how performance scales with reference count'",
            "description": "'Test how performance scales with reference count'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "print('\\n' + '=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "print('BENCHMARK: Scaling with Reference Count')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "print('=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "adaptor = get_adaptor('langchain')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "metadata = SkillMetadata(name='scaling_test', description='Scaling benchmark test')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "reference_counts = [1, 5, 10, 25, 50]",
            "description": "Assign reference_counts = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "results = []",
            "description": "Assign results = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "print(f\"\\n{'Refs':>4} | {'Time (ms)':>10} | {'Time/Ref':>10} | {'Size (KB)':>10}\")",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "print('-' * 50)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "first_per_ref = results[0]['time_per_ref']",
            "description": "Assign first_per_ref = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "last_per_ref = results[-1]['time_per_ref']",
            "description": "Assign last_per_ref = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "scaling_factor = last_per_ref / first_per_ref",
            "description": "Assign scaling_factor = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "print(f'\\nScaling Factor: {scaling_factor:.2f}x')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "print(f'(Time per ref at 50 refs / Time per ref at 1 ref)')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "self.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "skill_dir = self._create_skill_with_n_references(ref_count)",
            "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 19,
            "code": "formatted = adaptor.format_skill_md(skill_dir, metadata)",
            "description": "Assign formatted = adaptor.format_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 20,
            "code": "end = time.perf_counter()",
            "description": "Assign end = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 21,
            "code": "elapsed = end - start",
            "description": "Assign elapsed = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 22,
            "code": "time_per_ref = elapsed / ref_count",
            "description": "Assign time_per_ref = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 23,
            "code": "json.loads(formatted)",
            "description": "Call json.loads()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 24,
            "code": "size_kb = len(formatted) / 1024",
            "description": "Assign size_kb = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 25,
            "code": "results.append({'count': ref_count, 'time': elapsed, 'time_per_ref': time_per_ref, 'size_kb': size_kb})",
            "description": "Call results.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 26,
            "code": "print(f'{ref_count:4} | {elapsed * 1000:10.2f} | {time_per_ref * 1000:10.3f} | {size_kb:10.1f}')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Benchmark Scaling With Reference Count",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptor_benchmarks.py:188"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Benchmark Json Vs Zip Size Comparison": [
      {
        "guide_id": "be770dd96ae5",
        "title": "Benchmark Json Vs Zip Size Comparison",
        "overview": "Workflow: Compare output sizes: JSON vs ZIP/tar.gz",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "tempfile",
          "time",
          "unittest",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ac4a4955",
            "test_name": "test_benchmark_json_vs_zip_size_comparison",
            "category": "workflow",
            "code": "'Compare output sizes: JSON vs ZIP/tar.gz'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Output Size Comparison')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nformats = {'claude': ('ZIP', '.zip'), 'gemini': ('tar.gz', '.tar.gz'), 'langchain': ('JSON', '.json'), 'weaviate': ('JSON', '.json')}\nresults = {}\nprint(f\"\\n{'Platform':15} | {'Format':8} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor platform, (format_name, ext) in formats.items():\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'format': format_name, 'size_kb': size_kb}\n    print(f'{platform:15} | {format_name:8} | {size_kb:10.1f}')\njson_sizes = [v['size_kb'] for k, v in results.items() if v['format'] == 'JSON']\ncompressed_sizes = [v['size_kb'] for k, v in results.items() if v['format'] in ['ZIP', 'tar.gz']]\nif json_sizes and compressed_sizes:\n    avg_json = sum(json_sizes) / len(json_sizes)\n    avg_compressed = sum(compressed_sizes) / len(compressed_sizes)\n    print(f'\\nAverage JSON size: {avg_json:.1f} KB')\n    print(f'Average compressed size: {avg_compressed:.1f} KB')\n    print(f'Compression ratio: {avg_json / avg_compressed:.2f}x')",
            "language": "Python",
            "description": "Workflow: Compare output sizes: JSON vs ZIP/tar.gz",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
            "line_start": 245,
            "line_end": 289,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tempfile",
              "time",
              "unittest",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Compare output sizes: JSON vs ZIP/tar.gz'",
            "description": "'Compare output sizes: JSON vs ZIP/tar.gz'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "print('\\n' + '=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "print('BENCHMARK: Output Size Comparison')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "print('=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_dir = self._create_skill_with_n_references(10)",
            "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "formats = {'claude': ('ZIP', '.zip'), 'gemini': ('tar.gz', '.tar.gz'), 'langchain': ('JSON', '.json'), 'weaviate': ('JSON', '.json')}",
            "description": "Assign formats = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "results = {}",
            "description": "Assign results = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "print(f\"\\n{'Platform':15} | {'Format':8} | {'Size (KB)':>10}\")",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "print('-' * 50)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "json_sizes = [v['size_kb'] for k, v in results.items() if v['format'] == 'JSON']",
            "description": "Assign json_sizes = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "compressed_sizes = [v['size_kb'] for k, v in results.items() if v['format'] in ['ZIP', 'tar.gz']]",
            "description": "Assign compressed_sizes = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "package_path = adaptor.package(skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "size_kb = package_path.stat().st_size / 1024",
            "description": "Assign size_kb = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "results[platform] = {'format': format_name, 'size_kb': size_kb}",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "print(f'{platform:15} | {format_name:8} | {size_kb:10.1f}')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "avg_json = sum(json_sizes) / len(json_sizes)",
            "description": "Assign avg_json = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "avg_compressed = sum(compressed_sizes) / len(compressed_sizes)",
            "description": "Assign avg_compressed = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 19,
            "code": "print(f'\\nAverage JSON size: {avg_json:.1f} KB')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 20,
            "code": "print(f'Average compressed size: {avg_compressed:.1f} KB')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 21,
            "code": "print(f'Compression ratio: {avg_json / avg_compressed:.2f}x')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Benchmark Json Vs Zip Size Comparison",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptor_benchmarks.py:245"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Benchmark Metadata Overhead": [
      {
        "guide_id": "3a69022c7418",
        "title": "Benchmark Metadata Overhead",
        "overview": "Workflow: Measure metadata processing overhead",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tempfile",
          "time",
          "unittest",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "eed3ef32",
            "test_name": "test_benchmark_metadata_overhead",
            "category": "workflow",
            "code": "'Measure metadata processing overhead'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Metadata Processing Overhead')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nminimal_meta = SkillMetadata(name='test', description='Test')\nrich_meta = SkillMetadata(name='test', description='A comprehensive test skill for benchmarking purposes', version='2.5.0', author='Benchmark Suite', tags=['test', 'benchmark', 'performance', 'validation', 'quality'])\nadaptor = get_adaptor('langchain')\ntimes_minimal = []\nfor _ in range(5):\n    start = time.perf_counter()\n    adaptor.format_skill_md(skill_dir, minimal_meta)\n    end = time.perf_counter()\n    times_minimal.append(end - start)\ntimes_rich = []\nfor _ in range(5):\n    start = time.perf_counter()\n    adaptor.format_skill_md(skill_dir, rich_meta)\n    end = time.perf_counter()\n    times_rich.append(end - start)\navg_minimal = sum(times_minimal) / len(times_minimal)\navg_rich = sum(times_rich) / len(times_rich)\noverhead = avg_rich - avg_minimal\noverhead_pct = overhead / avg_minimal * 100\nprint(f'\\nMinimal metadata: {avg_minimal * 1000:.2f}ms')\nprint(f'Rich metadata:    {avg_rich * 1000:.2f}ms')\nprint(f'Overhead:         {overhead * 1000:.2f}ms ({overhead_pct:.1f}%)')\nself.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
            "language": "Python",
            "description": "Workflow: Measure metadata processing overhead",
            "expected_behavior": "self.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
            "line_start": 291,
            "line_end": 340,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tempfile",
              "time",
              "unittest",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Measure metadata processing overhead'",
            "description": "'Measure metadata processing overhead'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "print('\\n' + '=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "print('BENCHMARK: Metadata Processing Overhead')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "print('=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_dir = self._create_skill_with_n_references(10)",
            "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "minimal_meta = SkillMetadata(name='test', description='Test')",
            "description": "Assign minimal_meta = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "rich_meta = SkillMetadata(name='test', description='A comprehensive test skill for benchmarking purposes', version='2.5.0', author='Benchmark Suite', tags=['test', 'benchmark', 'performance', 'validation', 'quality'])",
            "description": "Assign rich_meta = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "adaptor = get_adaptor('langchain')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "times_minimal = []",
            "description": "Assign times_minimal = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "times_rich = []",
            "description": "Assign times_rich = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "avg_minimal = sum(times_minimal) / len(times_minimal)",
            "description": "Assign avg_minimal = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "avg_rich = sum(times_rich) / len(times_rich)",
            "description": "Assign avg_rich = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "overhead = avg_rich - avg_minimal",
            "description": "Assign overhead = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "overhead_pct = overhead / avg_minimal * 100",
            "description": "Assign overhead_pct = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "print(f'\\nMinimal metadata: {avg_minimal * 1000:.2f}ms')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "print(f'Rich metadata:    {avg_rich * 1000:.2f}ms')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "print(f'Overhead:         {overhead * 1000:.2f}ms ({overhead_pct:.1f}%)')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "self.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 19,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 20,
            "code": "adaptor.format_skill_md(skill_dir, minimal_meta)",
            "description": "Call adaptor.format_skill_md()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 21,
            "code": "end = time.perf_counter()",
            "description": "Assign end = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 22,
            "code": "times_minimal.append(end - start)",
            "description": "Call times_minimal.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 23,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 24,
            "code": "adaptor.format_skill_md(skill_dir, rich_meta)",
            "description": "Call adaptor.format_skill_md()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 25,
            "code": "end = time.perf_counter()",
            "description": "Assign end = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 26,
            "code": "times_rich.append(end - start)",
            "description": "Call times_rich.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Benchmark Metadata Overhead",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptor_benchmarks.py:291"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Benchmark Empty Vs Full Skill": [
      {
        "guide_id": "e15e92243558",
        "title": "Benchmark Empty Vs Full Skill",
        "overview": "Workflow: Compare performance: empty skill vs full skill",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tempfile",
          "time",
          "unittest",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "68aea8f2",
            "test_name": "test_benchmark_empty_vs_full_skill",
            "category": "workflow",
            "code": "'Compare performance: empty skill vs full skill'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Empty vs Full Skill')\nprint('=' * 80)\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='test', description='Test benchmark')\nempty_dir = Path(self.temp_dir.name) / 'empty'\nempty_dir.mkdir()\nstart = time.perf_counter()\nadaptor.format_skill_md(empty_dir, metadata)\nempty_time = time.perf_counter() - start\nfull_dir = self._create_skill_with_n_references(50)\nstart = time.perf_counter()\nadaptor.format_skill_md(full_dir, metadata)\nfull_time = time.perf_counter() - start\nprint(f'\\nEmpty skill: {empty_time * 1000:.2f}ms')\nprint(f'Full skill (50 refs): {full_time * 1000:.2f}ms')\nprint(f'Ratio: {full_time / empty_time:.1f}x')\nself.assertLess(empty_time, 0.01, 'Empty skill processing too slow')\nself.assertLess(full_time, 0.5, 'Full skill processing too slow')",
            "language": "Python",
            "description": "Workflow: Compare performance: empty skill vs full skill",
            "expected_behavior": "self.assertLess(full_time, 0.5, 'Full skill processing too slow')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
            "line_start": 342,
            "line_end": 374,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tempfile",
              "time",
              "unittest",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Compare performance: empty skill vs full skill'",
            "description": "'Compare performance: empty skill vs full skill'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "print('\\n' + '=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "print('BENCHMARK: Empty vs Full Skill')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "print('=' * 80)",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "adaptor = get_adaptor('chroma')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "metadata = SkillMetadata(name='test', description='Test benchmark')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "empty_dir = Path(self.temp_dir.name) / 'empty'",
            "description": "Assign empty_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "empty_dir.mkdir()",
            "description": "Call empty_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "adaptor.format_skill_md(empty_dir, metadata)",
            "description": "Call adaptor.format_skill_md()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "empty_time = time.perf_counter() - start",
            "description": "Assign empty_time = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "full_dir = self._create_skill_with_n_references(50)",
            "description": "Assign full_dir = self._create_skill_with_n_references(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "start = time.perf_counter()",
            "description": "Assign start = time.perf_counter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "adaptor.format_skill_md(full_dir, metadata)",
            "description": "Call adaptor.format_skill_md()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "full_time = time.perf_counter() - start",
            "description": "Assign full_time = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "print(f'\\nEmpty skill: {empty_time * 1000:.2f}ms')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "print(f'Full skill (50 refs): {full_time * 1000:.2f}ms')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "print(f'Ratio: {full_time / empty_time:.1f}x')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 19,
            "code": "self.assertLess(empty_time, 0.01, 'Empty skill processing too slow')",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 20,
            "code": "self.assertLess(full_time, 0.5, 'Full skill processing too slow')",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Benchmark Empty Vs Full Skill",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptor_benchmarks.py:342"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Estimate Tokens": [
      {
        "guide_id": "c04a99859eb3",
        "title": "Estimate Tokens",
        "overview": "Workflow: Test token estimation.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d446910c",
            "test_name": "test_estimate_tokens",
            "category": "workflow",
            "code": "'Test token estimation.'\nchunker = RAGChunker()\nassert chunker.estimate_tokens('') == 0\ntext = 'Hello world!'\ntokens = chunker.estimate_tokens(text)\nassert tokens == 3\ntext = 'A' * 1000\ntokens = chunker.estimate_tokens(text)\nassert tokens == 250",
            "language": "Python",
            "description": "Workflow: Test token estimation.",
            "expected_behavior": "assert tokens == 250",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 40,
            "line_end": 55,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test token estimation.'",
            "description": "'Test token estimation.'",
            "expected_result": null,
            "verification": "assert chunker.estimate_tokens('') == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker()",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": "assert tokens == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = 'Hello world!'",
            "description": "Assign text = 'Hello world!'",
            "expected_result": null,
            "verification": "assert tokens == 250",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "tokens = chunker.estimate_tokens(text)",
            "description": "Assign tokens = chunker.estimate_tokens(...)",
            "expected_result": null,
            "verification": "assert tokens == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "text = 'A' * 1000",
            "description": "Assign text = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "tokens = chunker.estimate_tokens(text)",
            "description": "Assign tokens = chunker.estimate_tokens(...)",
            "expected_result": null,
            "verification": "assert tokens == 250",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Estimate Tokens",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:40"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Document Simple": [
      {
        "guide_id": "109cfa8d3b4d",
        "title": "Chunk Document Simple",
        "overview": "Workflow: Test chunking simple document.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7e5bbcf1",
            "test_name": "test_chunk_document_simple",
            "category": "workflow",
            "code": "'Test chunking simple document.'\nchunker = RAGChunker(chunk_size=50, chunk_overlap=10)\ntext = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'\nmetadata = {'source': 'test', 'category': 'simple'}\nchunks = chunker.chunk_document(text, metadata)\nassert len(chunks) > 0\nassert all(('chunk_id' in chunk for chunk in chunks))\nassert all(('page_content' in chunk for chunk in chunks))\nassert all(('metadata' in chunk for chunk in chunks))\nfor i, chunk in enumerate(chunks):\n    assert chunk['metadata']['source'] == 'test'\n    assert chunk['metadata']['category'] == 'simple'\n    assert chunk['metadata']['chunk_index'] == i\n    assert chunk['metadata']['total_chunks'] == len(chunks)",
            "language": "Python",
            "description": "Workflow: Test chunking simple document.",
            "expected_behavior": "assert all(('metadata' in chunk for chunk in chunks))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 64,
            "line_end": 83,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test chunking simple document.'",
            "description": "'Test chunking simple document.'",
            "expected_result": null,
            "verification": "assert len(chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker(chunk_size=50, chunk_overlap=10)",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": "assert all(('chunk_id' in chunk for chunk in chunks))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'",
            "description": "Assign text = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'",
            "expected_result": null,
            "verification": "assert all(('page_content' in chunk for chunk in chunks))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test', 'category': 'simple'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": "assert all(('metadata' in chunk for chunk in chunks))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = chunker.chunk_document(text, metadata)",
            "description": "Assign chunks = chunker.chunk_document(...)",
            "expected_result": null,
            "verification": "assert chunk['metadata']['source'] == 'test'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Document Simple",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:64"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Code Block Not Split": [
      {
        "guide_id": "a2ddb728ec78",
        "title": "Code Block Not Split",
        "overview": "Workflow: Test that code blocks are not split across chunks.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ee4dd1d6",
            "test_name": "test_code_block_not_split",
            "category": "workflow",
            "code": "'Test that code blocks are not split across chunks.'\nchunker = RAGChunker(chunk_size=20, preserve_code_blocks=True)\ntext = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\ncode_chunks = [c for c in chunks if '```python' in c['page_content']]\nif code_chunks:\n    code_chunk = code_chunks[0]\n    assert code_chunk['page_content'].count('```') >= 2",
            "language": "Python",
            "description": "Workflow: Test that code blocks are not split across chunks.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 110,
            "line_end": 138,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that code blocks are not split across chunks.'",
            "description": "'Test that code blocks are not split across chunks.'",
            "expected_result": null,
            "verification": "assert code_chunk['page_content'].count('```') >= 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker(chunk_size=20, preserve_code_blocks=True)",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '",
            "description": "Assign text = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "chunks = chunker.chunk_document(text, {'source': 'test'})",
            "description": "Assign chunks = chunker.chunk_document(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "code_chunks = [c for c in chunks if '```python' in c['page_content']]",
            "description": "Assign code_chunks = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "code_chunk = code_chunks[0]",
            "description": "Assign code_chunk = value",
            "expected_result": null,
            "verification": "assert code_chunk['page_content'].count('```') >= 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Code Block Not Split",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:110"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Semantic Boundaries": [
      {
        "guide_id": "9c8b61112c2b",
        "title": "Semantic Boundaries",
        "overview": "Workflow: Test that chunks respect paragraph boundaries.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d3918756",
            "test_name": "test_semantic_boundaries",
            "category": "workflow",
            "code": "'Test that chunks respect paragraph boundaries.'\nchunker = RAGChunker(chunk_size=50, preserve_paragraphs=True)\ntext = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\nfor chunk in chunks:\n    content = chunk['page_content']\n    if content.strip():\n        assert not content.strip().endswith(',')",
            "language": "Python",
            "description": "Workflow: Test that chunks respect paragraph boundaries.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 140,
            "line_end": 162,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that chunks respect paragraph boundaries.'",
            "description": "'Test that chunks respect paragraph boundaries.'",
            "expected_result": null,
            "verification": "assert not content.strip().endswith(',')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker(chunk_size=50, preserve_paragraphs=True)",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '",
            "description": "Assign text = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "chunks = chunker.chunk_document(text, {'source': 'test'})",
            "description": "Assign chunks = chunker.chunk_document(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "content = chunk['page_content']",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": "assert not content.strip().endswith(',')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Semantic Boundaries",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:140"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Skill Directory": [
      {
        "guide_id": "88027111d27e",
        "title": "Chunk Skill Directory",
        "overview": "Workflow: Test chunking entire skill directory.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9c1e7df4",
            "test_name": "test_chunk_skill_directory",
            "category": "workflow",
            "code": "'Test chunking entire skill directory.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Main Skill\\n\\nThis is the main skill content.\\n\\nWith multiple paragraphs.')\nreferences_dir = skill_dir / 'references'\nreferences_dir.mkdir()\n(references_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start guide.')\n(references_dir / 'api.md').write_text('# API Reference\\n\\nAPI documentation.')\nchunker = RAGChunker(chunk_size=50)\nchunks = chunker.chunk_skill(skill_dir)\nassert len(chunks) > 0\ncategories = {chunk['metadata']['category'] for chunk in chunks}\nassert 'overview' in categories\nassert 'getting_started' in categories or 'api' in categories",
            "language": "Python",
            "description": "Workflow: Test chunking entire skill directory.",
            "expected_behavior": "assert 'getting_started' in categories or 'api' in categories",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 175,
            "line_end": 206,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test chunking entire skill directory.'",
            "description": "'Test chunking entire skill directory.'",
            "expected_result": null,
            "verification": "assert len(chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "skill_dir = tmp_path / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": "assert 'overview' in categories",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": "assert 'getting_started' in categories or 'api' in categories",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_md = skill_dir / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_md.write_text('# Main Skill\\n\\nThis is the main skill content.\\n\\nWith multiple paragraphs.')",
            "description": "Call skill_md.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "references_dir = skill_dir / 'references'",
            "description": "Assign references_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "references_dir.mkdir()",
            "description": "Call references_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "(references_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start guide.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "(references_dir / 'api.md').write_text('# API Reference\\n\\nAPI documentation.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "chunker = RAGChunker(chunk_size=50)",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "chunks = chunker.chunk_skill(skill_dir)",
            "description": "Assign chunks = chunker.chunk_skill(...)",
            "expected_result": null,
            "verification": "assert len(chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "categories = {chunk['metadata']['category'] for chunk in chunks}",
            "description": "Assign categories = value",
            "expected_result": null,
            "verification": "assert 'overview' in categories",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Skill Directory",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_rag_chunker.py:175"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Save Chunks": [
      {
        "guide_id": "7daeab4315ad",
        "title": "Save Chunks",
        "overview": "Workflow: Test saving chunks to JSON file.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "31b13860",
            "test_name": "test_save_chunks",
            "category": "workflow",
            "code": "'Test saving chunks to JSON file.'\nchunker = RAGChunker()\nchunks = [{'chunk_id': 'test_0', 'page_content': 'Test content', 'metadata': {'source': 'test', 'chunk_index': 0}}]\noutput_path = tmp_path / 'chunks.json'\nchunker.save_chunks(chunks, output_path)\nassert output_path.exists()\nwith open(output_path) as f:\n    loaded = json.load(f)\nassert len(loaded) == 1\nassert loaded[0]['chunk_id'] == 'test_0'",
            "language": "Python",
            "description": "Workflow: Test saving chunks to JSON file.",
            "expected_behavior": "assert loaded[0]['chunk_id'] == 'test_0'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 208,
            "line_end": 231,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test saving chunks to JSON file.'",
            "description": "'Test saving chunks to JSON file.'",
            "expected_result": null,
            "verification": "assert output_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker()",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": "assert len(loaded) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "chunks = [{'chunk_id': 'test_0', 'page_content': 'Test content', 'metadata': {'source': 'test', 'chunk_index': 0}}]",
            "description": "Assign chunks = value",
            "expected_result": null,
            "verification": "assert loaded[0]['chunk_id'] == 'test_0'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_path = tmp_path / 'chunks.json'",
            "description": "Assign output_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunker.save_chunks(chunks, output_path)",
            "description": "Call chunker.save_chunks()",
            "expected_result": null,
            "verification": "assert output_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "loaded = json.load(f)",
            "description": "Assign loaded = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Save Chunks",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:208"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Real World Documentation": [
      {
        "guide_id": "2b6704eeecc9",
        "title": "Real World Documentation",
        "overview": "Workflow: Test with realistic documentation content.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9cfb2366",
            "test_name": "test_real_world_documentation",
            "category": "workflow",
            "code": "'Test with realistic documentation content.'\nchunker = RAGChunker(chunk_size=512, chunk_overlap=50)\ntext = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '\nmetadata = {'source': 'react-docs', 'category': 'hooks', 'url': 'https://react.dev/reference/react'}\nchunks = chunker.chunk_document(text, metadata)\nassert len(chunks) > 0\ncode_chunks = [c for c in chunks if c['metadata']['has_code_block']]\nassert len(code_chunks) >= 1\nfor chunk in chunks:\n    assert chunk['metadata']['source'] == 'react-docs'\n    assert chunk['metadata']['category'] == 'hooks'\n    assert chunk['metadata']['estimated_tokens'] > 0",
            "language": "Python",
            "description": "Workflow: Test with realistic documentation content.",
            "expected_behavior": "assert len(code_chunks) >= 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 293,
            "line_end": 363,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test with realistic documentation content.'",
            "description": "'Test with realistic documentation content.'",
            "expected_result": null,
            "verification": "assert len(chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "chunker = RAGChunker(chunk_size=512, chunk_overlap=50)",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": "assert len(code_chunks) >= 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "text = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '",
            "description": "Assign text = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '",
            "expected_result": null,
            "verification": "assert chunk['metadata']['source'] == 'react-docs'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'react-docs', 'category': 'hooks', 'url': 'https://react.dev/reference/react'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": "assert chunk['metadata']['category'] == 'hooks'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = chunker.chunk_document(text, metadata)",
            "description": "Assign chunks = chunker.chunk_document(...)",
            "expected_result": null,
            "verification": "assert chunk['metadata']['estimated_tokens'] > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "code_chunks = [c for c in chunks if c['metadata']['has_code_block']]",
            "description": "Assign code_chunks = value",
            "expected_result": null,
            "verification": "assert len(code_chunks) >= 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Real World Documentation",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_rag_chunker.py:293"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Then Load With Langchain": [
      {
        "guide_id": "14e6720e9fb4",
        "title": "Chunk Then Load With Langchain",
        "overview": "Workflow: Test that chunks can be loaded by LangChain.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "01bb21ce",
            "test_name": "test_chunk_then_load_with_langchain",
            "category": "workflow",
            "code": "'Test that chunks can be loaded by LangChain.'\npytest.importorskip('langchain')\nfrom langchain.schema import Document\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LangChain.')\nchunker = RAGChunker()\nchunks = chunker.chunk_skill(skill_dir)\ndocs = [Document(page_content=chunk['page_content'], metadata=chunk['metadata']) for chunk in chunks]\nassert len(docs) > 0\nassert all((isinstance(doc, Document) for doc in docs))",
            "language": "Python",
            "description": "Workflow: Test that chunks can be loaded by LangChain.",
            "expected_behavior": "assert all((isinstance(doc, Document) for doc in docs))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 369,
            "line_end": 392,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that chunks can be loaded by LangChain.'",
            "description": "'Test that chunks can be loaded by LangChain.'",
            "expected_result": null,
            "verification": "assert len(docs) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "pytest.importorskip('langchain')",
            "description": "Call pytest.importorskip()",
            "expected_result": null,
            "verification": "assert all((isinstance(doc, Document) for doc in docs))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir = tmp_path / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LangChain.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "chunker = RAGChunker()",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "chunks = chunker.chunk_skill(skill_dir)",
            "description": "Assign chunks = chunker.chunk_skill(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "docs = [Document(page_content=chunk['page_content'], metadata=chunk['metadata']) for chunk in chunks]",
            "description": "Assign docs = value",
            "expected_result": null,
            "verification": "assert len(docs) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Then Load With Langchain",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_rag_chunker.py:369"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Then Load With Llamaindex": [
      {
        "guide_id": "a70c9327c88c",
        "title": "Chunk Then Load With Llamaindex",
        "overview": "Workflow: Test that chunks can be loaded by LlamaIndex.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "json",
          "skill_seekers.cli.rag_chunker",
          "langchain.schema",
          "llama_index.core.schema"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "98c630e0",
            "test_name": "test_chunk_then_load_with_llamaindex",
            "category": "workflow",
            "code": "'Test that chunks can be loaded by LlamaIndex.'\npytest.importorskip('llama_index')\nfrom llama_index.core.schema import TextNode\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LlamaIndex.')\nchunker = RAGChunker()\nchunks = chunker.chunk_skill(skill_dir)\nnodes = [TextNode(text=chunk['page_content'], metadata=chunk['metadata'], id_=chunk['chunk_id']) for chunk in chunks]\nassert len(nodes) > 0\nassert all((isinstance(node, TextNode) for node in nodes))",
            "language": "Python",
            "description": "Workflow: Test that chunks can be loaded by LlamaIndex.",
            "expected_behavior": "assert all((isinstance(node, TextNode) for node in nodes))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
            "line_start": 394,
            "line_end": 417,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "json",
              "skill_seekers.cli.rag_chunker",
              "langchain.schema",
              "llama_index.core.schema"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that chunks can be loaded by LlamaIndex.'",
            "description": "'Test that chunks can be loaded by LlamaIndex.'",
            "expected_result": null,
            "verification": "assert len(nodes) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "pytest.importorskip('llama_index')",
            "description": "Call pytest.importorskip()",
            "expected_result": null,
            "verification": "assert all((isinstance(node, TextNode) for node in nodes))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_dir = tmp_path / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_dir.mkdir()",
            "description": "Call skill_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LlamaIndex.')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "chunker = RAGChunker()",
            "description": "Assign chunker = RAGChunker(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "chunks = chunker.chunk_skill(skill_dir)",
            "description": "Assign chunks = chunker.chunk_skill(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "nodes = [TextNode(text=chunk['page_content'], metadata=chunk['metadata'], id_=chunk['chunk_id']) for chunk in chunks]",
            "description": "Assign nodes = value",
            "expected_result": null,
            "verification": "assert len(nodes) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Then Load With Llamaindex",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_rag_chunker.py:394"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Python From Heuristics": [
      {
        "guide_id": "2c6623f4c216",
        "title": "Detect Python From Heuristics",
        "overview": "Workflow: Test Python detection from code content",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4199eada",
            "test_name": "test_detect_python_from_heuristics",
            "category": "workflow",
            "code": "'Test Python detection from code content'\nhtml = '<code>import os\\nfrom pathlib import Path</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'python')",
            "language": "Python",
            "description": "Workflow: Test Python detection from code content",
            "expected_behavior": "self.assertEqual(lang, 'python')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 111,
            "line_end": 117,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Python detection from code content'",
            "description": "'Test Python detection from code content'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>import os\\nfrom pathlib import Path</code>'",
            "description": "Assign html = '<code>import os\\nfrom pathlib import Path</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'python')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Python From Heuristics",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:111"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Javascript From Const": [
      {
        "guide_id": "06e0e91b973c",
        "title": "Detect Javascript From Const",
        "overview": "Workflow: Test JavaScript detection from const keyword",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "974d5840",
            "test_name": "test_detect_javascript_from_const",
            "category": "workflow",
            "code": "'Test JavaScript detection from const keyword'\nhtml = '<code>const myVar = 10;</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'javascript')",
            "language": "Python",
            "description": "Workflow: Test JavaScript detection from const keyword",
            "expected_behavior": "self.assertEqual(lang, 'javascript')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 127,
            "line_end": 133,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test JavaScript detection from const keyword'",
            "description": "'Test JavaScript detection from const keyword'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>const myVar = 10;</code>'",
            "description": "Assign html = '<code>const myVar = 10;</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'javascript')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Javascript From Const",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:127"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Javascript From Arrow": [
      {
        "guide_id": "b6ed46e04dc9",
        "title": "Detect Javascript From Arrow",
        "overview": "Workflow: Test JavaScript detection from arrow function",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c65ab030",
            "test_name": "test_detect_javascript_from_arrow",
            "category": "workflow",
            "code": "'Test JavaScript detection from arrow function'\nhtml = '<code>const add = (a, b) => a + b;</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'javascript')",
            "language": "Python",
            "description": "Workflow: Test JavaScript detection from arrow function",
            "expected_behavior": "self.assertEqual(lang, 'javascript')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 135,
            "line_end": 141,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test JavaScript detection from arrow function'",
            "description": "'Test JavaScript detection from arrow function'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>const add = (a, b) => a + b;</code>'",
            "description": "Assign html = '<code>const add = (a, b) => a + b;</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'javascript')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Javascript From Arrow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:135"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Gdscript": [
      {
        "guide_id": "55933d78bd8c",
        "title": "Detect Gdscript",
        "overview": "Workflow: Test GDScript detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "02a40f20",
            "test_name": "test_detect_gdscript",
            "category": "workflow",
            "code": "'Test GDScript detection'\nhtml = '<code>func _ready():\\n    var x = 5</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'gdscript')",
            "language": "Python",
            "description": "Workflow: Test GDScript detection",
            "expected_behavior": "self.assertEqual(lang, 'gdscript')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 143,
            "line_end": 149,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test GDScript detection'",
            "description": "'Test GDScript detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>func _ready():\\n    var x = 5</code>'",
            "description": "Assign html = '<code>func _ready():\\n    var x = 5</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'gdscript')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Gdscript",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:143"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Cpp": [
      {
        "guide_id": "0670aa9e7702",
        "title": "Detect Cpp",
        "overview": "Workflow: Test C++ detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "eba50aa8",
            "test_name": "test_detect_cpp",
            "category": "workflow",
            "code": "'Test C++ detection'\nhtml = '<code>#include <iostream>\\nint main() { return 0; }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'cpp')",
            "language": "Python",
            "description": "Workflow: Test C++ detection",
            "expected_behavior": "self.assertEqual(lang, 'cpp')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 151,
            "line_end": 157,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test C++ detection'",
            "description": "'Test C++ detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>#include <iostream>\\nint main() { return 0; }</code>'",
            "description": "Assign html = '<code>#include <iostream>\\nint main() { return 0; }</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'cpp')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Cpp",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:151"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Unknown": [
      {
        "guide_id": "0ee92df64448",
        "title": "Detect Unknown",
        "overview": "Workflow: Test unknown language detection",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "aca8c16c",
            "test_name": "test_detect_unknown",
            "category": "workflow",
            "code": "'Test unknown language detection'\nhtml = '<code>some random text without clear indicators</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'unknown')",
            "language": "Python",
            "description": "Workflow: Test unknown language detection",
            "expected_behavior": "self.assertEqual(lang, 'unknown')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 159,
            "line_end": 165,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test unknown language detection'",
            "description": "'Test unknown language detection'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>some random text without clear indicators</code>'",
            "description": "Assign html = '<code>some random text without clear indicators</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'unknown')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Unknown",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:159"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Csharp From Using System": [
      {
        "guide_id": "09213194f843",
        "title": "Detect Csharp From Using System",
        "overview": "Workflow: Test C# detection from 'using System' keyword",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2a54cc7a",
            "test_name": "test_detect_csharp_from_using_system",
            "category": "workflow",
            "code": "\"Test C# detection from 'using System' keyword\"\nhtml = '<code>using System;\\nnamespace MyApp { }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
            "language": "Python",
            "description": "Workflow: Test C# detection from 'using System' keyword",
            "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 188,
            "line_end": 194,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test C# detection from 'using System' keyword\"",
            "description": "\"Test C# detection from 'using System' keyword\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>using System;\\nnamespace MyApp { }</code>'",
            "description": "Assign html = '<code>using System;\\nnamespace MyApp { }</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Csharp From Using System",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:188"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Csharp From Namespace": [
      {
        "guide_id": "65a89675ff68",
        "title": "Detect Csharp From Namespace",
        "overview": "Workflow: Test C# detection from 'namespace' keyword",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "228736e8",
            "test_name": "test_detect_csharp_from_namespace",
            "category": "workflow",
            "code": "\"Test C# detection from 'namespace' keyword\"\nhtml = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
            "language": "Python",
            "description": "Workflow: Test C# detection from 'namespace' keyword",
            "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 196,
            "line_end": 202,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test C# detection from 'namespace' keyword\"",
            "description": "\"Test C# detection from 'namespace' keyword\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'",
            "description": "Assign html = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Csharp From Namespace",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:196"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Csharp From Property Syntax": [
      {
        "guide_id": "dee29708c79c",
        "title": "Detect Csharp From Property Syntax",
        "overview": "Workflow: Test C# detection from property syntax",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c7a14a7a",
            "test_name": "test_detect_csharp_from_property_syntax",
            "category": "workflow",
            "code": "'Test C# detection from property syntax'\nhtml = '<code>public string Name { get; set; }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
            "language": "Python",
            "description": "Workflow: Test C# detection from property syntax",
            "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 204,
            "line_end": 210,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test C# detection from property syntax'",
            "description": "'Test C# detection from property syntax'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>public string Name { get; set; }</code>'",
            "description": "Assign html = '<code>public string Name { get; set; }</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Csharp From Property Syntax",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:204"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Csharp From Public Class": [
      {
        "guide_id": "b1aad196488a",
        "title": "Detect Csharp From Public Class",
        "overview": "Workflow: Test C# detection from 'public class' keyword",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "bs4",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b9045a34",
            "test_name": "test_detect_csharp_from_public_class",
            "category": "workflow",
            "code": "\"Test C# detection from 'public class' keyword\"\nhtml = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
            "language": "Python",
            "description": "Workflow: Test C# detection from 'public class' keyword",
            "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
            "line_start": 212,
            "line_end": 218,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "bs4",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "\"Test C# detection from 'public class' keyword\"",
            "description": "\"Test C# detection from 'public class' keyword\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "html = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'",
            "description": "Assign html = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
            "description": "Assign elem = BeautifulSoup.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code = elem.get_text()",
            "description": "Assign code = elem.get_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lang = self.converter.detect_language(elem, code)",
            "description": "Assign lang = self.converter.detect_language(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Csharp From Public Class",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_scraper_features.py:212"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Add And Retrieve Github Profile": [
      {
        "guide_id": "ff39300ecae5",
        "title": "Add And Retrieve Github Profile",
        "overview": "Workflow: Test adding and retrieving GitHub profiles.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "datetime",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_manager",
          "skill_seekers.cli.rate_limit_handler"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bde90d3d",
            "test_name": "test_add_and_retrieve_github_profile",
            "category": "workflow",
            "code": "'Test adding and retrieving GitHub profiles.'\nconfig_dir = tmp_path / '.config' / 'skill-seekers'\nmonkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)\nmonkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')\nmonkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', tmp_path / '.local' / 'share' / 'skill-seekers' / 'progress')\nconfig = ConfigManager()\nconfig.add_github_profile(name='test-profile', token='ghp_test123', description='Test profile', rate_limit_strategy='wait', timeout_minutes=45, set_as_default=True)\ntoken = config.get_github_token(profile_name='test-profile')\nassert token == 'ghp_test123'\nprofiles = config.list_github_profiles()\nassert len(profiles) == 1\nassert profiles[0]['is_default'] is True\nassert profiles[0]['name'] == 'test-profile'",
            "language": "Python",
            "description": "Workflow: Test adding and retrieving GitHub profiles.",
            "expected_behavior": "assert profiles[0]['name'] == 'test-profile'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
            "line_start": 224,
            "line_end": 255,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path, monkeypatch",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "datetime",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_manager",
              "skill_seekers.cli.rate_limit_handler"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test adding and retrieving GitHub profiles.'",
            "description": "'Test adding and retrieving GitHub profiles.'",
            "expected_result": null,
            "verification": "assert token == 'ghp_test123'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config_dir = tmp_path / '.config' / 'skill-seekers'",
            "description": "Assign config_dir = value",
            "expected_result": null,
            "verification": "assert len(profiles) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": "assert profiles[0]['is_default'] is True",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": "assert profiles[0]['name'] == 'test-profile'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "monkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', tmp_path / '.local' / 'share' / 'skill-seekers' / 'progress')",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "config = ConfigManager()",
            "description": "Assign config = ConfigManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "config.add_github_profile(name='test-profile', token='ghp_test123', description='Test profile', rate_limit_strategy='wait', timeout_minutes=45, set_as_default=True)",
            "description": "Call config.add_github_profile()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "token = config.get_github_token(profile_name='test-profile')",
            "description": "Assign token = config.get_github_token(...)",
            "expected_result": null,
            "verification": "assert token == 'ghp_test123'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "profiles = config.list_github_profiles()",
            "description": "Assign profiles = config.list_github_profiles(...)",
            "expected_result": null,
            "verification": "assert len(profiles) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Add And Retrieve Github Profile",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_rate_limit_handler.py:224"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Get Next Profile": [
      {
        "guide_id": "f6f4ec005d51",
        "title": "Get Next Profile",
        "overview": "Workflow: Test profile switching.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "datetime",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_manager",
          "skill_seekers.cli.rate_limit_handler"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "578bb227",
            "test_name": "test_get_next_profile",
            "category": "workflow",
            "code": "'Test profile switching.'\ntest_dir = tmp_path / 'test_switching'\nconfig_dir = test_dir / '.config' / 'skill-seekers'\nmonkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)\nmonkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')\nmonkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', test_dir / '.local' / 'share' / 'skill-seekers' / 'progress')\nmonkeypatch.setattr(ConfigManager, 'WELCOME_FLAG', config_dir / '.welcomed')\nconfig = ConfigManager()\nconfig.config['github']['profiles'] = {}\nconfig.add_github_profile('profile1', 'ghp_token1', set_as_default=True)\nconfig.add_github_profile('profile2', 'ghp_token2', set_as_default=False)\nprofiles = config.list_github_profiles()\nassert len(profiles) == 2\nnext_data = config.get_next_profile('ghp_token1')\nassert next_data is not None\nname, token = next_data\nassert name == 'profile2'\nassert token == 'ghp_token2'\nnext_data = config.get_next_profile('ghp_token2')\nassert next_data is not None\nname, token = next_data\nassert name == 'profile1'\nassert token == 'ghp_token1'",
            "language": "Python",
            "description": "Workflow: Test profile switching.",
            "expected_behavior": "assert token == 'ghp_token1'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
            "line_start": 257,
            "line_end": 296,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path, monkeypatch",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "datetime",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_manager",
              "skill_seekers.cli.rate_limit_handler"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test profile switching.'",
            "description": "'Test profile switching.'",
            "expected_result": null,
            "verification": "assert len(profiles) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "test_dir = tmp_path / 'test_switching'",
            "description": "Assign test_dir = value",
            "expected_result": null,
            "verification": "assert next_data is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_dir = test_dir / '.config' / 'skill-seekers'",
            "description": "Assign config_dir = value",
            "expected_result": null,
            "verification": "assert name == 'profile2'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": "assert token == 'ghp_token2'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": "assert next_data is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "monkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', test_dir / '.local' / 'share' / 'skill-seekers' / 'progress')",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": "assert name == 'profile1'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "monkeypatch.setattr(ConfigManager, 'WELCOME_FLAG', config_dir / '.welcomed')",
            "description": "Call monkeypatch.setattr()",
            "expected_result": null,
            "verification": "assert token == 'ghp_token1'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "config = ConfigManager()",
            "description": "Assign config = ConfigManager(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "config.config['github']['profiles'] = {}",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "config.add_github_profile('profile1', 'ghp_token1', set_as_default=True)",
            "description": "Call config.add_github_profile()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "config.add_github_profile('profile2', 'ghp_token2', set_as_default=False)",
            "description": "Call config.add_github_profile()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "profiles = config.list_github_profiles()",
            "description": "Assign profiles = config.list_github_profiles(...)",
            "expected_result": null,
            "verification": "assert len(profiles) == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "next_data = config.get_next_profile('ghp_token1')",
            "description": "Assign next_data = config.get_next_profile(...)",
            "expected_result": null,
            "verification": "assert next_data is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "name, token = next_data",
            "description": "Assign unknown = next_data",
            "expected_result": null,
            "verification": "assert name == 'profile2'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "next_data = config.get_next_profile('ghp_token2')",
            "description": "Assign next_data = config.get_next_profile(...)",
            "expected_result": null,
            "verification": "assert next_data is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "name, token = next_data",
            "description": "Assign unknown = next_data",
            "expected_result": null,
            "verification": "assert name == 'profile1'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Get Next Profile",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_rate_limit_handler.py:257"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parse Json Config": [
      {
        "guide_id": "2218a1937afb",
        "title": "Parse Json Config",
        "overview": "Workflow: Test parsing JSON configuration",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.config_extractor",
          "shutil",
          "shutil",
          "shutil",
          "shutil"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e82c288d",
            "test_name": "test_parse_json_config",
            "category": "workflow",
            "code": "'Test parsing JSON configuration'\njson_content = {'database': {'host': 'localhost', 'port': 5432}, 'api_key': 'secret'}\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'config.json'), relative_path='config.json', config_type='json', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'config.json'\nfile_path.write_text(json.dumps(json_content))\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_settings = [s for s in config_file.settings if 'database' in s.key]\nself.assertGreater(len(db_settings), 0)",
            "language": "Python",
            "description": "Workflow: Test parsing JSON configuration",
            "expected_behavior": "self.assertGreater(len(db_settings), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
            "line_start": 116,
            "line_end": 135,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.config_extractor",
              "shutil",
              "shutil",
              "shutil",
              "shutil"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parsing JSON configuration'",
            "description": "'Test parsing JSON configuration'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "json_content = {'database': {'host': 'localhost', 'port': 5432}, 'api_key': 'secret'}",
            "description": "Assign json_content = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'config.json'), relative_path='config.json', config_type='json', purpose='unknown')",
            "description": "Assign config_file = ConfigFile(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "file_path = Path(self.temp_dir) / 'config.json'",
            "description": "Assign file_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "file_path.write_text(json.dumps(json_content))",
            "description": "Call file_path.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.parser.parse_config_file(config_file)",
            "description": "Call self.parser.parse_config_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(len(config_file.settings), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "db_settings = [s for s in config_file.settings if 'database' in s.key]",
            "description": "Assign db_settings = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreater(len(db_settings), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parse Json Config",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_config_extractor.py:116"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parse Env File": [
      {
        "guide_id": "b9a9bec930f5",
        "title": "Parse Env File",
        "overview": "Workflow: Test parsing .env file",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.config_extractor",
          "shutil",
          "shutil",
          "shutil",
          "shutil"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "70942543",
            "test_name": "test_parse_env_file",
            "category": "workflow",
            "code": "'Test parsing .env file'\nenv_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / '.env'), relative_path='.env', config_type='env', purpose='unknown')\nfile_path = Path(self.temp_dir) / '.env'\nfile_path.write_text(env_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_url = [s for s in config_file.settings if s.key == 'DATABASE_URL']\nself.assertEqual(len(db_url), 1)\nself.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
            "language": "Python",
            "description": "Workflow: Test parsing .env file",
            "expected_behavior": "self.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
            "line_start": 165,
            "line_end": 191,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.config_extractor",
              "shutil",
              "shutil",
              "shutil",
              "shutil"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parsing .env file'",
            "description": "'Test parsing .env file'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "env_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'",
            "description": "Assign env_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / '.env'), relative_path='.env', config_type='env', purpose='unknown')",
            "description": "Assign config_file = ConfigFile(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "file_path = Path(self.temp_dir) / '.env'",
            "description": "Assign file_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "file_path.write_text(env_content)",
            "description": "Call file_path.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.parser.parse_config_file(config_file)",
            "description": "Call self.parser.parse_config_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(len(config_file.settings), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "db_url = [s for s in config_file.settings if s.key == 'DATABASE_URL']",
            "description": "Assign db_url = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertEqual(len(db_url), 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parse Env File",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_config_extractor.py:165"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parse Python Config": [
      {
        "guide_id": "6e224803ebaf",
        "title": "Parse Python Config",
        "overview": "Workflow: Test parsing Python config module",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.config_extractor",
          "shutil",
          "shutil",
          "shutil",
          "shutil"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "160b409c",
            "test_name": "test_parse_python_config",
            "category": "workflow",
            "code": "'Test parsing Python config module'\npython_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'settings.py'), relative_path='settings.py', config_type='python', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'settings.py'\nfile_path.write_text(python_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_host = [s for s in config_file.settings if s.key == 'DATABASE_HOST']\nself.assertGreaterEqual(len(db_host), 1)",
            "language": "Python",
            "description": "Workflow: Test parsing Python config module",
            "expected_behavior": "self.assertGreaterEqual(len(db_host), 1)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
            "line_start": 217,
            "line_end": 240,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.config_extractor",
              "shutil",
              "shutil",
              "shutil",
              "shutil"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parsing Python config module'",
            "description": "'Test parsing Python config module'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "python_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"",
            "description": "Assign python_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'settings.py'), relative_path='settings.py', config_type='python', purpose='unknown')",
            "description": "Assign config_file = ConfigFile(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "file_path = Path(self.temp_dir) / 'settings.py'",
            "description": "Assign file_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "file_path.write_text(python_content)",
            "description": "Call file_path.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.parser.parse_config_file(config_file)",
            "description": "Call self.parser.parse_config_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(len(config_file.settings), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "db_host = [s for s in config_file.settings if s.key == 'DATABASE_HOST']",
            "description": "Assign db_host = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreaterEqual(len(db_host), 1)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parse Python Config",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_config_extractor.py:217"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parse Dockerfile": [
      {
        "guide_id": "7a7fce5e9321",
        "title": "Parse Dockerfile",
        "overview": "Workflow: Test parsing Dockerfile for ENV vars",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "os",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.config_extractor",
          "shutil",
          "shutil",
          "shutil",
          "shutil"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "61a8dd02",
            "test_name": "test_parse_dockerfile",
            "category": "workflow",
            "code": "'Test parsing Dockerfile for ENV vars'\ndockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'Dockerfile'), relative_path='Dockerfile', config_type='dockerfile', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'Dockerfile'\nfile_path.write_text(dockerfile_content)\nself.parser.parse_config_file(config_file)\nenv_settings = [s for s in config_file.settings if s.env_var]\nself.assertGreater(len(env_settings), 0)",
            "language": "Python",
            "description": "Workflow: Test parsing Dockerfile for ENV vars",
            "expected_behavior": "self.assertGreater(len(env_settings), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
            "line_start": 242,
            "line_end": 263,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.config_extractor",
              "shutil",
              "shutil",
              "shutil",
              "shutil"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parsing Dockerfile for ENV vars'",
            "description": "'Test parsing Dockerfile for ENV vars'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "dockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'",
            "description": "Assign dockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'Dockerfile'), relative_path='Dockerfile', config_type='dockerfile', purpose='unknown')",
            "description": "Assign config_file = ConfigFile(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "file_path = Path(self.temp_dir) / 'Dockerfile'",
            "description": "Assign file_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "file_path.write_text(dockerfile_content)",
            "description": "Call file_path.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.parser.parse_config_file(config_file)",
            "description": "Call self.parser.parse_config_file()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "env_settings = [s for s in config_file.settings if s.env_var]",
            "description": "Assign env_settings = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertGreater(len(env_settings), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parse Dockerfile",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_config_extractor.py:242"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Analyze Python Workflow": [
      {
        "guide_id": "d0d4520a04b5",
        "title": "Analyze Python Workflow",
        "overview": "Workflow: Test analysis of Python workflow with multiple steps",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d61033bb",
            "test_name": "test_analyze_python_workflow",
            "category": "workflow",
            "code": "'Test analysis of Python workflow with multiple steps'\nworkflow = {'code': \"\\ndef test_user_creation_workflow():\\n    # Step 1: Create database\\n    db = Database('test.db')\\n\\n    # Step 2: Create user\\n    user = User(name='Alice', email='alice@example.com')\\n    db.save(user)\\n\\n    # Step 3: Verify creation\\n    assert db.get_user('Alice').email == 'alice@example.com'\\n\", 'language': 'python', 'category': 'workflow', 'test_name': 'test_user_creation_workflow', 'file_path': 'tests/test_user.py'}\nsteps, metadata = self.analyzer.analyze_workflow(workflow)\nself.assertGreaterEqual(len(steps), 2)\nself.assertIsInstance(steps[0], WorkflowStep)\nself.assertEqual(steps[0].step_number, 1)\nself.assertIsNotNone(steps[0].description)\nself.assertIn('complexity_level', metadata)\nself.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
            "language": "Python",
            "description": "Workflow: Test analysis of Python workflow with multiple steps",
            "expected_behavior": "self.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 42,
            "line_end": 75,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "self.analyzer = WorkflowAnalyzer()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test analysis of Python workflow with multiple steps'",
            "description": "'Test analysis of Python workflow with multiple steps'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "workflow = {'code': \"\\ndef test_user_creation_workflow():\\n    # Step 1: Create database\\n    db = Database('test.db')\\n\\n    # Step 2: Create user\\n    user = User(name='Alice', email='alice@example.com')\\n    db.save(user)\\n\\n    # Step 3: Verify creation\\n    assert db.get_user('Alice').email == 'alice@example.com'\\n\", 'language': 'python', 'category': 'workflow', 'test_name': 'test_user_creation_workflow', 'file_path': 'tests/test_user.py'}",
            "description": "Assign workflow = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "steps, metadata = self.analyzer.analyze_workflow(workflow)",
            "description": "Assign unknown = self.analyzer.analyze_workflow(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertGreaterEqual(len(steps), 2)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertIsInstance(steps[0], WorkflowStep)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(steps[0].step_number, 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIsNotNone(steps[0].description)",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('complexity_level', metadata)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Analyze Python Workflow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:42"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Calculate Complexity": [
      {
        "guide_id": "85f56a624add",
        "title": "Calculate Complexity",
        "overview": "Workflow: Test complexity level calculation",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "123790b8",
            "test_name": "test_calculate_complexity",
            "category": "workflow",
            "code": "'Test complexity level calculation'\nsimple_steps = [WorkflowStep(1, 'x = 1', 'Assign variable'), WorkflowStep(2, 'print(x)', 'Print variable')]\nsimple_workflow = {'code': 'x = 1\\nprint(x)', 'category': 'workflow'}\ncomplexity_simple = self.analyzer._calculate_complexity(simple_steps, simple_workflow)\nself.assertEqual(complexity_simple, 'beginner')\ncomplex_steps = [WorkflowStep(i, f'step{i}', f'Step {i}') for i in range(1, 8)]\ncomplex_workflow = {'code': '\\n'.join([f'async def step{i}(): await complex_operation()' for i in range(7)]), 'category': 'workflow'}\ncomplexity_complex = self.analyzer._calculate_complexity(complex_steps, complex_workflow)\nself.assertIn(complexity_complex, ['intermediate', 'advanced'])",
            "language": "Python",
            "description": "Workflow: Test complexity level calculation",
            "expected_behavior": "self.assertIn(complexity_complex, ['intermediate', 'advanced'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 121,
            "line_end": 141,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "self.analyzer = WorkflowAnalyzer()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complexity level calculation'",
            "description": "'Test complexity level calculation'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "simple_steps = [WorkflowStep(1, 'x = 1', 'Assign variable'), WorkflowStep(2, 'print(x)', 'Print variable')]",
            "description": "Assign simple_steps = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "simple_workflow = {'code': 'x = 1\\nprint(x)', 'category': 'workflow'}",
            "description": "Assign simple_workflow = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "complexity_simple = self.analyzer._calculate_complexity(simple_steps, simple_workflow)",
            "description": "Assign complexity_simple = self.analyzer._calculate_complexity(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(complexity_simple, 'beginner')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "complex_steps = [WorkflowStep(i, f'step{i}', f'Step {i}') for i in range(1, 8)]",
            "description": "Assign complex_steps = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "complex_workflow = {'code': '\\n'.join([f'async def step{i}(): await complex_operation()' for i in range(7)]), 'category': 'workflow'}",
            "description": "Assign complex_workflow = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "complexity_complex = self.analyzer._calculate_complexity(complex_steps, complex_workflow)",
            "description": "Assign complexity_complex = self.analyzer._calculate_complexity(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn(complexity_complex, ['intermediate', 'advanced'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Calculate Complexity",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:121"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Create Complete Example": [
      {
        "guide_id": "5b9403e61fb5",
        "title": "Create Complete Example",
        "overview": "Workflow: Test complete example generation",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "50490a77",
            "test_name": "test_create_complete_example",
            "category": "workflow",
            "code": "'Test complete example generation'\nguide = HowToGuide(guide_id='test-1', title='Test', overview='Test', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Assign'), WorkflowStep(2, 'print(x)', 'Print')], workflows=[{'code': 'x = 1\\nprint(x)', 'language': 'python'}])\nexample_md = self.generator._create_complete_example(guide)\nself.assertIn('## Complete Example', example_md)\nself.assertIn('```python', example_md)",
            "language": "Python",
            "description": "Workflow: Test complete example generation",
            "expected_behavior": "self.assertIn('```python', example_md)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 373,
            "line_end": 387,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": "self.generator = GuideGenerator()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete example generation'",
            "description": "'Test complete example generation'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "guide = HowToGuide(guide_id='test-1', title='Test', overview='Test', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Assign'), WorkflowStep(2, 'print(x)', 'Print')], workflows=[{'code': 'x = 1\\nprint(x)', 'language': 'python'}])",
            "description": "Assign guide = HowToGuide(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "example_md = self.generator._create_complete_example(guide)",
            "description": "Assign example_md = self.generator._create_complete_example(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIn('## Complete Example', example_md)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertIn('```python', example_md)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Create Complete Example",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:373"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Workflow Examples": [
      {
        "guide_id": "117472ac1efb",
        "title": "Extract Workflow Examples",
        "overview": "Workflow: Test extraction of workflow examples from mixed examples",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "852de058",
            "test_name": "test_extract_workflow_examples",
            "category": "workflow",
            "code": "'Test extraction of workflow examples from mixed examples'\nexamples = [{'category': 'workflow', 'code': 'db = Database()\\nuser = User()\\ndb.save(user)', 'test_name': 'test_user_workflow', 'file_path': 'tests/test_user.py', 'language': 'python'}, {'category': 'instantiation', 'code': 'db = Database()', 'test_name': 'test_db', 'file_path': 'tests/test_db.py', 'language': 'python'}]\nworkflows = self.builder._extract_workflow_examples(examples)\nself.assertEqual(len(workflows), 1)\nself.assertEqual(workflows[0]['category'], 'workflow')",
            "language": "Python",
            "description": "Workflow: Test extraction of workflow examples from mixed examples",
            "expected_behavior": "self.assertEqual(workflows[0]['category'], 'workflow')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 427,
            "line_end": 450,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test extraction of workflow examples from mixed examples'",
            "description": "'Test extraction of workflow examples from mixed examples'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "examples = [{'category': 'workflow', 'code': 'db = Database()\\nuser = User()\\ndb.save(user)', 'test_name': 'test_user_workflow', 'file_path': 'tests/test_user.py', 'language': 'python'}, {'category': 'instantiation', 'code': 'db = Database()', 'test_name': 'test_db', 'file_path': 'tests/test_db.py', 'language': 'python'}]",
            "description": "Assign examples = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "workflows = self.builder._extract_workflow_examples(examples)",
            "description": "Assign workflows = self.builder._extract_workflow_examples(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(len(workflows), 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(workflows[0]['category'], 'workflow')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Workflow Examples",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:427"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Create Guide From Workflows": [
      {
        "guide_id": "7f74bebd0366",
        "title": "Create Guide From Workflows",
        "overview": "Workflow: Test guide creation from grouped workflows",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "6af04b0b",
            "test_name": "test_create_guide_from_workflows",
            "category": "workflow",
            "code": "'Test guide creation from grouped workflows'\nworkflows = [{'code': 'user = User(name=\"Alice\")\\ndb.save(user)', 'test_name': 'test_create_user', 'file_path': 'tests/test_user.py', 'language': 'python', 'category': 'workflow'}]\nguide = self.builder._create_guide('User Management', workflows)\nself.assertIsInstance(guide, HowToGuide)\nself.assertEqual(guide.title, 'User Management')\nself.assertGreater(len(guide.steps), 0)\nself.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
            "language": "Python",
            "description": "Workflow: Test guide creation from grouped workflows",
            "expected_behavior": "self.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 452,
            "line_end": 469,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test guide creation from grouped workflows'",
            "description": "'Test guide creation from grouped workflows'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "workflows = [{'code': 'user = User(name=\"Alice\")\\ndb.save(user)', 'test_name': 'test_create_user', 'file_path': 'tests/test_user.py', 'language': 'python', 'category': 'workflow'}]",
            "description": "Assign workflows = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "guide = self.builder._create_guide('User Management', workflows)",
            "description": "Assign guide = self.builder._create_guide(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIsInstance(guide, HowToGuide)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(guide.title, 'User Management')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertGreater(len(guide.steps), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Create Guide From Workflows",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:452"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Save Guides To Files": [
      {
        "guide_id": "339f11c6e5d2",
        "title": "Save Guides To Files",
        "overview": "Workflow: Test saving guides to markdown files",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ecc0bb12",
            "test_name": "test_save_guides_to_files",
            "category": "workflow",
            "code": "'Test saving guides to markdown files'\nguides = [HowToGuide(guide_id='test-guide', title='Test Guide', overview='Test overview', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Test step')])]\ncollection = GuideCollection(total_guides=1, guides=guides, guides_by_complexity={'beginner': 1}, guides_by_use_case={})\noutput_dir = Path(self.temp_dir)\nself.builder._save_guides_to_files(collection, output_dir)\nself.assertTrue((output_dir / 'index.md').exists())\nindex_content = (output_dir / 'index.md').read_text()\nself.assertIn('Test Guide', index_content)\nmd_files = list(output_dir.glob('*.md'))\nself.assertGreaterEqual(len(md_files), 1)",
            "language": "Python",
            "description": "Workflow: Test saving guides to markdown files",
            "expected_behavior": "self.assertGreaterEqual(len(md_files), 1)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 490,
            "line_end": 522,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test saving guides to markdown files'",
            "description": "'Test saving guides to markdown files'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "guides = [HowToGuide(guide_id='test-guide', title='Test Guide', overview='Test overview', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Test step')])]",
            "description": "Assign guides = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "collection = GuideCollection(total_guides=1, guides=guides, guides_by_complexity={'beginner': 1}, guides_by_use_case={})",
            "description": "Assign collection = GuideCollection(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_dir = Path(self.temp_dir)",
            "description": "Assign output_dir = Path(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.builder._save_guides_to_files(collection, output_dir)",
            "description": "Call self.builder._save_guides_to_files()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertTrue((output_dir / 'index.md').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "index_content = (output_dir / 'index.md').read_text()",
            "description": "Assign index_content = unknown.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('Test Guide', index_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "md_files = list(output_dir.glob('*.md'))",
            "description": "Assign md_files = list(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreaterEqual(len(md_files), 1)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Save Guides To Files",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:490"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build With Ai Enhancement Disabled": [
      {
        "guide_id": "bc461b6a4336",
        "title": "Build With Ai Enhancement Disabled",
        "overview": "Workflow: Test building guides WITHOUT AI enhancement (backward compatibility)",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "285f6c98",
            "test_name": "test_build_with_ai_enhancement_disabled",
            "category": "workflow",
            "code": "'Test building guides WITHOUT AI enhancement (backward compatibility)'\nexamples = [{'example_id': 'test_001', 'test_name': 'test_user_registration', 'category': 'workflow', 'code': '\\ndef test_user_registration():\\n    user = User.create(username=\"test\", email=\"test@example.com\")\\n    assert user.id is not None\\n    assert user.is_active is True\\n                ', 'language': 'python', 'file_path': 'tests/test_user.py', 'line_start': 10, 'tags': ['authentication', 'user'], 'ai_analysis': {'tutorial_group': 'User Management', 'best_practices': ['Validate email format'], 'common_mistakes': ['Not checking uniqueness']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides'\ncollection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=False, ai_mode='none')\nself.assertIsInstance(collection, GuideCollection)\nself.assertGreater(collection.total_guides, 0)\nself.assertTrue(output_dir.exists())\nself.assertTrue((output_dir / 'index.md').exists())",
            "language": "Python",
            "description": "Workflow: Test building guides WITHOUT AI enhancement (backward compatibility)",
            "expected_behavior": "self.assertTrue((output_dir / 'index.md').exists())",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 653,
            "line_end": 696,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test building guides WITHOUT AI enhancement (backward compatibility)'",
            "description": "'Test building guides WITHOUT AI enhancement (backward compatibility)'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "examples = [{'example_id': 'test_001', 'test_name': 'test_user_registration', 'category': 'workflow', 'code': '\\ndef test_user_registration():\\n    user = User.create(username=\"test\", email=\"test@example.com\")\\n    assert user.id is not None\\n    assert user.is_active is True\\n                ', 'language': 'python', 'file_path': 'tests/test_user.py', 'line_start': 10, 'tags': ['authentication', 'user'], 'ai_analysis': {'tutorial_group': 'User Management', 'best_practices': ['Validate email format'], 'common_mistakes': ['Not checking uniqueness']}}]",
            "description": "Assign examples = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = HowToGuideBuilder()",
            "description": "Assign builder = HowToGuideBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_dir = Path(self.temp_dir) / 'guides'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=False, ai_mode='none')",
            "description": "Assign collection = builder.build_guides_from_examples(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIsInstance(collection, GuideCollection)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(collection.total_guides, 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(output_dir.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue((output_dir / 'index.md').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build With Ai Enhancement Disabled",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:653"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build With Ai Enhancement Api Mode Mocked": [
      {
        "guide_id": "0c352bf713b5",
        "title": "Build With Ai Enhancement Api Mode Mocked",
        "overview": "Workflow: Test building guides WITH AI enhancement in API mode (mocked)",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [
          "api_client"
        ],
        "workflows": [
          {
            "example_id": "ffc85d58",
            "test_name": "test_build_with_ai_enhancement_api_mode_mocked",
            "category": "workflow",
            "code": "'Test building guides WITH AI enhancement in API mode (mocked)'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_002', 'test_name': 'test_data_scraping', 'category': 'workflow', 'code': '\\ndef test_data_scraping():\\n    scraper = DocumentationScraper()\\n    result = scraper.scrape(\"https://example.com/docs\")\\n    assert result.pages > 0\\n                ', 'language': 'python', 'file_path': 'tests/test_scraper.py', 'line_start': 20, 'tags': ['scraping', 'documentation'], 'ai_analysis': {'tutorial_group': 'Data Collection', 'best_practices': ['Handle rate limiting'], 'common_mistakes': ['Not handling SSL errors']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_enhanced'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'api'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = [StepEnhancement(step_index=0, explanation='Test explanation', variations=[])]\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='api')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='api')",
            "language": "Python",
            "description": "Workflow: Test building guides WITH AI enhancement in API mode (mocked)",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 698,
            "line_end": 762,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test building guides WITH AI enhancement in API mode (mocked)'",
            "description": "'Test building guides WITH AI enhancement in API mode (mocked)'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "examples = [{'example_id': 'test_002', 'test_name': 'test_data_scraping', 'category': 'workflow', 'code': '\\ndef test_data_scraping():\\n    scraper = DocumentationScraper()\\n    result = scraper.scrape(\"https://example.com/docs\")\\n    assert result.pages > 0\\n                ', 'language': 'python', 'file_path': 'tests/test_scraper.py', 'line_start': 20, 'tags': ['scraping', 'documentation'], 'ai_analysis': {'tutorial_group': 'Data Collection', 'best_practices': ['Handle rate limiting'], 'common_mistakes': ['Not handling SSL errors']}}]",
            "description": "Assign examples = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = HowToGuideBuilder()",
            "description": "Assign builder = HowToGuideBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_dir = Path(self.temp_dir) / 'guides_enhanced'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "mock_enhancer = MockEnhancer.return_value",
            "description": "Assign mock_enhancer = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "mock_enhancer.mode = 'api'",
            "description": "Assign mock_enhancer.mode = 'api'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "mock_enhancer.enhance_guide = mock_enhance_guide",
            "description": "Assign mock_enhancer.enhance_guide = mock_enhance_guide",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='api')",
            "description": "Assign collection = builder.build_guides_from_examples(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIsInstance(collection, GuideCollection)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreater(collection.total_guides, 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "MockEnhancer.assert_called_once_with(mode='api')",
            "description": "Call MockEnhancer.assert_called_once_with()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "enhanced = guide_data.copy()",
            "description": "Assign enhanced = guide_data.copy(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "enhanced['step_enhancements'] = [StepEnhancement(step_index=0, explanation='Test explanation', variations=[])]",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "enhanced['troubleshooting_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "enhanced['prerequisites_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "enhanced['next_steps_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "enhanced['use_cases'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build With Ai Enhancement Api Mode Mocked",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:698"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build With Ai Enhancement Local Mode Mocked": [
      {
        "guide_id": "cd64eb3ec6b3",
        "title": "Build With Ai Enhancement Local Mode Mocked",
        "overview": "Workflow: Test building guides WITH AI enhancement in LOCAL mode (mocked)",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "830c1fe1",
            "test_name": "test_build_with_ai_enhancement_local_mode_mocked",
            "category": "workflow",
            "code": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_003', 'test_name': 'test_api_integration', 'category': 'workflow', 'code': '\\ndef test_api_integration():\\n    client = APIClient(base_url=\"https://api.example.com\")\\n    response = client.get(\"/users\")\\n    assert response.status_code == 200\\n                ', 'language': 'python', 'file_path': 'tests/test_api.py', 'line_start': 30, 'tags': ['api', 'integration'], 'ai_analysis': {'tutorial_group': 'API Testing', 'best_practices': ['Use environment variables'], 'common_mistakes': ['Hardcoded credentials']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_local'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'local'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = []\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='local')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='local')",
            "language": "Python",
            "description": "Workflow: Test building guides WITH AI enhancement in LOCAL mode (mocked)",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 764,
            "line_end": 825,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'",
            "description": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "examples = [{'example_id': 'test_003', 'test_name': 'test_api_integration', 'category': 'workflow', 'code': '\\ndef test_api_integration():\\n    client = APIClient(base_url=\"https://api.example.com\")\\n    response = client.get(\"/users\")\\n    assert response.status_code == 200\\n                ', 'language': 'python', 'file_path': 'tests/test_api.py', 'line_start': 30, 'tags': ['api', 'integration'], 'ai_analysis': {'tutorial_group': 'API Testing', 'best_practices': ['Use environment variables'], 'common_mistakes': ['Hardcoded credentials']}}]",
            "description": "Assign examples = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = HowToGuideBuilder()",
            "description": "Assign builder = HowToGuideBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_dir = Path(self.temp_dir) / 'guides_local'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "mock_enhancer = MockEnhancer.return_value",
            "description": "Assign mock_enhancer = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "mock_enhancer.mode = 'local'",
            "description": "Assign mock_enhancer.mode = 'local'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "mock_enhancer.enhance_guide = mock_enhance_guide",
            "description": "Assign mock_enhancer.enhance_guide = mock_enhance_guide",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='local')",
            "description": "Assign collection = builder.build_guides_from_examples(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIsInstance(collection, GuideCollection)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreater(collection.total_guides, 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "MockEnhancer.assert_called_once_with(mode='local')",
            "description": "Call MockEnhancer.assert_called_once_with()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "enhanced = guide_data.copy()",
            "description": "Assign enhanced = guide_data.copy(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "enhanced['step_enhancements'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "enhanced['troubleshooting_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "enhanced['prerequisites_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "enhanced['next_steps_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "enhanced['use_cases'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build With Ai Enhancement Local Mode Mocked",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:764"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build With Ai Enhancement Auto Mode": [
      {
        "guide_id": "efa6fd8ee314",
        "title": "Build With Ai Enhancement Auto Mode",
        "overview": "Workflow: Test building guides WITH AI enhancement in AUTO mode",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.guide_enhancer",
          "skill_seekers.cli.how_to_guide_builder",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "unittest.mock",
          "ast",
          "ast"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "6b4b2d61",
            "test_name": "test_build_with_ai_enhancement_auto_mode",
            "category": "workflow",
            "code": "'Test building guides WITH AI enhancement in AUTO mode'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_004', 'test_name': 'test_database_migration', 'category': 'workflow', 'code': '\\ndef test_database_migration():\\n    migrator = DatabaseMigrator()\\n    migrator.run_migrations()\\n    assert migrator.current_version == \"2.0\"\\n                ', 'language': 'python', 'file_path': 'tests/test_db.py', 'line_start': 40, 'tags': ['database', 'migration'], 'ai_analysis': {'tutorial_group': 'Database Operations', 'best_practices': ['Backup before migration'], 'common_mistakes': ['Not testing rollback']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_auto'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'local'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = []\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='auto')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='auto')",
            "language": "Python",
            "description": "Workflow: Test building guides WITH AI enhancement in AUTO mode",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
            "line_start": 827,
            "line_end": 887,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.guide_enhancer",
              "skill_seekers.cli.how_to_guide_builder",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "unittest.mock",
              "ast",
              "ast"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test building guides WITH AI enhancement in AUTO mode'",
            "description": "'Test building guides WITH AI enhancement in AUTO mode'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "examples = [{'example_id': 'test_004', 'test_name': 'test_database_migration', 'category': 'workflow', 'code': '\\ndef test_database_migration():\\n    migrator = DatabaseMigrator()\\n    migrator.run_migrations()\\n    assert migrator.current_version == \"2.0\"\\n                ', 'language': 'python', 'file_path': 'tests/test_db.py', 'line_start': 40, 'tags': ['database', 'migration'], 'ai_analysis': {'tutorial_group': 'Database Operations', 'best_practices': ['Backup before migration'], 'common_mistakes': ['Not testing rollback']}}]",
            "description": "Assign examples = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = HowToGuideBuilder()",
            "description": "Assign builder = HowToGuideBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "output_dir = Path(self.temp_dir) / 'guides_auto'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "mock_enhancer = MockEnhancer.return_value",
            "description": "Assign mock_enhancer = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "mock_enhancer.mode = 'local'",
            "description": "Assign mock_enhancer.mode = 'local'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "mock_enhancer.enhance_guide = mock_enhance_guide",
            "description": "Assign mock_enhancer.enhance_guide = mock_enhance_guide",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='auto')",
            "description": "Assign collection = builder.build_guides_from_examples(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIsInstance(collection, GuideCollection)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreater(collection.total_guides, 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "MockEnhancer.assert_called_once_with(mode='auto')",
            "description": "Call MockEnhancer.assert_called_once_with()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "enhanced = guide_data.copy()",
            "description": "Assign enhanced = guide_data.copy(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "enhanced['step_enhancements'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "enhanced['troubleshooting_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "enhanced['prerequisites_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "enhanced['next_steps_detailed'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "enhanced['use_cases'] = []",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build With Ai Enhancement Auto Mode",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_how_to_guide_builder.py:827"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Modified File": [
      {
        "guide_id": "4bbe506a618c",
        "title": "Detect Modified File",
        "overview": "Workflow: Test detection of modified files.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2e536985",
            "test_name": "test_detect_modified_file",
            "category": "workflow",
            "code": "'Test detection of modified files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\nskill_md = temp_skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nModified content')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.modified) == 1\nassert len(change_set.added) == 0\nassert len(change_set.deleted) == 0\nassert change_set.modified[0].file_path == 'SKILL.md'\nassert change_set.modified[0].version == 2",
            "language": "Python",
            "description": "Workflow: Test detection of modified files.",
            "expected_behavior": "assert change_set.modified[0].version == 2",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 80,
            "line_end": 101,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of modified files.'",
            "description": "'Test detection of modified files.'",
            "expected_result": null,
            "verification": "assert len(change_set.modified) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert len(change_set.added) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": "assert len(change_set.deleted) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": "assert change_set.modified[0].file_path == 'SKILL.md'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "time.sleep(0.01)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": "assert change_set.modified[0].version == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "skill_md = temp_skill_dir / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "skill_md.write_text('# Test Skill\\n\\nModified content')",
            "description": "Call skill_md.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "change_set = updater2.detect_changes()",
            "description": "Assign change_set = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": "assert len(change_set.modified) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Modified File",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_incremental_updates.py:80"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Added File": [
      {
        "guide_id": "0603c0d5b30d",
        "title": "Detect Added File",
        "overview": "Workflow: Test detection of new files.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "31b88c27",
            "test_name": "test_detect_added_file",
            "category": "workflow",
            "code": "'Test detection of new files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nrefs_dir = temp_skill_dir / 'references'\nnew_ref = refs_dir / 'api_reference.md'\nnew_ref.write_text('# API Reference\\n\\nNew documentation')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.added) == 1\nassert len(change_set.modified) == 0\nassert len(change_set.deleted) == 0\nassert change_set.added[0].file_path == 'references/api_reference.md'",
            "language": "Python",
            "description": "Workflow: Test detection of new files.",
            "expected_behavior": "assert change_set.added[0].file_path == 'references/api_reference.md'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 104,
            "line_end": 124,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of new files.'",
            "description": "'Test detection of new files.'",
            "expected_result": null,
            "verification": "assert len(change_set.added) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert len(change_set.modified) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": "assert len(change_set.deleted) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": "assert change_set.added[0].file_path == 'references/api_reference.md'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "refs_dir = temp_skill_dir / 'references'",
            "description": "Assign refs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "new_ref = refs_dir / 'api_reference.md'",
            "description": "Assign new_ref = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "new_ref.write_text('# API Reference\\n\\nNew documentation')",
            "description": "Call new_ref.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "change_set = updater2.detect_changes()",
            "description": "Assign change_set = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": "assert len(change_set.added) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Added File",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_incremental_updates.py:104"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Detect Deleted File": [
      {
        "guide_id": "064b50685afb",
        "title": "Detect Deleted File",
        "overview": "Workflow: Test detection of deleted files.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "da7dec84",
            "test_name": "test_detect_deleted_file",
            "category": "workflow",
            "code": "'Test detection of deleted files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nref_file = temp_skill_dir / 'references' / 'getting_started.md'\nref_file.unlink()\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.deleted) == 1\nassert len(change_set.added) == 0\nassert len(change_set.modified) == 0\nassert 'references/getting_started.md' in change_set.deleted",
            "language": "Python",
            "description": "Workflow: Test detection of deleted files.",
            "expected_behavior": "assert 'references/getting_started.md' in change_set.deleted",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 127,
            "line_end": 146,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of deleted files.'",
            "description": "'Test detection of deleted files.'",
            "expected_result": null,
            "verification": "assert len(change_set.deleted) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert len(change_set.added) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": "assert len(change_set.modified) == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": "assert 'references/getting_started.md' in change_set.deleted",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "ref_file = temp_skill_dir / 'references' / 'getting_started.md'",
            "description": "Assign ref_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "ref_file.unlink()",
            "description": "Call ref_file.unlink()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "change_set = updater2.detect_changes()",
            "description": "Assign change_set = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": "assert len(change_set.deleted) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Detect Deleted File",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_incremental_updates.py:127"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Mixed Changes": [
      {
        "guide_id": "4b7c3a78eeb7",
        "title": "Mixed Changes",
        "overview": "Workflow: Test detection of multiple types of changes.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "06aa74e5",
            "test_name": "test_mixed_changes",
            "category": "workflow",
            "code": "'Test detection of multiple types of changes.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Test Skill\\n\\nModified')\nrefs_dir = temp_skill_dir / 'references'\n(refs_dir / 'new_file.md').write_text('# New File')\n(refs_dir / 'getting_started.md').unlink()\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.modified) == 1\nassert len(change_set.added) == 1\nassert len(change_set.deleted) == 1\nassert change_set.total_changes == 3",
            "language": "Python",
            "description": "Workflow: Test detection of multiple types of changes.",
            "expected_behavior": "assert change_set.total_changes == 3",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 149,
            "line_end": 177,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test detection of multiple types of changes.'",
            "description": "'Test detection of multiple types of changes.'",
            "expected_result": null,
            "verification": "assert len(change_set.modified) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert len(change_set.added) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": "assert len(change_set.deleted) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": "assert change_set.total_changes == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "time.sleep(0.01)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(temp_skill_dir / 'SKILL.md').write_text('# Test Skill\\n\\nModified')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "refs_dir = temp_skill_dir / 'references'",
            "description": "Assign refs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "(refs_dir / 'new_file.md').write_text('# New File')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "(refs_dir / 'getting_started.md').unlink()",
            "description": "Call unknown.unlink()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "change_set = updater2.detect_changes()",
            "description": "Assign change_set = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": "assert len(change_set.modified) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Mixed Changes",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_incremental_updates.py:149"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Generate Update Package": [
      {
        "guide_id": "6b70a93b5f76",
        "title": "Generate Update Package",
        "overview": "Workflow: Test update package generation.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a16387fa",
            "test_name": "test_generate_update_package",
            "category": "workflow",
            "code": "'Test update package generation.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Modified')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    package_path = Path(tmpdir) / 'update.json'\n    result_path = updater2.generate_update_package(change_set, package_path)\n    assert result_path.exists()\n    package_data = json.loads(result_path.read_text())\n    assert 'metadata' in package_data\n    assert 'changes' in package_data\n    assert package_data['metadata']['total_changes'] == 1\n    assert 'SKILL.md' in package_data['changes']\n    assert package_data['changes']['SKILL.md']['action'] == 'modify'",
            "language": "Python",
            "description": "Workflow: Test update package generation.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 180,
            "line_end": 209,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test update package generation.'",
            "description": "'Test update package generation.'",
            "expected_result": null,
            "verification": "assert result_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert 'metadata' in package_data",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": "assert 'changes' in package_data",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": "assert package_data['metadata']['total_changes'] == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "time.sleep(0.01)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": "assert 'SKILL.md' in package_data['changes']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(temp_skill_dir / 'SKILL.md').write_text('# Modified')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert package_data['changes']['SKILL.md']['action'] == 'modify'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "change_set = updater2.detect_changes()",
            "description": "Assign change_set = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "package_path = Path(tmpdir) / 'update.json'",
            "description": "Assign package_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "result_path = updater2.generate_update_package(change_set, package_path)",
            "description": "Assign result_path = updater2.generate_update_package(...)",
            "expected_result": null,
            "verification": "assert result_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "package_data = json.loads(result_path.read_text())",
            "description": "Assign package_data = json.loads(...)",
            "expected_result": null,
            "verification": "assert 'metadata' in package_data",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Generate Update Package",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_incremental_updates.py:180"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Diff Report Generation": [
      {
        "guide_id": "37b1b62dd4a6",
        "title": "Diff Report Generation",
        "overview": "Workflow: Test diff report generation.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0815fd04",
            "test_name": "test_diff_report_generation",
            "category": "workflow",
            "code": "'Test diff report generation.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Modified content')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nreport = updater2.generate_diff_report(change_set)\nassert 'INCREMENTAL UPDATE REPORT' in report\nassert 'Modified: 1 files' in report\nassert 'SKILL.md' in report",
            "language": "Python",
            "description": "Workflow: Test diff report generation.",
            "expected_behavior": "assert 'SKILL.md' in report",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 212,
            "line_end": 231,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test diff report generation.'",
            "description": "'Test diff report generation.'",
            "expected_result": null,
            "verification": "assert 'INCREMENTAL UPDATE REPORT' in report",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert 'Modified: 1 files' in report",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": "assert 'SKILL.md' in report",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "time.sleep(0.01)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(temp_skill_dir / 'SKILL.md').write_text('# Modified content')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "change_set = updater2.detect_changes()",
            "description": "Assign change_set = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "report = updater2.generate_diff_report(change_set)",
            "description": "Assign report = updater2.generate_diff_report(...)",
            "expected_result": null,
            "verification": "assert 'INCREMENTAL UPDATE REPORT' in report",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Diff Report Generation",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_incremental_updates.py:212"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Version Increment": [
      {
        "guide_id": "cc341c50b999",
        "title": "Version Increment",
        "overview": "Workflow: Test version numbers increment correctly.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "46c630fc",
            "test_name": "test_version_increment",
            "category": "workflow",
            "code": "'Test version numbers increment correctly.'\nupdater = IncrementalUpdater(temp_skill_dir)\nchange_set1 = updater.detect_changes()\nupdater.save_current_versions()\nfor doc in change_set1.added:\n    assert doc.version == 1\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('Modified once')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set2 = updater2.detect_changes()\nupdater2.save_current_versions()\nassert change_set2.modified[0].version == 2\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('Modified twice')\nupdater3 = IncrementalUpdater(temp_skill_dir)\nchange_set3 = updater3.detect_changes()\nassert change_set3.modified[0].version == 3",
            "language": "Python",
            "description": "Workflow: Test version numbers increment correctly.",
            "expected_behavior": "assert change_set3.modified[0].version == 3",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 234,
            "line_end": 263,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test version numbers increment correctly.'",
            "description": "'Test version numbers increment correctly.'",
            "expected_result": null,
            "verification": "assert doc.version == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert change_set2.modified[0].version == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "change_set1 = updater.detect_changes()",
            "description": "Assign change_set1 = updater.detect_changes(...)",
            "expected_result": null,
            "verification": "assert change_set3.modified[0].version == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "time.sleep(0.01)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(temp_skill_dir / 'SKILL.md').write_text('Modified once')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater2 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "change_set2 = updater2.detect_changes()",
            "description": "Assign change_set2 = updater2.detect_changes(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "updater2.save_current_versions()",
            "description": "Call updater2.save_current_versions()",
            "expected_result": null,
            "verification": "assert change_set2.modified[0].version == 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "time.sleep(0.01)",
            "description": "Call time.sleep()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "(temp_skill_dir / 'SKILL.md').write_text('Modified twice')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "updater3 = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater3 = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "change_set3 = updater3.detect_changes()",
            "description": "Assign change_set3 = updater3.detect_changes(...)",
            "expected_result": null,
            "verification": "assert change_set3.modified[0].version == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Version Increment",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_incremental_updates.py:234"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Apply Update Package": [
      {
        "guide_id": "830031e152a0",
        "title": "Apply Update Package",
        "overview": "Workflow: Test applying an update package.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "6f4fe178",
            "test_name": "test_apply_update_package",
            "category": "workflow",
            "code": "'Test applying an update package.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    package_path = Path(tmpdir) / 'update.json'\n    update_data = {'metadata': {'timestamp': '2026-02-05T12:00:00', 'skill_name': 'test_skill', 'change_summary': {'modified': 1}, 'total_changes': 1}, 'changes': {'SKILL.md': {'action': 'modify', 'version': 2, 'content': '# Updated Content\\n\\nApplied from package'}}}\n    package_path.write_text(json.dumps(update_data))\n    success = updater.apply_update_package(package_path)\n    assert success\n    assert (temp_skill_dir / 'SKILL.md').read_text() == '# Updated Content\\n\\nApplied from package'",
            "language": "Python",
            "description": "Workflow: Test applying an update package.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 266,
            "line_end": 301,
            "complexity_score": 0.5,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test applying an update package.'",
            "description": "'Test applying an update package.'",
            "expected_result": null,
            "verification": "assert success",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": "assert (temp_skill_dir / 'SKILL.md').read_text() == '# Updated Content\\n\\nApplied from package'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updater.detect_changes()",
            "description": "Call updater.detect_changes()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "updater.save_current_versions()",
            "description": "Call updater.save_current_versions()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "package_path = Path(tmpdir) / 'update.json'",
            "description": "Assign package_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "update_data = {'metadata': {'timestamp': '2026-02-05T12:00:00', 'skill_name': 'test_skill', 'change_summary': {'modified': 1}, 'total_changes': 1}, 'changes': {'SKILL.md': {'action': 'modify', 'version': 2, 'content': '# Updated Content\\n\\nApplied from package'}}}",
            "description": "Assign update_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "package_path.write_text(json.dumps(update_data))",
            "description": "Call package_path.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "success = updater.apply_update_package(package_path)",
            "description": "Assign success = updater.apply_update_package(...)",
            "expected_result": null,
            "verification": "assert success",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Apply Update Package",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_incremental_updates.py:266"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Content Hash Consistency": [
      {
        "guide_id": "2f3b64159cc2",
        "title": "Content Hash Consistency",
        "overview": "Workflow: Test content hash is consistent for same content.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "time",
          "skill_seekers.cli.incremental_updater"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "afda60d8",
            "test_name": "test_content_hash_consistency",
            "category": "workflow",
            "code": "'Test content hash is consistent for same content.'\nupdater = IncrementalUpdater(temp_skill_dir)\nskill_md = temp_skill_dir / 'SKILL.md'\nhash1 = updater._compute_file_hash(skill_md)\ncontent = skill_md.read_text()\nskill_md.write_text(content)\nhash2 = updater._compute_file_hash(skill_md)\nassert hash1 == hash2",
            "language": "Python",
            "description": "Workflow: Test content hash is consistent for same content.",
            "expected_behavior": "assert hash1 == hash2",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
            "line_start": 304,
            "line_end": 319,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "time",
              "skill_seekers.cli.incremental_updater"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test content hash is consistent for same content.'",
            "description": "'Test content hash is consistent for same content.'",
            "expected_result": null,
            "verification": "assert hash1 == hash2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "updater = IncrementalUpdater(temp_skill_dir)",
            "description": "Assign updater = IncrementalUpdater(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "skill_md = temp_skill_dir / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "hash1 = updater._compute_file_hash(skill_md)",
            "description": "Assign hash1 = updater._compute_file_hash(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "content = skill_md.read_text()",
            "description": "Assign content = skill_md.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "skill_md.write_text(content)",
            "description": "Call skill_md.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "hash2 = updater._compute_file_hash(skill_md)",
            "description": "Assign hash2 = updater._compute_file_hash(...)",
            "expected_result": null,
            "verification": "assert hash1 == hash2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Content Hash Consistency",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_incremental_updates.py:304"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scraping Proceeds When Llms Txt Skipped": [
      {
        "guide_id": "f6aa73dcd536",
        "title": "Scraping Proceeds When Llms Txt Skipped",
        "overview": "Workflow: Test that HTML scraping proceeds normally when llms.txt is skipped.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "tempfile",
          "unittest",
          "unittest.mock",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [
          "api_client"
        ],
        "workflows": [
          {
            "example_id": "4dbd32f6",
            "test_name": "test_scraping_proceeds_when_llms_txt_skipped",
            "category": "workflow",
            "code": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'skip_llms_txt': True}\noriginal_cwd = os.getcwd()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=False)\n        scrape_called = []\n\n        def mock_scrape(url):\n            scrape_called.append(url)\n            return None\n        with patch.object(converter, 'scrape_page', side_effect=mock_scrape), patch.object(converter, 'save_summary'):\n            converter.scrape_all()\n            self.assertTrue(len(scrape_called) > 0)\n    finally:\n        os.chdir(original_cwd)",
            "language": "Python",
            "description": "Workflow: Test that HTML scraping proceeds normally when llms.txt is skipped.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
            "line_start": 295,
            "line_end": 325,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "tempfile",
              "unittest",
              "unittest.mock",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'",
            "description": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'skip_llms_txt': True}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "original_cwd = os.getcwd()",
            "description": "Assign original_cwd = os.getcwd(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "os.chdir(tmpdir)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter = DocToSkillConverter(config, dry_run=False)",
            "description": "Assign converter = DocToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "scrape_called = []",
            "description": "Assign scrape_called = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "os.chdir(original_cwd)",
            "description": "Call os.chdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "scrape_called.append(url)",
            "description": "Call scrape_called.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "converter.scrape_all()",
            "description": "Call converter.scrape_all()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertTrue(len(scrape_called) > 0)",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scraping Proceeds When Llms Txt Skipped",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_skip_llms_txt.py:295"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Issue Categorization By Topic": [
      {
        "guide_id": "3b36cb41e9dc",
        "title": "Issue Categorization By Topic",
        "overview": "Workflow: Test that issues are correctly categorized by topic keywords.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0b398609",
            "test_name": "test_issue_categorization_by_topic",
            "category": "workflow",
            "code": "'Test that issues are correctly categorized by topic keywords.'\nproblems = [{'title': 'OAuth fails on redirect', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token refresh issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth', 'token']}, {'title': 'Async deadlock', 'number': 40, 'state': 'open', 'comments': 12, 'labels': ['async', 'bug']}, {'title': 'Database connection lost', 'number': 35, 'state': 'open', 'comments': 10, 'labels': ['database']}]\nsolutions = [{'title': 'Fixed OAuth flow', 'number': 30, 'state': 'closed', 'comments': 8, 'labels': ['oauth']}, {'title': 'Resolved async race', 'number': 25, 'state': 'closed', 'comments': 6, 'labels': ['async']}]\ntopics = ['oauth', 'auth', 'authentication']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized\noauth_issues = categorized.get('oauth', []) + categorized.get('auth', []) + categorized.get('authentication', [])\nassert len(oauth_issues) >= 2\noauth_titles = [issue['title'] for issue in oauth_issues]\nassert any(('OAuth' in title for title in oauth_titles))",
            "language": "Python",
            "description": "Workflow: Test that issues are correctly categorized by topic keywords.",
            "expected_behavior": "assert any(('OAuth' in title for title in oauth_titles))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
            "line_start": 154,
            "line_end": 222,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that issues are correctly categorized by topic keywords.'",
            "description": "'Test that issues are correctly categorized by topic keywords.'",
            "expected_result": null,
            "verification": "assert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "problems = [{'title': 'OAuth fails on redirect', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token refresh issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth', 'token']}, {'title': 'Async deadlock', 'number': 40, 'state': 'open', 'comments': 12, 'labels': ['async', 'bug']}, {'title': 'Database connection lost', 'number': 35, 'state': 'open', 'comments': 10, 'labels': ['database']}]",
            "description": "Assign problems = value",
            "expected_result": null,
            "verification": "assert len(oauth_issues) >= 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "solutions = [{'title': 'Fixed OAuth flow', 'number': 30, 'state': 'closed', 'comments': 8, 'labels': ['oauth']}, {'title': 'Resolved async race', 'number': 25, 'state': 'closed', 'comments': 6, 'labels': ['async']}]",
            "description": "Assign solutions = value",
            "expected_result": null,
            "verification": "assert any(('OAuth' in title for title in oauth_titles))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "topics = ['oauth', 'auth', 'authentication']",
            "description": "Assign topics = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
            "description": "Assign categorized = categorize_issues_by_topic(...)",
            "expected_result": null,
            "verification": "assert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "oauth_issues = categorized.get('oauth', []) + categorized.get('auth', []) + categorized.get('authentication', [])",
            "description": "Assign oauth_issues = value",
            "expected_result": null,
            "verification": "assert len(oauth_issues) >= 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "oauth_titles = [issue['title'] for issue in oauth_issues]",
            "description": "Assign oauth_titles = value",
            "expected_result": null,
            "verification": "assert any(('OAuth' in title for title in oauth_titles))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Issue Categorization By Topic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_e2e_three_stream_pipeline.py:154"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Github Overhead Within Limits": [
      {
        "guide_id": "7fec3f8d3619",
        "title": "Github Overhead Within Limits",
        "overview": "Workflow: Test that GitHub integration adds ~30-50 lines per skill (not more).\n\nQuality metric: GitHub overhead should be minimal.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e2c9a8d6",
            "test_name": "test_github_overhead_within_limits",
            "category": "workflow",
            "code": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '\nconfig = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://github.com/test/repo', 'categories': {'api': ['api']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test\\n\\nA short README.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 100, 'forks': 10, 'language': 'Python', 'description': 'Test'}, common_problems=[{'title': 'Issue 1', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['bug']}, {'title': 'Issue 2', 'number': 2, 'state': 'open', 'comments': 3, 'labels': ['bug']}], known_solutions=[], top_labels=[{'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator_no_github = RouterGenerator([str(config_path)])\nskill_md_no_github = generator_no_github.generate_skill_md()\nlines_no_github = len(skill_md_no_github.split('\\n'))\ngenerator_with_github = RouterGenerator([str(config_path)], github_streams=github_streams)\nskill_md_with_github = generator_with_github.generate_skill_md()\nlines_with_github = len(skill_md_with_github.split('\\n'))\ngithub_overhead = lines_with_github - lines_no_github\nassert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
            "language": "Python",
            "description": "Workflow: Test that GitHub integration adds ~30-50 lines per skill (not more).\n\nQuality metric: GitHub overhead should be minimal.",
            "expected_behavior": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
            "line_start": 407,
            "line_end": 469,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '",
            "description": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '",
            "expected_result": null,
            "verification": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://github.com/test/repo', 'categories': {'api': ['api']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "docs_stream = DocsStream(readme='# Test\\n\\nA short README.', contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "insights_stream = InsightsStream(metadata={'stars': 100, 'forks': 10, 'language': 'Python', 'description': 'Test'}, common_problems=[{'title': 'Issue 1', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['bug']}, {'title': 'Issue 2', 'number': 2, 'state': 'open', 'comments': 3, 'labels': ['bug']}], known_solutions=[], top_labels=[{'label': 'bug', 'count': 10}])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "generator_no_github = RouterGenerator([str(config_path)])",
            "description": "Assign generator_no_github = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "skill_md_no_github = generator_no_github.generate_skill_md()",
            "description": "Assign skill_md_no_github = generator_no_github.generate_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "lines_no_github = len(skill_md_no_github.split('\\n'))",
            "description": "Assign lines_no_github = len(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "generator_with_github = RouterGenerator([str(config_path)], github_streams=github_streams)",
            "description": "Assign generator_with_github = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "skill_md_with_github = generator_with_github.generate_skill_md()",
            "description": "Assign skill_md_with_github = generator_with_github.generate_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "lines_with_github = len(skill_md_with_github.split('\\n'))",
            "description": "Assign lines_with_github = len(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "github_overhead = lines_with_github - lines_no_github",
            "description": "Assign github_overhead = value",
            "expected_result": null,
            "verification": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Github Overhead Within Limits",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_e2e_three_stream_pipeline.py:407"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Router Size Within Limits": [
      {
        "guide_id": "82d13a230834",
        "title": "Router Size Within Limits",
        "overview": "Workflow: Test that router SKILL.md is ~150 lines (\u00b120).\n\nQuality metric: Router should be concise overview, not exhaustive.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a65c1251",
            "test_name": "test_router_size_within_limits",
            "category": "workflow",
            "code": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '\nconfigs = []\nfor i in range(4):\n    config = {'name': f'test-skill-{i}', 'description': f'Test skill {i}', 'base_url': 'https://github.com/test/repo', 'categories': {f'topic{i}': [f'topic{i}']}}\n    config_path = tmp_path / f'config{i}.json'\n    with open(config_path, 'w') as f:\n        json.dump(config, f)\n    configs.append(str(config_path))\ngenerator = RouterGenerator(configs)\nskill_md = generator.generate_skill_md()\nlines = len(skill_md.split('\\n'))\nassert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
            "language": "Python",
            "description": "Workflow: Test that router SKILL.md is ~150 lines (\u00b120).\n\nQuality metric: Router should be concise overview, not exhaustive.",
            "expected_behavior": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
            "line_start": 471,
            "line_end": 498,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '",
            "description": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '",
            "expected_result": null,
            "verification": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "configs = []",
            "description": "Assign configs = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "generator = RouterGenerator(configs)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "skill_md = generator.generate_skill_md()",
            "description": "Assign skill_md = generator.generate_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "lines = len(skill_md.split('\\n'))",
            "description": "Assign lines = len(...)",
            "expected_result": null,
            "verification": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "config = {'name': f'test-skill-{i}', 'description': f'Test skill {i}', 'base_url': 'https://github.com/test/repo', 'categories': {f'topic{i}': [f'topic{i}']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "config_path = tmp_path / f'config{i}.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "configs.append(str(config_path))",
            "description": "Call configs.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Router Size Within Limits",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_e2e_three_stream_pipeline.py:471"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Router Without Github Streams": [
      {
        "guide_id": "fb1f881f8e7d",
        "title": "Router Without Github Streams",
        "overview": "Workflow: Test that router generation works without GitHub streams (backward compat).",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "be77a796",
            "test_name": "test_router_without_github_streams",
            "category": "workflow",
            "code": "'Test that router generation works without GitHub streams (backward compat).'\nconfig = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://example.com', 'categories': {'api': ['api']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nassert generator.github_metadata is None\nassert generator.github_docs is None\nassert generator.github_issues is None\nskill_md = generator.generate_skill_md()\nassert 'When to Use This Skill' in skill_md\nassert 'How It Works' in skill_md\nassert '\u2b50' not in skill_md\nassert 'Repository Info' not in skill_md\nassert 'Quick Start (from README)' not in skill_md\nassert 'Common Issues (from GitHub)' not in skill_md",
            "language": "Python",
            "description": "Workflow: Test that router generation works without GitHub streams (backward compat).",
            "expected_behavior": "assert 'Common Issues (from GitHub)' not in skill_md",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
            "line_start": 504,
            "line_end": 534,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that router generation works without GitHub streams (backward compat).'",
            "description": "'Test that router generation works without GitHub streams (backward compat).'",
            "expected_result": null,
            "verification": "assert generator.github_metadata is None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://example.com', 'categories': {'api': ['api']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": "assert generator.github_docs is None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = tmp_path / 'config.json'",
            "description": "Assign config_path = value",
            "expected_result": null,
            "verification": "assert generator.github_issues is None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generator = RouterGenerator([str(config_path)])",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert 'When to Use This Skill' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_md = generator.generate_skill_md()",
            "description": "Assign skill_md = generator.generate_skill_md(...)",
            "expected_result": null,
            "verification": "assert 'How It Works' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "json.dump(config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": "assert '\u2b50' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Router Without Github Streams",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_e2e_three_stream_pipeline.py:504"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Three Stream Produces Compact Output": [
      {
        "guide_id": "b08a6d8f862d",
        "title": "Three Stream Produces Compact Output",
        "overview": "Workflow: Test that three-stream architecture produces compact, efficient output.\n\nThis is a qualitative test - we verify that output is structured and\nnot duplicated across streams.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a4166214",
            "test_name": "test_three_stream_produces_compact_output",
            "category": "workflow",
            "code": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '\n(tmp_path / 'main.py').write_text(\"import os\\nprint('test')\")\ncode_stream = CodeStream(directory=tmp_path, files=[tmp_path / 'main.py'])\ndocs_stream = DocsStream(readme='# Test\\n\\nQuick start guide.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 100}, common_problems=[], known_solutions=[], top_labels=[])\n_three_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nassert code_stream.directory == tmp_path\nassert docs_stream.readme is not None\nassert insights_stream.metadata is not None\nassert 'Quick start guide' not in str(code_stream.files)\nassert str(tmp_path) not in docs_stream.readme",
            "language": "Python",
            "description": "Workflow: Test that three-stream architecture produces compact, efficient output.\n\nThis is a qualitative test - we verify that output is structured and\nnot duplicated across streams.",
            "expected_behavior": "assert str(tmp_path) not in docs_stream.readme",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
            "line_start": 567,
            "line_end": 594,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '",
            "description": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '",
            "expected_result": null,
            "verification": "assert code_stream.directory == tmp_path",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "(tmp_path / 'main.py').write_text(\"import os\\nprint('test')\")",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": "assert docs_stream.readme is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code_stream = CodeStream(directory=tmp_path, files=[tmp_path / 'main.py'])",
            "description": "Assign code_stream = CodeStream(...)",
            "expected_result": null,
            "verification": "assert insights_stream.metadata is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "docs_stream = DocsStream(readme='# Test\\n\\nQuick start guide.', contributing=None, docs_files=[])",
            "description": "Assign docs_stream = DocsStream(...)",
            "expected_result": null,
            "verification": "assert 'Quick start guide' not in str(code_stream.files)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "insights_stream = InsightsStream(metadata={'stars': 100}, common_problems=[], known_solutions=[], top_labels=[])",
            "description": "Assign insights_stream = InsightsStream(...)",
            "expected_result": null,
            "verification": "assert str(tmp_path) not in docs_stream.readme",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "_three_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
            "description": "Assign _three_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": "assert code_stream.directory == tmp_path",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Three Stream Produces Compact Output",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_e2e_three_stream_pipeline.py:567"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Preset Flag Preferred": [
      {
        "guide_id": "891a0f7b95b5",
        "title": "Preset Flag Preferred",
        "overview": "Workflow: Test that --preset flag is the recommended way.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "skill_seekers.cli.presets",
          "skill_seekers.cli.codebase_scraper",
          "argparse",
          "skill_seekers.cli.codebase_scraper",
          "argparse",
          "skill_seekers.cli.codebase_scraper",
          "argparse",
          "skill_seekers.cli.codebase_scraper",
          "argparse",
          "skill_seekers.cli.codebase_scraper",
          "argparse",
          "skill_seekers.cli.codebase_scraper",
          "argparse"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bd12e11a",
            "test_name": "test_preset_flag_preferred",
            "category": "workflow",
            "code": "'Test that --preset flag is the recommended way.'\nargs = {'preset': 'quick'}\nupdated = PresetManager.apply_preset('quick', args)\nassert updated['depth'] == 'surface'\nargs = {'preset': 'standard'}\nupdated = PresetManager.apply_preset('standard', args)\nassert updated['depth'] == 'deep'\nargs = {'preset': 'comprehensive'}\nupdated = PresetManager.apply_preset('comprehensive', args)\nassert updated['depth'] == 'full'",
            "language": "Python",
            "description": "Workflow: Test that --preset flag is the recommended way.",
            "expected_behavior": "assert updated['depth'] == 'full'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
            "line_start": 319,
            "line_end": 334,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "skill_seekers.cli.presets",
              "skill_seekers.cli.codebase_scraper",
              "argparse",
              "skill_seekers.cli.codebase_scraper",
              "argparse",
              "skill_seekers.cli.codebase_scraper",
              "argparse",
              "skill_seekers.cli.codebase_scraper",
              "argparse",
              "skill_seekers.cli.codebase_scraper",
              "argparse",
              "skill_seekers.cli.codebase_scraper",
              "argparse"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that --preset flag is the recommended way.'",
            "description": "'Test that --preset flag is the recommended way.'",
            "expected_result": null,
            "verification": "assert updated['depth'] == 'surface'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "args = {'preset': 'quick'}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": "assert updated['depth'] == 'deep'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "updated = PresetManager.apply_preset('quick', args)",
            "description": "Assign updated = PresetManager.apply_preset(...)",
            "expected_result": null,
            "verification": "assert updated['depth'] == 'full'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "args = {'preset': 'standard'}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "updated = PresetManager.apply_preset('standard', args)",
            "description": "Assign updated = PresetManager.apply_preset(...)",
            "expected_result": null,
            "verification": "assert updated['depth'] == 'deep'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "args = {'preset': 'comprehensive'}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "updated = PresetManager.apply_preset('comprehensive', args)",
            "description": "Assign updated = PresetManager.apply_preset(...)",
            "expected_result": null,
            "verification": "assert updated['depth'] == 'full'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Preset Flag Preferred",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_preset_system.py:319"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Completeness Full": [
      {
        "guide_id": "7d2940fc6a26",
        "title": "Completeness Full",
        "overview": "Workflow: Test completeness analysis with complete skill.",
        "complexity_level": "beginner",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.quality_metrics"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f368a9d1",
            "test_name": "test_completeness_full",
            "category": "workflow",
            "code": "'Test completeness analysis with complete skill.'\nanalyzer = QualityAnalyzer(complete_skill_dir)\nscore = analyzer.analyze_completeness()\nassert score >= 70",
            "language": "Python",
            "description": "Workflow: Test completeness analysis with complete skill.",
            "expected_behavior": "assert score >= 70",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
            "line_start": 60,
            "line_end": 65,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": "# Fixtures: complete_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.quality_metrics"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test completeness analysis with complete skill.'",
            "description": "'Test completeness analysis with complete skill.'",
            "expected_result": null,
            "verification": "assert score >= 70",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "analyzer = QualityAnalyzer(complete_skill_dir)",
            "description": "Assign analyzer = QualityAnalyzer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "score = analyzer.analyze_completeness()",
            "description": "Assign score = analyzer.analyze_completeness(...)",
            "expected_result": null,
            "verification": "assert score >= 70",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Completeness Full",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_quality_metrics.py:60"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Completeness Minimal": [
      {
        "guide_id": "862e0a58d213",
        "title": "Completeness Minimal",
        "overview": "Workflow: Test completeness analysis with minimal skill.",
        "complexity_level": "beginner",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.quality_metrics"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "632eb543",
            "test_name": "test_completeness_minimal",
            "category": "workflow",
            "code": "'Test completeness analysis with minimal skill.'\nanalyzer = QualityAnalyzer(minimal_skill_dir)\nscore = analyzer.analyze_completeness()\nassert score < 80",
            "language": "Python",
            "description": "Workflow: Test completeness analysis with minimal skill.",
            "expected_behavior": "assert score < 80",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
            "line_start": 68,
            "line_end": 73,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": "# Fixtures: minimal_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.quality_metrics"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test completeness analysis with minimal skill.'",
            "description": "'Test completeness analysis with minimal skill.'",
            "expected_result": null,
            "verification": "assert score < 80",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "analyzer = QualityAnalyzer(minimal_skill_dir)",
            "description": "Assign analyzer = QualityAnalyzer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "score = analyzer.analyze_completeness()",
            "description": "Assign score = analyzer.analyze_completeness(...)",
            "expected_result": null,
            "verification": "assert score < 80",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Completeness Minimal",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_quality_metrics.py:68"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Mock Github Repo": [
      {
        "guide_id": "cd78a2a0e35d",
        "title": "Mock Github Repo",
        "overview": "Workflow: Create mock GitHub repository structure.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e05661ef",
            "test_name": "mock_github_repo",
            "category": "workflow",
            "code": "'Create mock GitHub repository structure.'\nrepo_dir = tmp_path / 'fastmcp'\nrepo_dir.mkdir()\nsrc_dir = repo_dir / 'src'\nsrc_dir.mkdir()\n(src_dir / 'auth.py').write_text(\"\\n# OAuth authentication\\ndef google_provider(client_id, client_secret):\\n    '''Google OAuth provider'''\\n    return Provider('google', client_id, client_secret)\\n\\ndef azure_provider(tenant_id, client_id):\\n    '''Azure OAuth provider'''\\n    return Provider('azure', tenant_id, client_id)\\n\")\n(src_dir / 'async_tools.py').write_text('\\nimport asyncio\\n\\nasync def async_tool():\\n    \\'\\'\\'Async tool decorator\\'\\'\\'\\n    await asyncio.sleep(1)\\n    return \"result\"\\n')\ntests_dir = repo_dir / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")\n(repo_dir / 'README.md').write_text('\\n# FastMCP\\n\\nFastMCP is a Python framework for building MCP servers.\\n\\n## Quick Start\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Features\\n- OAuth authentication (Google, Azure, GitHub)\\n- Async/await support\\n- Easy testing with pytest\\n')\n(repo_dir / 'CONTRIBUTING.md').write_text('\\n# Contributing\\n\\nPlease follow these guidelines when contributing.\\n')\ndocs_dir = repo_dir / 'docs'\ndocs_dir.mkdir()\n(docs_dir / 'oauth.md').write_text('\\n# OAuth Guide\\n\\nHow to set up OAuth providers.\\n')\n(docs_dir / 'async.md').write_text('\\n# Async Guide\\n\\nHow to use async tools.\\n')\nreturn repo_dir",
            "language": "Python",
            "description": "Workflow: Create mock GitHub repository structure.",
            "expected_behavior": "(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 65,
            "line_end": 157,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "mock",
              "pytest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Create mock GitHub repository structure.'",
            "description": "'Create mock GitHub repository structure.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "repo_dir = tmp_path / 'fastmcp'",
            "description": "Assign repo_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "repo_dir.mkdir()",
            "description": "Call repo_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "src_dir = repo_dir / 'src'",
            "description": "Assign src_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "src_dir.mkdir()",
            "description": "Call src_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(src_dir / 'auth.py').write_text(\"\\n# OAuth authentication\\ndef google_provider(client_id, client_secret):\\n    '''Google OAuth provider'''\\n    return Provider('google', client_id, client_secret)\\n\\ndef azure_provider(tenant_id, client_id):\\n    '''Azure OAuth provider'''\\n    return Provider('azure', tenant_id, client_id)\\n\")",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "(src_dir / 'async_tools.py').write_text('\\nimport asyncio\\n\\nasync def async_tool():\\n    \\'\\'\\'Async tool decorator\\'\\'\\'\\n    await asyncio.sleep(1)\\n    return \"result\"\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "tests_dir = repo_dir / 'tests'",
            "description": "Assign tests_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "tests_dir.mkdir()",
            "description": "Call tests_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "(repo_dir / 'README.md').write_text('\\n# FastMCP\\n\\nFastMCP is a Python framework for building MCP servers.\\n\\n## Quick Start\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Features\\n- OAuth authentication (Google, Azure, GitHub)\\n- Async/await support\\n- Easy testing with pytest\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "(repo_dir / 'CONTRIBUTING.md').write_text('\\n# Contributing\\n\\nPlease follow these guidelines when contributing.\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "docs_dir = repo_dir / 'docs'",
            "description": "Assign docs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "docs_dir.mkdir()",
            "description": "Call docs_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "(docs_dir / 'oauth.md').write_text('\\n# OAuth Guide\\n\\nHow to set up OAuth providers.\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "(docs_dir / 'async.md').write_text('\\n# Async Guide\\n\\nHow to use async tools.\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Mock Github Repo",
        "tags": [
          "mock",
          "pytest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_architecture_scenarios.py:65"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 1 Quality Metrics": [
      {
        "guide_id": "7890bb5135bc",
        "title": "Scenario 1 Quality Metrics",
        "overview": "Workflow: Test quality metrics meet architecture targets.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2013ef2a",
            "test_name": "test_scenario_1_quality_metrics",
            "category": "workflow",
            "code": "'Test quality metrics meet architecture targets.'\nrouter_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'\nlines = router_md.strip().split('\\n')\nassert len(lines) <= 200, f'Router too large: {len(lines)} lines (max 200)'\ngithub_lines = 0\nif 'Repository:' in router_md:\n    github_lines += 1\nif 'Stars:' in router_md or '\u2b50' in router_md:\n    github_lines += 1\nif 'Common Issues' in router_md:\n    github_lines += router_md.count('Issue #')\nassert github_lines >= 3, f'GitHub overhead too small: {github_lines} lines'\nassert github_lines <= 60, f'GitHub overhead too large: {github_lines} lines'\nassert 'Issue #42' in router_md, 'Missing issue references'\nassert '\u2b50' in router_md or 'Stars:' in router_md, 'Missing GitHub metadata'\nassert 'Quick Start' in router_md or 'README' in router_md, 'Missing README content'",
            "language": "Python",
            "description": "Workflow: Test quality metrics meet architecture targets.",
            "expected_behavior": "assert 'Quick Start' in router_md or 'README' in router_md, 'Missing README content'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 427,
            "line_end": 482,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test quality metrics meet architecture targets.'",
            "description": "'Test quality metrics meet architecture targets.'",
            "expected_result": null,
            "verification": "assert len(lines) <= 200, f'Router too large: {len(lines)} lines (max 200)'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "router_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'",
            "description": "Assign router_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'",
            "expected_result": null,
            "verification": "assert github_lines >= 3, f'GitHub overhead too small: {github_lines} lines'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "lines = router_md.strip().split('\\n')",
            "description": "Assign lines = router_md.strip.split(...)",
            "expected_result": null,
            "verification": "assert github_lines <= 60, f'GitHub overhead too large: {github_lines} lines'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "github_lines = 0",
            "description": "Assign github_lines = 0",
            "expected_result": null,
            "verification": "assert 'Issue #42' in router_md, 'Missing issue references'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 1 Quality Metrics",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_architecture_scenarios.py:427"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 2 Issue Categorization": [
      {
        "guide_id": "f8f890371ff0",
        "title": "Scenario 2 Issue Categorization",
        "overview": "Workflow: Test categorizing GitHub issues by topic.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "16d35564",
            "test_name": "test_scenario_2_issue_categorization",
            "category": "workflow",
            "code": "'Test categorizing GitHub issues by topic.'\nproblems = [{'number': 42, 'title': 'OAuth setup fails', 'labels': ['oauth', 'bug']}, {'number': 38, 'title': 'Async tools not working', 'labels': ['async', 'question']}, {'number': 35, 'title': 'Testing with pytest', 'labels': ['testing', 'question']}, {'number': 30, 'title': 'Google OAuth redirect', 'labels': ['oauth', 'question']}]\nsolutions = [{'number': 25, 'title': 'Fixed OAuth redirect', 'labels': ['oauth', 'bug']}, {'number': 20, 'title': 'Async timeout solution', 'labels': ['async', 'bug']}]\ntopics = ['oauth', 'async', 'testing']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized\nassert 'async' in categorized\nassert 'testing' in categorized\noauth_issues = categorized['oauth']\nassert len(oauth_issues) >= 2\noauth_numbers = [i['number'] for i in oauth_issues]\nassert 42 in oauth_numbers\nasync_issues = categorized['async']\nassert len(async_issues) >= 2\nasync_numbers = [i['number'] for i in async_issues]\nassert 38 in async_numbers\ntesting_issues = categorized['testing']\nassert len(testing_issues) >= 1",
            "language": "Python",
            "description": "Workflow: Test categorizing GitHub issues by topic.",
            "expected_behavior": "assert len(testing_issues) >= 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 519,
            "line_end": 572,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test categorizing GitHub issues by topic.'",
            "description": "'Test categorizing GitHub issues by topic.'",
            "expected_result": null,
            "verification": "assert 'oauth' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "problems = [{'number': 42, 'title': 'OAuth setup fails', 'labels': ['oauth', 'bug']}, {'number': 38, 'title': 'Async tools not working', 'labels': ['async', 'question']}, {'number': 35, 'title': 'Testing with pytest', 'labels': ['testing', 'question']}, {'number': 30, 'title': 'Google OAuth redirect', 'labels': ['oauth', 'question']}]",
            "description": "Assign problems = value",
            "expected_result": null,
            "verification": "assert 'async' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "solutions = [{'number': 25, 'title': 'Fixed OAuth redirect', 'labels': ['oauth', 'bug']}, {'number': 20, 'title': 'Async timeout solution', 'labels': ['async', 'bug']}]",
            "description": "Assign solutions = value",
            "expected_result": null,
            "verification": "assert 'testing' in categorized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "topics = ['oauth', 'async', 'testing']",
            "description": "Assign topics = value",
            "expected_result": null,
            "verification": "assert len(oauth_issues) >= 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
            "description": "Assign categorized = categorize_issues_by_topic(...)",
            "expected_result": null,
            "verification": "assert 42 in oauth_numbers",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "oauth_issues = categorized['oauth']",
            "description": "Assign oauth_issues = value",
            "expected_result": null,
            "verification": "assert len(async_issues) >= 2",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "oauth_numbers = [i['number'] for i in oauth_issues]",
            "description": "Assign oauth_numbers = value",
            "expected_result": null,
            "verification": "assert 38 in async_numbers",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "async_issues = categorized['async']",
            "description": "Assign async_issues = value",
            "expected_result": null,
            "verification": "assert len(testing_issues) >= 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "async_numbers = [i['number'] for i in async_issues]",
            "description": "Assign async_numbers = value",
            "expected_result": null,
            "verification": "assert 38 in async_numbers",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "testing_issues = categorized['testing']",
            "description": "Assign testing_issues = value",
            "expected_result": null,
            "verification": "assert len(testing_issues) >= 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 2 Issue Categorization",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_architecture_scenarios.py:519"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 2 Conflict Detection": [
      {
        "guide_id": "55f3090c122c",
        "title": "Scenario 2 Conflict Detection",
        "overview": "Workflow: Test conflict detection between docs and code.",
        "complexity_level": "beginner",
        "prerequisites": [],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "15777a62",
            "test_name": "test_scenario_2_conflict_detection",
            "category": "workflow",
            "code": "'Test conflict detection between docs and code.'\napi_data = {'GoogleProvider': {'params': ['app_id', 'app_secret'], 'source': 'html_docs'}}\ngithub_docs = {'readme': 'Use client_id and client_secret for Google OAuth'}\nassert 'GoogleProvider' in api_data\nassert 'params' in api_data['GoogleProvider']\nassert github_docs is not None",
            "language": "Python",
            "description": "Workflow: Test conflict detection between docs and code.",
            "expected_behavior": "assert github_docs is not None",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 574,
            "line_end": 595,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test conflict detection between docs and code.'",
            "description": "'Test conflict detection between docs and code.'",
            "expected_result": null,
            "verification": "assert 'GoogleProvider' in api_data",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "api_data = {'GoogleProvider': {'params': ['app_id', 'app_secret'], 'source': 'html_docs'}}",
            "description": "Assign api_data = value",
            "expected_result": null,
            "verification": "assert 'params' in api_data['GoogleProvider']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "github_docs = {'readme': 'Use client_id and client_secret for Google OAuth'}",
            "description": "Assign github_docs = value",
            "expected_result": null,
            "verification": "assert github_docs is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 2 Conflict Detection",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_architecture_scenarios.py:574"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 2 Multi Layer Merge": [
      {
        "guide_id": "fbb1e020fb2e",
        "title": "Scenario 2 Multi Layer Merge",
        "overview": "Workflow: Test multi-layer source merging priority.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "32affc6b",
            "test_name": "test_scenario_2_multi_layer_merge",
            "category": "workflow",
            "code": "'Test multi-layer source merging priority.'\nsource1_data = {'api': [{'name': 'GoogleProvider', 'params': ['app_id', 'app_secret']}]}\nsource2_data = {'api': [{'name': 'GoogleProvider', 'params': ['client_id', 'client_secret']}]}\n_github_streams = ThreeStreamData(code_stream=CodeStream(directory=Path('/tmp'), files=[]), docs_stream=DocsStream(readme='Use client_id and client_secret', contributing=None, docs_files=[]), insights_stream=InsightsStream(metadata={'stars': 1000}, common_problems=[{'number': 42, 'title': 'OAuth parameter confusion', 'labels': ['oauth']}], known_solutions=[], top_labels=[]))\nmerger = RuleBasedMerger(docs_data=source1_data, github_data=source2_data, conflicts=[])\nmerged = merger.merge_all()\nassert merged is not None\nassert isinstance(merged, dict)",
            "language": "Python",
            "description": "Workflow: Test multi-layer source merging priority.",
            "expected_behavior": "assert isinstance(merged, dict)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 597,
            "line_end": 643,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test multi-layer source merging priority.'",
            "description": "'Test multi-layer source merging priority.'",
            "expected_result": null,
            "verification": "assert merged is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "source1_data = {'api': [{'name': 'GoogleProvider', 'params': ['app_id', 'app_secret']}]}",
            "description": "Assign source1_data = value",
            "expected_result": null,
            "verification": "assert isinstance(merged, dict)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "source2_data = {'api': [{'name': 'GoogleProvider', 'params': ['client_id', 'client_secret']}]}",
            "description": "Assign source2_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "_github_streams = ThreeStreamData(code_stream=CodeStream(directory=Path('/tmp'), files=[]), docs_stream=DocsStream(readme='Use client_id and client_secret', contributing=None, docs_files=[]), insights_stream=InsightsStream(metadata={'stars': 1000}, common_problems=[{'number': 42, 'title': 'OAuth parameter confusion', 'labels': ['oauth']}], known_solutions=[], top_labels=[]))",
            "description": "Assign _github_streams = ThreeStreamData(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "merger = RuleBasedMerger(docs_data=source1_data, github_data=source2_data, conflicts=[])",
            "description": "Assign merger = RuleBasedMerger(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "merged = merger.merge_all()",
            "description": "Assign merged = merger.merge_all(...)",
            "expected_result": null,
            "verification": "assert merged is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 2 Multi Layer Merge",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_architecture_scenarios.py:597"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 3 Local Analysis Basic": [
      {
        "guide_id": "026ad04a523b",
        "title": "Scenario 3 Local Analysis Basic",
        "overview": "Workflow: Test basic analysis of local codebase.",
        "complexity_level": "beginner",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "41b21168",
            "test_name": "test_scenario_3_local_analysis_basic",
            "category": "workflow",
            "code": "'Test basic analysis of local codebase.'\nanalyzer = UnifiedCodebaseAnalyzer()\nresult = analyzer.analyze(source=str(local_codebase), depth='basic', fetch_github_metadata=False)\nassert isinstance(result, AnalysisResult)\nassert result.source_type == 'local'\nassert result.analysis_depth == 'basic'\nassert result.code_analysis is not None\nassert 'files' in result.code_analysis\nassert len(result.code_analysis['files']) >= 2\nassert result.github_docs is None\nassert result.github_insights is None",
            "language": "Python",
            "description": "Workflow: Test basic analysis of local codebase.",
            "expected_behavior": "assert result.github_insights is None",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 720,
            "line_end": 740,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: local_codebase",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic analysis of local codebase.'",
            "description": "'Test basic analysis of local codebase.'",
            "expected_result": null,
            "verification": "assert isinstance(result, AnalysisResult)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "analyzer = UnifiedCodebaseAnalyzer()",
            "description": "Assign analyzer = UnifiedCodebaseAnalyzer(...)",
            "expected_result": null,
            "verification": "assert result.source_type == 'local'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = analyzer.analyze(source=str(local_codebase), depth='basic', fetch_github_metadata=False)",
            "description": "Assign result = analyzer.analyze(...)",
            "expected_result": null,
            "verification": "assert result.analysis_depth == 'basic'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 3 Local Analysis Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_architecture_scenarios.py:720"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 3 Local Analysis C3X": [
      {
        "guide_id": "73c421970825",
        "title": "Scenario 3 Local Analysis C3X",
        "overview": "Workflow: Test C3.x analysis of local codebase.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "393c5e0e",
            "test_name": "test_scenario_3_local_analysis_c3x",
            "category": "workflow",
            "code": "'Test C3.x analysis of local codebase.'\nanalyzer = UnifiedCodebaseAnalyzer()\nwith patch('skill_seekers.cli.unified_codebase_analyzer.UnifiedCodebaseAnalyzer.c3x_analysis') as mock_c3x:\n    mock_c3x.return_value = {'files': ['database.py', 'api.py'], 'analysis_type': 'c3x', 'c3_1_patterns': [{'name': 'Singleton', 'count': 1, 'file': 'database.py'}], 'c3_2_examples': [{'name': 'test_connection', 'file': 'test_database.py'}], 'c3_2_examples_count': 1, 'c3_3_guides': [], 'c3_4_configs': [], 'c3_7_architecture': []}\n    result = analyzer.analyze(source=str(local_codebase), depth='c3x', fetch_github_metadata=False)\n    assert result.source_type == 'local'\n    assert result.analysis_depth == 'c3x'\n    assert result.code_analysis['analysis_type'] == 'c3x'\n    assert 'c3_1_patterns' in result.code_analysis\n    assert 'c3_2_examples' in result.code_analysis\n    assert result.github_docs is None\n    assert result.github_insights is None",
            "language": "Python",
            "description": "Workflow: Test C3.x analysis of local codebase.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 742,
            "line_end": 776,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": "# Fixtures: local_codebase",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test C3.x analysis of local codebase.'",
            "description": "'Test C3.x analysis of local codebase.'",
            "expected_result": null,
            "verification": "assert result.source_type == 'local'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "analyzer = UnifiedCodebaseAnalyzer()",
            "description": "Assign analyzer = UnifiedCodebaseAnalyzer(...)",
            "expected_result": null,
            "verification": "assert result.analysis_depth == 'c3x'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "mock_c3x.return_value = {'files': ['database.py', 'api.py'], 'analysis_type': 'c3x', 'c3_1_patterns': [{'name': 'Singleton', 'count': 1, 'file': 'database.py'}], 'c3_2_examples': [{'name': 'test_connection', 'file': 'test_database.py'}], 'c3_2_examples_count': 1, 'c3_3_guides': [], 'c3_4_configs': [], 'c3_7_architecture': []}",
            "description": "Assign mock_c3x.return_value = value",
            "expected_result": null,
            "verification": "assert result.code_analysis['analysis_type'] == 'c3x'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = analyzer.analyze(source=str(local_codebase), depth='c3x', fetch_github_metadata=False)",
            "description": "Assign result = analyzer.analyze(...)",
            "expected_result": null,
            "verification": "assert 'c3_1_patterns' in result.code_analysis",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 3 Local Analysis C3X",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_architecture_scenarios.py:742"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Scenario 3 Router Without Github": [
      {
        "guide_id": "46561e5fecd4",
        "title": "Scenario 3 Router Without Github",
        "overview": "Workflow: Test router generation without GitHub data.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "634f58a2",
            "test_name": "test_scenario_3_router_without_github",
            "category": "workflow",
            "code": "'Test router generation without GitHub data.'\nconfig1 = tmp_path / 'internal-database.json'\nconfig1.write_text(json.dumps({'name': 'internal-database', 'description': 'Database layer', 'categories': {'database': ['db', 'sql', 'connection']}}))\nconfig2 = tmp_path / 'internal-api.json'\nconfig2.write_text(json.dumps({'name': 'internal-api', 'description': 'API endpoints', 'categories': {'api': ['api', 'endpoint', 'route']}}))\ngenerator = RouterGenerator(config_paths=[str(config1), str(config2)], router_name='internal-tool', github_streams=None)\nskill_md = generator.generate_skill_md()\nassert 'internal-tool' in skill_md.lower()\nassert 'Repository:' not in skill_md\nassert 'Stars:' not in skill_md\nassert '\u2b50' not in skill_md\nassert 'Common Issues' not in skill_md\nassert 'Issue #' not in skill_md\nassert 'internal-database' in skill_md\nassert 'internal-api' in skill_md",
            "language": "Python",
            "description": "Workflow: Test router generation without GitHub data.",
            "expected_behavior": "assert 'internal-api' in skill_md",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 778,
            "line_end": 826,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test router generation without GitHub data.'",
            "description": "'Test router generation without GitHub data.'",
            "expected_result": null,
            "verification": "assert 'internal-tool' in skill_md.lower()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config1 = tmp_path / 'internal-database.json'",
            "description": "Assign config1 = value",
            "expected_result": null,
            "verification": "assert 'Repository:' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config1.write_text(json.dumps({'name': 'internal-database', 'description': 'Database layer', 'categories': {'database': ['db', 'sql', 'connection']}}))",
            "description": "Call config1.write_text()",
            "expected_result": null,
            "verification": "assert 'Stars:' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "config2 = tmp_path / 'internal-api.json'",
            "description": "Assign config2 = value",
            "expected_result": null,
            "verification": "assert '\u2b50' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config2.write_text(json.dumps({'name': 'internal-api', 'description': 'API endpoints', 'categories': {'api': ['api', 'endpoint', 'route']}}))",
            "description": "Call config2.write_text()",
            "expected_result": null,
            "verification": "assert 'Common Issues' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "generator = RouterGenerator(config_paths=[str(config1), str(config2)], router_name='internal-tool', github_streams=None)",
            "description": "Assign generator = RouterGenerator(...)",
            "expected_result": null,
            "verification": "assert 'Issue #' not in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "skill_md = generator.generate_skill_md()",
            "description": "Assign skill_md = generator.generate_skill_md(...)",
            "expected_result": null,
            "verification": "assert 'internal-database' in skill_md",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Scenario 3 Router Without Github",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_architecture_scenarios.py:778"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Token Efficiency Calculation": [
      {
        "guide_id": "57228da4881c",
        "title": "Token Efficiency Calculation",
        "overview": "Workflow: Calculate token efficiency with GitHub overhead.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.generate_router",
          "skill_seekers.cli.github_fetcher",
          "skill_seekers.cli.merge_sources",
          "skill_seekers.cli.unified_codebase_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bab78031",
            "test_name": "test_token_efficiency_calculation",
            "category": "workflow",
            "code": "'Calculate token efficiency with GitHub overhead.'\nmonolithic_size = 666 + 50\nrouter_size = 150 + 50\navg_subskill_size = (250 + 200 + 250 + 400) / 4\navg_subskill_with_github = avg_subskill_size + 30\navg_router_query = router_size + avg_subskill_with_github\nreduction = (monolithic_size - avg_router_query) / monolithic_size\nreduction_percent = reduction * 100\nprint('\\n=== Token Efficiency Calculation ===')\nprint(f'Monolithic: {monolithic_size} lines')\nprint(f'Router: {router_size} lines')\nprint(f'Avg Sub-skill: {avg_subskill_with_github} lines')\nprint(f'Avg Query: {avg_router_query} lines')\nprint(f'Reduction: {reduction_percent:.1f}%')\nprint('Target: 35-40%')\nassert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
            "language": "Python",
            "description": "Workflow: Calculate token efficiency with GitHub overhead.",
            "expected_behavior": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
            "line_start": 1025,
            "line_end": 1054,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.generate_router",
              "skill_seekers.cli.github_fetcher",
              "skill_seekers.cli.merge_sources",
              "skill_seekers.cli.unified_codebase_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Calculate token efficiency with GitHub overhead.'",
            "description": "'Calculate token efficiency with GitHub overhead.'",
            "expected_result": null,
            "verification": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "monolithic_size = 666 + 50",
            "description": "Assign monolithic_size = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "router_size = 150 + 50",
            "description": "Assign router_size = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "avg_subskill_size = (250 + 200 + 250 + 400) / 4",
            "description": "Assign avg_subskill_size = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "avg_subskill_with_github = avg_subskill_size + 30",
            "description": "Assign avg_subskill_with_github = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "avg_router_query = router_size + avg_subskill_with_github",
            "description": "Assign avg_router_query = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "reduction = (monolithic_size - avg_router_query) / monolithic_size",
            "description": "Assign reduction = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "reduction_percent = reduction * 100",
            "description": "Assign reduction_percent = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "print('\\n=== Token Efficiency Calculation ===')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "print(f'Monolithic: {monolithic_size} lines')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "print(f'Router: {router_size} lines')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "print(f'Avg Sub-skill: {avg_subskill_with_github} lines')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "print(f'Avg Query: {avg_router_query} lines')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "print(f'Reduction: {reduction_percent:.1f}%')",
            "description": "Call print()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "print('Target: 35-40%')",
            "description": "Call print()",
            "expected_result": null,
            "verification": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Token Efficiency Calculation",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_architecture_scenarios.py:1025"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Bootstrap Validates Yaml Frontmatter": [
      {
        "guide_id": "68f4257389a6",
        "title": "Bootstrap Validates Yaml Frontmatter",
        "overview": "Workflow: Verify generated SKILL.md has valid YAML frontmatter",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "subprocess",
          "sys",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "82685bf1",
            "test_name": "test_bootstrap_validates_yaml_frontmatter",
            "category": "workflow",
            "code": "'Verify generated SKILL.md has valid YAML frontmatter'\nresult = run_bootstrap()\nassert result.returncode == 0\ncontent = (output_skill_dir / 'SKILL.md').read_text()\nassert content.startswith('---'), 'Missing frontmatter start'\nlines = content.split('\\n')\nclosing_found = False\nfor _i, line in enumerate(lines[1:], 1):\n    if line.strip() == '---':\n        closing_found = True\n        break\nassert closing_found, 'Missing frontmatter closing delimiter'\nassert 'name:' in content[:500], 'Missing name field'\nassert 'description:' in content[:500], 'Missing description field'",
            "language": "Python",
            "description": "Workflow: Verify generated SKILL.md has valid YAML frontmatter",
            "expected_behavior": "assert 'description:' in content[:500], 'Missing description field'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
            "line_start": 85,
            "line_end": 107,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: run_bootstrap, output_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "subprocess",
              "sys",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Verify generated SKILL.md has valid YAML frontmatter'",
            "description": "'Verify generated SKILL.md has valid YAML frontmatter'",
            "expected_result": null,
            "verification": "assert result.returncode == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "result = run_bootstrap()",
            "description": "Assign result = run_bootstrap(...)",
            "expected_result": null,
            "verification": "assert content.startswith('---'), 'Missing frontmatter start'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = (output_skill_dir / 'SKILL.md').read_text()",
            "description": "Assign content = unknown.read_text(...)",
            "expected_result": null,
            "verification": "assert closing_found, 'Missing frontmatter closing delimiter'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "lines = content.split('\\n')",
            "description": "Assign lines = content.split(...)",
            "expected_result": null,
            "verification": "assert 'name:' in content[:500], 'Missing name field'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "closing_found = False",
            "description": "Assign closing_found = False",
            "expected_result": null,
            "verification": "assert 'description:' in content[:500], 'Missing description field'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "closing_found = True",
            "description": "Assign closing_found = True",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Bootstrap Validates Yaml Frontmatter",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_bootstrap_skill_e2e.py:85"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Skill Installable In Venv": [
      {
        "guide_id": "0f8bfeb7d956",
        "title": "Skill Installable In Venv",
        "overview": "Workflow: Test skill is installable in clean virtual environment",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "subprocess",
          "sys",
          "pathlib",
          "pytest",
          "skill_seekers.cli.adaptors"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0aae0187",
            "test_name": "test_skill_installable_in_venv",
            "category": "workflow",
            "code": "'Test skill is installable in clean virtual environment'\nresult = run_bootstrap()\nassert result.returncode == 0\nvenv_path = tmp_path / 'test_venv'\nsubprocess.run([sys.executable, '-m', 'venv', str(venv_path)], check=True, timeout=60)\npip_path = venv_path / 'bin' / 'pip'\nresult = subprocess.run([str(pip_path), 'install', '-e', '.'], cwd=output_skill_dir.parent.parent, capture_output=True, text=True, timeout=120)\nassert result.returncode == 0, f'Install failed: {result.stderr}'",
            "language": "Python",
            "description": "Workflow: Test skill is installable in clean virtual environment",
            "expected_behavior": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
            "line_start": 122,
            "line_end": 143,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "# Fixtures: run_bootstrap, output_skill_dir, tmp_path",
            "tags": [
              "pytest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "subprocess",
              "sys",
              "pathlib",
              "pytest",
              "skill_seekers.cli.adaptors"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test skill is installable in clean virtual environment'",
            "description": "'Test skill is installable in clean virtual environment'",
            "expected_result": null,
            "verification": "assert result.returncode == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "result = run_bootstrap()",
            "description": "Assign result = run_bootstrap(...)",
            "expected_result": null,
            "verification": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "venv_path = tmp_path / 'test_venv'",
            "description": "Assign venv_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "subprocess.run([sys.executable, '-m', 'venv', str(venv_path)], check=True, timeout=60)",
            "description": "Call subprocess.run()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "pip_path = venv_path / 'bin' / 'pip'",
            "description": "Assign pip_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "result = subprocess.run([str(pip_path), 'install', '-e', '.'], cwd=output_skill_dir.parent.parent, capture_output=True, text=True, timeout=120)",
            "description": "Assign result = subprocess.run(...)",
            "expected_result": null,
            "verification": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Skill Installable In Venv",
        "tags": [
          "pytest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_bootstrap_skill_e2e.py:122"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Analyze Quick Preset": [
      {
        "guide_id": "c03a43b63541",
        "title": "Analyze Quick Preset",
        "overview": "Workflow: Test quick analysis preset (real execution).",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "shutil",
          "subprocess",
          "sys",
          "tempfile",
          "unittest",
          "pathlib"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b3823f05",
            "test_name": "test_analyze_quick_preset",
            "category": "workflow",
            "code": "'Test quick analysis preset (real execution).'\noutput_dir = self.test_dir / 'output_quick'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Quick analysis failed:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}')\nself.assertTrue(output_dir.exists(), 'Output directory not created')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not generated')\nskill_content = skill_file.read_text()\nself.assertGreater(len(skill_content), 100, 'SKILL.md is too short')\nself.assertIn('Codebase', skill_content, 'Missing codebase header')\nself.assertIn('Analysis', skill_content, 'Missing analysis section')\nself.assertTrue(skill_content.startswith('---'), 'Missing YAML frontmatter')\nself.assertIn('name:', skill_content, 'Missing name in frontmatter')",
            "language": "Python",
            "description": "Workflow: Test quick analysis preset (real execution).",
            "expected_behavior": "self.assertIn('name:', skill_content, 'Missing name in frontmatter')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
            "line_start": 106,
            "line_end": 138,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "subprocess",
              "sys",
              "tempfile",
              "unittest",
              "pathlib"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test quick analysis preset (real execution).'",
            "description": "'Test quick analysis preset (real execution).'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = self.test_dir / 'output_quick'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')",
            "description": "Assign result = self.run_command(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(result.returncode, 0, f'Quick analysis failed:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(output_dir.exists(), 'Output directory not created')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "skill_file = output_dir / 'SKILL.md'",
            "description": "Assign skill_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(skill_file.exists(), 'SKILL.md not generated')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "skill_content = skill_file.read_text()",
            "description": "Assign skill_content = skill_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreater(len(skill_content), 100, 'SKILL.md is too short')",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('Codebase', skill_content, 'Missing codebase header')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('Analysis', skill_content, 'Missing analysis section')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertTrue(skill_content.startswith('---'), 'Missing YAML frontmatter')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertIn('name:', skill_content, 'Missing name in frontmatter')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Analyze Quick Preset",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_analyze_e2e.py:106"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Analyze Output Structure": [
      {
        "guide_id": "35a688f57b3a",
        "title": "Analyze Output Structure",
        "overview": "Workflow: Test that output has expected structure.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "shutil",
          "subprocess",
          "sys",
          "tempfile",
          "unittest",
          "pathlib"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4db84019",
            "test_name": "test_analyze_output_structure",
            "category": "workflow",
            "code": "'Test that output has expected structure.'\noutput_dir = self.test_dir / 'output_structure'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nself.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')\nanalysis_file = output_dir / 'code_analysis.json'\nif analysis_file.exists():\n    with open(analysis_file) as f:\n        data = json.load(f)\n        self.assertIsInstance(data, (dict, list), 'code_analysis.json is not valid JSON')",
            "language": "Python",
            "description": "Workflow: Test that output has expected structure.",
            "expected_behavior": "self.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
            "line_start": 228,
            "line_end": 247,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "subprocess",
              "sys",
              "tempfile",
              "unittest",
              "pathlib"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that output has expected structure.'",
            "description": "'Test that output has expected structure.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = self.test_dir / 'output_structure'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')",
            "description": "Assign result = self.run_command(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "analysis_file = output_dir / 'code_analysis.json'",
            "description": "Assign analysis_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIsInstance(data, (dict, list), 'code_analysis.json is not valid JSON')",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Analyze Output Structure",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_analyze_e2e.py:228"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Analyze Then Check Output": [
      {
        "guide_id": "361de2024a8d",
        "title": "Analyze Then Check Output",
        "overview": "Workflow: Test analyzing and verifying output can be read.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "json",
          "shutil",
          "subprocess",
          "sys",
          "tempfile",
          "unittest",
          "pathlib"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c431e62b",
            "test_name": "test_analyze_then_check_output",
            "category": "workflow",
            "code": "'Test analyzing and verifying output can be read.'\noutput_dir = self.test_dir / 'output'\nresult = subprocess.run(['skill-seekers', 'analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick'], capture_output=True, text=True, timeout=120)\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not created')\ncontent = skill_file.read_text()\nself.assertGreater(len(content), 50, 'Output too short')\nself.assertIn('Codebase', content, 'Missing codebase header')\nself.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
            "language": "Python",
            "description": "Workflow: Test analyzing and verifying output can be read.",
            "expected_behavior": "self.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
            "line_start": 283,
            "line_end": 314,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "subprocess",
              "sys",
              "tempfile",
              "unittest",
              "pathlib"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test analyzing and verifying output can be read.'",
            "description": "'Test analyzing and verifying output can be read.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = self.test_dir / 'output'",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = subprocess.run(['skill-seekers', 'analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick'], capture_output=True, text=True, timeout=120)",
            "description": "Assign result = subprocess.run(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "skill_file = output_dir / 'SKILL.md'",
            "description": "Assign skill_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertTrue(skill_file.exists(), 'SKILL.md not created')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "content = skill_file.read_text()",
            "description": "Assign content = skill_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertGreater(len(content), 50, 'Output too short')",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('Codebase', content, 'Missing codebase header')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Analyze Then Check Output",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_analyze_e2e.py:283"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E All Platforms From Same Skill": [
      {
        "guide_id": "9cef025ada5d",
        "title": "E2E All Platforms From Same Skill",
        "overview": "Workflow: Test that all platforms can package the same skill",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "91db06e1",
            "test_name": "test_e2e_all_platforms_from_same_skill",
            "category": "workflow",
            "code": "'Test that all platforms can package the same skill'\nplatforms = ['claude', 'gemini', 'openai', 'markdown']\npackages = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    self.assertTrue(package_path.exists(), f'Package not created for {platform}')\n    packages[platform] = package_path\nself.assertEqual(len(packages), 4)\nself.assertTrue(str(packages['claude']).endswith('.zip'))\nself.assertTrue(str(packages['gemini']).endswith('.tar.gz'))\nself.assertTrue(str(packages['openai']).endswith('.zip'))\nself.assertTrue(str(packages['markdown']).endswith('.zip'))",
            "language": "Python",
            "description": "Workflow: Test that all platforms can package the same skill",
            "expected_behavior": "self.assertTrue(str(packages['markdown']).endswith('.zip'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 129,
            "line_end": 153,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that all platforms can package the same skill'",
            "description": "'Test that all platforms can package the same skill'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "platforms = ['claude', 'gemini', 'openai', 'markdown']",
            "description": "Assign platforms = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "packages = {}",
            "description": "Assign packages = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(len(packages), 4)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(str(packages['claude']).endswith('.zip'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertTrue(str(packages['gemini']).endswith('.tar.gz'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(str(packages['openai']).endswith('.zip'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(str(packages['markdown']).endswith('.zip'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue(package_path.exists(), f'Package not created for {platform}')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "packages[platform] = package_path",
            "description": "Assign unknown = package_path",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E All Platforms From Same Skill",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptors_e2e.py:129"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Claude Workflow": [
      {
        "guide_id": "2335bec7aae7",
        "title": "E2E Claude Workflow",
        "overview": "Workflow: Test complete Claude workflow: package + verify structure",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "62dfc4ba",
            "test_name": "test_e2e_claude_workflow",
            "category": "workflow",
            "code": "'Test complete Claude workflow: package + verify structure'\nadaptor = get_adaptor('claude')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('SKILL.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    skill_content = zf.read('SKILL.md').decode('utf-8')\n    self.assertGreater(len(skill_content), 0)",
            "language": "Python",
            "description": "Workflow: Test complete Claude workflow: package + verify structure",
            "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 155,
            "line_end": 180,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete Claude workflow: package + verify structure'",
            "description": "'Test complete Claude workflow: package + verify structure'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('claude')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertTrue(package_path.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(str(package_path).endswith('.zip'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "names = zf.namelist()",
            "description": "Assign names = zf.namelist(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('SKILL.md', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(any(('references/' in name for name in names)))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "skill_content = zf.read('SKILL.md').decode('utf-8')",
            "description": "Assign skill_content = zf.read.decode(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreater(len(skill_content), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Claude Workflow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_adaptors_e2e.py:155"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Gemini Workflow": [
      {
        "guide_id": "c576abb575e3",
        "title": "E2E Gemini Workflow",
        "overview": "Workflow: Test complete Gemini workflow: package + verify structure",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7a17248a",
            "test_name": "test_e2e_gemini_workflow",
            "category": "workflow",
            "code": "'Test complete Gemini workflow: package + verify structure'\nadaptor = get_adaptor('gemini')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.tar.gz'))\nwith tarfile.open(package_path, 'r:gz') as tar:\n    names = tar.getnames()\n    self.assertIn('system_instructions.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    self.assertIn('gemini_metadata.json', names)\n    metadata_member = tar.getmember('gemini_metadata.json')\n    metadata_file = tar.extractfile(metadata_member)\n    metadata = json.loads(metadata_file.read().decode('utf-8'))\n    self.assertEqual(metadata['platform'], 'gemini')\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertIn('created_with', metadata)",
            "language": "Python",
            "description": "Workflow: Test complete Gemini workflow: package + verify structure",
            "expected_behavior": "self.assertTrue(str(package_path).endswith('.tar.gz'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 182,
            "line_end": 213,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete Gemini workflow: package + verify structure'",
            "description": "'Test complete Gemini workflow: package + verify structure'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('gemini')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertTrue(package_path.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(str(package_path).endswith('.tar.gz'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "names = tar.getnames()",
            "description": "Assign names = tar.getnames(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('system_instructions.md', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(any(('references/' in name for name in names)))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('gemini_metadata.json', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "metadata_member = tar.getmember('gemini_metadata.json')",
            "description": "Assign metadata_member = tar.getmember(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "metadata_file = tar.extractfile(metadata_member)",
            "description": "Assign metadata_file = tar.extractfile(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "metadata = json.loads(metadata_file.read().decode('utf-8'))",
            "description": "Assign metadata = json.loads(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertEqual(metadata['platform'], 'gemini')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "self.assertEqual(metadata['name'], 'test-skill')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "self.assertIn('created_with', metadata)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Gemini Workflow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptors_e2e.py:182"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Openai Workflow": [
      {
        "guide_id": "1760c5590ae0",
        "title": "E2E Openai Workflow",
        "overview": "Workflow: Test complete OpenAI workflow: package + verify structure",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "500562d5",
            "test_name": "test_e2e_openai_workflow",
            "category": "workflow",
            "code": "'Test complete OpenAI workflow: package + verify structure'\nadaptor = get_adaptor('openai')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('assistant_instructions.txt', names)\n    self.assertTrue(any(('vector_store_files/' in name for name in names)))\n    self.assertIn('openai_metadata.json', names)\n    metadata_content = zf.read('openai_metadata.json').decode('utf-8')\n    metadata = json.loads(metadata_content)\n    self.assertEqual(metadata['platform'], 'openai')\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertEqual(metadata['model'], 'gpt-4o')\n    self.assertIn('file_search', metadata['tools'])",
            "language": "Python",
            "description": "Workflow: Test complete OpenAI workflow: package + verify structure",
            "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 215,
            "line_end": 246,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete OpenAI workflow: package + verify structure'",
            "description": "'Test complete OpenAI workflow: package + verify structure'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('openai')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertTrue(package_path.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(str(package_path).endswith('.zip'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "names = zf.namelist()",
            "description": "Assign names = zf.namelist(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('assistant_instructions.txt', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(any(('vector_store_files/' in name for name in names)))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('openai_metadata.json', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "metadata_content = zf.read('openai_metadata.json').decode('utf-8')",
            "description": "Assign metadata_content = zf.read.decode(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "metadata = json.loads(metadata_content)",
            "description": "Assign metadata = json.loads(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertEqual(metadata['platform'], 'openai')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertEqual(metadata['name'], 'test-skill')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "self.assertEqual(metadata['model'], 'gpt-4o')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "self.assertIn('file_search', metadata['tools'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Openai Workflow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptors_e2e.py:215"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Markdown Workflow": [
      {
        "guide_id": "732d51639142",
        "title": "E2E Markdown Workflow",
        "overview": "Workflow: Test complete Markdown workflow: package + verify structure",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "dec94e70",
            "test_name": "test_e2e_markdown_workflow",
            "category": "workflow",
            "code": "'Test complete Markdown workflow: package + verify structure'\nadaptor = get_adaptor('markdown')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('README.md', names)\n    self.assertIn('DOCUMENTATION.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    self.assertIn('metadata.json', names)\n    doc_content = zf.read('DOCUMENTATION.md').decode('utf-8')\n    self.assertIn('Getting Started', doc_content)\n    self.assertIn('React Hooks', doc_content)\n    self.assertIn('Components', doc_content)",
            "language": "Python",
            "description": "Workflow: Test complete Markdown workflow: package + verify structure",
            "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 248,
            "line_end": 281,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete Markdown workflow: package + verify structure'",
            "description": "'Test complete Markdown workflow: package + verify structure'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('markdown')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertTrue(package_path.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(str(package_path).endswith('.zip'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "names = zf.namelist()",
            "description": "Assign names = zf.namelist(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('README.md', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('DOCUMENTATION.md', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(any(('references/' in name for name in names)))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('metadata.json', names)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "doc_content = zf.read('DOCUMENTATION.md').decode('utf-8')",
            "description": "Assign doc_content = zf.read.decode(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('Getting Started', doc_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertIn('React Hooks', doc_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "self.assertIn('Components', doc_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Markdown Workflow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptors_e2e.py:248"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Package Format Validation": [
      {
        "guide_id": "7dca11399660",
        "title": "E2E Package Format Validation",
        "overview": "Workflow: Test that each platform creates correct package format",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "13e57c58",
            "test_name": "test_e2e_package_format_validation",
            "category": "workflow",
            "code": "'Test that each platform creates correct package format'\ntest_cases = [('claude', '.zip'), ('gemini', '.tar.gz'), ('openai', '.zip'), ('markdown', '.zip')]\nfor platform, expected_ext in test_cases:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if expected_ext == '.tar.gz':\n        self.assertTrue(str(package_path).endswith('.tar.gz'), f'{platform} should create .tar.gz file')\n    else:\n        self.assertTrue(str(package_path).endswith('.zip'), f'{platform} should create .zip file')",
            "language": "Python",
            "description": "Workflow: Test that each platform creates correct package format",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 283,
            "line_end": 304,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that each platform creates correct package format'",
            "description": "'Test that each platform creates correct package format'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "test_cases = [('claude', '.zip'), ('gemini', '.tar.gz'), ('openai', '.zip'), ('markdown', '.zip')]",
            "description": "Assign test_cases = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertTrue(str(package_path).endswith('.tar.gz'), f'{platform} should create .tar.gz file')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertTrue(str(package_path).endswith('.zip'), f'{platform} should create .zip file')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Package Format Validation",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_adaptors_e2e.py:283"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Package Filename Convention": [
      {
        "guide_id": "f6abb97012e1",
        "title": "E2E Package Filename Convention",
        "overview": "Workflow: Test that package filenames follow convention",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a20b3287",
            "test_name": "test_e2e_package_filename_convention",
            "category": "workflow",
            "code": "'Test that package filenames follow convention'\ntest_cases = [('claude', 'test-skill.zip'), ('gemini', 'test-skill-gemini.tar.gz'), ('openai', 'test-skill-openai.zip'), ('markdown', 'test-skill-markdown.zip')]\nfor platform, expected_name in test_cases:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    self.assertEqual(package_path.name, expected_name, f'{platform} package filename incorrect')",
            "language": "Python",
            "description": "Workflow: Test that package filenames follow convention",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 306,
            "line_end": 322,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that package filenames follow convention'",
            "description": "'Test that package filenames follow convention'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "test_cases = [('claude', 'test-skill.zip'), ('gemini', 'test-skill-gemini.tar.gz'), ('openai', 'test-skill-openai.zip'), ('markdown', 'test-skill-markdown.zip')]",
            "description": "Assign test_cases = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(package_path.name, expected_name, f'{platform} package filename incorrect')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Package Filename Convention",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_adaptors_e2e.py:306"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E All Platforms Preserve References": [
      {
        "guide_id": "0f9576266a85",
        "title": "E2E All Platforms Preserve References",
        "overview": "Workflow: Test that all platforms preserve reference files",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "7c83641e",
            "test_name": "test_e2e_all_platforms_preserve_references",
            "category": "workflow",
            "code": "'Test that all platforms preserve reference files'\nref_files = ['getting_started.md', 'hooks.md', 'components.md']\nfor platform in ['claude', 'gemini', 'openai', 'markdown']:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if platform == 'gemini':\n        with tarfile.open(package_path, 'r:gz') as tar:\n            names = tar.getnames()\n            for ref_file in ref_files:\n                self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')\n    else:\n        with zipfile.ZipFile(package_path, 'r') as zf:\n            names = zf.namelist()\n            for ref_file in ref_files:\n                if platform == 'openai':\n                    self.assertTrue(any((f'vector_store_files/{ref_file}' in name for name in names)), f'{platform}: {ref_file} not found in vector_store_files/')\n                else:\n                    self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
            "language": "Python",
            "description": "Workflow: Test that all platforms preserve reference files",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 324,
            "line_end": 355,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that all platforms preserve reference files'",
            "description": "'Test that all platforms preserve reference files'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "ref_files = ['getting_started.md', 'hooks.md', 'components.md']",
            "description": "Assign ref_files = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "names = tar.getnames()",
            "description": "Assign names = tar.getnames(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "names = zf.namelist()",
            "description": "Assign names = zf.namelist(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue(any((f'vector_store_files/{ref_file}' in name for name in names)), f'{platform}: {ref_file} not found in vector_store_files/')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E All Platforms Preserve References",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_adaptors_e2e.py:324"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Metadata Consistency": [
      {
        "guide_id": "31d0911f4584",
        "title": "E2E Metadata Consistency",
        "overview": "Workflow: Test that metadata is consistent across platforms",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "baaebdb2",
            "test_name": "test_e2e_metadata_consistency",
            "category": "workflow",
            "code": "'Test that metadata is consistent across platforms'\nplatforms_with_metadata = ['gemini', 'openai', 'markdown']\nfor platform in platforms_with_metadata:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if platform == 'gemini':\n        with tarfile.open(package_path, 'r:gz') as tar:\n            metadata_member = tar.getmember('gemini_metadata.json')\n            metadata_file = tar.extractfile(metadata_member)\n            metadata = json.loads(metadata_file.read().decode('utf-8'))\n    else:\n        with zipfile.ZipFile(package_path, 'r') as zf:\n            metadata_filename = f'{platform}_metadata.json' if platform == 'openai' else 'metadata.json'\n            metadata_content = zf.read(metadata_filename).decode('utf-8')\n            metadata = json.loads(metadata_content)\n    self.assertEqual(metadata['platform'], platform)\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertIn('created_with', metadata)",
            "language": "Python",
            "description": "Workflow: Test that metadata is consistent across platforms",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 357,
            "line_end": 382,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that metadata is consistent across platforms'",
            "description": "'Test that metadata is consistent across platforms'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "platforms_with_metadata = ['gemini', 'openai', 'markdown']",
            "description": "Assign platforms_with_metadata = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
            "description": "Assign package_path = adaptor.package(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(metadata['platform'], platform)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(metadata['name'], 'test-skill')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('created_with', metadata)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "metadata_member = tar.getmember('gemini_metadata.json')",
            "description": "Assign metadata_member = tar.getmember(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "metadata_file = tar.extractfile(metadata_member)",
            "description": "Assign metadata_file = tar.extractfile(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "metadata = json.loads(metadata_file.read().decode('utf-8'))",
            "description": "Assign metadata = json.loads(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "metadata_filename = f'{platform}_metadata.json' if platform == 'openai' else 'metadata.json'",
            "description": "Assign metadata_filename = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "metadata_content = zf.read(metadata_filename).decode('utf-8')",
            "description": "Assign metadata_content = zf.read.decode(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "metadata = json.loads(metadata_content)",
            "description": "Assign metadata = json.loads(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Metadata Consistency",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptors_e2e.py:357"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "E2E Format Skill Md Differences": [
      {
        "guide_id": "22a8553ab2e9",
        "title": "E2E Format Skill Md Differences",
        "overview": "Workflow: Test that each platform formats SKILL.md differently",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "tarfile",
          "tempfile",
          "unittest",
          "zipfile",
          "pathlib",
          "skill_seekers.cli.adaptors",
          "skill_seekers.cli.adaptors.base",
          "chromadb"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "cd0700dc",
            "test_name": "test_e2e_format_skill_md_differences",
            "category": "workflow",
            "code": "'Test that each platform formats SKILL.md differently'\nmetadata = SkillMetadata(name='test-skill', description='Test skill for E2E testing')\nformats = {}\nfor platform in ['claude', 'gemini', 'openai', 'markdown']:\n    adaptor = get_adaptor(platform)\n    formatted = adaptor.format_skill_md(self.skill_dir, metadata)\n    formats[platform] = formatted\nself.assertTrue(formats['claude'].startswith('---'))\nself.assertFalse(formats['gemini'].startswith('---'))\nself.assertFalse(formats['markdown'].startswith('---'))\nfor platform, formatted in formats.items():\n    self.assertIn('react', formatted.lower(), f'{platform} should contain skill content')\n    self.assertGreater(len(formatted), 100, f'{platform} should have substantial content')",
            "language": "Python",
            "description": "Workflow: Test that each platform formats SKILL.md differently",
            "expected_behavior": "self.assertFalse(formats['markdown'].startswith('---'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
            "line_start": 384,
            "line_end": 406,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "tarfile",
              "tempfile",
              "unittest",
              "zipfile",
              "pathlib",
              "skill_seekers.cli.adaptors",
              "skill_seekers.cli.adaptors.base",
              "chromadb"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that each platform formats SKILL.md differently'",
            "description": "'Test that each platform formats SKILL.md differently'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "metadata = SkillMetadata(name='test-skill', description='Test skill for E2E testing')",
            "description": "Assign metadata = SkillMetadata(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "formats = {}",
            "description": "Assign formats = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertTrue(formats['claude'].startswith('---'))",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertFalse(formats['gemini'].startswith('---'))",
            "description": "Call self.assertFalse()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertFalse(formats['markdown'].startswith('---'))",
            "description": "Call self.assertFalse()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "adaptor = get_adaptor(platform)",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "formatted = adaptor.format_skill_md(self.skill_dir, metadata)",
            "description": "Assign formatted = adaptor.format_skill_md(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "formats[platform] = formatted",
            "description": "Assign unknown = formatted",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('react', formatted.lower(), f'{platform} should contain skill content')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertGreater(len(formatted), 100, f'{platform} should have substantial content')",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "E2E Format Skill Md Differences",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_adaptors_e2e.py:384"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Comprehensive Preset Implies Full Depth": [
      {
        "guide_id": "9c54e465506d",
        "title": "Comprehensive Preset Implies Full Depth",
        "overview": "Workflow: Test that --comprehensive preset should trigger full depth.",
        "complexity_level": "beginner",
        "prerequisites": [],
        "required_imports": [
          "sys",
          "unittest",
          "pathlib",
          "skill_seekers.cli.main"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "4bd3db24",
            "test_name": "test_comprehensive_preset_implies_full_depth",
            "category": "workflow",
            "code": "'Test that --comprehensive preset should trigger full depth.'\nargs = self.parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nself.assertTrue(args.comprehensive)",
            "language": "Python",
            "description": "Workflow: Test that --comprehensive preset should trigger full depth.",
            "expected_behavior": "self.assertTrue(args.comprehensive)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
            "line_start": 170,
            "line_end": 173,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "sys",
              "unittest",
              "pathlib",
              "skill_seekers.cli.main"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that --comprehensive preset should trigger full depth.'",
            "description": "'Test that --comprehensive preset should trigger full depth.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "args = self.parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])",
            "description": "Assign args = self.parser.parse_args(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "self.assertTrue(args.comprehensive)",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Comprehensive Preset Implies Full Depth",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "5 minutes",
        "source_files": [
          "test_analyze_command.py:170"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Codebase Analysis Enabled By Default": [
      {
        "guide_id": "e5e03ff108b5",
        "title": "Codebase Analysis Enabled By Default",
        "overview": "Workflow: Test that enable_codebase_analysis defaults to True.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "ad73a5fc",
            "test_name": "test_codebase_analysis_enabled_by_default",
            "category": "workflow",
            "code": "'Test that enable_codebase_analysis defaults to True.'\nconfig_without_flag = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'github', 'repo': 'test/repo', 'local_repo_path': temp_dir}]}\nconfig_path = os.path.join(temp_dir, 'config.json')\nwith open(config_path, 'w') as f:\n    json.dump(config_without_flag, f)\nscraper = UnifiedScraper(config_path)\ngithub_source = scraper.config['sources'][0]\nassert github_source.get('enable_codebase_analysis', True)",
            "language": "Python",
            "description": "Workflow: Test that enable_codebase_analysis defaults to True.",
            "expected_behavior": "assert github_source.get('enable_codebase_analysis', True)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
            "line_start": 139,
            "line_end": 158,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_config, temp_dir",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that enable_codebase_analysis defaults to True.'",
            "description": "'Test that enable_codebase_analysis defaults to True.'",
            "expected_result": null,
            "verification": "assert github_source.get('enable_codebase_analysis', True)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config_without_flag = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'github', 'repo': 'test/repo', 'local_repo_path': temp_dir}]}",
            "description": "Assign config_without_flag = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config_path = os.path.join(temp_dir, 'config.json')",
            "description": "Assign config_path = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "scraper = UnifiedScraper(config_path)",
            "description": "Assign scraper = UnifiedScraper(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "github_source = scraper.config['sources'][0]",
            "description": "Assign github_source = value",
            "expected_result": null,
            "verification": "assert github_source.get('enable_codebase_analysis', True)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "json.dump(config_without_flag, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Codebase Analysis Enabled By Default",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_c3_integration.py:139"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Skip Codebase Analysis Flag": [
      {
        "guide_id": "2466861affd0",
        "title": "Skip Codebase Analysis Flag",
        "overview": "Workflow: Test --skip-codebase-analysis CLI flag disables analysis.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "999a84fb",
            "test_name": "test_skip_codebase_analysis_flag",
            "category": "workflow",
            "code": "'Test --skip-codebase-analysis CLI flag disables analysis.'\nconfig_path = os.path.join(temp_dir, 'config.json')\nwith open(config_path, 'w') as f:\n    json.dump(mock_config, f)\nscraper = UnifiedScraper(config_path)\nfor source in scraper.config.get('sources', []):\n    if source['type'] == 'github':\n        source['enable_codebase_analysis'] = False\ngithub_source = scraper.config['sources'][0]\nassert not github_source['enable_codebase_analysis']",
            "language": "Python",
            "description": "Workflow: Test --skip-codebase-analysis CLI flag disables analysis.",
            "expected_behavior": "assert not github_source['enable_codebase_analysis']",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
            "line_start": 160,
            "line_end": 177,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_config, temp_dir",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test --skip-codebase-analysis CLI flag disables analysis.'",
            "description": "'Test --skip-codebase-analysis CLI flag disables analysis.'",
            "expected_result": null,
            "verification": "assert not github_source['enable_codebase_analysis']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config_path = os.path.join(temp_dir, 'config.json')",
            "description": "Assign config_path = os.path.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraper = UnifiedScraper(config_path)",
            "description": "Assign scraper = UnifiedScraper(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "github_source = scraper.config['sources'][0]",
            "description": "Assign github_source = value",
            "expected_result": null,
            "verification": "assert not github_source['enable_codebase_analysis']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "json.dump(mock_config, f)",
            "description": "Call json.dump()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "source['enable_codebase_analysis'] = False",
            "description": "Assign unknown = False",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Skip Codebase Analysis Flag",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_c3_integration.py:160"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Architecture Md Generation": [
      {
        "guide_id": "db4d4e027f57",
        "title": "Architecture Md Generation",
        "overview": "Workflow: Test ARCHITECTURE.md is generated with all 8 sections.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "eb6091e1",
            "test_name": "test_architecture_md_generation",
            "category": "workflow",
            "code": "'Test ARCHITECTURE.md is generated with all 8 sections.'\ngithub_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}\nscraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nc3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')\nos.makedirs(c3_dir, exist_ok=True)\nbuilder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)\narch_file = os.path.join(c3_dir, 'ARCHITECTURE.md')\nassert os.path.exists(arch_file)\nwith open(arch_file) as f:\n    content = f.read()\nassert '## 1. Overview' in content\nassert '## 2. Architectural Patterns' in content\nassert '## 3. Technology Stack' in content\nassert '## 4. Design Patterns' in content\nassert '## 5. Configuration Overview' in content\nassert '## 6. Common Workflows' in content\nassert '## 7. Usage Examples' in content\nassert '## 8. Entry Points & Directory Structure' in content\nassert 'MVC' in content\nassert 'Flask' in content\nassert 'Factory' in content\nassert '15 usage example(s)' in content or '15 total' in content\nassert 'Security Alert' in content",
            "language": "Python",
            "description": "Workflow: Test ARCHITECTURE.md is generated with all 8 sections.",
            "expected_behavior": "assert 'Security Alert' in content",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
            "line_start": 179,
            "line_end": 218,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test ARCHITECTURE.md is generated with all 8 sections.'",
            "description": "'Test ARCHITECTURE.md is generated with all 8 sections.'",
            "expected_result": null,
            "verification": "assert os.path.exists(arch_file)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "github_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert '## 1. Overview' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": "assert '## 2. Architectural Patterns' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(mock_config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": "assert '## 3. Technology Stack' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder.skill_dir = temp_dir",
            "description": "Assign builder.skill_dir = temp_dir",
            "expected_result": null,
            "verification": "assert '## 4. Design Patterns' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "c3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')",
            "description": "Assign c3_dir = os.path.join(...)",
            "expected_result": null,
            "verification": "assert '## 5. Configuration Overview' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "os.makedirs(c3_dir, exist_ok=True)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": "assert '## 6. Common Workflows' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "builder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)",
            "description": "Call builder._generate_architecture_overview()",
            "expected_result": null,
            "verification": "assert '## 7. Usage Examples' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "arch_file = os.path.join(c3_dir, 'ARCHITECTURE.md')",
            "description": "Assign arch_file = os.path.join(...)",
            "expected_result": null,
            "verification": "assert '## 8. Entry Points & Directory Structure' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": "assert 'MVC' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Architecture Md Generation",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_c3_integration.py:179"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "C3 Reference Directory Structure": [
      {
        "guide_id": "1eb38bee1b88",
        "title": "C3 Reference Directory Structure",
        "overview": "Workflow: Test correct C3.x reference directory structure is created.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e20cfa94",
            "test_name": "test_c3_reference_directory_structure",
            "category": "workflow",
            "code": "'Test correct C3.x reference directory structure is created.'\ngithub_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}\nscraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nc3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')\nos.makedirs(c3_dir, exist_ok=True)\nbuilder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)\nbuilder._generate_pattern_references(c3_dir, mock_c3_data.get('patterns'))\nbuilder._generate_example_references(c3_dir, mock_c3_data.get('test_examples'))\nbuilder._generate_guide_references(c3_dir, mock_c3_data.get('how_to_guides'))\nbuilder._generate_config_references(c3_dir, mock_c3_data.get('config_patterns'))\nbuilder._copy_architecture_details(c3_dir, mock_c3_data.get('architecture'))\nassert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns'))\nassert os.path.exists(os.path.join(c3_dir, 'examples'))\nassert os.path.exists(os.path.join(c3_dir, 'guides'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration'))\nassert os.path.exists(os.path.join(c3_dir, 'architecture_details'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'examples', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'guides', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'architecture_details', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns', 'detected_patterns.json'))\nassert os.path.exists(os.path.join(c3_dir, 'examples', 'test_examples.json'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration', 'config_patterns.json'))",
            "language": "Python",
            "description": "Workflow: Test correct C3.x reference directory structure is created.",
            "expected_behavior": "assert os.path.exists(os.path.join(c3_dir, 'configuration', 'config_patterns.json'))",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
            "line_start": 220,
            "line_end": 260,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test correct C3.x reference directory structure is created.'",
            "description": "'Test correct C3.x reference directory structure is created.'",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "github_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}",
            "description": "Assign github_data = value",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'patterns'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "scraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'examples'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder = UnifiedSkillBuilder(mock_config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'guides'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder.skill_dir = temp_dir",
            "description": "Assign builder.skill_dir = temp_dir",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'configuration'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "c3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')",
            "description": "Assign c3_dir = os.path.join(...)",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'architecture_details'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "os.makedirs(c3_dir, exist_ok=True)",
            "description": "Call os.makedirs()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'patterns', 'index.md'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "builder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)",
            "description": "Call builder._generate_architecture_overview()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'examples', 'index.md'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "builder._generate_pattern_references(c3_dir, mock_c3_data.get('patterns'))",
            "description": "Call builder._generate_pattern_references()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'guides', 'index.md'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "builder._generate_example_references(c3_dir, mock_c3_data.get('test_examples'))",
            "description": "Call builder._generate_example_references()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'configuration', 'index.md'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "builder._generate_guide_references(c3_dir, mock_c3_data.get('how_to_guides'))",
            "description": "Call builder._generate_guide_references()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'architecture_details', 'index.md'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "builder._generate_config_references(c3_dir, mock_c3_data.get('config_patterns'))",
            "description": "Call builder._generate_config_references()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'patterns', 'detected_patterns.json'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "builder._copy_architecture_details(c3_dir, mock_c3_data.get('architecture'))",
            "description": "Call builder._copy_architecture_details()",
            "expected_result": null,
            "verification": "assert os.path.exists(os.path.join(c3_dir, 'examples', 'test_examples.json'))",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "C3 Reference Directory Structure",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_c3_integration.py:220"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Skill Md Includes C3 Summary": [
      {
        "guide_id": "9faccc35c712",
        "title": "Skill Md Includes C3 Summary",
        "overview": "Workflow: Test SKILL.md includes C3.x architecture summary.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "os",
          "shutil",
          "tempfile",
          "unittest.mock",
          "pytest",
          "skill_seekers.cli.config_validator",
          "skill_seekers.cli.unified_scraper",
          "skill_seekers.cli.unified_skill_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "3720510e",
            "test_name": "test_skill_md_includes_c3_summary",
            "category": "workflow",
            "code": "'Test SKILL.md includes C3.x architecture summary.'\nscraped_data = {'github': {'data': {'readme': 'Test README', 'c3_analysis': mock_c3_data}}}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nbuilder._generate_skill_md()\nskill_file = os.path.join(temp_dir, 'SKILL.md')\nwith open(skill_file) as f:\n    content = f.read()\nassert '## \ud83c\udfd7\ufe0f Architecture & Code Analysis' in content\nassert 'Primary Architecture' in content\nassert 'MVC' in content\nassert 'Design Patterns' in content\nassert 'Factory' in content\nassert 'references/codebase_analysis/ARCHITECTURE.md' in content",
            "language": "Python",
            "description": "Workflow: Test SKILL.md includes C3.x architecture summary.",
            "expected_behavior": "assert 'references/codebase_analysis/ARCHITECTURE.md' in content",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
            "line_start": 339,
            "line_end": 358,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
            "tags": [
              "mock",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "os",
              "shutil",
              "tempfile",
              "unittest.mock",
              "pytest",
              "skill_seekers.cli.config_validator",
              "skill_seekers.cli.unified_scraper",
              "skill_seekers.cli.unified_skill_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test SKILL.md includes C3.x architecture summary.'",
            "description": "'Test SKILL.md includes C3.x architecture summary.'",
            "expected_result": null,
            "verification": "assert '## \ud83c\udfd7\ufe0f Architecture & Code Analysis' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "scraped_data = {'github': {'data': {'readme': 'Test README', 'c3_analysis': mock_c3_data}}}",
            "description": "Assign scraped_data = value",
            "expected_result": null,
            "verification": "assert 'Primary Architecture' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = UnifiedSkillBuilder(mock_config, scraped_data)",
            "description": "Assign builder = UnifiedSkillBuilder(...)",
            "expected_result": null,
            "verification": "assert 'MVC' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "builder.skill_dir = temp_dir",
            "description": "Assign builder.skill_dir = temp_dir",
            "expected_result": null,
            "verification": "assert 'Design Patterns' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "builder._generate_skill_md()",
            "description": "Call builder._generate_skill_md()",
            "expected_result": null,
            "verification": "assert 'Factory' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "skill_file = os.path.join(temp_dir, 'SKILL.md')",
            "description": "Assign skill_file = os.path.join(...)",
            "expected_result": null,
            "verification": "assert 'references/codebase_analysis/ARCHITECTURE.md' in content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "content = f.read()",
            "description": "Assign content = f.read(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Skill Md Includes C3 Summary",
        "tags": [
          "mock",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_c3_integration.py:339"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Get Config In Subdir": [
      {
        "guide_id": "00b4a37be209",
        "title": "Get Config In Subdir",
        "overview": "Workflow: Test loading config from subdirectory.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pathlib",
          "unittest.mock",
          "pytest",
          "git.exc",
          "skill_seekers.mcp.git_repo"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9c566935",
            "test_name": "test_get_config_in_subdir",
            "category": "workflow",
            "code": "'Test loading config from subdirectory.'\nrepo_path = temp_cache_dir / 'test-repo'\nconfigs_dir = repo_path / 'configs'\nconfigs_dir.mkdir(parents=True)\nconfig_data = {'name': 'nestjs'}\n(configs_dir / 'nestjs.json').write_text(json.dumps(config_data))\nresult = git_repo.get_config(repo_path, 'nestjs')\nassert result == config_data",
            "language": "Python",
            "description": "Workflow: Test loading config from subdirectory.",
            "expected_behavior": "assert result == config_data",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
            "line_start": 370,
            "line_end": 381,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "# Fixtures: git_repo, temp_cache_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pathlib",
              "unittest.mock",
              "pytest",
              "git.exc",
              "skill_seekers.mcp.git_repo"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test loading config from subdirectory.'",
            "description": "'Test loading config from subdirectory.'",
            "expected_result": null,
            "verification": "assert result == config_data",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "repo_path = temp_cache_dir / 'test-repo'",
            "description": "Assign repo_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "configs_dir = repo_path / 'configs'",
            "description": "Assign configs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "configs_dir.mkdir(parents=True)",
            "description": "Call configs_dir.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "config_data = {'name': 'nestjs'}",
            "description": "Assign config_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "(configs_dir / 'nestjs.json').write_text(json.dumps(config_data))",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "result = git_repo.get_config(repo_path, 'nestjs')",
            "description": "Assign result = git_repo.get_config(...)",
            "expected_result": null,
            "verification": "assert result == config_data",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Get Config In Subdir",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_git_repo.py:370"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Valid Complete Config": [
      {
        "guide_id": "68fc662ee0ee",
        "title": "Valid Complete Config",
        "overview": "Workflow: Test valid complete configuration",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "32f8dabf",
            "test_name": "test_valid_complete_config",
            "category": "workflow",
            "code": "'Test valid complete configuration'\nconfig = {'name': 'godot', 'base_url': 'https://docs.godotengine.org/en/stable/', 'description': 'Godot Engine documentation', 'selectors': {'main_content': 'div[role=\"main\"]', 'title': 'title', 'code_blocks': 'pre code'}, 'url_patterns': {'include': ['/guide/', '/api/'], 'exclude': ['/blog/']}, 'categories': {'getting_started': ['intro', 'tutorial'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 500}\nerrors, _ = validate_config(config)\nself.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
            "language": "Python",
            "description": "Workflow: Test valid complete configuration",
            "expected_behavior": "self.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
            "line_start": 27,
            "line_end": 44,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test valid complete configuration'",
            "description": "'Test valid complete configuration'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'godot', 'base_url': 'https://docs.godotengine.org/en/stable/', 'description': 'Godot Engine documentation', 'selectors': {'main_content': 'div[role=\"main\"]', 'title': 'title', 'code_blocks': 'pre code'}, 'url_patterns': {'include': ['/guide/', '/api/'], 'exclude': ['/blog/']}, 'categories': {'getting_started': ['intro', 'tutorial'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 500}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "errors, _ = validate_config(config)",
            "description": "Assign unknown = validate_config(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Valid Complete Config",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_config_validation.py:27"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Valid Name Formats": [
      {
        "guide_id": "722cacd154d6",
        "title": "Valid Name Formats",
        "overview": "Workflow: Test various valid name formats",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a6fc1ff6",
            "test_name": "test_valid_name_formats",
            "category": "workflow",
            "code": "'Test various valid name formats'\nvalid_names = ['test', 'test-skill', 'test_skill', 'TestSkill123', 'my-awesome-skill_v2']\nfor name in valid_names:\n    config = {'name': name, 'base_url': 'https://example.com/'}\n    errors, _ = validate_config(config)\n    name_errors = [e for e in errors if 'invalid name' in e.lower()]\n    self.assertEqual(len(name_errors), 0, f\"Name '{name}' should be valid\")",
            "language": "Python",
            "description": "Workflow: Test various valid name formats",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
            "line_start": 64,
            "line_end": 71,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test various valid name formats'",
            "description": "'Test various valid name formats'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "valid_names = ['test', 'test-skill', 'test_skill', 'TestSkill123', 'my-awesome-skill_v2']",
            "description": "Assign valid_names = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "config = {'name': name, 'base_url': 'https://example.com/'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "errors, _ = validate_config(config)",
            "description": "Assign unknown = validate_config(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "name_errors = [e for e in errors if 'invalid name' in e.lower()]",
            "description": "Assign name_errors = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(len(name_errors), 0, f\"Name '{name}' should be valid\")",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Valid Name Formats",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_config_validation.py:64"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Class Formatting": [
      {
        "guide_id": "2eb52e8ee916",
        "title": "Class Formatting",
        "overview": "Workflow: Test markdown formatting for class signatures.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.api_reference_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "cb8d825e",
            "test_name": "test_class_formatting",
            "category": "workflow",
            "code": "'Test markdown formatting for class signatures.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'docstring': 'A simple calculator class.', 'base_classes': ['object'], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'int', 'default': None}, {'name': 'b', 'type_hint': 'int', 'default': None}], 'return_type': 'int', 'docstring': 'Add two numbers.', 'is_async': False, 'is_method': True, 'decorators': []}]}], 'functions': []}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 1)\noutput_file = list(generated.values())[0]\nself.assertTrue(output_file.exists())\ncontent = output_file.read_text()\nself.assertIn('### Calculator', content)\nself.assertIn('A simple calculator class', content)\nself.assertIn('**Inherits from**: object', content)\nself.assertIn('##### add', content)\nself.assertIn('Add two numbers', content)",
            "language": "Python",
            "description": "Workflow: Test markdown formatting for class signatures.",
            "expected_behavior": "self.assertIn('Add two numbers', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
            "line_start": 38,
            "line_end": 85,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.api_reference_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test markdown formatting for class signatures.'",
            "description": "'Test markdown formatting for class signatures.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'docstring': 'A simple calculator class.', 'base_classes': ['object'], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'int', 'default': None}, {'name': 'b', 'type_hint': 'int', 'default': None}], 'return_type': 'int', 'docstring': 'Add two numbers.', 'is_async': False, 'is_method': True, 'decorators': []}]}], 'functions': []}]}",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = APIReferenceBuilder(code_analysis)",
            "description": "Assign builder = APIReferenceBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generated = builder.build_reference(self.output_dir)",
            "description": "Assign generated = builder.build_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(len(generated), 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "output_file = list(generated.values())[0]",
            "description": "Assign output_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertTrue(output_file.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = output_file.read_text()",
            "description": "Assign content = output_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('### Calculator', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('A simple calculator class', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('**Inherits from**: object', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('##### add', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertIn('Add two numbers', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Class Formatting",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_api_reference_builder.py:38"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Function Formatting": [
      {
        "guide_id": "0a8628b5d419",
        "title": "Function Formatting",
        "overview": "Workflow: Test markdown formatting for function signatures.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.api_reference_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "0ccbbef2",
            "test_name": "test_function_formatting",
            "category": "workflow",
            "code": "'Test markdown formatting for function signatures.'\ncode_analysis = {'files': [{'file': 'utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'calculate_sum', 'parameters': [{'name': 'numbers', 'type_hint': 'list', 'default': None}], 'return_type': 'int', 'docstring': 'Calculate sum of numbers.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('## Functions', content)\nself.assertIn('### calculate_sum', content)\nself.assertIn('Calculate sum of numbers', content)\nself.assertIn('**Returns**: `int`', content)",
            "language": "Python",
            "description": "Workflow: Test markdown formatting for function signatures.",
            "expected_behavior": "self.assertIn('**Returns**: `int`', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
            "line_start": 87,
            "line_end": 122,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.api_reference_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test markdown formatting for function signatures.'",
            "description": "'Test markdown formatting for function signatures.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code_analysis = {'files': [{'file': 'utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'calculate_sum', 'parameters': [{'name': 'numbers', 'type_hint': 'list', 'default': None}], 'return_type': 'int', 'docstring': 'Calculate sum of numbers.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = APIReferenceBuilder(code_analysis)",
            "description": "Assign builder = APIReferenceBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generated = builder.build_reference(self.output_dir)",
            "description": "Assign generated = builder.build_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "output_file = list(generated.values())[0]",
            "description": "Assign output_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "content = output_file.read_text()",
            "description": "Assign content = output_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('## Functions', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('### calculate_sum', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('Calculate sum of numbers', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('**Returns**: `int`', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Function Formatting",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_api_reference_builder.py:87"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Parameter Table Generation": [
      {
        "guide_id": "3923abb18bdf",
        "title": "Parameter Table Generation",
        "overview": "Workflow: Test parameter table formatting.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.api_reference_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "176f53b5",
            "test_name": "test_parameter_table_generation",
            "category": "workflow",
            "code": "'Test parameter table formatting.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'create_user', 'parameters': [{'name': 'name', 'type_hint': 'str', 'default': None}, {'name': 'age', 'type_hint': 'int', 'default': '18'}, {'name': 'active', 'type_hint': 'bool', 'default': 'True'}], 'return_type': 'dict', 'docstring': 'Create a user object.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Parameters**:', content)\nself.assertIn('| Name | Type | Default | Description |', content)\nself.assertIn('| name | str | - |', content)\nself.assertIn('| age | int | 18 |', content)\nself.assertIn('| active | bool | True |', content)",
            "language": "Python",
            "description": "Workflow: Test parameter table formatting.",
            "expected_behavior": "self.assertIn('| active | bool | True |', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
            "line_start": 124,
            "line_end": 162,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.api_reference_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test parameter table formatting.'",
            "description": "'Test parameter table formatting.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'create_user', 'parameters': [{'name': 'name', 'type_hint': 'str', 'default': None}, {'name': 'age', 'type_hint': 'int', 'default': '18'}, {'name': 'active', 'type_hint': 'bool', 'default': 'True'}], 'return_type': 'dict', 'docstring': 'Create a user object.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = APIReferenceBuilder(code_analysis)",
            "description": "Assign builder = APIReferenceBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generated = builder.build_reference(self.output_dir)",
            "description": "Assign generated = builder.build_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "output_file = list(generated.values())[0]",
            "description": "Assign output_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "content = output_file.read_text()",
            "description": "Assign content = output_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('**Parameters**:', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('| Name | Type | Default | Description |', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('| name | str | - |', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('| age | int | 18 |', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('| active | bool | True |', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Parameter Table Generation",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_api_reference_builder.py:124"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Markdown Output Structure": [
      {
        "guide_id": "4266be2eedb3",
        "title": "Markdown Output Structure",
        "overview": "Workflow: Test overall markdown document structure.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.api_reference_builder"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "002fab06",
            "test_name": "test_markdown_output_structure",
            "category": "workflow",
            "code": "'Test overall markdown document structure.'\ncode_analysis = {'files': [{'file': 'module.py', 'language': 'Python', 'classes': [{'name': 'TestClass', 'docstring': 'Test class.', 'base_classes': [], 'methods': []}], 'functions': [{'name': 'test_func', 'parameters': [], 'return_type': None, 'docstring': 'Test function.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('# API Reference: module.py', content)\nself.assertIn('**Language**: Python', content)\nself.assertIn('**Source**: `module.py`', content)\nclasses_pos = content.find('## Classes')\nfunctions_pos = content.find('## Functions')\nself.assertNotEqual(classes_pos, -1)\nself.assertNotEqual(functions_pos, -1)\nself.assertLess(classes_pos, functions_pos)",
            "language": "Python",
            "description": "Workflow: Test overall markdown document structure.",
            "expected_behavior": "self.assertLess(classes_pos, functions_pos)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
            "line_start": 164,
            "line_end": 212,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.api_reference_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test overall markdown document structure.'",
            "description": "'Test overall markdown document structure.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code_analysis = {'files': [{'file': 'module.py', 'language': 'Python', 'classes': [{'name': 'TestClass', 'docstring': 'Test class.', 'base_classes': [], 'methods': []}], 'functions': [{'name': 'test_func', 'parameters': [], 'return_type': None, 'docstring': 'Test function.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = APIReferenceBuilder(code_analysis)",
            "description": "Assign builder = APIReferenceBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generated = builder.build_reference(self.output_dir)",
            "description": "Assign generated = builder.build_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "output_file = list(generated.values())[0]",
            "description": "Assign output_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "content = output_file.read_text()",
            "description": "Assign content = output_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('# API Reference: module.py', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('**Language**: Python', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('**Source**: `module.py`', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "classes_pos = content.find('## Classes')",
            "description": "Assign classes_pos = content.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "functions_pos = content.find('## Functions')",
            "description": "Assign functions_pos = content.find(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertNotEqual(classes_pos, -1)",
            "description": "Call self.assertNotEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertNotEqual(functions_pos, -1)",
            "description": "Call self.assertNotEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "self.assertLess(classes_pos, functions_pos)",
            "description": "Call self.assertLess()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Markdown Output Structure",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_api_reference_builder.py:164"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Integration With Code Analyzer": [
      {
        "guide_id": "39b49a6b3f00",
        "title": "Integration With Code Analyzer",
        "overview": "Workflow: Test integration with actual code analyzer output format.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.api_reference_builder"
        ],
        "required_fixtures": [
          "api_client"
        ],
        "workflows": [
          {
            "example_id": "8dba195d",
            "test_name": "test_integration_with_code_analyzer",
            "category": "workflow",
            "code": "'Test integration with actual code analyzer output format.'\ncode_analysis = {'files': [{'file': 'calculator.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'base_classes': [], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'float', 'default': None}, {'name': 'b', 'type_hint': 'float', 'default': None}], 'return_type': 'float', 'docstring': 'Add two numbers.', 'decorators': [], 'is_async': False, 'is_method': True}], 'docstring': 'Calculator class.', 'line_number': 1}], 'functions': []}, {'file': 'utils.js', 'language': 'JavaScript', 'classes': [], 'functions': [{'name': 'formatDate', 'parameters': [{'name': 'date', 'type_hint': None, 'default': None}], 'return_type': None, 'docstring': None, 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 2)\nfilenames = [f.name for f in generated.values()]\nself.assertIn('calculator.md', filenames)\nself.assertIn('utils.md', filenames)\npy_file = next((f for f in generated.values() if f.name == 'calculator.md'))\npy_content = py_file.read_text()\nself.assertIn('Calculator class', py_content)\nself.assertIn('add(a: float, b: float) \u2192 float', py_content)\njs_file = next((f for f in generated.values() if f.name == 'utils.md'))\njs_content = js_file.read_text()\nself.assertIn('formatDate', js_content)\nself.assertIn('**Language**: JavaScript', js_content)",
            "language": "Python",
            "description": "Workflow: Test integration with actual code analyzer output format.",
            "expected_behavior": "self.assertIn('**Language**: JavaScript', js_content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
            "line_start": 214,
            "line_end": 286,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.api_reference_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test integration with actual code analyzer output format.'",
            "description": "'Test integration with actual code analyzer output format.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code_analysis = {'files': [{'file': 'calculator.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'base_classes': [], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'float', 'default': None}, {'name': 'b', 'type_hint': 'float', 'default': None}], 'return_type': 'float', 'docstring': 'Add two numbers.', 'decorators': [], 'is_async': False, 'is_method': True}], 'docstring': 'Calculator class.', 'line_number': 1}], 'functions': []}, {'file': 'utils.js', 'language': 'JavaScript', 'classes': [], 'functions': [{'name': 'formatDate', 'parameters': [{'name': 'date', 'type_hint': None, 'default': None}], 'return_type': None, 'docstring': None, 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = APIReferenceBuilder(code_analysis)",
            "description": "Assign builder = APIReferenceBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generated = builder.build_reference(self.output_dir)",
            "description": "Assign generated = builder.build_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(len(generated), 2)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "filenames = [f.name for f in generated.values()]",
            "description": "Assign filenames = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('calculator.md', filenames)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('utils.md', filenames)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "py_file = next((f for f in generated.values() if f.name == 'calculator.md'))",
            "description": "Assign py_file = next(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "py_content = py_file.read_text()",
            "description": "Assign py_content = py_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('Calculator class', py_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('add(a: float, b: float) \u2192 float', py_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "js_file = next((f for f in generated.values() if f.name == 'utils.md'))",
            "description": "Assign js_file = next(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "js_content = js_file.read_text()",
            "description": "Assign js_content = js_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "self.assertIn('formatDate', js_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "self.assertIn('**Language**: JavaScript', js_content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Integration With Code Analyzer",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_api_reference_builder.py:214"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Async Function Indicator": [
      {
        "guide_id": "06f1f42a0531",
        "title": "Async Function Indicator",
        "overview": "Workflow: Test that async functions are marked in output.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.api_reference_builder"
        ],
        "required_fixtures": [
          "api_client"
        ],
        "workflows": [
          {
            "example_id": "a2d82022",
            "test_name": "test_async_function_indicator",
            "category": "workflow",
            "code": "'Test that async functions are marked in output.'\ncode_analysis = {'files': [{'file': 'async_utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'fetch_data', 'parameters': [{'name': 'url', 'type_hint': 'str', 'default': None}], 'return_type': 'dict', 'docstring': 'Fetch data from URL.', 'is_async': True, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Async function**', content)\nself.assertIn('fetch_data', content)",
            "language": "Python",
            "description": "Workflow: Test that async functions are marked in output.",
            "expected_behavior": "self.assertIn('fetch_data', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
            "line_start": 288,
            "line_end": 319,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.api_reference_builder"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that async functions are marked in output.'",
            "description": "'Test that async functions are marked in output.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code_analysis = {'files': [{'file': 'async_utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'fetch_data', 'parameters': [{'name': 'url', 'type_hint': 'str', 'default': None}], 'return_type': 'dict', 'docstring': 'Fetch data from URL.', 'is_async': True, 'is_method': False, 'decorators': []}]}]}",
            "description": "Assign code_analysis = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "builder = APIReferenceBuilder(code_analysis)",
            "description": "Assign builder = APIReferenceBuilder(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "generated = builder.build_reference(self.output_dir)",
            "description": "Assign generated = builder.build_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "output_file = list(generated.values())[0]",
            "description": "Assign output_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "content = output_file.read_text()",
            "description": "Assign content = output_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('**Async function**', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('fetch_data', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Async Function Indicator",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_api_reference_builder.py:288"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Export To Weaviate": [
      {
        "guide_id": "39793d362284",
        "title": "Export To Weaviate",
        "overview": "Workflow: Test Weaviate export tool.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "asyncio",
          "skill_seekers.mcp.tools.vector_db_tools"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "67934803",
            "test_name": "test_export_to_weaviate",
            "category": "workflow",
            "code": "'Test Weaviate export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_weaviate_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Weaviate Export Complete!' in text\nassert 'test_skill-weaviate.json' in text\nassert 'weaviate.Client' in text",
            "language": "Python",
            "description": "Workflow: Test Weaviate export tool.",
            "expected_behavior": "assert 'weaviate.Client' in text",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
            "line_start": 60,
            "line_end": 80,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: test_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "asyncio",
              "skill_seekers.mcp.tools.vector_db_tools"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Weaviate export tool.'",
            "description": "'Test Weaviate export tool.'",
            "expected_result": null,
            "verification": "assert isinstance(result, list)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = test_skill_dir.parent",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": "assert len(result) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": "assert hasattr(result[0], 'text')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = run_async(export_to_weaviate_impl(args))",
            "description": "Assign result = run_async(...)",
            "expected_result": null,
            "verification": "assert '\u2705 Weaviate Export Complete!' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "text = result[0].text",
            "description": "Assign text = value",
            "expected_result": null,
            "verification": "assert 'test_skill-weaviate.json' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Export To Weaviate",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_mcp_vector_dbs.py:60"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Export To Chroma": [
      {
        "guide_id": "de3f589af9b1",
        "title": "Export To Chroma",
        "overview": "Workflow: Test Chroma export tool.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "asyncio",
          "skill_seekers.mcp.tools.vector_db_tools"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "03bf9106",
            "test_name": "test_export_to_chroma",
            "category": "workflow",
            "code": "'Test Chroma export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_chroma_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Chroma Export Complete!' in text\nassert 'test_skill-chroma.json' in text\nassert 'chromadb' in text",
            "language": "Python",
            "description": "Workflow: Test Chroma export tool.",
            "expected_behavior": "assert 'chromadb' in text",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
            "line_start": 83,
            "line_end": 103,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: test_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "asyncio",
              "skill_seekers.mcp.tools.vector_db_tools"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Chroma export tool.'",
            "description": "'Test Chroma export tool.'",
            "expected_result": null,
            "verification": "assert isinstance(result, list)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = test_skill_dir.parent",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": "assert len(result) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": "assert hasattr(result[0], 'text')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = run_async(export_to_chroma_impl(args))",
            "description": "Assign result = run_async(...)",
            "expected_result": null,
            "verification": "assert '\u2705 Chroma Export Complete!' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "text = result[0].text",
            "description": "Assign text = value",
            "expected_result": null,
            "verification": "assert 'test_skill-chroma.json' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Export To Chroma",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_mcp_vector_dbs.py:83"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Export To Faiss": [
      {
        "guide_id": "979530b58380",
        "title": "Export To Faiss",
        "overview": "Workflow: Test FAISS export tool.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "asyncio",
          "skill_seekers.mcp.tools.vector_db_tools"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d0cc1231",
            "test_name": "test_export_to_faiss",
            "category": "workflow",
            "code": "'Test FAISS export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_faiss_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 FAISS Export Complete!' in text\nassert 'test_skill-faiss.json' in text\nassert 'import faiss' in text",
            "language": "Python",
            "description": "Workflow: Test FAISS export tool.",
            "expected_behavior": "assert 'import faiss' in text",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
            "line_start": 106,
            "line_end": 126,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: test_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "asyncio",
              "skill_seekers.mcp.tools.vector_db_tools"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test FAISS export tool.'",
            "description": "'Test FAISS export tool.'",
            "expected_result": null,
            "verification": "assert isinstance(result, list)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = test_skill_dir.parent",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": "assert len(result) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": "assert hasattr(result[0], 'text')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = run_async(export_to_faiss_impl(args))",
            "description": "Assign result = run_async(...)",
            "expected_result": null,
            "verification": "assert '\u2705 FAISS Export Complete!' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "text = result[0].text",
            "description": "Assign text = value",
            "expected_result": null,
            "verification": "assert 'test_skill-faiss.json' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Export To Faiss",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_mcp_vector_dbs.py:106"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Export To Qdrant": [
      {
        "guide_id": "314d01af3e71",
        "title": "Export To Qdrant",
        "overview": "Workflow: Test Qdrant export tool.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "asyncio",
          "skill_seekers.mcp.tools.vector_db_tools"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d678d20a",
            "test_name": "test_export_to_qdrant",
            "category": "workflow",
            "code": "'Test Qdrant export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_qdrant_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Qdrant Export Complete!' in text\nassert 'test_skill-qdrant.json' in text\nassert 'QdrantClient' in text",
            "language": "Python",
            "description": "Workflow: Test Qdrant export tool.",
            "expected_behavior": "assert 'QdrantClient' in text",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
            "line_start": 129,
            "line_end": 149,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: test_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "asyncio",
              "skill_seekers.mcp.tools.vector_db_tools"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test Qdrant export tool.'",
            "description": "'Test Qdrant export tool.'",
            "expected_result": null,
            "verification": "assert isinstance(result, list)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = test_skill_dir.parent",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": "assert len(result) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": "assert hasattr(result[0], 'text')",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = run_async(export_to_qdrant_impl(args))",
            "description": "Assign result = run_async(...)",
            "expected_result": null,
            "verification": "assert '\u2705 Qdrant Export Complete!' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "text = result[0].text",
            "description": "Assign text = value",
            "expected_result": null,
            "verification": "assert 'test_skill-qdrant.json' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Export To Qdrant",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_mcp_vector_dbs.py:129"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "All Exports Create Files": [
      {
        "guide_id": "661843b03aa3",
        "title": "All Exports Create Files",
        "overview": "Workflow: Test that all export tools create output files.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "json",
          "asyncio",
          "skill_seekers.mcp.tools.vector_db_tools"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a9129e6d",
            "test_name": "test_all_exports_create_files",
            "category": "workflow",
            "code": "'Test that all export tools create output files.'\noutput_dir = test_skill_dir.parent\nexports = [('weaviate', export_to_weaviate_impl), ('chroma', export_to_chroma_impl), ('faiss', export_to_faiss_impl), ('qdrant', export_to_qdrant_impl)]\nfor target, export_func in exports:\n    args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\n    result = run_async(export_func(args))\n    assert isinstance(result, list)\n    text = result[0].text\n    assert '\u2705' in text\n    expected_file = output_dir / f'test_skill-{target}.json'\n    assert expected_file.exists(), f'{target} export file not created'\n    with open(expected_file) as f:\n        data = json.load(f)\n        assert isinstance(data, dict)",
            "language": "Python",
            "description": "Workflow: Test that all export tools create output files.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
            "line_start": 179,
            "line_end": 211,
            "complexity_score": 0.4,
            "confidence": 0.9,
            "setup_code": "# Fixtures: test_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "json",
              "asyncio",
              "skill_seekers.mcp.tools.vector_db_tools"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that all export tools create output files.'",
            "description": "'Test that all export tools create output files.'",
            "expected_result": null,
            "verification": "assert isinstance(result, list)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "output_dir = test_skill_dir.parent",
            "description": "Assign output_dir = value",
            "expected_result": null,
            "verification": "assert '\u2705' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "exports = [('weaviate', export_to_weaviate_impl), ('chroma', export_to_chroma_impl), ('faiss', export_to_faiss_impl), ('qdrant', export_to_qdrant_impl)]",
            "description": "Assign exports = value",
            "expected_result": null,
            "verification": "assert expected_file.exists(), f'{target} export file not created'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
            "description": "Assign args = value",
            "expected_result": null,
            "verification": "assert isinstance(data, dict)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "result = run_async(export_func(args))",
            "description": "Assign result = run_async(...)",
            "expected_result": null,
            "verification": "assert isinstance(result, list)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "text = result[0].text",
            "description": "Assign text = value",
            "expected_result": null,
            "verification": "assert '\u2705' in text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "expected_file = output_dir / f'test_skill-{target}.json'",
            "description": "Assign expected_file = value",
            "expected_result": null,
            "verification": "assert expected_file.exists(), f'{target} export file not created'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "data = json.load(f)",
            "description": "Assign data = json.load(...)",
            "expected_result": null,
            "verification": "assert isinstance(data, dict)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "All Exports Create Files",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_mcp_vector_dbs.py:179"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chroma Upload Without Chromadb Installed": [
      {
        "guide_id": "a7ef126dbf60",
        "title": "Chroma Upload Without Chromadb Installed",
        "overview": "Workflow: Test upload fails gracefully without chromadb installed.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "sys",
          "sys",
          "skill_seekers.cli.upload_skill",
          "inspect"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "b0e0cc26",
            "test_name": "test_chroma_upload_without_chromadb_installed",
            "category": "workflow",
            "code": "'Test upload fails gracefully without chromadb installed.'\nadaptor = get_adaptor('chroma')\nimport sys\nchromadb_backup = sys.modules.get('chromadb')\nif 'chromadb' in sys.modules:\n    del sys.modules['chromadb']\ntry:\n    result = adaptor.upload(sample_chroma_package)\n    assert result['success'] is False\n    assert 'chromadb not installed' in result['message']\n    assert 'pip install chromadb' in result['message']\nfinally:\n    if chromadb_backup:\n        sys.modules['chromadb'] = chromadb_backup",
            "language": "Python",
            "description": "Workflow: Test upload fails gracefully without chromadb installed.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
            "line_start": 79,
            "line_end": 98,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "# Fixtures: sample_chroma_package",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "sys",
              "sys",
              "skill_seekers.cli.upload_skill",
              "inspect"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test upload fails gracefully without chromadb installed.'",
            "description": "'Test upload fails gracefully without chromadb installed.'",
            "expected_result": null,
            "verification": "assert result['success'] is False",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('chroma')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert 'chromadb not installed' in result['message']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "chromadb_backup = sys.modules.get('chromadb')",
            "description": "Assign chromadb_backup = sys.modules.get(...)",
            "expected_result": null,
            "verification": "assert 'pip install chromadb' in result['message']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = adaptor.upload(sample_chroma_package)",
            "description": "Assign result = adaptor.upload(...)",
            "expected_result": null,
            "verification": "assert result['success'] is False",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "sys.modules['chromadb'] = chromadb_backup",
            "description": "Assign unknown = chromadb_backup",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chroma Upload Without Chromadb Installed",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_upload_integration.py:79"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Weaviate Upload Without Weaviate Installed": [
      {
        "guide_id": "369a8df570c3",
        "title": "Weaviate Upload Without Weaviate Installed",
        "overview": "Workflow: Test upload fails gracefully without weaviate-client installed.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "pytest",
          "skill_seekers.cli.adaptors",
          "sys",
          "sys",
          "skill_seekers.cli.upload_skill",
          "inspect"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "d7180035",
            "test_name": "test_weaviate_upload_without_weaviate_installed",
            "category": "workflow",
            "code": "'Test upload fails gracefully without weaviate-client installed.'\nadaptor = get_adaptor('weaviate')\nimport sys\nweaviate_backup = sys.modules.get('weaviate')\nif 'weaviate' in sys.modules:\n    del sys.modules['weaviate']\ntry:\n    result = adaptor.upload(sample_weaviate_package)\n    assert result['success'] is False\n    assert 'weaviate-client not installed' in result['message']\n    assert 'pip install weaviate-client' in result['message']\nfinally:\n    if weaviate_backup:\n        sys.modules['weaviate'] = weaviate_backup",
            "language": "Python",
            "description": "Workflow: Test upload fails gracefully without weaviate-client installed.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
            "line_start": 121,
            "line_end": 140,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "# Fixtures: sample_weaviate_package",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "pytest",
              "skill_seekers.cli.adaptors",
              "sys",
              "sys",
              "skill_seekers.cli.upload_skill",
              "inspect"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test upload fails gracefully without weaviate-client installed.'",
            "description": "'Test upload fails gracefully without weaviate-client installed.'",
            "expected_result": null,
            "verification": "assert result['success'] is False",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "adaptor = get_adaptor('weaviate')",
            "description": "Assign adaptor = get_adaptor(...)",
            "expected_result": null,
            "verification": "assert 'weaviate-client not installed' in result['message']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "weaviate_backup = sys.modules.get('weaviate')",
            "description": "Assign weaviate_backup = sys.modules.get(...)",
            "expected_result": null,
            "verification": "assert 'pip install weaviate-client' in result['message']",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = adaptor.upload(sample_weaviate_package)",
            "description": "Assign result = adaptor.upload(...)",
            "expected_result": null,
            "verification": "assert result['success'] is False",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "sys.modules['weaviate'] = weaviate_backup",
            "description": "Assign unknown = weaviate_backup",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Weaviate Upload Without Weaviate Installed",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_upload_integration.py:121"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Document Single Chunk": [
      {
        "guide_id": "a93a5569faef",
        "title": "Chunk Document Single Chunk",
        "overview": "Workflow: Test chunking when document fits in single chunk.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.streaming_ingest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "f7cb18da",
            "test_name": "test_chunk_document_single_chunk",
            "category": "workflow",
            "code": "'Test chunking when document fits in single chunk.'\ningester = StreamingIngester(chunk_size=1000, chunk_overlap=100)\ncontent = 'Small document'\nmetadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}\nchunks = list(ingester.chunk_document(content, metadata))\nassert len(chunks) == 1\nchunk_text, chunk_meta = chunks[0]\nassert chunk_text == content\nassert chunk_meta.chunk_index == 0\nassert chunk_meta.total_chunks == 1\nassert chunk_meta.source == 'test'",
            "language": "Python",
            "description": "Workflow: Test chunking when document fits in single chunk.",
            "expected_behavior": "assert chunk_meta.source == 'test'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
            "line_start": 48,
            "line_end": 63,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.streaming_ingest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test chunking when document fits in single chunk.'",
            "description": "'Test chunking when document fits in single chunk.'",
            "expected_result": null,
            "verification": "assert len(chunks) == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "ingester = StreamingIngester(chunk_size=1000, chunk_overlap=100)",
            "description": "Assign ingester = StreamingIngester(...)",
            "expected_result": null,
            "verification": "assert chunk_text == content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = 'Small document'",
            "description": "Assign content = 'Small document'",
            "expected_result": null,
            "verification": "assert chunk_meta.chunk_index == 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": "assert chunk_meta.total_chunks == 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = list(ingester.chunk_document(content, metadata))",
            "description": "Assign chunks = list(...)",
            "expected_result": null,
            "verification": "assert chunk_meta.source == 'test'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "chunk_text, chunk_meta = chunks[0]",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": "assert chunk_text == content",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Document Single Chunk",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_streaming_ingestion.py:48"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Document Multiple Chunks": [
      {
        "guide_id": "6995f78dac8a",
        "title": "Chunk Document Multiple Chunks",
        "overview": "Workflow: Test chunking with multiple chunks.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.streaming_ingest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2e944c86",
            "test_name": "test_chunk_document_multiple_chunks",
            "category": "workflow",
            "code": "'Test chunking with multiple chunks.'\ningester = StreamingIngester(chunk_size=100, chunk_overlap=20)\ncontent = 'A' * 250\nmetadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}\nchunks = list(ingester.chunk_document(content, metadata))\nassert len(chunks) > 1\nfor i in range(len(chunks) - 1):\n    chunk1_text, chunk1_meta = chunks[i]\n    chunk2_text, chunk2_meta = chunks[i + 1]\n    assert chunk2_meta.char_start < chunk1_meta.char_end",
            "language": "Python",
            "description": "Workflow: Test chunking with multiple chunks.",
            "expected_behavior": "assert len(chunks) > 1",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
            "line_start": 66,
            "line_end": 84,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.streaming_ingest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test chunking with multiple chunks.'",
            "description": "'Test chunking with multiple chunks.'",
            "expected_result": null,
            "verification": "assert len(chunks) > 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "ingester = StreamingIngester(chunk_size=100, chunk_overlap=20)",
            "description": "Assign ingester = StreamingIngester(...)",
            "expected_result": null,
            "verification": "assert chunk2_meta.char_start < chunk1_meta.char_end",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = 'A' * 250",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = list(ingester.chunk_document(content, metadata))",
            "description": "Assign chunks = list(...)",
            "expected_result": null,
            "verification": "assert len(chunks) > 1",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "chunk1_text, chunk1_meta = chunks[i]",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "chunk2_text, chunk2_meta = chunks[i + 1]",
            "description": "Assign unknown = value",
            "expected_result": null,
            "verification": "assert chunk2_meta.char_start < chunk1_meta.char_end",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Document Multiple Chunks",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_streaming_ingestion.py:66"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Document Metadata": [
      {
        "guide_id": "931a806df1f7",
        "title": "Chunk Document Metadata",
        "overview": "Workflow: Test chunk metadata is correct.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.streaming_ingest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e804f7e6",
            "test_name": "test_chunk_document_metadata",
            "category": "workflow",
            "code": "'Test chunk metadata is correct.'\ningester = StreamingIngester(chunk_size=100, chunk_overlap=20)\ncontent = 'B' * 250\nmetadata = {'source': 'test_source', 'file': 'test_file.md', 'category': 'test_cat'}\nchunks = list(ingester.chunk_document(content, metadata))\nfor i, (chunk_text, chunk_meta) in enumerate(chunks):\n    assert chunk_meta.chunk_index == i\n    assert chunk_meta.total_chunks == len(chunks)\n    assert chunk_meta.source == 'test_source'\n    assert chunk_meta.file == 'test_file.md'\n    assert chunk_meta.category == 'test_cat'\n    assert len(chunk_meta.chunk_id) == 32",
            "language": "Python",
            "description": "Workflow: Test chunk metadata is correct.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
            "line_start": 87,
            "line_end": 102,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.streaming_ingest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test chunk metadata is correct.'",
            "description": "'Test chunk metadata is correct.'",
            "expected_result": null,
            "verification": "assert chunk_meta.chunk_index == i",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "ingester = StreamingIngester(chunk_size=100, chunk_overlap=20)",
            "description": "Assign ingester = StreamingIngester(...)",
            "expected_result": null,
            "verification": "assert chunk_meta.total_chunks == len(chunks)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "content = 'B' * 250",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": "assert chunk_meta.source == 'test_source'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "metadata = {'source': 'test_source', 'file': 'test_file.md', 'category': 'test_cat'}",
            "description": "Assign metadata = value",
            "expected_result": null,
            "verification": "assert chunk_meta.file == 'test_file.md'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "chunks = list(ingester.chunk_document(content, metadata))",
            "description": "Assign chunks = list(...)",
            "expected_result": null,
            "verification": "assert chunk_meta.category == 'test_cat'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Document Metadata",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_streaming_ingestion.py:87"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Stream Skill Directory": [
      {
        "guide_id": "4f53309d901d",
        "title": "Stream Skill Directory",
        "overview": "Workflow: Test streaming entire skill directory.",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.streaming_ingest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "00f58fd0",
            "test_name": "test_stream_skill_directory",
            "category": "workflow",
            "code": "'Test streaming entire skill directory.'\ningester = StreamingIngester(chunk_size=500, chunk_overlap=50)\nchunks = list(ingester.stream_skill_directory(temp_skill_dir))\nassert len(chunks) > 0\nassert ingester.progress is not None\nassert ingester.progress.total_documents == 3\nassert ingester.progress.processed_documents == 3\nassert ingester.progress.total_chunks > 0\nassert ingester.progress.processed_chunks == len(chunks)\nsources = set()\ncategories = set()\nfor chunk_text, chunk_meta in chunks:\n    assert chunk_text\n    assert chunk_meta['chunk_id']\n    sources.add(chunk_meta['source'])\n    categories.add(chunk_meta['category'])\nassert 'test_skill' in sources\nassert 'overview' in categories",
            "language": "Python",
            "description": "Workflow: Test streaming entire skill directory.",
            "expected_behavior": "assert 'overview' in categories",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
            "line_start": 105,
            "line_end": 132,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: temp_skill_dir",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.streaming_ingest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test streaming entire skill directory.'",
            "description": "'Test streaming entire skill directory.'",
            "expected_result": null,
            "verification": "assert len(chunks) > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "ingester = StreamingIngester(chunk_size=500, chunk_overlap=50)",
            "description": "Assign ingester = StreamingIngester(...)",
            "expected_result": null,
            "verification": "assert ingester.progress is not None",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "chunks = list(ingester.stream_skill_directory(temp_skill_dir))",
            "description": "Assign chunks = list(...)",
            "expected_result": null,
            "verification": "assert ingester.progress.total_documents == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "sources = set()",
            "description": "Assign sources = set(...)",
            "expected_result": null,
            "verification": "assert ingester.progress.processed_documents == 3",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categories = set()",
            "description": "Assign categories = set(...)",
            "expected_result": null,
            "verification": "assert ingester.progress.total_chunks > 0",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "sources.add(chunk_meta['source'])",
            "description": "Call sources.add()",
            "expected_result": null,
            "verification": "assert ingester.progress.processed_chunks == len(chunks)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "categories.add(chunk_meta['category'])",
            "description": "Call categories.add()",
            "expected_result": null,
            "verification": "assert chunk_text",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Stream Skill Directory",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_streaming_ingestion.py:105"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Checkpoint Save Load": [
      {
        "guide_id": "41e6f06843df",
        "title": "Checkpoint Save Load",
        "overview": "Workflow: Test checkpoint save and load.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.streaming_ingest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "facc692d",
            "test_name": "test_checkpoint_save_load",
            "category": "workflow",
            "code": "'Test checkpoint save and load.'\ningester = StreamingIngester()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    checkpoint_path = Path(tmpdir) / 'checkpoint.json'\n    ingester.progress = IngestionProgress(total_documents=10, processed_documents=5, total_chunks=100, processed_chunks=50, failed_chunks=2, bytes_processed=10000, start_time=1234567890.0)\n    state = {'last_processed_file': 'test.md', 'batch_number': 3}\n    ingester.save_checkpoint(checkpoint_path, state)\n    assert checkpoint_path.exists()\n    loaded_state = ingester.load_checkpoint(checkpoint_path)\n    assert loaded_state == state",
            "language": "Python",
            "description": "Workflow: Test checkpoint save and load.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
            "line_start": 178,
            "line_end": 205,
            "complexity_score": 0.3,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.streaming_ingest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test checkpoint save and load.'",
            "description": "'Test checkpoint save and load.'",
            "expected_result": null,
            "verification": "assert checkpoint_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "ingester = StreamingIngester()",
            "description": "Assign ingester = StreamingIngester(...)",
            "expected_result": null,
            "verification": "assert loaded_state == state",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "checkpoint_path = Path(tmpdir) / 'checkpoint.json'",
            "description": "Assign checkpoint_path = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "ingester.progress = IngestionProgress(total_documents=10, processed_documents=5, total_chunks=100, processed_chunks=50, failed_chunks=2, bytes_processed=10000, start_time=1234567890.0)",
            "description": "Assign ingester.progress = IngestionProgress(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "state = {'last_processed_file': 'test.md', 'batch_number': 3}",
            "description": "Assign state = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "ingester.save_checkpoint(checkpoint_path, state)",
            "description": "Call ingester.save_checkpoint()",
            "expected_result": null,
            "verification": "assert checkpoint_path.exists()",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "loaded_state = ingester.load_checkpoint(checkpoint_path)",
            "description": "Assign loaded_state = ingester.load_checkpoint(...)",
            "expected_result": null,
            "verification": "assert loaded_state == state",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Checkpoint Save Load",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_streaming_ingestion.py:178"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Chunk Size Validation": [
      {
        "guide_id": "b32ee1a6cfb5",
        "title": "Chunk Size Validation",
        "overview": "Workflow: Test different chunk sizes.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "pytest",
          "pathlib",
          "sys",
          "tempfile",
          "skill_seekers.cli.streaming_ingest"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "6531de8b",
            "test_name": "test_chunk_size_validation",
            "category": "workflow",
            "code": "'Test different chunk sizes.'\ncontent = 'X' * 1000\ningester_small = StreamingIngester(chunk_size=100, chunk_overlap=10)\nchunks_small = list(ingester_small.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))\ningester_large = StreamingIngester(chunk_size=500, chunk_overlap=50)\nchunks_large = list(ingester_large.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))\nassert len(chunks_small) > len(chunks_large)",
            "language": "Python",
            "description": "Workflow: Test different chunk sizes.",
            "expected_behavior": "assert len(chunks_small) > len(chunks_large)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
            "line_start": 243,
            "line_end": 264,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "pathlib",
              "sys",
              "tempfile",
              "skill_seekers.cli.streaming_ingest"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test different chunk sizes.'",
            "description": "'Test different chunk sizes.'",
            "expected_result": null,
            "verification": "assert len(chunks_small) > len(chunks_large)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "content = 'X' * 1000",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "ingester_small = StreamingIngester(chunk_size=100, chunk_overlap=10)",
            "description": "Assign ingester_small = StreamingIngester(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "chunks_small = list(ingester_small.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))",
            "description": "Assign chunks_small = list(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "ingester_large = StreamingIngester(chunk_size=500, chunk_overlap=50)",
            "description": "Assign ingester_large = StreamingIngester(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "chunks_large = list(ingester_large.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))",
            "description": "Assign chunks_large = list(...)",
            "expected_result": null,
            "verification": "assert len(chunks_small) > len(chunks_large)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Chunk Size Validation",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_streaming_ingestion.py:243"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Categorize By Keywords": [
      {
        "guide_id": "9a815d8ec214",
        "title": "Categorize By Keywords",
        "overview": "Workflow: Test categorization using keyword matching",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e89f472c",
            "test_name": "test_categorize_by_keywords",
            "category": "workflow",
            "code": "'Test categorization using keyword matching'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf', 'categories': {'getting_started': ['introduction', 'getting started'], 'api': ['api', 'reference', 'function']}}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Introduction to the API', 'chapter': 'Chapter 1: Getting Started'}, {'page_number': 2, 'text': 'API reference for functions', 'chapter': None}]}\ncategories = converter.categorize_content()\nself.assertIn('test', categories)\nself.assertEqual(len(categories), 1)\nself.assertEqual(len(categories['test']['pages']), 2)",
            "language": "Python",
            "description": "Workflow: Test categorization using keyword matching",
            "expected_behavior": "self.assertEqual(len(categories['test']['pages']), 2)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 90,
            "line_end": 121,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test categorization using keyword matching'",
            "description": "'Test categorization using keyword matching'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test', 'pdf_path': 'test.pdf', 'categories': {'getting_started': ['introduction', 'getting started'], 'api': ['api', 'reference', 'function']}}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Introduction to the API', 'chapter': 'Chapter 1: Getting Started'}, {'page_number': 2, 'text': 'API reference for functions', 'chapter': None}]}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categories = converter.categorize_content()",
            "description": "Assign categories = converter.categorize_content(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIn('test', categories)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertEqual(len(categories), 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(len(categories['test']['pages']), 2)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Categorize By Keywords",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_scraper.py:90"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Categorize By Chapters": [
      {
        "guide_id": "c1f062a0f13a",
        "title": "Categorize By Chapters",
        "overview": "Workflow: Test categorization using chapter information",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "bf742326",
            "test_name": "test_categorize_by_chapters",
            "category": "workflow",
            "code": "'Test categorization using chapter information'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Content here', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 2, 'text': 'More content', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 3, 'text': 'New chapter', 'chapter': 'Chapter 2: Advanced Topics'}]}\ncategories = converter.categorize_content()\nself.assertIsInstance(categories, dict)\nself.assertGreater(len(categories), 0)",
            "language": "Python",
            "description": "Workflow: Test categorization using chapter information",
            "expected_behavior": "self.assertGreater(len(categories), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 123,
            "line_end": 141,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test categorization using chapter information'",
            "description": "'Test categorization using chapter information'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Content here', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 2, 'text': 'More content', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 3, 'text': 'New chapter', 'chapter': 'Chapter 2: Advanced Topics'}]}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categories = converter.categorize_content()",
            "description": "Assign categories = converter.categorize_content(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIsInstance(categories, dict)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(len(categories), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Categorize By Chapters",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_scraper.py:123"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Categorize Handles No Chapters": [
      {
        "guide_id": "4a384a49631e",
        "title": "Categorize Handles No Chapters",
        "overview": "Workflow: Test categorization when no chapters are detected",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "06381c0f",
            "test_name": "test_categorize_handles_no_chapters",
            "category": "workflow",
            "code": "'Test categorization when no chapters are detected'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Some content', 'chapter': None}]}\ncategories = converter.categorize_content()\nself.assertIsInstance(categories, dict)",
            "language": "Python",
            "description": "Workflow: Test categorization when no chapters are detected",
            "expected_behavior": "self.assertIsInstance(categories, dict)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 143,
            "line_end": 156,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test categorization when no chapters are detected'",
            "description": "'Test categorization when no chapters are detected'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Some content', 'chapter': None}]}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "categories = converter.categorize_content()",
            "description": "Assign categories = converter.categorize_content(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIsInstance(categories, dict)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Categorize Handles No Chapters",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_pdf_scraper.py:143"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Skill Creates Structure": [
      {
        "guide_id": "2773de75271b",
        "title": "Build Skill Creates Structure",
        "overview": "Workflow: Test that build_skill creates required directory structure",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e4fdbc9d",
            "test_name": "test_build_skill_creates_structure",
            "category": "workflow",
            "code": "'Test that build_skill creates required directory structure'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test content', 'code_blocks': [], 'images': []}], 'total_pages': 1}\nconverter.categories = {'getting_started': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nskill_dir = Path(self.temp_dir) / 'test_skill'\nself.assertTrue(skill_dir.exists())\nself.assertTrue((skill_dir / 'references').exists())\nself.assertTrue((skill_dir / 'scripts').exists())\nself.assertTrue((skill_dir / 'assets').exists())",
            "language": "Python",
            "description": "Workflow: Test that build_skill creates required directory structure",
            "expected_behavior": "self.assertTrue((skill_dir / 'assets').exists())",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 173,
            "line_end": 197,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that build_skill creates required directory structure'",
            "description": "'Test that build_skill creates required directory structure'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test content', 'code_blocks': [], 'images': []}], 'total_pages': 1}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.categories = {'getting_started': [converter.extracted_data['pages'][0]]}",
            "description": "Assign converter.categories = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "skill_dir = Path(self.temp_dir) / 'test_skill'",
            "description": "Assign skill_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(skill_dir.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertTrue((skill_dir / 'references').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertTrue((skill_dir / 'scripts').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertTrue((skill_dir / 'assets').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Skill Creates Structure",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_pdf_scraper.py:173"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Skill Creates Skill Md": [
      {
        "guide_id": "a7ac157a9827",
        "title": "Build Skill Creates Skill Md",
        "overview": "Workflow: Test that SKILL.md is created",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "6ee4a77e",
            "test_name": "test_build_skill_creates_skill_md",
            "category": "workflow",
            "code": "'Test that SKILL.md is created'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf', 'description': 'Test description'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test', 'code_blocks': [], 'images': []}], 'total_pages': 1}\nconverter.categories = {'test': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nskill_md = Path(self.temp_dir) / 'test_skill' / 'SKILL.md'\nself.assertTrue(skill_md.exists())\ncontent = skill_md.read_text()\nself.assertIn('test_skill', content)\nself.assertIn('Test description', content)",
            "language": "Python",
            "description": "Workflow: Test that SKILL.md is created",
            "expected_behavior": "self.assertIn('Test description', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 199,
            "line_end": 221,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that SKILL.md is created'",
            "description": "'Test that SKILL.md is created'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf', 'description': 'Test description'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test', 'code_blocks': [], 'images': []}], 'total_pages': 1}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.categories = {'test': [converter.extracted_data['pages'][0]]}",
            "description": "Assign converter.categories = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "skill_md = Path(self.temp_dir) / 'test_skill' / 'SKILL.md'",
            "description": "Assign skill_md = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(skill_md.exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "content = skill_md.read_text()",
            "description": "Assign content = skill_md.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('test_skill', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIn('Test description', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Skill Creates Skill Md",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_pdf_scraper.py:199"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Build Skill Creates Reference Files": [
      {
        "guide_id": "f497f3eb5acb",
        "title": "Build Skill Creates Reference Files",
        "overview": "Workflow: Test that reference files are created for categories",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e94d8fca",
            "test_name": "test_build_skill_creates_reference_files",
            "category": "workflow",
            "code": "'Test that reference files are created for categories'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Getting started', 'code_blocks': [], 'images': []}, {'page_number': 2, 'text': 'API reference', 'code_blocks': [], 'images': []}], 'total_pages': 2}\nconverter.build_skill()\nrefs_dir = Path(self.temp_dir) / 'test_skill' / 'references'\nself.assertTrue((refs_dir / 'test.md').exists())\nself.assertTrue((refs_dir / 'index.md').exists())",
            "language": "Python",
            "description": "Workflow: Test that reference files are created for categories",
            "expected_behavior": "self.assertTrue((refs_dir / 'index.md').exists())",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 223,
            "line_end": 245,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that reference files are created for categories'",
            "description": "'Test that reference files are created for categories'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Getting started', 'code_blocks': [], 'images': []}, {'page_number': 2, 'text': 'API reference', 'code_blocks': [], 'images': []}], 'total_pages': 2}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "refs_dir = Path(self.temp_dir) / 'test_skill' / 'references'",
            "description": "Assign refs_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertTrue((refs_dir / 'test.md').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue((refs_dir / 'index.md').exists())",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Build Skill Creates Reference Files",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_scraper.py:223"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Code Blocks Included In References": [
      {
        "guide_id": "4eaf1387d3c5",
        "title": "Code Blocks Included In References",
        "overview": "Workflow: Test that code blocks are included in reference files",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "85d89c03",
            "test_name": "test_code_blocks_included_in_references",
            "category": "workflow",
            "code": "'Test that code blocks are included in reference files'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Example code', 'code_blocks': [{'code': \"def hello():\\n    print('world')\", 'language': 'python', 'quality': 8.0}], 'images': []}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('```python', content)\nself.assertIn('def hello()', content)\nself.assertIn(\"print('world')\", content)",
            "language": "Python",
            "description": "Workflow: Test that code blocks are included in reference files",
            "expected_behavior": "self.assertIn(\"print('world')\", content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 262,
            "line_end": 298,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that code blocks are included in reference files'",
            "description": "'Test that code blocks are included in reference files'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Example code', 'code_blocks': [{'code': \"def hello():\\n    print('world')\", 'language': 'python', 'quality': 8.0}], 'images': []}], 'total_pages': 1}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "ref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'",
            "description": "Assign ref_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = ref_file.read_text()",
            "description": "Assign content = ref_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('```python', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('def hello()', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn(\"print('world')\", content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Code Blocks Included In References",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_pdf_scraper.py:262"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "High Quality Code Preferred": [
      {
        "guide_id": "3dec7674c88d",
        "title": "High Quality Code Preferred",
        "overview": "Workflow: Test that high-quality code blocks are prioritized",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "69471952",
            "test_name": "test_high_quality_code_preferred",
            "category": "workflow",
            "code": "'Test that high-quality code blocks are prioritized'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Code examples', 'code_blocks': [{'code': 'x = 1', 'language': 'python', 'quality': 2.0}, {'code': 'def process():\\n    return result', 'language': 'python', 'quality': 9.0}], 'images': []}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('def process()', content)",
            "language": "Python",
            "description": "Workflow: Test that high-quality code blocks are prioritized",
            "expected_behavior": "self.assertIn('def process()', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 300,
            "line_end": 335,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that high-quality code blocks are prioritized'",
            "description": "'Test that high-quality code blocks are prioritized'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Code examples', 'code_blocks': [{'code': 'x = 1', 'language': 'python', 'quality': 2.0}, {'code': 'def process():\\n    return result', 'language': 'python', 'quality': 9.0}], 'images': []}], 'total_pages': 1}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "ref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'",
            "description": "Assign ref_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "content = ref_file.read_text()",
            "description": "Assign content = ref_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('def process()', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "High Quality Code Preferred",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_pdf_scraper.py:300"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Images Saved To Assets": [
      {
        "guide_id": "d1535bf4a940",
        "title": "Images Saved To Assets",
        "overview": "Workflow: Test that images are saved to assets directory",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "dbbdbb69",
            "test_name": "test_images_saved_to_assets",
            "category": "workflow",
            "code": "'Test that images are saved to assets directory'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nmock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'See diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 100, 'height': 100, 'data': mock_image_bytes}]}], 'total_pages': 1}\nconverter.categories = {'diagrams': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nassets_dir = Path(self.temp_dir) / 'test_skill' / 'assets'\nimage_files = list(assets_dir.glob('*.png'))\nself.assertGreater(len(image_files), 0)",
            "language": "Python",
            "description": "Workflow: Test that images are saved to assets directory",
            "expected_behavior": "self.assertGreater(len(image_files), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 352,
            "line_end": 389,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that images are saved to assets directory'",
            "description": "'Test that images are saved to assets directory'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
            "description": "Assign mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'See diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 100, 'height': 100, 'data': mock_image_bytes}]}], 'total_pages': 1}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "converter.categories = {'diagrams': [converter.extracted_data['pages'][0]]}",
            "description": "Assign converter.categories = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "assets_dir = Path(self.temp_dir) / 'test_skill' / 'assets'",
            "description": "Assign assets_dir = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "image_files = list(assets_dir.glob('*.png'))",
            "description": "Assign image_files = list(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertGreater(len(image_files), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Images Saved To Assets",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_pdf_scraper.py:352"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Image References In Markdown": [
      {
        "guide_id": "358147205750",
        "title": "Image References In Markdown",
        "overview": "Workflow: Test that images are referenced in markdown files",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "json",
          "shutil",
          "tempfile",
          "unittest",
          "pathlib",
          "fitz",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper",
          "skill_seekers.cli.pdf_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "e8478fb4",
            "test_name": "test_image_references_in_markdown",
            "category": "workflow",
            "code": "'Test that images are referenced in markdown files'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nmock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Architecture diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 200, 'height': 150, 'data': mock_image_bytes}]}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('![', content)\nself.assertIn('../assets/', content)",
            "language": "Python",
            "description": "Workflow: Test that images are referenced in markdown files",
            "expected_behavior": "self.assertIn('../assets/', content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
            "line_start": 391,
            "line_end": 429,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
            "tags": [
              "mock",
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "json",
              "shutil",
              "tempfile",
              "unittest",
              "pathlib",
              "fitz",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper",
              "skill_seekers.cli.pdf_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that images are referenced in markdown files'",
            "description": "'Test that images are referenced in markdown files'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "converter = self.PDFToSkillConverter(config)",
            "description": "Assign converter = self.PDFToSkillConverter(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
            "description": "Assign converter.skill_dir = str(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
            "description": "Assign mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Architecture diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 200, 'height': 150, 'data': mock_image_bytes}]}], 'total_pages': 1}",
            "description": "Assign converter.extracted_data = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "converter.build_skill()",
            "description": "Call converter.build_skill()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "ref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'",
            "description": "Assign ref_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "content = ref_file.read_text()",
            "description": "Assign content = ref_file.read_text(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('![', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertIn('../assets/', content)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Image References In Markdown",
        "tags": [
          "mock",
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_pdf_scraper.py:391"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Summarize Reference Basic": [
      {
        "guide_id": "4b680b43b793",
        "title": "Summarize Reference Basic",
        "overview": "Workflow: Test basic summarization preserves structure",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "skill_seekers.cli.enhance_skill_local"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5f8a4852",
            "test_name": "test_summarize_reference_basic",
            "category": "workflow",
            "code": "'Test basic summarization preserves structure'\nenhancer = LocalSkillEnhancer(tmp_path)\nsections = []\nfor i in range(20):\n    sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with detailed explanation that would benefit from summarization.\\nWe add multiple paragraphs to make the content more realistic and substantial.\\nThis content explains various aspects of the framework in detail.\\n\\nAnother paragraph with more information about this specific topic.\\nTechnical details and explanations continue here with examples and use cases.\\n\\n```python\\n# Example code for section {i}\\ndef function_{i}():\\n    print(\"Section {i}\")\\n    return {i}\\n```\\n\\nFinal paragraph wrapping up this section with concluding remarks.\\n')\ncontent = '# Introduction\\n\\nThis is the framework introduction.\\n' + '\\n'.join(sections)\nsummarized = enhancer.summarize_reference(content, target_ratio=0.3)\nassert '# Introduction' in summarized\nassert '```python' in summarized\nassert '[Content intelligently summarized' in summarized\nassert len(summarized) < len(content)",
            "language": "Python",
            "description": "Workflow: Test basic summarization preserves structure",
            "expected_behavior": "assert len(summarized) < len(content)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
            "line_start": 16,
            "line_end": 53,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "skill_seekers.cli.enhance_skill_local"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test basic summarization preserves structure'",
            "description": "'Test basic summarization preserves structure'",
            "expected_result": null,
            "verification": "assert '# Introduction' in summarized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "enhancer = LocalSkillEnhancer(tmp_path)",
            "description": "Assign enhancer = LocalSkillEnhancer(...)",
            "expected_result": null,
            "verification": "assert '```python' in summarized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "sections = []",
            "description": "Assign sections = value",
            "expected_result": null,
            "verification": "assert '[Content intelligently summarized' in summarized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "content = '# Introduction\\n\\nThis is the framework introduction.\\n' + '\\n'.join(sections)",
            "description": "Assign content = value",
            "expected_result": null,
            "verification": "assert len(summarized) < len(content)",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.3)",
            "description": "Assign summarized = enhancer.summarize_reference(...)",
            "expected_result": null,
            "verification": "assert '# Introduction' in summarized",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with detailed explanation that would benefit from summarization.\\nWe add multiple paragraphs to make the content more realistic and substantial.\\nThis content explains various aspects of the framework in detail.\\n\\nAnother paragraph with more information about this specific topic.\\nTechnical details and explanations continue here with examples and use cases.\\n\\n```python\\n# Example code for section {i}\\ndef function_{i}():\\n    print(\"Section {i}\")\\n    return {i}\\n```\\n\\nFinal paragraph wrapping up this section with concluding remarks.\\n')",
            "description": "Call sections.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Summarize Reference Basic",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "10 minutes",
        "source_files": [
          "test_smart_summarization.py:16"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Summarize Large Content": [
      {
        "guide_id": "0f757c58bad2",
        "title": "Summarize Large Content",
        "overview": "Workflow: Test summarization with very large content",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "pytest",
          "skill_seekers.cli.enhance_skill_local"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "fecb1f6d",
            "test_name": "test_summarize_large_content",
            "category": "workflow",
            "code": "'Test summarization with very large content'\nenhancer = LocalSkillEnhancer(tmp_path)\nsections = []\nfor i in range(50):\n    sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with lots of content that needs to be summarized.\\nWe add multiple paragraphs to make it realistic.\\n\\n```python\\n# Code example {i}\\ndef function_{i}():\\n    return {i}\\n```\\n\\nMore explanatory text follows here.\\nAnother paragraph of content.\\n')\ncontent = '\\n'.join(sections)\noriginal_size = len(content)\nsummarized = enhancer.summarize_reference(content, target_ratio=0.3)\nsummarized_size = len(summarized)\nassert summarized_size < original_size\nratio = summarized_size / original_size\nassert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
            "language": "Python",
            "description": "Workflow: Test summarization with very large content",
            "expected_behavior": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
            "line_start": 94,
            "line_end": 128,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "# Fixtures: tmp_path",
            "tags": [
              "workflow",
              "integration"
            ],
            "dependencies": [
              "pytest",
              "skill_seekers.cli.enhance_skill_local"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test summarization with very large content'",
            "description": "'Test summarization with very large content'",
            "expected_result": null,
            "verification": "assert summarized_size < original_size",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "enhancer = LocalSkillEnhancer(tmp_path)",
            "description": "Assign enhancer = LocalSkillEnhancer(...)",
            "expected_result": null,
            "verification": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "sections = []",
            "description": "Assign sections = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "content = '\\n'.join(sections)",
            "description": "Assign content = unknown.join(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "original_size = len(content)",
            "description": "Assign original_size = len(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.3)",
            "description": "Assign summarized = enhancer.summarize_reference(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "summarized_size = len(summarized)",
            "description": "Assign summarized_size = len(...)",
            "expected_result": null,
            "verification": "assert summarized_size < original_size",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "ratio = summarized_size / original_size",
            "description": "Assign ratio = value",
            "expected_result": null,
            "verification": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with lots of content that needs to be summarized.\\nWe add multiple paragraphs to make it realistic.\\n\\n```python\\n# Code example {i}\\ndef function_{i}():\\n    return {i}\\n```\\n\\nMore explanatory text follows here.\\nAnother paragraph of content.\\n')",
            "description": "Call sections.append()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Summarize Large Content",
        "tags": [
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_smart_summarization.py:94"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Python Docstring Extraction": [
      {
        "guide_id": "3a740d6bc441",
        "title": "Python Docstring Extraction",
        "overview": "Workflow: Test docstring extraction for functions and classes.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "c8c19ef1",
            "test_name": "test_python_docstring_extraction",
            "category": "workflow",
            "code": "'Test docstring extraction for functions and classes.'\ncode = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'\nresult = self.analyzer.analyze_file('test.py', code, 'Python')\ncalc_class = result['classes'][0]\nself.assertIn('A simple calculator class', calc_class['docstring'])\nself.assertIn('Supports basic arithmetic operations', calc_class['docstring'])\nadd_method = calc_class['methods'][0]\nself.assertIn('Add two numbers', add_method['docstring'])\nself.assertIn('Args:', add_method['docstring'])\nself.assertIn('Returns:', add_method['docstring'])",
            "language": "Python",
            "description": "Workflow: Test docstring extraction for functions and classes.",
            "expected_behavior": "self.assertIn('Returns:', add_method['docstring'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 134,
            "line_end": 166,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test docstring extraction for functions and classes.'",
            "description": "'Test docstring extraction for functions and classes.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'",
            "description": "Assign code = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.py', code, 'Python')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "calc_class = result['classes'][0]",
            "description": "Assign calc_class = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertIn('A simple calculator class', calc_class['docstring'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertIn('Supports basic arithmetic operations', calc_class['docstring'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "add_method = calc_class['methods'][0]",
            "description": "Assign add_method = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('Add two numbers', add_method['docstring'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertIn('Args:', add_method['docstring'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('Returns:', add_method['docstring'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Python Docstring Extraction",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:134"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Javascript Class Methods": [
      {
        "guide_id": "42e77f7b8db1",
        "title": "Javascript Class Methods",
        "overview": "Workflow: Test ES6 class method extraction.\n\nNote: Regex-based parser has limitations in extracting all methods.\nThis test verifies basic method extraction works.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a692fb42",
            "test_name": "test_javascript_class_methods",
            "category": "workflow",
            "code": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '\ncode = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\nself.assertIn('classes', result)\nuser_class = result['classes'][0]\nself.assertEqual(user_class['name'], 'User')\nself.assertGreaterEqual(len(user_class['methods']), 1)\nmethod_names = [m['name'] for m in user_class['methods']]\nself.assertGreater(len(method_names), 0)",
            "language": "Python",
            "description": "Workflow: Test ES6 class method extraction.\n\nNote: Regex-based parser has limitations in extracting all methods.\nThis test verifies basic method extraction works.",
            "expected_behavior": "self.assertGreater(len(method_names), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 253,
            "line_end": 286,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '",
            "description": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"",
            "description": "Assign code = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIn('classes', result)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "user_class = result['classes'][0]",
            "description": "Assign user_class = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(user_class['name'], 'User')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreaterEqual(len(user_class['methods']), 1)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "method_names = [m['name'] for m in user_class['methods']]",
            "description": "Assign method_names = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreater(len(method_names), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Javascript Class Methods",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:253"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Typescript Type Annotations": [
      {
        "guide_id": "7b6f05348140",
        "title": "Typescript Type Annotations",
        "overview": "Workflow: Test TypeScript type annotation extraction.\n\nNote: Current regex-based parser extracts parameter type hints\nbut NOT return types. Return type extraction requires a proper\nTypeScript parser (ts-morph or typescript library).",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "39ad407d",
            "test_name": "test_typescript_type_annotations",
            "category": "workflow",
            "code": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '\ncode = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'\nresult = self.analyzer.analyze_file('test.ts', code, 'TypeScript')\nself.assertIn('functions', result)\ncalc_func = result['functions'][0]\nself.assertEqual(calc_func['name'], 'calculate')\nself.assertEqual(calc_func['parameters'][0]['type_hint'], 'number')\nself.assertIsNone(calc_func['return_type'])\ncreate_func = result['functions'][1]\nself.assertEqual(create_func['name'], 'createUser')\nself.assertEqual(create_func['parameters'][1]['default'], '18')\nself.assertIsNone(create_func['return_type'])",
            "language": "Python",
            "description": "Workflow: Test TypeScript type annotation extraction.\n\nNote: Current regex-based parser extracts parameter type hints\nbut NOT return types. Return type extraction requires a proper\nTypeScript parser (ts-morph or typescript library).",
            "expected_behavior": "self.assertIsNone(create_func['return_type'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 288,
            "line_end": 325,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '",
            "description": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'",
            "description": "Assign code = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.ts', code, 'TypeScript')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIn('functions', result)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "calc_func = result['functions'][0]",
            "description": "Assign calc_func = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(calc_func['name'], 'calculate')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertEqual(calc_func['parameters'][0]['type_hint'], 'number')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIsNone(calc_func['return_type'])",
            "description": "Call self.assertIsNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "create_func = result['functions'][1]",
            "description": "Assign create_func = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertEqual(create_func['name'], 'createUser')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertEqual(create_func['parameters'][1]['default'], '18')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIsNone(create_func['return_type'])",
            "description": "Call self.assertIsNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Typescript Type Annotations",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_code_analyzer.py:288"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cpp Class Extraction": [
      {
        "guide_id": "2abe9e258c1d",
        "title": "Cpp Class Extraction",
        "overview": "Workflow: Test C++ class extraction with inheritance.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "3d148051",
            "test_name": "test_cpp_class_extraction",
            "category": "workflow",
            "code": "'Test C++ class extraction with inheritance.'\ncode = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'\nresult = self.analyzer.analyze_file('test.h', code, 'C++')\nself.assertIn('classes', result)\nself.assertEqual(len(result['classes']), 2)\nanimal_class = result['classes'][0]\nself.assertEqual(animal_class['name'], 'Animal')\ndog_class = result['classes'][1]\nself.assertEqual(dog_class['name'], 'Dog')\nself.assertIn('Animal', dog_class['base_classes'])",
            "language": "Python",
            "description": "Workflow: Test C++ class extraction with inheritance.",
            "expected_behavior": "self.assertIn('Animal', dog_class['base_classes'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 376,
            "line_end": 404,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test C++ class extraction with inheritance.'",
            "description": "'Test C++ class extraction with inheritance.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'",
            "description": "Assign code = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.h', code, 'C++')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIn('classes', result)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(len(result['classes']), 2)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "animal_class = result['classes'][0]",
            "description": "Assign animal_class = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertEqual(animal_class['name'], 'Animal')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "dog_class = result['classes'][1]",
            "description": "Assign dog_class = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertEqual(dog_class['name'], 'Dog')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertIn('Animal', dog_class['base_classes'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cpp Class Extraction",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:376"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Deep Depth Extracts Signatures": [
      {
        "guide_id": "276f9514e9e9",
        "title": "Deep Depth Extracts Signatures",
        "overview": "Workflow: Test that deep depth extracts full signatures.",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "fe9f26b5",
            "test_name": "test_deep_depth_extracts_signatures",
            "category": "workflow",
            "code": "'Test that deep depth extracts full signatures.'\nanalyzer = CodeAnalyzer(depth='deep')\ncode = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'\nresult = analyzer.analyze_file('test.py', code, 'Python')\nself.assertIn('functions', result)\nself.assertEqual(len(result['functions']), 1)\nfunc = result['functions'][0]\nself.assertEqual(func['name'], 'calculate')\nself.assertEqual(func['return_type'], 'int')",
            "language": "Python",
            "description": "Workflow: Test that deep depth extracts full signatures.",
            "expected_behavior": "self.assertEqual(func['return_type'], 'int')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 459,
            "line_end": 474,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test that deep depth extracts full signatures.'",
            "description": "'Test that deep depth extracts full signatures.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "analyzer = CodeAnalyzer(depth='deep')",
            "description": "Assign analyzer = CodeAnalyzer(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "code = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'",
            "description": "Assign code = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = analyzer.analyze_file('test.py', code, 'Python')",
            "description": "Assign result = analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertIn('functions', result)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertEqual(len(result['functions']), 1)",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "func = result['functions'][0]",
            "description": "Assign func = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(func['name'], 'calculate')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertEqual(func['return_type'], 'int')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Deep Depth Extracts Signatures",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:459"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Javascript Inline Comments": [
      {
        "guide_id": "f04cd8a6be30",
        "title": "Javascript Inline Comments",
        "overview": "Workflow: Test JavaScript // comment extraction.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5c7f9d11",
            "test_name": "test_javascript_inline_comments",
            "category": "workflow",
            "code": "'Test JavaScript // comment extraction.'\ncode = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\nself.assertIn('comments', result)\ncomments = result['comments']\nself.assertGreaterEqual(len(comments), 3)\ninline_comments = [c for c in comments if c['type'] == 'inline']\nself.assertGreaterEqual(len(inline_comments), 3)",
            "language": "Python",
            "description": "Workflow: Test JavaScript // comment extraction.",
            "expected_behavior": "self.assertGreaterEqual(len(inline_comments), 3)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 627,
            "line_end": 650,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test JavaScript // comment extraction.'",
            "description": "'Test JavaScript // comment extraction.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'",
            "description": "Assign code = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIn('comments', result)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "comments = result['comments']",
            "description": "Assign comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertGreaterEqual(len(comments), 3)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "inline_comments = [c for c in comments if c['type'] == 'inline']",
            "description": "Assign inline_comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertGreaterEqual(len(inline_comments), 3)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Javascript Inline Comments",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:627"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Javascript Block Comments": [
      {
        "guide_id": "32a8eb6a4a20",
        "title": "Javascript Block Comments",
        "overview": "Workflow: Test JavaScript /* */ block comment extraction.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "885c9e6b",
            "test_name": "test_javascript_block_comments",
            "category": "workflow",
            "code": "'Test JavaScript /* */ block comment extraction.'\ncode = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\ncomments = result['comments']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(block_comments), 2)\nfirst_block = next((c for c in comments if 'multi-line' in c['text']))\nself.assertIn('multi-line', first_block['text'])",
            "language": "Python",
            "description": "Workflow: Test JavaScript /* */ block comment extraction.",
            "expected_behavior": "self.assertIn('multi-line', first_block['text'])",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 652,
            "line_end": 673,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test JavaScript /* */ block comment extraction.'",
            "description": "'Test JavaScript /* */ block comment extraction.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'",
            "description": "Assign code = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "comments = result['comments']",
            "description": "Assign comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "block_comments = [c for c in comments if c['type'] == 'block']",
            "description": "Assign block_comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertGreaterEqual(len(block_comments), 2)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "first_block = next((c for c in comments if 'multi-line' in c['text']))",
            "description": "Assign first_block = next(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('multi-line', first_block['text'])",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Javascript Block Comments",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:652"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Javascript Mixed Comments": [
      {
        "guide_id": "5e8fd494ddbd",
        "title": "Javascript Mixed Comments",
        "overview": "Workflow: Test JavaScript mixed inline and block comments.",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "86bdbb68",
            "test_name": "test_javascript_mixed_comments",
            "category": "workflow",
            "code": "'Test JavaScript mixed inline and block comments.'\ncode = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\ncomments = result['comments']\ninline_comments = [c for c in comments if c['type'] == 'inline']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(inline_comments), 2)\nself.assertGreaterEqual(len(block_comments), 2)",
            "language": "Python",
            "description": "Workflow: Test JavaScript mixed inline and block comments.",
            "expected_behavior": "self.assertGreaterEqual(len(block_comments), 2)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 675,
            "line_end": 695,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test JavaScript mixed inline and block comments.'",
            "description": "'Test JavaScript mixed inline and block comments.'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'",
            "description": "Assign code = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "comments = result['comments']",
            "description": "Assign comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "inline_comments = [c for c in comments if c['type'] == 'inline']",
            "description": "Assign inline_comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "block_comments = [c for c in comments if c['type'] == 'block']",
            "description": "Assign block_comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreaterEqual(len(inline_comments), 2)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertGreaterEqual(len(block_comments), 2)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Javascript Mixed Comments",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:675"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Cpp Comment Extraction": [
      {
        "guide_id": "fffb839997c1",
        "title": "Cpp Comment Extraction",
        "overview": "Workflow: Test C++ comment extraction (uses same logic as JavaScript).",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "sys",
          "unittest",
          "skill_seekers.cli.code_analyzer"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2e6f1fe6",
            "test_name": "test_cpp_comment_extraction",
            "category": "workflow",
            "code": "'Test C++ comment extraction (uses same logic as JavaScript).'\ncode = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'\nresult = self.analyzer.analyze_file('test.h', code, 'C++')\nself.assertIn('comments', result)\ncomments = result['comments']\nself.assertGreaterEqual(len(comments), 3)\ninline_comments = [c for c in comments if c['type'] == 'inline']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(inline_comments), 2)\nself.assertGreaterEqual(len(block_comments), 1)",
            "language": "Python",
            "description": "Workflow: Test C++ comment extraction (uses same logic as JavaScript).",
            "expected_behavior": "self.assertGreaterEqual(len(block_comments), 1)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
            "line_start": 697,
            "line_end": 723,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "sys",
              "unittest",
              "skill_seekers.cli.code_analyzer"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test C++ comment extraction (uses same logic as JavaScript).'",
            "description": "'Test C++ comment extraction (uses same logic as JavaScript).'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'",
            "description": "Assign code = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "result = self.analyzer.analyze_file('test.h', code, 'C++')",
            "description": "Assign result = self.analyzer.analyze_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertIn('comments', result)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "comments = result['comments']",
            "description": "Assign comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertGreaterEqual(len(comments), 3)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "inline_comments = [c for c in comments if c['type'] == 'inline']",
            "description": "Assign inline_comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "block_comments = [c for c in comments if c['type'] == 'block']",
            "description": "Assign block_comments = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreaterEqual(len(inline_comments), 2)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertGreaterEqual(len(block_comments), 1)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Cpp Comment Extraction",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_code_analyzer.py:697"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Instantiation": [
      {
        "guide_id": "25c59001e10d",
        "title": "Extract Instantiation",
        "overview": "Workflow: Test extraction of object instantiation patterns",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "a7e11ae3",
            "test_name": "test_extract_instantiation",
            "category": "workflow",
            "code": "'Test extraction of object instantiation patterns'\ncode = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'\nexamples = self.analyzer.extract('test_db.py', code)\ninstantiations = [ex for ex in examples if ex.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\ninst = instantiations[0]\nself.assertIn('Database', inst.code)\nself.assertIn('host', inst.code)\nself.assertGreaterEqual(inst.confidence, 0.7)",
            "language": "Python",
            "description": "Workflow: Test extraction of object instantiation patterns",
            "expected_behavior": "self.assertGreaterEqual(inst.confidence, 0.7)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 40,
            "line_end": 60,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test extraction of object instantiation patterns'",
            "description": "'Test extraction of object instantiation patterns'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'",
            "description": "Assign code = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "examples = self.analyzer.extract('test_db.py', code)",
            "description": "Assign examples = self.analyzer.extract(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "instantiations = [ex for ex in examples if ex.category == 'instantiation']",
            "description": "Assign instantiations = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertGreater(len(instantiations), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "inst = instantiations[0]",
            "description": "Assign inst = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('Database', inst.code)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('host', inst.code)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreaterEqual(inst.confidence, 0.7)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Instantiation",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:40"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Method Call With Assertion": [
      {
        "guide_id": "613b8ce15119",
        "title": "Extract Method Call With Assertion",
        "overview": "Workflow: Test extraction of method calls followed by assertions",
        "complexity_level": "advanced",
        "prerequisites": [],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "04c960f6",
            "test_name": "test_extract_method_call_with_assertion",
            "category": "workflow",
            "code": "'Test extraction of method calls followed by assertions'\ncode = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'\nexamples = self.analyzer.extract('test_api.py', code)\nself.assertGreater(len(examples), 0)\nmethod_calls = [ex for ex in examples if ex.category == 'method_call']\nif method_calls:\n    call = method_calls[0]\n    self.assertIn('get', call.code)\n    self.assertGreaterEqual(call.confidence, 0.7)",
            "language": "Python",
            "description": "Workflow: Test extraction of method calls followed by assertions",
            "expected_behavior": "self.assertGreater(len(examples), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 62,
            "line_end": 83,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test extraction of method calls followed by assertions'",
            "description": "'Test extraction of method calls followed by assertions'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'",
            "description": "Assign code = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "examples = self.analyzer.extract('test_api.py', code)",
            "description": "Assign examples = self.analyzer.extract(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertGreater(len(examples), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "method_calls = [ex for ex in examples if ex.category == 'method_call']",
            "description": "Assign method_calls = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "call = method_calls[0]",
            "description": "Assign call = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('get', call.code)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertGreaterEqual(call.confidence, 0.7)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Method Call With Assertion",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:62"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Config Dict": [
      {
        "guide_id": "060ad49799fb",
        "title": "Extract Config Dict",
        "overview": "Workflow: Test extraction of configuration dictionaries",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2107235c",
            "test_name": "test_extract_config_dict",
            "category": "workflow",
            "code": "'Test extraction of configuration dictionaries'\ncode = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'\nexamples = self.analyzer.extract('test_config.py', code)\nconfigs = [ex for ex in examples if ex.category == 'config']\nself.assertGreater(len(configs), 0)\nconfig = configs[0]\nself.assertIn('debug', config.code)\nself.assertIn('database_url', config.code)\nself.assertGreaterEqual(config.confidence, 0.7)",
            "language": "Python",
            "description": "Workflow: Test extraction of configuration dictionaries",
            "expected_behavior": "self.assertGreaterEqual(config.confidence, 0.7)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 85,
            "line_end": 108,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "self.analyzer = PythonTestAnalyzer()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test extraction of configuration dictionaries'",
            "description": "'Test extraction of configuration dictionaries'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'",
            "description": "Assign code = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "examples = self.analyzer.extract('test_config.py', code)",
            "description": "Assign examples = self.analyzer.extract(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "configs = [ex for ex in examples if ex.category == 'config']",
            "description": "Assign configs = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertGreater(len(configs), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "config = configs[0]",
            "description": "Assign config = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn('debug', config.code)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIn('database_url', config.code)",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreaterEqual(config.confidence, 0.7)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Config Dict",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:85"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Confidence Scoring": [
      {
        "guide_id": "646a64f2ec7e",
        "title": "Confidence Scoring",
        "overview": "Workflow: Test confidence scores are calculated correctly",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "2bc519d6",
            "test_name": "test_confidence_scoring",
            "category": "workflow",
            "code": "'Test confidence scores are calculated correctly'\nsimple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'\nsimple_examples = self.analyzer.extract('test_simple.py', simple_code)\ncomplex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'\ncomplex_examples = self.analyzer.extract('test_complex.py', complex_code)\nif simple_examples and complex_examples:\n    simple_complexity = max((ex.complexity_score for ex in simple_examples))\n    complex_complexity = max((ex.complexity_score for ex in complex_examples))\n    self.assertGreater(complex_complexity, simple_complexity)",
            "language": "Python",
            "description": "Workflow: Test confidence scores are calculated correctly",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 209,
            "line_end": 238,
            "complexity_score": 0.6,
            "confidence": 0.9,
            "setup_code": "self.analyzer = PythonTestAnalyzer()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test confidence scores are calculated correctly'",
            "description": "'Test confidence scores are calculated correctly'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "simple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'",
            "description": "Assign simple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "simple_examples = self.analyzer.extract('test_simple.py', simple_code)",
            "description": "Assign simple_examples = self.analyzer.extract(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "complex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'",
            "description": "Assign complex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "complex_examples = self.analyzer.extract('test_complex.py', complex_code)",
            "description": "Assign complex_examples = self.analyzer.extract(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "simple_complexity = max((ex.complexity_score for ex in simple_examples))",
            "description": "Assign simple_complexity = max(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "complex_complexity = max((ex.complexity_score for ex in complex_examples))",
            "description": "Assign complex_complexity = max(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertGreater(complex_complexity, simple_complexity)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Confidence Scoring",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:209"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Extract Gdscript Gut Tests": [
      {
        "guide_id": "10a9afe7c2e6",
        "title": "Extract Gdscript Gut Tests",
        "overview": "Workflow: Test GDScript GUT/gdUnit4 test extraction",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "3017fb5b",
            "test_name": "test_extract_gdscript_gut_tests",
            "category": "workflow",
            "code": "'Test GDScript GUT/gdUnit4 test extraction'\ncode = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'\nexamples = self.analyzer.extract('test_game.gd', code, 'GDScript')\nself.assertGreater(len(examples), 0)\nself.assertEqual(examples[0].language, 'GDScript')\ninstantiations = [e for e in examples if e.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\nhas_preload = any(('preload' in e.code or 'load' in e.code for e in instantiations))\nself.assertTrue(has_preload or len(instantiations) > 0)",
            "language": "Python",
            "description": "Workflow: Test GDScript GUT/gdUnit4 test extraction",
            "expected_behavior": "self.assertTrue(has_preload or len(instantiations) > 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 386,
            "line_end": 443,
            "complexity_score": 0.9,
            "confidence": 0.9,
            "setup_code": "self.analyzer = GenericTestAnalyzer()",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test GDScript GUT/gdUnit4 test extraction'",
            "description": "'Test GDScript GUT/gdUnit4 test extraction'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "code = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'",
            "description": "Assign code = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "examples = self.analyzer.extract('test_game.gd', code, 'GDScript')",
            "description": "Assign examples = self.analyzer.extract(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "self.assertGreater(len(examples), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "self.assertEqual(examples[0].language, 'GDScript')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "instantiations = [e for e in examples if e.category == 'instantiation']",
            "description": "Assign instantiations = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertGreater(len(instantiations), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "has_preload = any(('preload' in e.code or 'load' in e.code for e in instantiations))",
            "description": "Assign has_preload = any(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertTrue(has_preload or len(instantiations) > 0)",
            "description": "Call self.assertTrue()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Extract Gdscript Gut Tests",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:386"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Language Filtering": [
      {
        "guide_id": "7625a7957c13",
        "title": "Language Filtering",
        "overview": "Workflow: Test filtering by programming language",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "8286b6de",
            "test_name": "test_language_filtering",
            "category": "workflow",
            "code": "'Test filtering by programming language'\npy_file = self.temp_dir / 'test_py.py'\npy_file.write_text('\\ndef test_python():\\n    obj = MyClass(param=\"value\")\\n    assert obj is not None\\n')\njs_file = self.temp_dir / 'test_js.js'\njs_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')\npython_extractor = TestExampleExtractor(languages=['python'])\nreport = python_extractor.extract_from_directory(self.temp_dir)\nfor example in report.examples:\n    self.assertEqual(example.language, 'Python')",
            "language": "Python",
            "description": "Workflow: Test filtering by programming language",
            "expected_behavior": "js_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 622,
            "line_end": 647,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test filtering by programming language'",
            "description": "'Test filtering by programming language'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "py_file = self.temp_dir / 'test_py.py'",
            "description": "Assign py_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "py_file.write_text('\\ndef test_python():\\n    obj = MyClass(param=\"value\")\\n    assert obj is not None\\n')",
            "description": "Call py_file.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "js_file = self.temp_dir / 'test_js.js'",
            "description": "Assign js_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "js_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')",
            "description": "Call js_file.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "python_extractor = TestExampleExtractor(languages=['python'])",
            "description": "Assign python_extractor = TestExampleExtractor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "report = python_extractor.extract_from_directory(self.temp_dir)",
            "description": "Assign report = python_extractor.extract_from_directory(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertEqual(example.language, 'Python')",
            "description": "Call self.assertEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Language Filtering",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:622"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Max Examples Limit": [
      {
        "guide_id": "44881a0fe949",
        "title": "Max Examples Limit",
        "overview": "Workflow: Test max examples per file limit",
        "complexity_level": "intermediate",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9784e155",
            "test_name": "test_max_examples_limit",
            "category": "workflow",
            "code": "'Test max examples per file limit'\ntest_file = self.temp_dir / 'test_many.py'\ntest_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'\nfor i in range(20):\n    test_code += f'\\n    def test_example_{i}(self):\\n        \"\"\"Test {i}\"\"\"\\n        obj = MyClass(id={i}, name=\"test_{i}\")\\n        self.assertIsNotNone(obj)\\n'\ntest_file.write_text(test_code)\nlimited_extractor = TestExampleExtractor(max_per_file=5)\nexamples = limited_extractor.extract_from_file(test_file)\nself.assertLessEqual(len(examples), 5)",
            "language": "Python",
            "description": "Workflow: Test max examples per file limit",
            "expected_behavior": "self.assertLessEqual(len(examples), 5)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 649,
            "line_end": 668,
            "complexity_score": 0.8,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test max examples per file limit'",
            "description": "'Test max examples per file limit'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "test_file = self.temp_dir / 'test_many.py'",
            "description": "Assign test_file = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "test_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'",
            "description": "Assign test_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "test_file.write_text(test_code)",
            "description": "Call test_file.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "limited_extractor = TestExampleExtractor(max_per_file=5)",
            "description": "Assign limited_extractor = TestExampleExtractor(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "examples = limited_extractor.extract_from_file(test_file)",
            "description": "Assign examples = limited_extractor.extract_from_file(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertLessEqual(len(examples), 5)",
            "description": "Call self.assertLessEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Max Examples Limit",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_test_example_extractor.py:649"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "End To End Workflow": [
      {
        "guide_id": "2494640e0a93",
        "title": "End To End Workflow",
        "overview": "Workflow: Test complete extraction workflow",
        "complexity_level": "advanced",
        "prerequisites": [
          "Setup code must be executed first"
        ],
        "required_imports": [
          "os",
          "shutil",
          "sys",
          "tempfile",
          "unittest",
          "pathlib",
          "skill_seekers.cli.test_example_extractor"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "5e3da05f",
            "test_name": "test_end_to_end_workflow",
            "category": "workflow",
            "code": "'Test complete extraction workflow'\n(self.temp_dir / 'tests').mkdir()\n(self.temp_dir / 'tests' / 'test_unit.py').write_text('\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test API connection\"\"\"\\n        api = APIClient(url=\"https://api.example.com\", timeout=30)\\n        self.assertTrue(api.connect())\\n')\n(self.temp_dir / 'tests' / 'test_integration.py').write_text('\\ndef test_workflow():\\n    \"\"\"Test complete workflow\"\"\"\\n    user = User(name=\"John\", email=\"john@example.com\")\\n    user.save()\\n    user.verify()\\n    assert user.is_active\\n')\nreport = self.extractor.extract_from_directory(self.temp_dir / 'tests')\nself.assertGreater(report.total_examples, 0)\nself.assertIsInstance(report.examples_by_category, dict)\nself.assertIsInstance(report.examples_by_language, dict)\nself.assertGreaterEqual(report.avg_complexity, 0.0)\nself.assertLessEqual(report.avg_complexity, 1.0)\nself.assertGreater(len(report.examples_by_category), 0)\nfor example in report.examples:\n    self.assertIsNotNone(example.example_id)\n    self.assertIsNotNone(example.test_name)\n    self.assertIsNotNone(example.category)\n    self.assertIsNotNone(example.code)\n    self.assertIsNotNone(example.language)\n    self.assertGreaterEqual(example.confidence, 0.0)\n    self.assertLessEqual(example.confidence, 1.0)",
            "language": "Python",
            "description": "Workflow: Test complete extraction workflow",
            "expected_behavior": "self.assertGreater(len(report.examples_by_category), 0)",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
            "line_start": 670,
            "line_end": 717,
            "complexity_score": 1.0,
            "confidence": 0.9,
            "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "os",
              "shutil",
              "sys",
              "tempfile",
              "unittest",
              "pathlib",
              "skill_seekers.cli.test_example_extractor"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'Test complete extraction workflow'",
            "description": "'Test complete extraction workflow'",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "(self.temp_dir / 'tests').mkdir()",
            "description": "Call unknown.mkdir()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "(self.temp_dir / 'tests' / 'test_unit.py').write_text('\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test API connection\"\"\"\\n        api = APIClient(url=\"https://api.example.com\", timeout=30)\\n        self.assertTrue(api.connect())\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "(self.temp_dir / 'tests' / 'test_integration.py').write_text('\\ndef test_workflow():\\n    \"\"\"Test complete workflow\"\"\"\\n    user = User(name=\"John\", email=\"john@example.com\")\\n    user.save()\\n    user.verify()\\n    assert user.is_active\\n')",
            "description": "Call unknown.write_text()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "report = self.extractor.extract_from_directory(self.temp_dir / 'tests')",
            "description": "Assign report = self.extractor.extract_from_directory(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertGreater(report.total_examples, 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIsInstance(report.examples_by_category, dict)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 8,
            "code": "self.assertIsInstance(report.examples_by_language, dict)",
            "description": "Call self.assertIsInstance()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 9,
            "code": "self.assertGreaterEqual(report.avg_complexity, 0.0)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 10,
            "code": "self.assertLessEqual(report.avg_complexity, 1.0)",
            "description": "Call self.assertLessEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 11,
            "code": "self.assertGreater(len(report.examples_by_category), 0)",
            "description": "Call self.assertGreater()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 12,
            "code": "self.assertIsNotNone(example.example_id)",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 13,
            "code": "self.assertIsNotNone(example.test_name)",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 14,
            "code": "self.assertIsNotNone(example.category)",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 15,
            "code": "self.assertIsNotNone(example.code)",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 16,
            "code": "self.assertIsNotNone(example.language)",
            "description": "Call self.assertIsNotNone()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 17,
            "code": "self.assertGreaterEqual(example.confidence, 0.0)",
            "description": "Call self.assertGreaterEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 18,
            "code": "self.assertLessEqual(example.confidence, 1.0)",
            "description": "Call self.assertLessEqual()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "End To End Workflow",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "20 minutes",
        "source_files": [
          "test_test_example_extractor.py:670"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ],
    "Issue 277 Error Message Urls": [
      {
        "guide_id": "011f77eaa181",
        "title": "Issue 277 Error Message Urls",
        "overview": "Workflow: Test the exact URLs that appeared in error messages from the issue report.\nThese were the actual 404-causing URLs that need to be fixed.",
        "complexity_level": "intermediate",
        "prerequisites": [],
        "required_imports": [
          "unittest",
          "unittest.mock",
          "skill_seekers.cli.doc_scraper"
        ],
        "required_fixtures": [],
        "workflows": [
          {
            "example_id": "9bb44f09",
            "test_name": "test_issue_277_error_message_urls",
            "category": "workflow",
            "code": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '\nerror_urls_with_anchors = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization/index.html.md', 'https://mikro-orm.io/docs/defining-entities#formulas/index.html.md', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums/index.html.md']\ninput_urls = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization', 'https://mikro-orm.io/docs/propagation', 'https://mikro-orm.io/docs/defining-entities#formulas', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums']\nresult = self.converter._convert_to_md_urls(input_urls)\nfor error_url in error_urls_with_anchors:\n    self.assertNotIn(error_url, result, f'Should not generate the 404-causing URL: {error_url}')\ncorrect_urls = ['https://mikro-orm.io/docs/quick-start/index.html.md', 'https://mikro-orm.io/docs/propagation/index.html.md', 'https://mikro-orm.io/docs/defining-entities/index.html.md']\nfor correct_url in correct_urls:\n    self.assertIn(correct_url, result, f'Should generate the correct URL: {correct_url}')",
            "language": "Python",
            "description": "Workflow: Test the exact URLs that appeared in error messages from the issue report.\nThese were the actual 404-causing URLs that need to be fixed.",
            "expected_behavior": "",
            "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
            "line_start": 213,
            "line_end": 255,
            "complexity_score": 0.7,
            "confidence": 0.9,
            "setup_code": null,
            "tags": [
              "unittest",
              "workflow",
              "integration"
            ],
            "dependencies": [
              "unittest",
              "unittest.mock",
              "skill_seekers.cli.doc_scraper"
            ],
            "ai_analysis": null
          }
        ],
        "steps": [
          {
            "step_number": 1,
            "code": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '",
            "description": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 2,
            "code": "error_urls_with_anchors = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization/index.html.md', 'https://mikro-orm.io/docs/defining-entities#formulas/index.html.md', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums/index.html.md']",
            "description": "Assign error_urls_with_anchors = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 3,
            "code": "input_urls = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization', 'https://mikro-orm.io/docs/propagation', 'https://mikro-orm.io/docs/defining-entities#formulas', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums']",
            "description": "Assign input_urls = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 4,
            "code": "result = self.converter._convert_to_md_urls(input_urls)",
            "description": "Assign result = self.converter._convert_to_md_urls(...)",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 5,
            "code": "correct_urls = ['https://mikro-orm.io/docs/quick-start/index.html.md', 'https://mikro-orm.io/docs/propagation/index.html.md', 'https://mikro-orm.io/docs/defining-entities/index.html.md']",
            "description": "Assign correct_urls = value",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 6,
            "code": "self.assertNotIn(error_url, result, f'Should not generate the 404-causing URL: {error_url}')",
            "description": "Call self.assertNotIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          },
          {
            "step_number": 7,
            "code": "self.assertIn(correct_url, result, f'Should generate the correct URL: {correct_url}')",
            "description": "Call self.assertIn()",
            "expected_result": null,
            "verification": null,
            "setup_required": null,
            "explanation": null,
            "common_pitfall": null,
            "common_variations": []
          }
        ],
        "use_case": "Issue 277 Error Message Urls",
        "tags": [
          "unittest",
          "workflow",
          "integration"
        ],
        "estimated_time": "15 minutes",
        "source_files": [
          "test_issue_277_real_world.py:213"
        ],
        "common_pitfalls": [],
        "troubleshooting": {},
        "variations": [],
        "related_guides": [],
        "prerequisites_detailed": [],
        "troubleshooting_detailed": [],
        "next_steps_detailed": [],
        "use_cases": []
      }
    ]
  },
  "guides": [
    {
      "guide_id": "35455dea07d1",
      "title": "Chain Dependencies",
      "overview": "Workflow: Test chain of dependencies.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ae8eb210",
          "test_name": "test_chain_dependencies",
          "category": "workflow",
          "code": "'Test chain of dependencies.'\nself.analyzer.analyze_file('main.py', 'import utils', 'Python')\nself.analyzer.analyze_file('utils.py', 'import helpers', 'Python')\nself.analyzer.analyze_file('helpers.py', '', 'Python')\ngraph = self.analyzer.build_graph()\nself.assertEqual(graph.number_of_nodes(), 3)",
          "language": "Python",
          "description": "Workflow: Test chain of dependencies.",
          "expected_behavior": "self.assertEqual(graph.number_of_nodes(), 3)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
          "line_start": 208,
          "line_end": 217,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.dependency_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test chain of dependencies.'",
          "description": "'Test chain of dependencies.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "self.analyzer.analyze_file('main.py', 'import utils', 'Python')",
          "description": "Call self.analyzer.analyze_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "self.analyzer.analyze_file('utils.py', 'import helpers', 'Python')",
          "description": "Call self.analyzer.analyze_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.analyzer.analyze_file('helpers.py', '', 'Python')",
          "description": "Call self.analyzer.analyze_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "graph = self.analyzer.build_graph()",
          "description": "Assign graph = self.analyzer.build_graph(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(graph.number_of_nodes(), 3)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chain Dependencies",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_dependency_analyzer.py:208"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3be0db480f23",
      "title": "Scrape Parser Creates Subparser",
      "overview": "Workflow: Test that ScrapeParser creates valid subparser.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e01a676e",
          "test_name": "test_scrape_parser_creates_subparser",
          "category": "workflow",
          "code": "'Test that ScrapeParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\nscrape_parser = ScrapeParser()\nsubparser = scrape_parser.create_parser(subparsers)\nassert subparser is not None\nassert scrape_parser.name == 'scrape'\nassert scrape_parser.help == 'Scrape documentation website'",
          "language": "Python",
          "description": "Workflow: Test that ScrapeParser creates valid subparser.",
          "expected_behavior": "assert scrape_parser.help == 'Scrape documentation website'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 72,
          "line_end": 82,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that ScrapeParser creates valid subparser.'",
          "description": "'Test that ScrapeParser creates valid subparser.'",
          "expected_result": null,
          "verification": "assert subparser is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert scrape_parser.name == 'scrape'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers()",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": "assert scrape_parser.help == 'Scrape documentation website'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "scrape_parser = ScrapeParser()",
          "description": "Assign scrape_parser = ScrapeParser(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "subparser = scrape_parser.create_parser(subparsers)",
          "description": "Assign subparser = scrape_parser.create_parser(...)",
          "expected_result": null,
          "verification": "assert subparser is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scrape Parser Creates Subparser",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_cli_parsers.py:72"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "41ef2cbefcb5",
      "title": "Github Parser Creates Subparser",
      "overview": "Workflow: Test that GitHubParser creates valid subparser.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "04c400c9",
          "test_name": "test_github_parser_creates_subparser",
          "category": "workflow",
          "code": "'Test that GitHubParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\ngithub_parser = GitHubParser()\nsubparser = github_parser.create_parser(subparsers)\nassert subparser is not None\nassert github_parser.name == 'github'",
          "language": "Python",
          "description": "Workflow: Test that GitHubParser creates valid subparser.",
          "expected_behavior": "assert github_parser.name == 'github'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 84,
          "line_end": 93,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that GitHubParser creates valid subparser.'",
          "description": "'Test that GitHubParser creates valid subparser.'",
          "expected_result": null,
          "verification": "assert subparser is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert github_parser.name == 'github'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers()",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "github_parser = GitHubParser()",
          "description": "Assign github_parser = GitHubParser(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "subparser = github_parser.create_parser(subparsers)",
          "description": "Assign subparser = github_parser.create_parser(...)",
          "expected_result": null,
          "verification": "assert subparser is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Github Parser Creates Subparser",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_cli_parsers.py:84"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5828ca734e15",
      "title": "Package Parser Creates Subparser",
      "overview": "Workflow: Test that PackageParser creates valid subparser.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4a3afacf",
          "test_name": "test_package_parser_creates_subparser",
          "category": "workflow",
          "code": "'Test that PackageParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\npackage_parser = PackageParser()\nsubparser = package_parser.create_parser(subparsers)\nassert subparser is not None\nassert package_parser.name == 'package'",
          "language": "Python",
          "description": "Workflow: Test that PackageParser creates valid subparser.",
          "expected_behavior": "assert package_parser.name == 'package'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 95,
          "line_end": 104,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that PackageParser creates valid subparser.'",
          "description": "'Test that PackageParser creates valid subparser.'",
          "expected_result": null,
          "verification": "assert subparser is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert package_parser.name == 'package'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers()",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_parser = PackageParser()",
          "description": "Assign package_parser = PackageParser(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "subparser = package_parser.create_parser(subparsers)",
          "description": "Assign subparser = package_parser.create_parser(...)",
          "expected_result": null,
          "verification": "assert subparser is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Package Parser Creates Subparser",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_cli_parsers.py:95"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d35258a3778e",
      "title": "Register Parsers Creates All Subcommands",
      "overview": "Workflow: Test that register_parsers creates all 19 subcommands.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "1d07962e",
          "test_name": "test_register_parsers_creates_all_subcommands",
          "category": "workflow",
          "code": "'Test that register_parsers creates all 19 subcommands.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nregister_parsers(subparsers)\ntest_commands = ['config --show', 'scrape --config test.json', 'github --repo owner/repo', 'package output/test/', 'upload test.zip', 'analyze --directory .', 'enhance output/test/', 'estimate test.json']\nfor cmd in test_commands:\n    args = main_parser.parse_args(cmd.split())\n    assert args.command is not None",
          "language": "Python",
          "description": "Workflow: Test that register_parsers creates all 19 subcommands.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 106,
          "line_end": 128,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that register_parsers creates all 19 subcommands.'",
          "description": "'Test that register_parsers creates all 19 subcommands.'",
          "expected_result": null,
          "verification": "assert args.command is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers(dest='command')",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "register_parsers(subparsers)",
          "description": "Call register_parsers()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "test_commands = ['config --show', 'scrape --config test.json', 'github --repo owner/repo', 'package output/test/', 'upload test.zip', 'analyze --directory .', 'enhance output/test/', 'estimate test.json']",
          "description": "Assign test_commands = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "args = main_parser.parse_args(cmd.split())",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.command is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Register Parsers Creates All Subcommands",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_cli_parsers.py:106"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4f1b5f83ed73",
      "title": "Scrape Parser Arguments",
      "overview": "Workflow: Test ScrapeParser has correct arguments.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9ab8ad64",
          "test_name": "test_scrape_parser_arguments",
          "category": "workflow",
          "code": "'Test ScrapeParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nscrape_parser = ScrapeParser()\nscrape_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['scrape', '--config', 'test.json'])\nassert args.command == 'scrape'\nassert args.config == 'test.json'\nargs = main_parser.parse_args(['scrape', '--config', 'test.json', '--max-pages', '100'])\nassert args.max_pages == 100\nargs = main_parser.parse_args(['scrape', '--enhance'])\nassert args.enhance is True",
          "language": "Python",
          "description": "Workflow: Test ScrapeParser has correct arguments.",
          "expected_behavior": "assert args.enhance is True",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 134,
          "line_end": 151,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test ScrapeParser has correct arguments.'",
          "description": "'Test ScrapeParser has correct arguments.'",
          "expected_result": null,
          "verification": "assert args.command == 'scrape'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert args.config == 'test.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers(dest='command')",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": "assert args.max_pages == 100",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "scrape_parser = ScrapeParser()",
          "description": "Assign scrape_parser = ScrapeParser(...)",
          "expected_result": null,
          "verification": "assert args.enhance is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "scrape_parser.create_parser(subparsers)",
          "description": "Call scrape_parser.create_parser()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "args = main_parser.parse_args(['scrape', '--config', 'test.json'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.command == 'scrape'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "args = main_parser.parse_args(['scrape', '--config', 'test.json', '--max-pages', '100'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.max_pages == 100",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "args = main_parser.parse_args(['scrape', '--enhance'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.enhance is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scrape Parser Arguments",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_cli_parsers.py:134"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ec8bec88404b",
      "title": "Github Parser Arguments",
      "overview": "Workflow: Test GitHubParser has correct arguments.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ee30eed2",
          "test_name": "test_github_parser_arguments",
          "category": "workflow",
          "code": "'Test GitHubParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\ngithub_parser = GitHubParser()\ngithub_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['github', '--repo', 'owner/repo'])\nassert args.command == 'github'\nassert args.repo == 'owner/repo'\nargs = main_parser.parse_args(['github', '--repo', 'owner/repo', '--non-interactive'])\nassert args.non_interactive is True",
          "language": "Python",
          "description": "Workflow: Test GitHubParser has correct arguments.",
          "expected_behavior": "assert args.non_interactive is True",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 153,
          "line_end": 166,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test GitHubParser has correct arguments.'",
          "description": "'Test GitHubParser has correct arguments.'",
          "expected_result": null,
          "verification": "assert args.command == 'github'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert args.repo == 'owner/repo'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers(dest='command')",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": "assert args.non_interactive is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "github_parser = GitHubParser()",
          "description": "Assign github_parser = GitHubParser(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "github_parser.create_parser(subparsers)",
          "description": "Call github_parser.create_parser()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "args = main_parser.parse_args(['github', '--repo', 'owner/repo'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.command == 'github'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "args = main_parser.parse_args(['github', '--repo', 'owner/repo', '--non-interactive'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.non_interactive is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Github Parser Arguments",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_cli_parsers.py:153"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a8bd303ec0a3",
      "title": "Package Parser Arguments",
      "overview": "Workflow: Test PackageParser has correct arguments.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "485bdd9c",
          "test_name": "test_package_parser_arguments",
          "category": "workflow",
          "code": "'Test PackageParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\npackage_parser = PackageParser()\npackage_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['package', 'output/test/'])\nassert args.command == 'package'\nassert args.skill_directory == 'output/test/'\nargs = main_parser.parse_args(['package', 'output/test/', '--target', 'gemini'])\nassert args.target == 'gemini'\nargs = main_parser.parse_args(['package', 'output/test/', '--no-open'])\nassert args.no_open is True",
          "language": "Python",
          "description": "Workflow: Test PackageParser has correct arguments.",
          "expected_behavior": "assert args.no_open is True",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 168,
          "line_end": 184,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test PackageParser has correct arguments.'",
          "description": "'Test PackageParser has correct arguments.'",
          "expected_result": null,
          "verification": "assert args.command == 'package'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert args.skill_directory == 'output/test/'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers(dest='command')",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": "assert args.target == 'gemini'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_parser = PackageParser()",
          "description": "Assign package_parser = PackageParser(...)",
          "expected_result": null,
          "verification": "assert args.no_open is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "package_parser.create_parser(subparsers)",
          "description": "Call package_parser.create_parser()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "args = main_parser.parse_args(['package', 'output/test/'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.command == 'package'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "args = main_parser.parse_args(['package', 'output/test/', '--target', 'gemini'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.target == 'gemini'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "args = main_parser.parse_args(['package', 'output/test/', '--no-open'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.no_open is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Package Parser Arguments",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_cli_parsers.py:168"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5c714bd9ad6e",
      "title": "Analyze Parser Arguments",
      "overview": "Workflow: Test AnalyzeParser has correct arguments.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c475f8f2",
          "test_name": "test_analyze_parser_arguments",
          "category": "workflow",
          "code": "'Test AnalyzeParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nfrom skill_seekers.cli.parsers.analyze_parser import AnalyzeParser\nanalyze_parser = AnalyzeParser()\nanalyze_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['analyze', '--directory', '.'])\nassert args.command == 'analyze'\nassert args.directory == '.'\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--quick'])\nassert args.quick is True\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nassert args.comprehensive is True\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--skip-patterns'])\nassert args.skip_patterns is True",
          "language": "Python",
          "description": "Workflow: Test AnalyzeParser has correct arguments.",
          "expected_behavior": "assert args.skip_patterns is True",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
          "line_start": 186,
          "line_end": 207,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "argparse",
            "pytest",
            "skill_seekers.cli.parsers",
            "skill_seekers.cli.parsers.scrape_parser",
            "skill_seekers.cli.parsers.github_parser",
            "skill_seekers.cli.parsers.package_parser",
            "skill_seekers.cli.parsers.analyze_parser"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test AnalyzeParser has correct arguments.'",
          "description": "'Test AnalyzeParser has correct arguments.'",
          "expected_result": null,
          "verification": "assert args.command == 'analyze'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "main_parser = argparse.ArgumentParser()",
          "description": "Assign main_parser = argparse.ArgumentParser(...)",
          "expected_result": null,
          "verification": "assert args.directory == '.'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "subparsers = main_parser.add_subparsers(dest='command')",
          "description": "Assign subparsers = main_parser.add_subparsers(...)",
          "expected_result": null,
          "verification": "assert args.quick is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "analyze_parser = AnalyzeParser()",
          "description": "Assign analyze_parser = AnalyzeParser(...)",
          "expected_result": null,
          "verification": "assert args.comprehensive is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "analyze_parser.create_parser(subparsers)",
          "description": "Call analyze_parser.create_parser()",
          "expected_result": null,
          "verification": "assert args.skip_patterns is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "args = main_parser.parse_args(['analyze', '--directory', '.'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.command == 'analyze'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "args = main_parser.parse_args(['analyze', '--directory', '.', '--quick'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.quick is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "args = main_parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.comprehensive is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "args = main_parser.parse_args(['analyze', '--directory', '.', '--skip-patterns'])",
          "description": "Assign args = main_parser.parse_args(...)",
          "expected_result": null,
          "verification": "assert args.skip_patterns is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Analyze Parser Arguments",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_cli_parsers.py:186"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "908b1476c0fc",
      "title": "Init Loads Data",
      "overview": "Workflow: Test that converter loads data file on initialization",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a8c7065c",
          "test_name": "test_init_loads_data",
          "category": "workflow",
          "code": "'Test that converter loads data file on initialization'\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter.__init__') as mock_init:\n    mock_init.return_value = None\n    converter = self.GitHubToSkillConverter(config)\n    converter.data_file = str(self.data_file)\n    converter.data = converter._load_data()\n    self.assertIn('repo_info', converter.data)\n    self.assertEqual(converter.data['repo_info']['name'], 'react')",
          "language": "Python",
          "description": "Workflow: Test that converter loads data file on initialization",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
          "line_start": 596,
          "line_end": 608,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "datetime",
            "pathlib",
            "unittest.mock",
            "github",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that converter loads data file on initialization'",
          "description": "'Test that converter loads data file on initialization'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "mock_init.return_value = None",
          "description": "Assign mock_init.return_value = None",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter = self.GitHubToSkillConverter(config)",
          "description": "Assign converter = self.GitHubToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter.data_file = str(self.data_file)",
          "description": "Assign converter.data_file = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.data = converter._load_data()",
          "description": "Assign converter.data = converter._load_data(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('repo_info', converter.data)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(converter.data['repo_info']['name'], 'react')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Init Loads Data",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_github_scraper.py:596"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ecf7c22b2833",
      "title": "Build Skill Creates Directory Structure",
      "overview": "Workflow: Test that build_skill creates proper directory structure",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bf61f1d8",
          "test_name": "test_build_skill_creates_directory_structure",
          "category": "workflow",
          "code": "'Test that build_skill creates proper directory structure'\ndata_file_path = self.output_dir / 'test_github_data.json'\nwith open(data_file_path, 'w') as f:\n    json.dump(self.mock_data, f)\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter._load_data') as mock_load:\n    mock_load.return_value = self.mock_data\n    converter = self.GitHubToSkillConverter(config)\n    converter.skill_dir = str(self.output_dir / 'test_skill')\n    converter.data = self.mock_data\n    converter.build_skill()\n    skill_dir = Path(converter.skill_dir)\n    self.assertTrue(skill_dir.exists())\n    self.assertTrue((skill_dir / 'SKILL.md').exists())\n    self.assertTrue((skill_dir / 'references').exists())",
          "language": "Python",
          "description": "Workflow: Test that build_skill creates proper directory structure",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
          "line_start": 610,
          "line_end": 633,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "datetime",
            "pathlib",
            "unittest.mock",
            "github",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that build_skill creates proper directory structure'",
          "description": "'Test that build_skill creates proper directory structure'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "data_file_path = self.output_dir / 'test_github_data.json'",
          "description": "Assign data_file_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "json.dump(self.mock_data, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "mock_load.return_value = self.mock_data",
          "description": "Assign mock_load.return_value = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter = self.GitHubToSkillConverter(config)",
          "description": "Assign converter = self.GitHubToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "converter.skill_dir = str(self.output_dir / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "converter.data = self.mock_data",
          "description": "Assign converter.data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "skill_dir = Path(converter.skill_dir)",
          "description": "Assign skill_dir = Path(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue(skill_dir.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertTrue((skill_dir / 'SKILL.md').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertTrue((skill_dir / 'references').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Skill Creates Directory Structure",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_github_scraper.py:610"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "713d0e2ae559",
      "title": "Invalid Repo Name",
      "overview": "Workflow: Test handling of invalid repository name",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5528a4b0",
          "test_name": "test_invalid_repo_name",
          "category": "workflow",
          "code": "'Test handling of invalid repository name'\nconfig = {'repo': 'invalid_repo_format', 'name': 'test', 'github_token': None}\nwith patch('skill_seekers.cli.github_scraper.Github'):\n    scraper = self.GitHubScraper(config)\n    scraper.repo = None\n    scraper.github.get_repo = Mock(side_effect=GithubException(404, 'Not found'))\n    with self.assertRaises(ValueError) as context:\n        scraper._fetch_repository()\n    self.assertIn('Repository not found', str(context.exception))",
          "language": "Python",
          "description": "Workflow: Test handling of invalid repository name",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
          "line_start": 980,
          "line_end": 993,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "datetime",
            "pathlib",
            "unittest.mock",
            "github",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper",
            "skill_seekers.cli.github_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test handling of invalid repository name'",
          "description": "'Test handling of invalid repository name'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'repo': 'invalid_repo_format', 'name': 'test', 'github_token': None}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraper = self.GitHubScraper(config)",
          "description": "Assign scraper = self.GitHubScraper(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "scraper.repo = None",
          "description": "Assign scraper.repo = None",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "scraper.github.get_repo = Mock(side_effect=GithubException(404, 'Not found'))",
          "description": "Assign scraper.github.get_repo = Mock(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIn('Repository not found', str(context.exception))",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "scraper._fetch_repository()",
          "description": "Call scraper._fetch_repository()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Invalid Repo Name",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_github_scraper.py:980"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c316a486c9e3",
      "title": "Github Workflows Reference Correct Paths",
      "overview": "Workflow: Test that GitHub workflows reference correct MCP paths",
      "complexity_level": "beginner",
      "prerequisites": [],
      "required_imports": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5bbe62dc",
          "test_name": "test_github_workflows_reference_correct_paths",
          "category": "workflow",
          "code": "'Test that GitHub workflows reference correct MCP paths'\nworkflow_file = Path('.github/workflows/tests.yml')\nif workflow_file.exists():\n    with open(workflow_file) as f:\n        content = f.read()\n    assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
          "language": "Python",
          "description": "Workflow: Test that GitHub workflows reference correct MCP paths",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
          "line_start": 200,
          "line_end": 210,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "re",
            "subprocess",
            "pathlib",
            "pytest",
            "re",
            "re",
            "os"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that GitHub workflows reference correct MCP paths'",
          "description": "'Test that GitHub workflows reference correct MCP paths'",
          "expected_result": null,
          "verification": "assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "workflow_file = Path('.github/workflows/tests.yml')",
          "description": "Assign workflow_file = Path(...)",
          "expected_result": null,
          "verification": "assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Github Workflows Reference Correct Paths",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_setup_scripts.py:200"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e8a544094a84",
      "title": "Flask Framework Detection From Imports",
      "overview": "Workflow: Test that Flask is detected from import statements (Issue #239).",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "3627d120",
          "test_name": "test_flask_framework_detection_from_imports",
          "category": "workflow",
          "code": "'Test that Flask is detected from import statements (Issue #239).'\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / '__init__.py').write_text('from flask import Flask\\napp = Flask(__name__)')\n(app_dir / 'routes.py').write_text(\"from flask import render_template\\nfrom app import app\\n\\n@app.route('/')\\ndef index():\\n    return render_template('index.html')\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none', '--skip-patterns', '--skip-test-examples', '--skip-how-to-guides', '--skip-config-patterns', '--skip-docs']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nself.assertTrue(arch_file.exists(), 'Architecture file should be created')\nwith open(arch_file) as f:\n    arch_data = json.load(f)\nself.assertIn('frameworks_detected', arch_data)\nself.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
          "language": "Python",
          "description": "Workflow: Test that Flask is detected from import statements (Issue #239).",
          "expected_behavior": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
          "line_start": 31,
          "line_end": 85,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.codebase_scraper",
            "sys",
            "skill_seekers.cli.codebase_scraper",
            "sys",
            "skill_seekers.cli.codebase_scraper",
            "sys"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that Flask is detected from import statements (Issue #239).'",
          "description": "'Test that Flask is detected from import statements (Issue #239).'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "app_dir = self.test_project / 'app'",
          "description": "Assign app_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "app_dir.mkdir()",
          "description": "Call app_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(app_dir / '__init__.py').write_text('from flask import Flask\\napp = Flask(__name__)')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "(app_dir / 'routes.py').write_text(\"from flask import render_template\\nfrom app import app\\n\\n@app.route('/')\\ndef index():\\n    return render_template('index.html')\\n\")",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "old_argv = sys.argv",
          "description": "Assign old_argv = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "arch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'",
          "description": "Assign arch_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(arch_file.exists(), 'Architecture file should be created')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('frameworks_detected', arch_data)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none', '--skip-patterns', '--skip-test-examples', '--skip-how-to-guides', '--skip-config-patterns', '--skip-docs']",
          "description": "Assign sys.argv = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "scraper_main()",
          "description": "Call scraper_main()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "sys.argv = old_argv",
          "description": "Assign sys.argv = old_argv",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "arch_data = json.load(f)",
          "description": "Assign arch_data = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Flask Framework Detection From Imports",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_framework_detection.py:31"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "72325028bc67",
      "title": "Files With Imports Are Included",
      "overview": "Workflow: Test that files with only imports are included in analysis (Issue #239).",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "94b9c455",
          "test_name": "test_files_with_imports_are_included",
          "category": "workflow",
          "code": "'Test that files with only imports are included in analysis (Issue #239).'\n(self.test_project / 'imports_only.py').write_text('import django\\nfrom flask import Flask\\nimport requests')\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\ncode_analysis = self.output_dir / 'code_analysis.json'\nself.assertTrue(code_analysis.exists(), 'Code analysis file should exist')\nwith open(code_analysis) as f:\n    analysis_data = json.load(f)\nself.assertGreater(len(analysis_data['files']), 0, 'Files with imports should be included')\nimport_file = next((f for f in analysis_data['files'] if 'imports_only.py' in f['file']), None)\nself.assertIsNotNone(import_file, 'Import-only file should be in analysis')\nself.assertIn('imports', import_file, 'Imports should be extracted')\nself.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')\nself.assertIn('django', import_file['imports'], 'Django import should be captured')\nself.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
          "language": "Python",
          "description": "Workflow: Test that files with only imports are included in analysis (Issue #239).",
          "expected_behavior": "self.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
          "line_start": 87,
          "line_end": 135,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.codebase_scraper",
            "sys",
            "skill_seekers.cli.codebase_scraper",
            "sys",
            "skill_seekers.cli.codebase_scraper",
            "sys"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that files with only imports are included in analysis (Issue #239).'",
          "description": "'Test that files with only imports are included in analysis (Issue #239).'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "(self.test_project / 'imports_only.py').write_text('import django\\nfrom flask import Flask\\nimport requests')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "old_argv = sys.argv",
          "description": "Assign old_argv = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_analysis = self.output_dir / 'code_analysis.json'",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(code_analysis.exists(), 'Code analysis file should exist')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertGreater(len(analysis_data['files']), 0, 'Files with imports should be included')",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "import_file = next((f for f in analysis_data['files'] if 'imports_only.py' in f['file']), None)",
          "description": "Assign import_file = next(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIsNotNone(import_file, 'Import-only file should be in analysis')",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('imports', import_file, 'Imports should be extracted')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('django', import_file['imports'], 'Django import should be captured')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']",
          "description": "Assign sys.argv = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "scraper_main()",
          "description": "Call scraper_main()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "sys.argv = old_argv",
          "description": "Assign sys.argv = old_argv",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "analysis_data = json.load(f)",
          "description": "Assign analysis_data = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Files With Imports Are Included",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_framework_detection.py:87"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5261066f942b",
      "title": "No False Positive Frameworks",
      "overview": "Workflow: Test that framework detection doesn't produce false positives (Issue #239).",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e8ebe64b",
          "test_name": "test_no_false_positive_frameworks",
          "category": "workflow",
          "code": "\"Test that framework detection doesn't produce false positives (Issue #239).\"\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / 'utils.py').write_text(\"def my_function():\\n    return 'hello'\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nif arch_file.exists():\n    with open(arch_file) as f:\n        arch_data = json.load(f)\n    frameworks = arch_data.get('frameworks_detected', [])\n    self.assertNotIn('Flask', frameworks, 'Should not detect Flask without imports')\n    for fw in ['ASP.NET', 'Rails', 'Laravel']:\n        self.assertNotIn(fw, frameworks, f'Should not detect {fw} without real evidence')",
          "language": "Python",
          "description": "Workflow: Test that framework detection doesn't produce false positives (Issue #239).",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
          "line_start": 137,
          "line_end": 179,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.codebase_scraper",
            "sys",
            "skill_seekers.cli.codebase_scraper",
            "sys",
            "skill_seekers.cli.codebase_scraper",
            "sys"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test that framework detection doesn't produce false positives (Issue #239).\"",
          "description": "\"Test that framework detection doesn't produce false positives (Issue #239).\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "app_dir = self.test_project / 'app'",
          "description": "Assign app_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "app_dir.mkdir()",
          "description": "Call app_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(app_dir / 'utils.py').write_text(\"def my_function():\\n    return 'hello'\\n\")",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "old_argv = sys.argv",
          "description": "Assign old_argv = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "arch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'",
          "description": "Assign arch_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']",
          "description": "Assign sys.argv = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "scraper_main()",
          "description": "Call scraper_main()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "sys.argv = old_argv",
          "description": "Assign sys.argv = old_argv",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "frameworks = arch_data.get('frameworks_detected', [])",
          "description": "Assign frameworks = arch_data.get(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertNotIn('Flask', frameworks, 'Should not detect Flask without imports')",
          "description": "Call self.assertNotIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "arch_data = json.load(f)",
          "description": "Assign arch_data = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertNotIn(fw, frameworks, f'Should not detect {fw} without real evidence')",
          "description": "Call self.assertNotIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "No False Positive Frameworks",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_framework_detection.py:137"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "1b63857d3d29",
      "title": "Detect Unified Format",
      "overview": "Workflow: Test unified format detection and legacy rejection",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e893a84b",
          "test_name": "test_detect_unified_format",
          "category": "workflow",
          "code": "'Test unified format detection and legacy rejection'\nimport json\nimport tempfile\nunified_config = {'name': 'test', 'description': 'Test skill', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nlegacy_config = {'name': 'test', 'description': 'Test skill', 'base_url': 'https://example.com'}\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    json.dump(unified_config, f)\n    config_path = f.name\ntry:\n    validator = ConfigValidator(config_path)\n    assert validator.is_unified\n    validator.validate()\nfinally:\n    os.unlink(config_path)\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    json.dump(legacy_config, f)\n    config_path = f.name\ntry:\n    validator = ConfigValidator(config_path)\n    assert validator.is_unified\n    with pytest.raises(ValueError, match='LEGACY CONFIG FORMAT DETECTED'):\n        validator.validate()\nfinally:\n    os.unlink(config_path)",
          "language": "Python",
          "description": "Workflow: Test unified format detection and legacy rejection",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 29,
          "line_end": 66,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test unified format detection and legacy rejection'",
          "description": "'Test unified format detection and legacy rejection'",
          "expected_result": null,
          "verification": "assert validator.is_unified",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "unified_config = {'name': 'test', 'description': 'Test skill', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}",
          "description": "Assign unified_config = value",
          "expected_result": null,
          "verification": "assert validator.is_unified",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "legacy_config = {'name': 'test', 'description': 'Test skill', 'base_url': 'https://example.com'}",
          "description": "Assign legacy_config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "json.dump(unified_config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config_path = f.name",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "validator = ConfigValidator(config_path)",
          "description": "Assign validator = ConfigValidator(...)",
          "expected_result": null,
          "verification": "assert validator.is_unified",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "validator.validate()",
          "description": "Call validator.validate()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "os.unlink(config_path)",
          "description": "Call os.unlink()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "json.dump(legacy_config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "config_path = f.name",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "validator = ConfigValidator(config_path)",
          "description": "Assign validator = ConfigValidator(...)",
          "expected_result": null,
          "verification": "assert validator.is_unified",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "os.unlink(config_path)",
          "description": "Call os.unlink()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "validator.validate()",
          "description": "Call validator.validate()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Unified Format",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_unified.py:29"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "da92791621ef",
      "title": "Needs Api Merge",
      "overview": "Workflow: Test API merge detection",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [
        "api_client"
      ],
      "workflows": [
        {
          "example_id": "1f45a493",
          "test_name": "test_needs_api_merge",
          "category": "workflow",
          "code": "'Test API merge detection'\nconfig_needs_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com', 'extract_api': True}, {'type': 'github', 'repo': 'user/repo', 'include_code': True}]}\nvalidator = ConfigValidator(config_needs_merge)\nassert validator.needs_api_merge()\nconfig_no_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nvalidator = ConfigValidator(config_no_merge)\nassert not validator.needs_api_merge()",
          "language": "Python",
          "description": "Workflow: Test API merge detection",
          "expected_behavior": "assert not validator.needs_api_merge()",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 99,
          "line_end": 122,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test API merge detection'",
          "description": "'Test API merge detection'",
          "expected_result": null,
          "verification": "assert validator.needs_api_merge()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config_needs_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com', 'extract_api': True}, {'type': 'github', 'repo': 'user/repo', 'include_code': True}]}",
          "description": "Assign config_needs_merge = value",
          "expected_result": null,
          "verification": "assert not validator.needs_api_merge()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "validator = ConfigValidator(config_needs_merge)",
          "description": "Assign validator = ConfigValidator(...)",
          "expected_result": null,
          "verification": "assert validator.needs_api_merge()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config_no_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}",
          "description": "Assign config_no_merge = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "validator = ConfigValidator(config_no_merge)",
          "description": "Assign validator = ConfigValidator(...)",
          "expected_result": null,
          "verification": "assert not validator.needs_api_merge()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Needs Api Merge",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_unified.py:99"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2887aaadf6b5",
      "title": "Detect Missing In Docs",
      "overview": "Workflow: Test detection of APIs missing in documentation",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a5be4d48",
          "test_name": "test_detect_missing_in_docs",
          "category": "workflow",
          "code": "'Test detection of APIs missing in documentation'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'documented_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'undocumented_func', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_missing_in_docs()\nassert len(conflicts) > 0\nassert any((c.type == 'missing_in_docs' for c in conflicts))\nassert any((c.api_name == 'undocumented_func' for c in conflicts))",
          "language": "Python",
          "description": "Workflow: Test detection of APIs missing in documentation",
          "expected_behavior": "assert any((c.api_name == 'undocumented_func' for c in conflicts))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 152,
          "line_end": 190,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of APIs missing in documentation'",
          "description": "'Test detection of APIs missing in documentation'",
          "expected_result": null,
          "verification": "assert len(conflicts) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'documented_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert any((c.type == 'missing_in_docs' for c in conflicts))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'undocumented_func', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert any((c.api_name == 'undocumented_func' for c in conflicts))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector._find_missing_in_docs()",
          "description": "Assign conflicts = detector._find_missing_in_docs(...)",
          "expected_result": null,
          "verification": "assert len(conflicts) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Missing In Docs",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_unified.py:152"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7b59118bfab5",
      "title": "Detect Missing In Code",
      "overview": "Workflow: Test detection of APIs missing in code",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f213a2d1",
          "test_name": "test_detect_missing_in_code",
          "category": "workflow",
          "code": "'Test detection of APIs missing in code'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'obsolete_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': []}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_missing_in_code()\nassert len(conflicts) > 0\nassert any((c.type == 'missing_in_code' for c in conflicts))\nassert any((c.api_name == 'obsolete_func' for c in conflicts))",
          "language": "Python",
          "description": "Workflow: Test detection of APIs missing in code",
          "expected_behavior": "assert any((c.api_name == 'obsolete_func' for c in conflicts))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 193,
          "line_end": 217,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of APIs missing in code'",
          "description": "'Test detection of APIs missing in code'",
          "expected_result": null,
          "verification": "assert len(conflicts) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'obsolete_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert any((c.type == 'missing_in_code' for c in conflicts))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': []}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert any((c.api_name == 'obsolete_func' for c in conflicts))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector._find_missing_in_code()",
          "description": "Assign conflicts = detector._find_missing_in_code(...)",
          "expected_result": null,
          "verification": "assert len(conflicts) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Missing In Code",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_unified.py:193"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "28f994940ed9",
      "title": "Detect Signature Mismatch",
      "overview": "Workflow: Test detection of signature mismatches",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "fd49d2de",
          "test_name": "test_detect_signature_mismatch",
          "category": "workflow",
          "code": "'Test detection of signature mismatches'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'func', 'parameters': [{'name': 'x', 'type_hint': 'int'}, {'name': 'y', 'type_hint': 'bool', 'default': 'False'}], 'return_type': 'str'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_signature_mismatches()\nassert len(conflicts) > 0\nassert any((c.type == 'signature_mismatch' for c in conflicts))\nassert any((c.api_name == 'func' for c in conflicts))",
          "language": "Python",
          "description": "Workflow: Test detection of signature mismatches",
          "expected_behavior": "assert any((c.api_name == 'func' for c in conflicts))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 220,
          "line_end": 261,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of signature mismatches'",
          "description": "'Test detection of signature mismatches'",
          "expected_result": null,
          "verification": "assert len(conflicts) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert any((c.type == 'signature_mismatch' for c in conflicts))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'func', 'parameters': [{'name': 'x', 'type_hint': 'int'}, {'name': 'y', 'type_hint': 'bool', 'default': 'False'}], 'return_type': 'str'}]}]}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert any((c.api_name == 'func' for c in conflicts))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector._find_signature_mismatches()",
          "description": "Assign conflicts = detector._find_signature_mismatches(...)",
          "expected_result": null,
          "verification": "assert len(conflicts) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Signature Mismatch",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_unified.py:220"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "61d729216fc9",
      "title": "Rule Based Merge Docs Only",
      "overview": "Workflow: Test rule-based merge for docs-only APIs",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5e0faf15",
          "test_name": "test_rule_based_merge_docs_only",
          "category": "workflow",
          "code": "'Test rule-based merge for docs-only APIs'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'docs_only_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': []}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'docs_only_api' in merged['apis']\nassert merged['apis']['docs_only_api']['status'] == 'docs_only'",
          "language": "Python",
          "description": "Workflow: Test rule-based merge for docs-only APIs",
          "expected_behavior": "assert merged['apis']['docs_only_api']['status'] == 'docs_only'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 294,
          "line_end": 321,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test rule-based merge for docs-only APIs'",
          "description": "'Test rule-based merge for docs-only APIs'",
          "expected_result": null,
          "verification": "assert 'apis' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'docs_only_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert 'docs_only_api' in merged['apis']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': []}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert merged['apis']['docs_only_api']['status'] == 'docs_only'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector.detect_all_conflicts()",
          "description": "Assign conflicts = detector.detect_all_conflicts(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "merged = merger.merge_all()",
          "description": "Assign merged = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert 'apis' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Rule Based Merge Docs Only",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_unified.py:294"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7359cbc1cfbe",
      "title": "Rule Based Merge Code Only",
      "overview": "Workflow: Test rule-based merge for code-only APIs",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ee3da183",
          "test_name": "test_rule_based_merge_code_only",
          "category": "workflow",
          "code": "'Test rule-based merge for code-only APIs'\ndocs_data = {'pages': []}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'code_only_api', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'code_only_api' in merged['apis']\nassert merged['apis']['code_only_api']['status'] == 'code_only'",
          "language": "Python",
          "description": "Workflow: Test rule-based merge for code-only APIs",
          "expected_behavior": "assert merged['apis']['code_only_api']['status'] == 'code_only'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 324,
          "line_end": 352,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test rule-based merge for code-only APIs'",
          "description": "'Test rule-based merge for code-only APIs'",
          "expected_result": null,
          "verification": "assert 'apis' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': []}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert 'code_only_api' in merged['apis']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'code_only_api', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert merged['apis']['code_only_api']['status'] == 'code_only'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector.detect_all_conflicts()",
          "description": "Assign conflicts = detector.detect_all_conflicts(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "merged = merger.merge_all()",
          "description": "Assign merged = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert 'apis' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Rule Based Merge Code Only",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_unified.py:324"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "afa88306920c",
      "title": "Rule Based Merge Matched",
      "overview": "Workflow: Test rule-based merge for matched APIs",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "42fb31d7",
          "test_name": "test_rule_based_merge_matched",
          "category": "workflow",
          "code": "'Test rule-based merge for matched APIs'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type_hint': 'int'}], 'return_type': 'str'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'matched_api' in merged['apis']\nassert merged['apis']['matched_api']['status'] == 'matched'",
          "language": "Python",
          "description": "Workflow: Test rule-based merge for matched APIs",
          "expected_behavior": "assert merged['apis']['matched_api']['status'] == 'matched'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 355,
          "line_end": 396,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test rule-based merge for matched APIs'",
          "description": "'Test rule-based merge for matched APIs'",
          "expected_result": null,
          "verification": "assert 'apis' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert 'matched_api' in merged['apis']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type_hint': 'int'}], 'return_type': 'str'}]}]}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert merged['apis']['matched_api']['status'] == 'matched'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector.detect_all_conflicts()",
          "description": "Assign conflicts = detector.detect_all_conflicts(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "merged = merger.merge_all()",
          "description": "Assign merged = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert 'apis' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Rule Based Merge Matched",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_unified.py:355"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "337a1b9f6b2f",
      "title": "Merge Summary",
      "overview": "Workflow: Test merge summary statistics",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "20f90863",
          "test_name": "test_merge_summary",
          "category": "workflow",
          "code": "'Test merge summary statistics'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'api1', 'parameters': [], 'return_type': 'str'}, {'name': 'api2', 'parameters': [], 'return_type': 'int'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'api3', 'parameters': [], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'summary' in merged\nassert merged['summary']['total_apis'] == 3\nassert merged['summary']['docs_only'] == 2\nassert merged['summary']['code_only'] == 1",
          "language": "Python",
          "description": "Workflow: Test merge summary statistics",
          "expected_behavior": "assert merged['summary']['code_only'] == 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 399,
          "line_end": 430,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test merge summary statistics'",
          "description": "'Test merge summary statistics'",
          "expected_result": null,
          "verification": "assert 'summary' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'api1', 'parameters': [], 'return_type': 'str'}, {'name': 'api2', 'parameters': [], 'return_type': 'int'}]}]}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert merged['summary']['total_apis'] == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'api3', 'parameters': [], 'return_type': 'bool'}]}]}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert merged['summary']['docs_only'] == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "detector = ConflictDetector(docs_data, github_data)",
          "description": "Assign detector = ConflictDetector(...)",
          "expected_result": null,
          "verification": "assert merged['summary']['code_only'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = detector.detect_all_conflicts()",
          "description": "Assign conflicts = detector.detect_all_conflicts(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "merged = merger.merge_all()",
          "description": "Assign merged = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert 'summary' in merged",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Merge Summary",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_unified.py:399"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ef9dbc3ab78d",
      "title": "Skill Builder Basic",
      "overview": "Workflow: Test basic skill building",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "819b98bf",
          "test_name": "test_skill_builder_basic",
          "category": "workflow",
          "code": "'Test basic skill building'\nconfig = {'name': 'test_skill', 'description': 'Test skill description', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nscraped_data = {'documentation': {'pages': [], 'data_file': '/tmp/test.json'}}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    builder = UnifiedSkillBuilder(config, scraped_data)\n    builder.skill_dir = tmpdir\n    builder._generate_skill_md()\n    skill_md = Path(tmpdir) / 'SKILL.md'\n    assert skill_md.exists()\n    content = skill_md.read_text()\n    assert 'test_skill' in content.lower()\n    assert 'Test skill description' in content",
          "language": "Python",
          "description": "Workflow: Test basic skill building",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
          "line_start": 438,
          "line_end": 461,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "tempfile",
            "pathlib",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_skill_builder",
            "json",
            "tempfile"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic skill building'",
          "description": "'Test basic skill building'",
          "expected_result": null,
          "verification": "assert skill_md.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'description': 'Test skill description', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert 'test_skill' in content.lower()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'documentation': {'pages': [], 'data_file': '/tmp/test.json'}}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": "assert 'Test skill description' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder.skill_dir = tmpdir",
          "description": "Assign builder.skill_dir = tmpdir",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "builder._generate_skill_md()",
          "description": "Call builder._generate_skill_md()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "skill_md = Path(tmpdir) / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": "assert skill_md.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = skill_md.read_text()",
          "description": "Assign content = skill_md.read_text(...)",
          "expected_result": null,
          "verification": "assert 'test_skill' in content.lower()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Skill Builder Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_unified.py:438"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "89861b3d5d97",
      "title": "Format Skill Md",
      "overview": "Workflow: Test formatting SKILL.md as Qdrant points.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bccba00b",
          "test_name": "test_format_skill_md",
          "category": "workflow",
          "code": "'Test formatting SKILL.md as Qdrant points.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for Qdrant format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert 'collection_name' in result\nassert 'points' in result\nassert 'config' in result\nassert len(result['points']) == 3\nfor point in result['points']:\n    assert 'id' in point\n    assert 'vector' in point\n    assert 'payload' in point\n    payload = point['payload']\n    assert 'content' in payload\n    assert payload['source'] == 'test_skill'\n    assert payload['version'] == '1.0.0'\n    assert 'category' in payload\n    assert 'file' in payload\n    assert 'type' in payload\ncategories = {point['payload']['category'] for point in result['points']}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
          "language": "Python",
          "description": "Workflow: Test formatting SKILL.md as Qdrant points.",
          "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
          "line_start": 23,
          "line_end": 69,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test formatting SKILL.md as Qdrant points.'",
          "description": "'Test formatting SKILL.md as Qdrant points.'",
          "expected_result": null,
          "verification": "assert 'collection_name' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": "assert 'points' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": "assert 'config' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_md = skill_dir / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": "assert len(result['points']) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_md.write_text('# Test Skill\\n\\nThis is a test skill for Qdrant format.')",
          "description": "Call skill_md.write_text()",
          "expected_result": null,
          "verification": "assert 'id' in point",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "refs_dir = skill_dir / 'references'",
          "description": "Assign refs_dir = value",
          "expected_result": null,
          "verification": "assert 'vector' in point",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "refs_dir.mkdir()",
          "description": "Call refs_dir.mkdir()",
          "expected_result": null,
          "verification": "assert 'payload' in point",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert 'content' in payload",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert payload['source'] == 'test_skill'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "adaptor = get_adaptor('qdrant')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert payload['version'] == '1.0.0'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": "assert 'category' in payload",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
          "description": "Assign points_json = adaptor.format_skill_md(...)",
          "expected_result": null,
          "verification": "assert 'file' in payload",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "result = json.loads(points_json)",
          "description": "Assign result = json.loads(...)",
          "expected_result": null,
          "verification": "assert 'type' in payload",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "categories = {point['payload']['category'] for point in result['points']}",
          "description": "Assign categories = value",
          "expected_result": null,
          "verification": "assert 'overview' in categories",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "payload = point['payload']",
          "description": "Assign payload = value",
          "expected_result": null,
          "verification": "assert 'getting started' in categories or 'api' in categories",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Format Skill Md",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_qdrant_adaptor.py:23"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "864b2b61b4de",
      "title": "Package Creates Json",
      "overview": "Workflow: Test packaging skill into JSON file.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f9fcbe20",
          "test_name": "test_package_creates_json",
          "category": "workflow",
          "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('qdrant')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'qdrant' in output_path.name\nwith open(output_path) as f:\n    result = json.load(f)\nassert isinstance(result, dict)\nassert 'points' in result\nassert len(result['points']) > 0\nassert 'id' in result['points'][0]\nassert 'payload' in result['points'][0]",
          "language": "Python",
          "description": "Workflow: Test packaging skill into JSON file.",
          "expected_behavior": "assert 'payload' in result['points'][0]",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
          "line_start": 71,
          "line_end": 95,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test packaging skill into JSON file.'",
          "description": "'Test packaging skill into JSON file.'",
          "expected_result": null,
          "verification": "assert output_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": "assert output_path.suffix == '.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": "assert 'qdrant' in output_path.name",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert isinstance(result, dict)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "adaptor = get_adaptor('qdrant')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert 'points' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "output_path = adaptor.package(skill_dir, tmp_path)",
          "description": "Assign output_path = adaptor.package(...)",
          "expected_result": null,
          "verification": "assert len(result['points']) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "result = json.load(f)",
          "description": "Assign result = json.load(...)",
          "expected_result": null,
          "verification": "assert 'id' in result['points'][0]",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Package Creates Json",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_qdrant_adaptor.py:71"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d43f20c7e5e7",
      "title": "Package Output Filename",
      "overview": "Workflow: Test package output filename generation.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "baec8673",
          "test_name": "test_package_output_filename",
          "category": "workflow",
          "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('qdrant')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-qdrant.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'qdrant' in output_path.name",
          "language": "Python",
          "description": "Workflow: Test package output filename generation.",
          "expected_behavior": "assert 'qdrant' in output_path.name",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
          "line_start": 97,
          "line_end": 112,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test package output filename generation.'",
          "description": "'Test package output filename generation.'",
          "expected_result": null,
          "verification": "assert output_path.name == 'react-qdrant.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'react'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": "assert output_path.suffix == '.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": "assert 'qdrant' in output_path.name",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "adaptor = get_adaptor('qdrant')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "output_path = adaptor.package(skill_dir, tmp_path)",
          "description": "Assign output_path = adaptor.package(...)",
          "expected_result": null,
          "verification": "assert output_path.name == 'react-qdrant.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "output_path = adaptor.package(skill_dir, tmp_path / 'test.zip')",
          "description": "Assign output_path = adaptor.package(...)",
          "expected_result": null,
          "verification": "assert output_path.suffix == '.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Package Output Filename",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_qdrant_adaptor.py:97"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "730bac34a020",
      "title": "Empty Skill Directory",
      "overview": "Workflow: Test handling of empty skill directory.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ca3d402d",
          "test_name": "test_empty_skill_directory",
          "category": "workflow",
          "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert 'points' in result\nassert result['points'] == []",
          "language": "Python",
          "description": "Workflow: Test handling of empty skill directory.",
          "expected_behavior": "assert result['points'] == []",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
          "line_start": 153,
          "line_end": 166,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test handling of empty skill directory.'",
          "description": "'Test handling of empty skill directory.'",
          "expected_result": null,
          "verification": "assert 'points' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'empty_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": "assert result['points'] == []",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "adaptor = get_adaptor('qdrant')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "metadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
          "description": "Assign points_json = adaptor.format_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "result = json.loads(points_json)",
          "description": "Assign result = json.loads(...)",
          "expected_result": null,
          "verification": "assert 'points' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Empty Skill Directory",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_qdrant_adaptor.py:153"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ea38d1f6af4b",
      "title": "References Only",
      "overview": "Workflow: Test skill with references but no SKILL.md.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "8566ae4f",
          "test_name": "test_references_only",
          "category": "workflow",
          "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert len(result['points']) == 1\nassert result['points'][0]['payload']['category'] == 'test'\nassert result['points'][0]['payload']['type'] == 'reference'",
          "language": "Python",
          "description": "Workflow: Test skill with references but no SKILL.md.",
          "expected_behavior": "assert result['points'][0]['payload']['type'] == 'reference'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
          "line_start": 168,
          "line_end": 185,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test skill with references but no SKILL.md.'",
          "description": "'Test skill with references but no SKILL.md.'",
          "expected_result": null,
          "verification": "assert len(result['points']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'refs_only'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": "assert result['points'][0]['payload']['category'] == 'test'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": "assert result['points'][0]['payload']['type'] == 'reference'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "refs_dir = skill_dir / 'references'",
          "description": "Assign refs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "refs_dir.mkdir()",
          "description": "Call refs_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "adaptor = get_adaptor('qdrant')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "metadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
          "description": "Assign points_json = adaptor.format_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "result = json.loads(points_json)",
          "description": "Assign result = json.loads(...)",
          "expected_result": null,
          "verification": "assert len(result['points']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "References Only",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_qdrant_adaptor.py:168"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "23bde6202e31",
      "title": "Temp Git Repo",
      "overview": "Workflow: Create a temporary git repository with sample configs.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7428f5fa",
          "test_name": "temp_git_repo",
          "category": "workflow",
          "code": "'Create a temporary git repository with sample configs.'\nrepo_dir = tempfile.mkdtemp(prefix='ss_repo_')\nrepo = git.Repo.init(repo_dir)\nconfigs = {'react.json': {'name': 'react', 'description': 'React framework for UIs', 'base_url': 'https://react.dev/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {'getting_started': ['learn', 'start'], 'api': ['reference', 'api']}, 'rate_limit': 0.5, 'max_pages': 100}, 'vue.json': {'name': 'vue', 'description': 'Vue.js progressive framework', 'base_url': 'https://vuejs.org/', 'selectors': {'main_content': 'main', 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 50}, 'django.json': {'name': 'django', 'description': 'Django web framework', 'base_url': 'https://docs.djangoproject.com/', 'selectors': {'main_content': \"div[role='main']\", 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 200}}\nfor filename, config_data in configs.items():\n    config_path = Path(repo_dir) / filename\n    with open(config_path, 'w') as f:\n        json.dump(config_data, f, indent=2)\nrepo.index.add(['*.json'])\nrepo.index.commit('Initial commit with sample configs')\nyield (repo_dir, repo)\nshutil.rmtree(repo_dir, ignore_errors=True)",
          "language": "Python",
          "description": "Workflow: Create a temporary git repository with sample configs.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 51,
          "line_end": 105,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "pytest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Create a temporary git repository with sample configs.'",
          "description": "'Create a temporary git repository with sample configs.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "repo_dir = tempfile.mkdtemp(prefix='ss_repo_')",
          "description": "Assign repo_dir = tempfile.mkdtemp(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo = git.Repo.init(repo_dir)",
          "description": "Assign repo = git.Repo.init(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "configs = {'react.json': {'name': 'react', 'description': 'React framework for UIs', 'base_url': 'https://react.dev/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {'getting_started': ['learn', 'start'], 'api': ['reference', 'api']}, 'rate_limit': 0.5, 'max_pages': 100}, 'vue.json': {'name': 'vue', 'description': 'Vue.js progressive framework', 'base_url': 'https://vuejs.org/', 'selectors': {'main_content': 'main', 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 50}, 'django.json': {'name': 'django', 'description': 'Django web framework', 'base_url': 'https://docs.djangoproject.com/', 'selectors': {'main_content': \"div[role='main']\", 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 200}}",
          "description": "Assign configs = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "repo.index.add(['*.json'])",
          "description": "Call repo.index.add()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "repo.index.commit('Initial commit with sample configs')",
          "description": "Call repo.index.commit()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "yield (repo_dir, repo)",
          "description": "yield (repo_dir, repo)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "shutil.rmtree(repo_dir, ignore_errors=True)",
          "description": "Call shutil.rmtree()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "config_path = Path(repo_dir) / filename",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "json.dump(config_data, f, indent=2)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Temp Git Repo",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_git_sources_e2e.py:51"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c85d3079c25c",
      "title": "E2E Workflow Direct Git Url",
      "overview": "Workflow: E2E Test 1: Direct git URL workflow (no source registration)\n\nSteps:\n1. Clone repository via direct git URL\n2. List available configs\n3. Fetch specific config\n4. Verify config content",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b0071f7e",
          "test_name": "test_e2e_workflow_direct_git_url",
          "category": "workflow",
          "code": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-direct', git_url=git_url, branch='master')\nassert repo_path.exists()\nassert (repo_path / '.git').exists()\nconfigs = git_repo.find_configs(repo_path)\nassert len(configs) == 3\nconfig_names = [c.stem for c in configs]\nassert set(config_names) == {'react', 'vue', 'django'}\nconfig = git_repo.get_config(repo_path, 'react')\nassert config['name'] == 'react'\nassert config['description'] == 'React framework for UIs'\nassert config['base_url'] == 'https://react.dev/'\nassert 'selectors' in config\nassert 'categories' in config\nassert config['max_pages'] == 100",
          "language": "Python",
          "description": "Workflow: E2E Test 1: Direct git URL workflow (no source registration)\n\nSteps:\n1. Clone repository via direct git URL\n2. List available configs\n3. Fetch specific config\n4. Verify config content",
          "expected_behavior": "assert config['max_pages'] == 100",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 107,
          "line_end": 148,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '",
          "description": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '",
          "expected_result": null,
          "verification": "assert repo_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert (repo_path / '.git').exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert len(configs) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": "assert set(config_names) == {'react', 'vue', 'django'}",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
          "description": "Assign git_repo = GitConfigRepo(...)",
          "expected_result": null,
          "verification": "assert config['name'] == 'react'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "repo_path = git_repo.clone_or_pull(source_name='test-direct', git_url=git_url, branch='master')",
          "description": "Assign repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": "assert config['description'] == 'React framework for UIs'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "configs = git_repo.find_configs(repo_path)",
          "description": "Assign configs = git_repo.find_configs(...)",
          "expected_result": null,
          "verification": "assert config['base_url'] == 'https://react.dev/'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "config_names = [c.stem for c in configs]",
          "description": "Assign config_names = value",
          "expected_result": null,
          "verification": "assert 'selectors' in config",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "config = git_repo.get_config(repo_path, 'react')",
          "description": "Assign config = git_repo.get_config(...)",
          "expected_result": null,
          "verification": "assert 'categories' in config",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Workflow Direct Git Url",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_git_sources_e2e.py:107"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5b7515179249",
      "title": "E2E Workflow With Source Registration",
      "overview": "Workflow: E2E Test 2: Complete workflow with source registration\n\nSteps:\n1. Add source to registry\n2. List sources\n3. Get source details\n4. Clone via source name\n5. Fetch config\n6. Update source (re-add with different priority)\n7. Remove source\n8. Verify removal",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "98f1ba4a",
          "test_name": "test_e2e_workflow_with_source_registration",
          "category": "workflow",
          "code": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nsource_manager = SourceManager(config_dir=config_dir)\nsource = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=10)\nassert source['name'] == 'team-configs'\nassert source['git_url'] == git_url\nassert source['type'] == 'custom'\nassert source['branch'] == 'master'\nassert source['priority'] == 10\nassert source['enabled'] is True\nsources = source_manager.list_sources()\nassert len(sources) == 1\nassert sources[0]['name'] == 'team-configs'\nretrieved_source = source_manager.get_source('team-configs')\nassert retrieved_source['git_url'] == git_url\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name=source['name'], git_url=source['git_url'], branch=source['branch'])\nassert repo_path.exists()\nconfig = git_repo.get_config(repo_path, 'vue')\nassert config['name'] == 'vue'\nassert config['base_url'] == 'https://vuejs.org/'\nupdated_source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=5)\nassert updated_source['priority'] == 5\nremoved = source_manager.remove_source('team-configs')\nassert removed is True\nsources = source_manager.list_sources()\nassert len(sources) == 0\nwith pytest.raises(KeyError, match=\"Source 'team-configs' not found\"):\n    source_manager.get_source('team-configs')",
          "language": "Python",
          "description": "Workflow: E2E Test 2: Complete workflow with source registration\n\nSteps:\n1. Add source to registry\n2. List sources\n3. Get source details\n4. Clone via source name\n5. Fetch config\n6. Update source (re-add with different priority)\n7. Remove source\n8. Verify removal",
          "expected_behavior": "assert len(sources) == 0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 150,
          "line_end": 223,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '",
          "description": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '",
          "expected_result": null,
          "verification": "assert source['name'] == 'team-configs'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert source['git_url'] == git_url",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert source['type'] == 'custom'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": "assert source['branch'] == 'master'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "source_manager = SourceManager(config_dir=config_dir)",
          "description": "Assign source_manager = SourceManager(...)",
          "expected_result": null,
          "verification": "assert source['priority'] == 10",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=10)",
          "description": "Assign source = source_manager.add_source(...)",
          "expected_result": null,
          "verification": "assert source['enabled'] is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "sources = source_manager.list_sources()",
          "description": "Assign sources = source_manager.list_sources(...)",
          "expected_result": null,
          "verification": "assert len(sources) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "retrieved_source = source_manager.get_source('team-configs')",
          "description": "Assign retrieved_source = source_manager.get_source(...)",
          "expected_result": null,
          "verification": "assert sources[0]['name'] == 'team-configs'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
          "description": "Assign git_repo = GitConfigRepo(...)",
          "expected_result": null,
          "verification": "assert retrieved_source['git_url'] == git_url",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "repo_path = git_repo.clone_or_pull(source_name=source['name'], git_url=source['git_url'], branch=source['branch'])",
          "description": "Assign repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": "assert repo_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "config = git_repo.get_config(repo_path, 'vue')",
          "description": "Assign config = git_repo.get_config(...)",
          "expected_result": null,
          "verification": "assert config['name'] == 'vue'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "updated_source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=5)",
          "description": "Assign updated_source = source_manager.add_source(...)",
          "expected_result": null,
          "verification": "assert config['base_url'] == 'https://vuejs.org/'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "removed = source_manager.remove_source('team-configs')",
          "description": "Assign removed = source_manager.remove_source(...)",
          "expected_result": null,
          "verification": "assert updated_source['priority'] == 5",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "sources = source_manager.list_sources()",
          "description": "Assign sources = source_manager.list_sources(...)",
          "expected_result": null,
          "verification": "assert removed is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "source_manager.get_source('team-configs')",
          "description": "Call source_manager.get_source()",
          "expected_result": null,
          "verification": "assert len(sources) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Workflow With Source Registration",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_git_sources_e2e.py:150"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5ef70de4b9e9",
      "title": "E2E Multiple Sources Priority Resolution",
      "overview": "Workflow: E2E Test 3: Multiple sources with priority resolution\n\nSteps:\n1. Add multiple sources with different priorities\n2. Verify sources are sorted by priority\n3. Enable/disable sources\n4. List enabled sources only",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c77e4d8d",
          "test_name": "test_e2e_multiple_sources_priority_resolution",
          "category": "workflow",
          "code": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nsource_manager = SourceManager(config_dir=config_dir)\nsource_manager.add_source(name='low-priority', git_url=git_url, priority=100)\nsource_manager.add_source(name='high-priority', git_url=git_url, priority=1)\nsource_manager.add_source(name='medium-priority', git_url=git_url, priority=50)\nsources = source_manager.list_sources()\nassert len(sources) == 3\nassert sources[0]['name'] == 'high-priority'\nassert sources[1]['name'] == 'medium-priority'\nassert sources[2]['name'] == 'low-priority'\nsource_manager.add_source(name='high-priority', git_url=git_url, priority=1, enabled=False)\nenabled_sources = source_manager.list_sources(enabled_only=True)\nassert len(enabled_sources) == 2\nassert all((s['enabled'] for s in enabled_sources))\nassert 'high-priority' not in [s['name'] for s in enabled_sources]",
          "language": "Python",
          "description": "Workflow: E2E Test 3: Multiple sources with priority resolution\n\nSteps:\n1. Add multiple sources with different priorities\n2. Verify sources are sorted by priority\n3. Enable/disable sources\n4. List enabled sources only",
          "expected_behavior": "assert 'high-priority' not in [s['name'] for s in enabled_sources]",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 225,
          "line_end": 260,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '",
          "description": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '",
          "expected_result": null,
          "verification": "assert len(sources) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert sources[0]['name'] == 'high-priority'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert sources[1]['name'] == 'medium-priority'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": "assert sources[2]['name'] == 'low-priority'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "source_manager = SourceManager(config_dir=config_dir)",
          "description": "Assign source_manager = SourceManager(...)",
          "expected_result": null,
          "verification": "assert len(enabled_sources) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "source_manager.add_source(name='low-priority', git_url=git_url, priority=100)",
          "description": "Call source_manager.add_source()",
          "expected_result": null,
          "verification": "assert all((s['enabled'] for s in enabled_sources))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "source_manager.add_source(name='high-priority', git_url=git_url, priority=1)",
          "description": "Call source_manager.add_source()",
          "expected_result": null,
          "verification": "assert 'high-priority' not in [s['name'] for s in enabled_sources]",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "source_manager.add_source(name='medium-priority', git_url=git_url, priority=50)",
          "description": "Call source_manager.add_source()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "sources = source_manager.list_sources()",
          "description": "Assign sources = source_manager.list_sources(...)",
          "expected_result": null,
          "verification": "assert len(sources) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "source_manager.add_source(name='high-priority', git_url=git_url, priority=1, enabled=False)",
          "description": "Call source_manager.add_source()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "enabled_sources = source_manager.list_sources(enabled_only=True)",
          "description": "Assign enabled_sources = source_manager.list_sources(...)",
          "expected_result": null,
          "verification": "assert len(enabled_sources) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Multiple Sources Priority Resolution",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_git_sources_e2e.py:225"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "207e9ccdf9d1",
      "title": "E2E Pull Existing Repository",
      "overview": "Workflow: E2E Test 4: Pull updates from existing repository\n\nSteps:\n1. Clone repository\n2. Add new commit to original repo\n3. Pull updates\n4. Verify new config is available",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9313eeac",
          "test_name": "test_e2e_pull_existing_repository",
          "category": "workflow",
          "code": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master')\ninitial_configs = git_repo.find_configs(repo_path)\nassert len(initial_configs) == 3\nnew_config = {'name': 'fastapi', 'description': 'FastAPI framework', 'base_url': 'https://fastapi.tiangolo.com/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 150}\nnew_config_path = Path(repo_dir) / 'fastapi.json'\nwith open(new_config_path, 'w') as f:\n    json.dump(new_config, f, indent=2)\nrepo.index.add(['fastapi.json'])\nrepo.index.commit('Add FastAPI config')\nupdated_repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master', force_refresh=False)\nupdated_configs = git_repo.find_configs(updated_repo_path)\nassert len(updated_configs) == 4\nfastapi_config = git_repo.get_config(updated_repo_path, 'fastapi')\nassert fastapi_config['name'] == 'fastapi'\nassert fastapi_config['max_pages'] == 150",
          "language": "Python",
          "description": "Workflow: E2E Test 4: Pull updates from existing repository\n\nSteps:\n1. Clone repository\n2. Add new commit to original repo\n3. Pull updates\n4. Verify new config is available",
          "expected_behavior": "assert fastapi_config['max_pages'] == 150",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 262,
          "line_end": 319,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '",
          "description": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '",
          "expected_result": null,
          "verification": "assert len(initial_configs) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert len(updated_configs) == 4",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert fastapi_config['name'] == 'fastapi'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": "assert fastapi_config['max_pages'] == 150",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
          "description": "Assign git_repo = GitConfigRepo(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master')",
          "description": "Assign repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "initial_configs = git_repo.find_configs(repo_path)",
          "description": "Assign initial_configs = git_repo.find_configs(...)",
          "expected_result": null,
          "verification": "assert len(initial_configs) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "new_config = {'name': 'fastapi', 'description': 'FastAPI framework', 'base_url': 'https://fastapi.tiangolo.com/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 150}",
          "description": "Assign new_config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "new_config_path = Path(repo_dir) / 'fastapi.json'",
          "description": "Assign new_config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "repo.index.add(['fastapi.json'])",
          "description": "Call repo.index.add()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "repo.index.commit('Add FastAPI config')",
          "description": "Call repo.index.commit()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "updated_repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master', force_refresh=False)",
          "description": "Assign updated_repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "updated_configs = git_repo.find_configs(updated_repo_path)",
          "description": "Assign updated_configs = git_repo.find_configs(...)",
          "expected_result": null,
          "verification": "assert len(updated_configs) == 4",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "fastapi_config = git_repo.get_config(updated_repo_path, 'fastapi')",
          "description": "Assign fastapi_config = git_repo.get_config(...)",
          "expected_result": null,
          "verification": "assert fastapi_config['name'] == 'fastapi'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "json.dump(new_config, f, indent=2)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Pull Existing Repository",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_git_sources_e2e.py:262"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "30a7346dfa8e",
      "title": "E2E Force Refresh",
      "overview": "Workflow: E2E Test 5: Force refresh (delete and re-clone)\n\nSteps:\n1. Clone repository\n2. Modify local cache manually\n3. Force refresh\n4. Verify cache was reset",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "704093e0",
          "test_name": "test_e2e_force_refresh",
          "category": "workflow",
          "code": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master')\ncorrupt_file = repo_path / 'CORRUPTED.txt'\nwith open(corrupt_file, 'w') as f:\n    f.write('This file should not exist after refresh')\nassert corrupt_file.exists()\nrefreshed_repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master', force_refresh=True)\nassert not corrupt_file.exists()\nconfigs = git_repo.find_configs(refreshed_repo_path)\nassert len(configs) == 3",
          "language": "Python",
          "description": "Workflow: E2E Test 5: Force refresh (delete and re-clone)\n\nSteps:\n1. Clone repository\n2. Modify local cache manually\n3. Force refresh\n4. Verify cache was reset",
          "expected_behavior": "assert len(configs) == 3",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 321,
          "line_end": 360,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '",
          "description": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '",
          "expected_result": null,
          "verification": "assert corrupt_file.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert not corrupt_file.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert len(configs) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
          "description": "Assign git_repo = GitConfigRepo(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master')",
          "description": "Assign repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "corrupt_file = repo_path / 'CORRUPTED.txt'",
          "description": "Assign corrupt_file = value",
          "expected_result": null,
          "verification": "assert corrupt_file.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "refreshed_repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master', force_refresh=True)",
          "description": "Assign refreshed_repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": "assert not corrupt_file.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "configs = git_repo.find_configs(refreshed_repo_path)",
          "description": "Assign configs = git_repo.find_configs(...)",
          "expected_result": null,
          "verification": "assert len(configs) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "f.write('This file should not exist after refresh')",
          "description": "Call f.write()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Force Refresh",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_git_sources_e2e.py:321"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ae876e1427a0",
      "title": "E2E Config Not Found",
      "overview": "Workflow: E2E Test 6: Error handling - config not found\n\nSteps:\n1. Clone repository\n2. Try to fetch non-existent config\n3. Verify helpful error message with suggestions",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "879de16a",
          "test_name": "test_e2e_config_not_found",
          "category": "workflow",
          "code": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-not-found', git_url=git_url, branch='master')\nwith pytest.raises(FileNotFoundError) as exc_info:\n    git_repo.get_config(repo_path, 'nonexistent')\nerror_msg = str(exc_info.value)\nassert 'nonexistent.json' in error_msg\nassert 'not found' in error_msg\nassert 'react' in error_msg\nassert 'vue' in error_msg\nassert 'django' in error_msg",
          "language": "Python",
          "description": "Workflow: E2E Test 6: Error handling - config not found\n\nSteps:\n1. Clone repository\n2. Try to fetch non-existent config\n3. Verify helpful error message with suggestions",
          "expected_behavior": "assert 'django' in error_msg",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 362,
          "line_end": 392,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '",
          "description": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '",
          "expected_result": null,
          "verification": "assert 'nonexistent.json' in error_msg",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert 'not found' in error_msg",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert 'react' in error_msg",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": "assert 'vue' in error_msg",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
          "description": "Assign git_repo = GitConfigRepo(...)",
          "expected_result": null,
          "verification": "assert 'django' in error_msg",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "repo_path = git_repo.clone_or_pull(source_name='test-not-found', git_url=git_url, branch='master')",
          "description": "Assign repo_path = git_repo.clone_or_pull(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "error_msg = str(exc_info.value)",
          "description": "Assign error_msg = str(...)",
          "expected_result": null,
          "verification": "assert 'nonexistent.json' in error_msg",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "git_repo.get_config(repo_path, 'nonexistent')",
          "description": "Call git_repo.get_config()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Config Not Found",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_git_sources_e2e.py:362"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "cff856a62f38",
      "title": "E2E Invalid Git Url",
      "overview": "Workflow: E2E Test 7: Error handling - invalid git URL\n\nSteps:\n1. Try to clone with invalid URL\n2. Verify validation error",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7a766988",
          "test_name": "test_e2e_invalid_git_url",
          "category": "workflow",
          "code": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '\ncache_dir, config_dir = temp_dirs\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\ninvalid_urls = ['', 'not-a-url', 'ftp://invalid.com/repo.git', \"javascript:alert('xss')\"]\nfor invalid_url in invalid_urls:\n    with pytest.raises(ValueError, match='Invalid git URL'):\n        git_repo.clone_or_pull(source_name='test-invalid', git_url=invalid_url, branch='master')",
          "language": "Python",
          "description": "Workflow: E2E Test 7: Error handling - invalid git URL\n\nSteps:\n1. Try to clone with invalid URL\n2. Verify validation error",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 394,
          "line_end": 412,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '",
          "description": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "git_repo = GitConfigRepo(cache_dir=cache_dir)",
          "description": "Assign git_repo = GitConfigRepo(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "invalid_urls = ['', 'not-a-url', 'ftp://invalid.com/repo.git', \"javascript:alert('xss')\"]",
          "description": "Assign invalid_urls = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "git_repo.clone_or_pull(source_name='test-invalid', git_url=invalid_url, branch='master')",
          "description": "Call git_repo.clone_or_pull()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Invalid Git Url",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_git_sources_e2e.py:394"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5cbfaadf0c4d",
      "title": "E2E Source Name Validation",
      "overview": "Workflow: E2E Test 8: Error handling - invalid source names\n\nSteps:\n1. Try to add sources with invalid names\n2. Verify validation errors",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "dc3326f6",
          "test_name": "test_e2e_source_name_validation",
          "category": "workflow",
          "code": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '\ncache_dir, config_dir = temp_dirs\nsource_manager = SourceManager(config_dir=config_dir)\ninvalid_names = ['', 'name with spaces', 'name/with/slashes', 'name@with@symbols', 'name.with.dots', '123-only-numbers-start-is-ok', 'name!exclamation']\nvalid_git_url = 'https://github.com/test/repo.git'\nfor invalid_name in invalid_names[:-2]:\n    if invalid_name == '123-only-numbers-start-is-ok':\n        continue\n    with pytest.raises(ValueError, match='Invalid source name'):\n        source_manager.add_source(name=invalid_name, git_url=valid_git_url)",
          "language": "Python",
          "description": "Workflow: E2E Test 8: Error handling - invalid source names\n\nSteps:\n1. Try to add sources with invalid names\n2. Verify validation errors",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 414,
          "line_end": 442,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '",
          "description": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "source_manager = SourceManager(config_dir=config_dir)",
          "description": "Assign source_manager = SourceManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "invalid_names = ['', 'name with spaces', 'name/with/slashes', 'name@with@symbols', 'name.with.dots', '123-only-numbers-start-is-ok', 'name!exclamation']",
          "description": "Assign invalid_names = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "valid_git_url = 'https://github.com/test/repo.git'",
          "description": "Assign valid_git_url = 'https://github.com/test/repo.git'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "source_manager.add_source(name=invalid_name, git_url=valid_git_url)",
          "description": "Call source_manager.add_source()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Source Name Validation",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_git_sources_e2e.py:414"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "85a89d8c798a",
      "title": "E2E Registry Persistence",
      "overview": "Workflow: E2E Test 9: Registry persistence across instances\n\nSteps:\n1. Add source with one SourceManager instance\n2. Create new SourceManager instance\n3. Verify source persists\n4. Modify source with new instance\n5. Verify changes persist",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4b861a9f",
          "test_name": "test_e2e_registry_persistence",
          "category": "workflow",
          "code": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nmanager1 = SourceManager(config_dir=config_dir)\nmanager1.add_source(name='persistent-source', git_url=git_url, priority=25)\nmanager2 = SourceManager(config_dir=config_dir)\nsources = manager2.list_sources()\nassert len(sources) == 1\nassert sources[0]['name'] == 'persistent-source'\nassert sources[0]['priority'] == 25\nmanager2.add_source(name='persistent-source', git_url=git_url, priority=50)\nmanager3 = SourceManager(config_dir=config_dir)\nsource = manager3.get_source('persistent-source')\nassert source['priority'] == 50",
          "language": "Python",
          "description": "Workflow: E2E Test 9: Registry persistence across instances\n\nSteps:\n1. Add source with one SourceManager instance\n2. Create new SourceManager instance\n3. Verify source persists\n4. Modify source with new instance\n5. Verify changes persist",
          "expected_behavior": "assert source['priority'] == 50",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
          "line_start": 444,
          "line_end": 483,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "pathlib",
            "git",
            "pytest",
            "skill_seekers.mcp.git_repo",
            "skill_seekers.mcp.source_manager",
            "mcp",
            "mcp.types",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server",
            "skill_seekers.mcp.server"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '",
          "description": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '",
          "expected_result": null,
          "verification": "assert len(sources) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache_dir, config_dir = temp_dirs",
          "description": "Assign unknown = temp_dirs",
          "expected_result": null,
          "verification": "assert sources[0]['name'] == 'persistent-source'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir, repo = temp_git_repo",
          "description": "Assign unknown = temp_git_repo",
          "expected_result": null,
          "verification": "assert sources[0]['priority'] == 25",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "git_url = f'file://{repo_dir}'",
          "description": "Assign git_url = value",
          "expected_result": null,
          "verification": "assert source['priority'] == 50",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "manager1 = SourceManager(config_dir=config_dir)",
          "description": "Assign manager1 = SourceManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "manager1.add_source(name='persistent-source', git_url=git_url, priority=25)",
          "description": "Call manager1.add_source()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "manager2 = SourceManager(config_dir=config_dir)",
          "description": "Assign manager2 = SourceManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "sources = manager2.list_sources()",
          "description": "Assign sources = manager2.list_sources(...)",
          "expected_result": null,
          "verification": "assert len(sources) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "manager2.add_source(name='persistent-source', git_url=git_url, priority=50)",
          "description": "Call manager2.add_source()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "manager3 = SourceManager(config_dir=config_dir)",
          "description": "Assign manager3 = SourceManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "source = manager3.get_source('persistent-source')",
          "description": "Assign source = manager3.get_source(...)",
          "expected_result": null,
          "verification": "assert source['priority'] == 50",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Registry Persistence",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_git_sources_e2e.py:444"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6c01f82338af",
      "title": "With Configs Prefix",
      "overview": "Workflow: Test resolution with configs/ prefix.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c2beb8b6",
          "test_name": "test_with_configs_prefix",
          "category": "workflow",
          "code": "'Test resolution with configs/ prefix.'\nconfigs_dir = tmp_path / 'configs'\nconfigs_dir.mkdir()\nconfig_file = configs_dir / 'test.json'\nconfig_file.write_text('{\"name\": \"test\"}')\nimport os\noriginal_cwd = os.getcwd()\ntry:\n    os.chdir(tmp_path)\n    result = resolve_config_path('test.json', auto_fetch=False)\n    assert result is not None\n    assert result.exists()\n    assert result.name == 'test.json'\nfinally:\n    os.chdir(original_cwd)",
          "language": "Python",
          "description": "Workflow: Test resolution with configs/ prefix.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
          "line_start": 239,
          "line_end": 258,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "httpx",
            "pytest",
            "skill_seekers.cli.config_fetcher",
            "os",
            "os"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test resolution with configs/ prefix.'",
          "description": "'Test resolution with configs/ prefix.'",
          "expected_result": null,
          "verification": "assert result is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "configs_dir = tmp_path / 'configs'",
          "description": "Assign configs_dir = value",
          "expected_result": null,
          "verification": "assert result.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "configs_dir.mkdir()",
          "description": "Call configs_dir.mkdir()",
          "expected_result": null,
          "verification": "assert result.name == 'test.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config_file = configs_dir / 'test.json'",
          "description": "Assign config_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config_file.write_text('{\"name\": \"test\"}')",
          "description": "Call config_file.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "original_cwd = os.getcwd()",
          "description": "Assign original_cwd = os.getcwd(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "os.chdir(tmp_path)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "result = resolve_config_path('test.json', auto_fetch=False)",
          "description": "Assign result = resolve_config_path(...)",
          "expected_result": null,
          "verification": "assert result is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "os.chdir(original_cwd)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "With Configs Prefix",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_config_fetcher.py:239"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9e22cb477351",
      "title": "Config Name Normalization",
      "overview": "Workflow: Test various config name formats.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "347d551e",
          "test_name": "test_config_name_normalization",
          "category": "workflow",
          "code": "'Test various config name formats.'\nconfigs_dir = tmp_path / 'configs'\nconfigs_dir.mkdir()\nconfig_file = configs_dir / 'react.json'\nconfig_file.write_text('{\"name\": \"react\"}')\nimport os\noriginal_cwd = os.getcwd()\ntry:\n    os.chdir(tmp_path)\n    test_cases = ['react.json', 'configs/react.json']\n    for config_name in test_cases:\n        result = resolve_config_path(config_name, auto_fetch=False)\n        assert result is not None, f'Failed for {config_name}'\n        assert result.exists()\n        assert result.name == 'react.json'\nfinally:\n    os.chdir(original_cwd)",
          "language": "Python",
          "description": "Workflow: Test various config name formats.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
          "line_start": 290,
          "line_end": 312,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "httpx",
            "pytest",
            "skill_seekers.cli.config_fetcher",
            "os",
            "os"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test various config name formats.'",
          "description": "'Test various config name formats.'",
          "expected_result": null,
          "verification": "assert result is not None, f'Failed for {config_name}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "configs_dir = tmp_path / 'configs'",
          "description": "Assign configs_dir = value",
          "expected_result": null,
          "verification": "assert result.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "configs_dir.mkdir()",
          "description": "Call configs_dir.mkdir()",
          "expected_result": null,
          "verification": "assert result.name == 'react.json'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config_file = configs_dir / 'react.json'",
          "description": "Assign config_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config_file.write_text('{\"name\": \"react\"}')",
          "description": "Call config_file.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "original_cwd = os.getcwd()",
          "description": "Assign original_cwd = os.getcwd(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "os.chdir(tmp_path)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "test_cases = ['react.json', 'configs/react.json']",
          "description": "Assign test_cases = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "os.chdir(original_cwd)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "result = resolve_config_path(config_name, auto_fetch=False)",
          "description": "Assign result = resolve_config_path(...)",
          "expected_result": null,
          "verification": "assert result is not None, f'Failed for {config_name}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Config Name Normalization",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_config_fetcher.py:290"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2353c5b4be0f",
      "title": "Classify Files",
      "overview": "Workflow: Test classify_files separates code and docs correctly.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c3fda686",
          "test_name": "test_classify_files",
          "category": "workflow",
          "code": "'Test classify_files separates code and docs correctly.'\n(tmp_path / 'src').mkdir()\n(tmp_path / 'src' / 'main.py').write_text(\"print('hello')\")\n(tmp_path / 'src' / 'utils.js').write_text('function(){}')\n(tmp_path / 'docs').mkdir()\n(tmp_path / 'README.md').write_text('# README')\n(tmp_path / 'docs' / 'guide.md').write_text('# Guide')\n(tmp_path / 'docs' / 'api.rst').write_text('API')\n(tmp_path / 'node_modules').mkdir()\n(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')\nfetcher = GitHubThreeStreamFetcher('https://github.com/test/repo')\ncode_files, doc_files = fetcher.classify_files(tmp_path)\ncode_paths = [f.name for f in code_files]\nassert 'main.py' in code_paths\nassert 'utils.js' in code_paths\nassert 'lib.js' not in code_paths\ndoc_paths = [f.name for f in doc_files]\nassert 'README.md' in doc_paths\nassert 'guide.md' in doc_paths\nassert 'api.rst' in doc_paths",
          "language": "Python",
          "description": "Workflow: Test classify_files separates code and docs correctly.",
          "expected_behavior": "assert 'api.rst' in doc_paths",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
          "line_start": 105,
          "line_end": 133,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test classify_files separates code and docs correctly.'",
          "description": "'Test classify_files separates code and docs correctly.'",
          "expected_result": null,
          "verification": "assert 'main.py' in code_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "(tmp_path / 'src').mkdir()",
          "description": "Call unknown.mkdir()",
          "expected_result": null,
          "verification": "assert 'utils.js' in code_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "(tmp_path / 'src' / 'main.py').write_text(\"print('hello')\")",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert 'lib.js' not in code_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(tmp_path / 'src' / 'utils.js').write_text('function(){}')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert 'README.md' in doc_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "(tmp_path / 'docs').mkdir()",
          "description": "Call unknown.mkdir()",
          "expected_result": null,
          "verification": "assert 'guide.md' in doc_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(tmp_path / 'README.md').write_text('# README')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert 'api.rst' in doc_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "(tmp_path / 'docs' / 'guide.md').write_text('# Guide')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "(tmp_path / 'docs' / 'api.rst').write_text('API')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "(tmp_path / 'node_modules').mkdir()",
          "description": "Call unknown.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "fetcher = GitHubThreeStreamFetcher('https://github.com/test/repo')",
          "description": "Assign fetcher = GitHubThreeStreamFetcher(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "code_files, doc_files = fetcher.classify_files(tmp_path)",
          "description": "Assign unknown = fetcher.classify_files(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "code_paths = [f.name for f in code_files]",
          "description": "Assign code_paths = value",
          "expected_result": null,
          "verification": "assert 'main.py' in code_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "doc_paths = [f.name for f in doc_files]",
          "description": "Assign doc_paths = value",
          "expected_result": null,
          "verification": "assert 'README.md' in doc_paths",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Classify Files",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_github_fetcher.py:105"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "268eb4dbbcba",
      "title": "Detect Python With Confidence",
      "overview": "Workflow: Test Python detection returns language and confidence",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5932c544",
          "test_name": "test_detect_python_with_confidence",
          "category": "workflow",
          "code": "'Test Python detection returns language and confidence'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"def hello():\\n    print('world')\\n    return True\"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'python')\nself.assertGreater(confidence, 0.4)\nself.assertLessEqual(confidence, 1.0)",
          "language": "Python",
          "description": "Workflow: Test Python detection returns language and confidence",
          "expected_behavior": "self.assertLessEqual(confidence, 1.0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 40,
          "line_end": 54,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Python detection returns language and confidence'",
          "description": "'Test Python detection returns language and confidence'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = \"def hello():\\n    print('world')\\n    return True\"",
          "description": "Assign code = \"def hello():\\n    print('world')\\n    return True\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'python')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.4)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertLessEqual(confidence, 1.0)",
          "description": "Call self.assertLessEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Python With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:40"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a5def7288dd7",
      "title": "Detect Javascript With Confidence",
      "overview": "Workflow: Test JavaScript detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5942f5df",
          "test_name": "test_detect_javascript_with_confidence",
          "category": "workflow",
          "code": "'Test JavaScript detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'javascript')\nself.assertGreater(confidence, 0.5)",
          "language": "Python",
          "description": "Workflow: Test JavaScript detection",
          "expected_behavior": "self.assertGreater(confidence, 0.5)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 56,
          "line_end": 69,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test JavaScript detection'",
          "description": "'Test JavaScript detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"",
          "description": "Assign code = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'javascript')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.5)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Javascript With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:56"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "758d02dcc573",
      "title": "Detect Cpp With Confidence",
      "overview": "Workflow: Test C++ detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b50ed04d",
          "test_name": "test_detect_cpp_with_confidence",
          "category": "workflow",
          "code": "'Test C++ detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'cpp')\nself.assertGreater(confidence, 0.5)",
          "language": "Python",
          "description": "Workflow: Test C++ detection",
          "expected_behavior": "self.assertGreater(confidence, 0.5)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 71,
          "line_end": 84,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test C++ detection'",
          "description": "'Test C++ detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'",
          "description": "Assign code = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'cpp')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.5)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Cpp With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:71"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "fd9108a8328f",
      "title": "Detect Unknown Low Confidence",
      "overview": "Workflow: Test unknown language returns low confidence",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "705db234",
          "test_name": "test_detect_unknown_low_confidence",
          "category": "workflow",
          "code": "'Test unknown language returns low confidence'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = 'this is not code at all just plain text'\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'unknown')\nself.assertLess(confidence, 0.3)",
          "language": "Python",
          "description": "Workflow: Test unknown language returns low confidence",
          "expected_behavior": "self.assertLess(confidence, 0.3)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 86,
          "line_end": 99,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test unknown language returns low confidence'",
          "description": "'Test unknown language returns low confidence'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = 'this is not code at all just plain text'",
          "description": "Assign code = 'this is not code at all just plain text'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'unknown')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertLess(confidence, 0.3)",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Unknown Low Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:86"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "1e1172bdb310",
      "title": "Detect Scss With Confidence",
      "overview": "Workflow: Test SCSS detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "956a066a",
          "test_name": "test_detect_scss_with_confidence",
          "category": "workflow",
          "code": "'Test SCSS detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'scss')\nself.assertGreater(confidence, 0.8)",
          "language": "Python",
          "description": "Workflow: Test SCSS detection",
          "expected_behavior": "self.assertGreater(confidence, 0.8)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 122,
          "line_end": 148,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test SCSS detection'",
          "description": "'Test SCSS detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '",
          "description": "Assign code = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'scss')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.8)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Scss With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:122"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "12afd0dc31a5",
      "title": "Detect Dart With Confidence",
      "overview": "Workflow: Test Dart detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bb83a4b1",
          "test_name": "test_detect_dart_with_confidence",
          "category": "workflow",
          "code": "'Test Dart detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'dart')\nself.assertGreater(confidence, 0.6)",
          "language": "Python",
          "description": "Workflow: Test Dart detection",
          "expected_behavior": "self.assertGreater(confidence, 0.6)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 150,
          "line_end": 172,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Dart detection'",
          "description": "'Test Dart detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"",
          "description": "Assign code = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'dart')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.6)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Dart With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:150"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9494e2522bde",
      "title": "Detect Scala With Confidence",
      "overview": "Workflow: Test Scala detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f88a839c",
          "test_name": "test_detect_scala_with_confidence",
          "category": "workflow",
          "code": "'Test Scala detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'scala')\nself.assertGreater(confidence, 0.7)",
          "language": "Python",
          "description": "Workflow: Test Scala detection",
          "expected_behavior": "self.assertGreater(confidence, 0.7)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 174,
          "line_end": 195,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Scala detection'",
          "description": "'Test Scala detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '",
          "description": "Assign code = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'scala')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.7)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Scala With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:174"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0148d4bd9b07",
      "title": "Detect Sass With Confidence",
      "overview": "Workflow: Test SASS detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "981c2491",
          "test_name": "test_detect_sass_with_confidence",
          "category": "workflow",
          "code": "'Test SASS detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'sass')\nself.assertGreater(confidence, 0.8)",
          "language": "Python",
          "description": "Workflow: Test SASS detection",
          "expected_behavior": "self.assertGreater(confidence, 0.8)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 197,
          "line_end": 220,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test SASS detection'",
          "description": "'Test SASS detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '",
          "description": "Assign code = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'sass')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.8)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Sass With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:197"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5a9546a12556",
      "title": "Detect Elixir With Confidence",
      "overview": "Workflow: Test Elixir detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b0934b21",
          "test_name": "test_detect_elixir_with_confidence",
          "category": "workflow",
          "code": "'Test Elixir detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'elixir')\nself.assertGreater(confidence, 0.8)",
          "language": "Python",
          "description": "Workflow: Test Elixir detection",
          "expected_behavior": "self.assertGreater(confidence, 0.8)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 222,
          "line_end": 250,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Elixir detection'",
          "description": "'Test Elixir detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '",
          "description": "Assign code = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'elixir')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.8)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Elixir With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:222"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0e6e748e9dda",
      "title": "Detect Lua With Confidence",
      "overview": "Workflow: Test Lua detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "cfaed997",
          "test_name": "test_detect_lua_with_confidence",
          "category": "workflow",
          "code": "'Test Lua detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'lua')\nself.assertGreater(confidence, 0.7)",
          "language": "Python",
          "description": "Workflow: Test Lua detection",
          "expected_behavior": "self.assertGreater(confidence, 0.7)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
          "line_start": 252,
          "line_end": 275,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "skill_seekers.cli.pdf_extractor_poc",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz",
            "unittest.mock",
            "fitz"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Lua detection'",
          "description": "'Test Lua detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor.language_detector = LanguageDetector(min_confidence=0.15)",
          "description": "Assign extractor.language_detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '",
          "description": "Assign code = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "language, confidence = extractor.detect_language_from_code(code)",
          "description": "Assign unknown = extractor.detect_language_from_code(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(language, 'lua')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(confidence, 0.7)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Lua With Confidence",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_extractor.py:252"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ecebc0d6f331",
      "title": "Router Generator Init",
      "overview": "Workflow: Test router generator initialization.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "84956d78",
          "test_name": "test_router_generator_init",
          "category": "workflow",
          "code": "'Test router generator initialization.'\nconfig1 = {'name': 'test-oauth', 'description': 'OAuth authentication', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth']}}\nconfig2 = {'name': 'test-async', 'description': 'Async operations', 'base_url': 'https://example.com', 'categories': {'async': ['async', 'await']}}\nconfig_path1 = tmp_path / 'config1.json'\nconfig_path2 = tmp_path / 'config2.json'\nwith open(config_path1, 'w') as f:\n    json.dump(config1, f)\nwith open(config_path2, 'w') as f:\n    json.dump(config2, f)\ngenerator = RouterGenerator([str(config_path1), str(config_path2)])\nassert generator.router_name == 'test'\nassert len(generator.configs) == 2\nassert generator.github_streams is None",
          "language": "Python",
          "description": "Workflow: Test router generator initialization.",
          "expected_behavior": "assert generator.github_streams is None",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 20,
          "line_end": 49,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test router generator initialization.'",
          "description": "'Test router generator initialization.'",
          "expected_result": null,
          "verification": "assert generator.router_name == 'test'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config1 = {'name': 'test-oauth', 'description': 'OAuth authentication', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth']}}",
          "description": "Assign config1 = value",
          "expected_result": null,
          "verification": "assert len(generator.configs) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config2 = {'name': 'test-async', 'description': 'Async operations', 'base_url': 'https://example.com', 'categories': {'async': ['async', 'await']}}",
          "description": "Assign config2 = value",
          "expected_result": null,
          "verification": "assert generator.github_streams is None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config_path1 = tmp_path / 'config1.json'",
          "description": "Assign config_path1 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config_path2 = tmp_path / 'config2.json'",
          "description": "Assign config_path2 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "generator = RouterGenerator([str(config_path1), str(config_path2)])",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert generator.router_name == 'test'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "json.dump(config1, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "json.dump(config2, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Router Generator Init",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:20"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e50d5b87da10",
      "title": "Infer Router Name",
      "overview": "Workflow: Test router name inference from sub-skill names.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f7ccecdf",
          "test_name": "test_infer_router_name",
          "category": "workflow",
          "code": "'Test router name inference from sub-skill names.'\nconfig1 = {'name': 'fastmcp-oauth', 'base_url': 'https://example.com'}\nconfig2 = {'name': 'fastmcp-async', 'base_url': 'https://example.com'}\nconfig_path1 = tmp_path / 'config1.json'\nconfig_path2 = tmp_path / 'config2.json'\nwith open(config_path1, 'w') as f:\n    json.dump(config1, f)\nwith open(config_path2, 'w') as f:\n    json.dump(config2, f)\ngenerator = RouterGenerator([str(config_path1), str(config_path2)])\nassert generator.router_name == 'fastmcp'",
          "language": "Python",
          "description": "Workflow: Test router name inference from sub-skill names.",
          "expected_behavior": "assert generator.router_name == 'fastmcp'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 51,
          "line_end": 66,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test router name inference from sub-skill names.'",
          "description": "'Test router name inference from sub-skill names.'",
          "expected_result": null,
          "verification": "assert generator.router_name == 'fastmcp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config1 = {'name': 'fastmcp-oauth', 'base_url': 'https://example.com'}",
          "description": "Assign config1 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config2 = {'name': 'fastmcp-async', 'base_url': 'https://example.com'}",
          "description": "Assign config2 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config_path1 = tmp_path / 'config1.json'",
          "description": "Assign config_path1 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config_path2 = tmp_path / 'config2.json'",
          "description": "Assign config_path2 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "generator = RouterGenerator([str(config_path1), str(config_path2)])",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert generator.router_name == 'fastmcp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "json.dump(config1, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "json.dump(config2, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Infer Router Name",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:51"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2d7e4e660265",
      "title": "Extract Routing Keywords Basic",
      "overview": "Workflow: Test basic keyword extraction without GitHub.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "997a58df",
          "test_name": "test_extract_routing_keywords_basic",
          "category": "workflow",
          "code": "'Test basic keyword extraction without GitHub.'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth'], 'tokens': ['token', 'jwt']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nrouting = generator.extract_routing_keywords()\nassert 'test-oauth' in routing\nkeywords = routing['test-oauth']\nassert 'authentication' in keywords\nassert 'tokens' in keywords\nassert 'oauth' in keywords",
          "language": "Python",
          "description": "Workflow: Test basic keyword extraction without GitHub.",
          "expected_behavior": "assert 'oauth' in keywords",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 68,
          "line_end": 87,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic keyword extraction without GitHub.'",
          "description": "'Test basic keyword extraction without GitHub.'",
          "expected_result": null,
          "verification": "assert 'test-oauth' in routing",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth'], 'tokens': ['token', 'jwt']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert 'authentication' in keywords",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert 'tokens' in keywords",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generator = RouterGenerator([str(config_path)])",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert 'oauth' in keywords",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "routing = generator.extract_routing_keywords()",
          "description": "Assign routing = generator.extract_routing_keywords(...)",
          "expected_result": null,
          "verification": "assert 'test-oauth' in routing",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "keywords = routing['test-oauth']",
          "description": "Assign keywords = value",
          "expected_result": null,
          "verification": "assert 'authentication' in keywords",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Routing Keywords Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:68"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e0d85dde39fa",
      "title": "Router With Github Metadata",
      "overview": "Workflow: Test router generator with GitHub metadata.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "dc5ba794",
          "test_name": "test_router_with_github_metadata",
          "category": "workflow",
          "code": "'Test router generator with GitHub metadata.'\nconfig = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://github.com/test/repo', 'categories': {'oauth': ['oauth', 'auth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test Project\\n\\nA test OAuth library.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'OAuth helper'}, common_problems=[{'title': 'OAuth fails on redirect', 'number': 42, 'state': 'open', 'comments': 15, 'labels': ['bug', 'oauth']}], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 20}, {'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nassert generator.github_metadata is not None\nassert generator.github_metadata['stars'] == 1234\nassert generator.github_docs is not None\nassert generator.github_docs['readme'].startswith('# Test Project')\nassert generator.github_issues is not None",
          "language": "Python",
          "description": "Workflow: Test router generator with GitHub metadata.",
          "expected_behavior": "assert generator.github_issues is not None",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 93,
          "line_end": 139,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test router generator with GitHub metadata.'",
          "description": "'Test router generator with GitHub metadata.'",
          "expected_result": null,
          "verification": "assert generator.github_metadata is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://github.com/test/repo', 'categories': {'oauth': ['oauth', 'auth']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert generator.github_metadata['stars'] == 1234",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert generator.github_docs is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": "assert generator.github_docs['readme'].startswith('# Test Project')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme='# Test Project\\n\\nA test OAuth library.', contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": "assert generator.github_issues is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'OAuth helper'}, common_problems=[{'title': 'OAuth fails on redirect', 'number': 42, 'state': 'open', 'comments': 15, 'labels': ['bug', 'oauth']}], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 20}, {'label': 'bug', 'count': 10}])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert generator.github_metadata is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Router With Github Metadata",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:93"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f035e38c4bac",
      "title": "Extract Keywords With Github Labels",
      "overview": "Workflow: Test keyword extraction with GitHub issue labels (2x weight).",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "23b763ea",
          "test_name": "test_extract_keywords_with_github_labels",
          "category": "workflow",
          "code": "'Test keyword extraction with GitHub issue labels (2x weight).'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth', 'auth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 50}, {'label': 'authentication', 'count': 30}, {'label': 'bug', 'count': 20}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nrouting = generator.extract_routing_keywords()\nkeywords = routing['test-oauth']\noauth_count = keywords.count('oauth')\nassert oauth_count >= 4",
          "language": "Python",
          "description": "Workflow: Test keyword extraction with GitHub issue labels (2x weight).",
          "expected_behavior": "assert oauth_count >= 4",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 141,
          "line_end": 174,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test keyword extraction with GitHub issue labels (2x weight).'",
          "description": "'Test keyword extraction with GitHub issue labels (2x weight).'",
          "expected_result": null,
          "verification": "assert oauth_count >= 4",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth', 'auth']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme=None, contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={}, common_problems=[], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 50}, {'label': 'authentication', 'count': 30}, {'label': 'bug', 'count': 20}])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "routing = generator.extract_routing_keywords()",
          "description": "Assign routing = generator.extract_routing_keywords(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "keywords = routing['test-oauth']",
          "description": "Assign keywords = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "oauth_count = keywords.count('oauth')",
          "description": "Assign oauth_count = keywords.count(...)",
          "expected_result": null,
          "verification": "assert oauth_count >= 4",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Keywords With Github Labels",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_generate_router_github.py:141"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "706f151e5034",
      "title": "Generate Skill Md With Github",
      "overview": "Workflow: Test SKILL.md generation with GitHub metadata.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "31845373",
          "test_name": "test_generate_skill_md_with_github",
          "category": "workflow",
          "code": "'Test SKILL.md generation with GitHub metadata.'\nconfig = {'name': 'test-oauth', 'description': 'OAuth authentication skill', 'base_url': 'https://github.com/test/oauth', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# OAuth Library\\n\\nQuick start: Install with pip install oauth', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 5000, 'forks': 200, 'language': 'Python', 'description': 'OAuth 2.0 library'}, common_problems=[{'title': 'Redirect URI mismatch', 'number': 100, 'state': 'open', 'comments': 25, 'labels': ['bug', 'oauth']}, {'title': 'Token refresh fails', 'number': 95, 'state': 'open', 'comments': 18, 'labels': ['oauth']}], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nskill_md = generator.generate_skill_md()\nassert '\u2b50 5,000' in skill_md\nassert 'Python' in skill_md\nassert 'OAuth 2.0 library' in skill_md\nassert '## Quick Start' in skill_md\nassert 'OAuth Library' in skill_md\nassert '## Common Issues' in skill_md or '## Examples' in skill_md\nassert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
          "language": "Python",
          "description": "Workflow: Test SKILL.md generation with GitHub metadata.",
          "expected_behavior": "assert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 176,
          "line_end": 241,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test SKILL.md generation with GitHub metadata.'",
          "description": "'Test SKILL.md generation with GitHub metadata.'",
          "expected_result": null,
          "verification": "assert '\u2b50 5,000' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-oauth', 'description': 'OAuth authentication skill', 'base_url': 'https://github.com/test/oauth', 'categories': {'oauth': ['oauth']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert 'Python' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert 'OAuth 2.0 library' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": "assert '## Quick Start' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme='# OAuth Library\\n\\nQuick start: Install with pip install oauth', contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": "assert 'OAuth Library' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={'stars': 5000, 'forks': 200, 'language': 'Python', 'description': 'OAuth 2.0 library'}, common_problems=[{'title': 'Redirect URI mismatch', 'number': 100, 'state': 'open', 'comments': 25, 'labels': ['bug', 'oauth']}, {'title': 'Token refresh fails', 'number': 95, 'state': 'open', 'comments': 18, 'labels': ['oauth']}], known_solutions=[], top_labels=[])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": "assert '## Common Issues' in skill_md or '## Examples' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": "assert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "skill_md = generator.generate_skill_md()",
          "description": "Assign skill_md = generator.generate_skill_md(...)",
          "expected_result": null,
          "verification": "assert '\u2b50 5,000' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Skill Md With Github",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:176"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "af430b496a48",
      "title": "Generate Skill Md Without Github",
      "overview": "Workflow: Test SKILL.md generation without GitHub (backward compat).",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2f9ec2e1",
          "test_name": "test_generate_skill_md_without_github",
          "category": "workflow",
          "code": "'Test SKILL.md generation without GitHub (backward compat).'\nconfig = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nskill_md = generator.generate_skill_md()\nassert '\u2b50' not in skill_md\nassert 'Repository Info' not in skill_md\nassert 'Quick Start (from README)' not in skill_md\nassert 'Common Issues (from GitHub)' not in skill_md\nassert 'When to Use This Skill' in skill_md\nassert 'How It Works' in skill_md",
          "language": "Python",
          "description": "Workflow: Test SKILL.md generation without GitHub (backward compat).",
          "expected_behavior": "assert 'How It Works' in skill_md",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 244,
          "line_end": 269,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test SKILL.md generation without GitHub (backward compat).'",
          "description": "'Test SKILL.md generation without GitHub (backward compat).'",
          "expected_result": null,
          "verification": "assert '\u2b50' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert 'Repository Info' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert 'Quick Start (from README)' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generator = RouterGenerator([str(config_path)])",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert 'Common Issues (from GitHub)' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_md = generator.generate_skill_md()",
          "description": "Assign skill_md = generator.generate_skill_md(...)",
          "expected_result": null,
          "verification": "assert 'When to Use This Skill' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": "assert 'How It Works' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Skill Md Without Github",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_generate_router_github.py:244"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6a2dffb9ece1",
      "title": "Generate Subskill Issues Section",
      "overview": "Workflow: Test generation of issues section for sub-skills.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2b19ef0b",
          "test_name": "test_generate_subskill_issues_section",
          "category": "workflow",
          "code": "'Test generation of issues section for sub-skills.'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth redirect fails', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token expiration issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth']}], known_solutions=[{'title': 'Fixed OAuth flow', 'number': 40, 'state': 'closed', 'comments': 10, 'labels': ['oauth']}], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nissues_section = generator.generate_subskill_issues_section('test-oauth', ['oauth'])\nassert 'Common Issues (from GitHub)' in issues_section\nassert 'OAuth redirect fails' in issues_section\nassert 'Issue #50' in issues_section\nassert '20 comments' in issues_section\nassert '\ud83d\udd34' in issues_section\nassert '\u2705' in issues_section",
          "language": "Python",
          "description": "Workflow: Test generation of issues section for sub-skills.",
          "expected_behavior": "assert '\u2705' in issues_section",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 275,
          "line_end": 332,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test generation of issues section for sub-skills.'",
          "description": "'Test generation of issues section for sub-skills.'",
          "expected_result": null,
          "verification": "assert 'Common Issues (from GitHub)' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert 'OAuth redirect fails' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert 'Issue #50' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": "assert '20 comments' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme=None, contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": "assert '\ud83d\udd34' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth redirect fails', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token expiration issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth']}], known_solutions=[{'title': 'Fixed OAuth flow', 'number': 40, 'state': 'closed', 'comments': 10, 'labels': ['oauth']}], top_labels=[])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": "assert '\u2705' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "issues_section = generator.generate_subskill_issues_section('test-oauth', ['oauth'])",
          "description": "Assign issues_section = generator.generate_subskill_issues_section(...)",
          "expected_result": null,
          "verification": "assert 'Common Issues (from GitHub)' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Subskill Issues Section",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:275"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ffe278705782",
      "title": "Generate Subskill Issues No Matches",
      "overview": "Workflow: Test issues section when no issues match the topic.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "11694666",
          "test_name": "test_generate_subskill_issues_no_matches",
          "category": "workflow",
          "code": "'Test issues section when no issues match the topic.'\nconfig = {'name': 'test-async', 'base_url': 'https://example.com', 'categories': {'async': ['async']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth fails', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['oauth']}], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nissues_section = generator.generate_subskill_issues_section('test-async', ['async'])\nassert 'Common Issues (from GitHub)' in issues_section\nassert 'Other' in issues_section\nassert 'OAuth fails' in issues_section",
          "language": "Python",
          "description": "Workflow: Test issues section when no issues match the topic.",
          "expected_behavior": "assert 'OAuth fails' in issues_section",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
          "line_start": 334,
          "line_end": 373,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test issues section when no issues match the topic.'",
          "description": "'Test issues section when no issues match the topic.'",
          "expected_result": null,
          "verification": "assert 'Common Issues (from GitHub)' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-async', 'base_url': 'https://example.com', 'categories': {'async': ['async']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert 'Other' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert 'OAuth fails' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme=None, contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth fails', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['oauth']}], known_solutions=[], top_labels=[])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "generator = RouterGenerator([str(config_path)], github_streams=github_streams)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "issues_section = generator.generate_subskill_issues_section('test-async', ['async'])",
          "description": "Assign issues_section = generator.generate_subskill_issues_section(...)",
          "expected_result": null,
          "verification": "assert 'Common Issues (from GitHub)' in issues_section",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Subskill Issues No Matches",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_generate_router_github.py:334"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "66920b680749",
      "title": "Creates Subdirectory Per Source",
      "overview": "Workflow: Test that each doc source gets its own subdirectory.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5295fab3",
          "test_name": "test_creates_subdirectory_per_source",
          "category": "workflow",
          "code": "'Test that each doc source gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_docs_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'source_a', 'base_url': 'https://a.com', 'total_pages': 5, 'refs_dir': refs_dir1}, {'source_id': 'source_b', 'base_url': 'https://b.com', 'total_pages': 3, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\ndocs_dir = os.path.join(builder.skill_dir, 'references', 'documentation')\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_a')))\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
          "language": "Python",
          "description": "Workflow: Test that each doc source gets its own subdirectory.",
          "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 103,
          "line_end": 139,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that each doc source gets its own subdirectory.'",
          "description": "'Test that each doc source gets its own subdirectory.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "refs_dir1 = os.path.join(self.temp_dir, 'refs1')",
          "description": "Assign refs_dir1 = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "refs_dir2 = os.path.join(self.temp_dir, 'refs2')",
          "description": "Assign refs_dir2 = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "os.makedirs(refs_dir1)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "os.makedirs(refs_dir2)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "config = {'name': 'test_docs_refs', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "scraped_data = {'documentation': [{'source_id': 'source_a', 'base_url': 'https://a.com', 'total_pages': 5, 'refs_dir': refs_dir1}, {'source_id': 'source_b', 'base_url': 'https://b.com', 'total_pages': 3, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "builder._generate_docs_references(scraped_data['documentation'])",
          "description": "Call builder._generate_docs_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "docs_dir = os.path.join(builder.skill_dir, 'references', 'documentation')",
          "description": "Assign docs_dir = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_a')))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Subdirectory Per Source",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_multi_source.py:103"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "55ad11cdceda",
      "title": "Creates Index Per Source",
      "overview": "Workflow: Test that each source subdirectory has its own index.md.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "457c3874",
          "test_name": "test_creates_index_per_source",
          "category": "workflow",
          "code": "'Test that each source subdirectory has its own index.md.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir = os.path.join(self.temp_dir, 'refs')\nos.makedirs(refs_dir)\nconfig = {'name': 'test_source_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'my_source', 'base_url': 'https://example.com', 'total_pages': 10, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nsource_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'my_source', 'index.md')\nself.assertTrue(os.path.exists(source_index))\nwith open(source_index) as f:\n    content = f.read()\n    self.assertIn('my_source', content)\n    self.assertIn('https://example.com', content)",
          "language": "Python",
          "description": "Workflow: Test that each source subdirectory has its own index.md.",
          "expected_behavior": "self.assertTrue(os.path.exists(source_index))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 141,
          "line_end": 174,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that each source subdirectory has its own index.md.'",
          "description": "'Test that each source subdirectory has its own index.md.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "refs_dir = os.path.join(self.temp_dir, 'refs')",
          "description": "Assign refs_dir = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "os.makedirs(refs_dir)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config = {'name': 'test_source_index', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "scraped_data = {'documentation': [{'source_id': 'my_source', 'base_url': 'https://example.com', 'total_pages': 10, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "builder._generate_docs_references(scraped_data['documentation'])",
          "description": "Call builder._generate_docs_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "source_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'my_source', 'index.md')",
          "description": "Assign source_index = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(os.path.exists(source_index))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('my_source', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('https://example.com', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Index Per Source",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_multi_source.py:141"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9052d7085f07",
      "title": "Creates Main Index Listing All Sources",
      "overview": "Workflow: Test that main index.md lists all documentation sources.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "514fd982",
          "test_name": "test_creates_main_index_listing_all_sources",
          "category": "workflow",
          "code": "'Test that main index.md lists all documentation sources.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_main_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'docs_one', 'base_url': 'https://one.com', 'total_pages': 10, 'refs_dir': refs_dir1}, {'source_id': 'docs_two', 'base_url': 'https://two.com', 'total_pages': 20, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nmain_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'index.md')\nself.assertTrue(os.path.exists(main_index))\nwith open(main_index) as f:\n    content = f.read()\n    self.assertIn('docs_one', content)\n    self.assertIn('docs_two', content)\n    self.assertIn('2 documentation sources', content)",
          "language": "Python",
          "description": "Workflow: Test that main index.md lists all documentation sources.",
          "expected_behavior": "self.assertTrue(os.path.exists(main_index))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 176,
          "line_end": 216,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that main index.md lists all documentation sources.'",
          "description": "'Test that main index.md lists all documentation sources.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "refs_dir1 = os.path.join(self.temp_dir, 'refs1')",
          "description": "Assign refs_dir1 = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "refs_dir2 = os.path.join(self.temp_dir, 'refs2')",
          "description": "Assign refs_dir2 = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "os.makedirs(refs_dir1)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "os.makedirs(refs_dir2)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "config = {'name': 'test_main_index', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "scraped_data = {'documentation': [{'source_id': 'docs_one', 'base_url': 'https://one.com', 'total_pages': 10, 'refs_dir': refs_dir1}, {'source_id': 'docs_two', 'base_url': 'https://two.com', 'total_pages': 20, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "builder._generate_docs_references(scraped_data['documentation'])",
          "description": "Call builder._generate_docs_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "main_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'index.md')",
          "description": "Assign main_index = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue(os.path.exists(main_index))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertIn('docs_one', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "self.assertIn('docs_two', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "self.assertIn('2 documentation sources', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Main Index Listing All Sources",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_multi_source.py:176"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4fe17849c2f4",
      "title": "Copies Reference Files To Source Dir",
      "overview": "Workflow: Test that reference files are copied to source subdirectory.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "15a9374c",
          "test_name": "test_copies_reference_files_to_source_dir",
          "category": "workflow",
          "code": "'Test that reference files are copied to source subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir = os.path.join(self.temp_dir, 'refs')\nos.makedirs(refs_dir)\nwith open(os.path.join(refs_dir, 'api.md'), 'w') as f:\n    f.write('# API Reference')\nwith open(os.path.join(refs_dir, 'guide.md'), 'w') as f:\n    f.write('# User Guide')\nconfig = {'name': 'test_copy_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'test_source', 'base_url': 'https://test.com', 'total_pages': 5, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nsource_dir = os.path.join(builder.skill_dir, 'references', 'documentation', 'test_source')\nself.assertTrue(os.path.exists(os.path.join(source_dir, 'api.md')))\nself.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
          "language": "Python",
          "description": "Workflow: Test that reference files are copied to source subdirectory.",
          "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 218,
          "line_end": 251,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that reference files are copied to source subdirectory.'",
          "description": "'Test that reference files are copied to source subdirectory.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "refs_dir = os.path.join(self.temp_dir, 'refs')",
          "description": "Assign refs_dir = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "os.makedirs(refs_dir)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config = {'name': 'test_copy_refs', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "scraped_data = {'documentation': [{'source_id': 'test_source', 'base_url': 'https://test.com', 'total_pages': 5, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "builder._generate_docs_references(scraped_data['documentation'])",
          "description": "Call builder._generate_docs_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "source_dir = os.path.join(builder.skill_dir, 'references', 'documentation', 'test_source')",
          "description": "Assign source_dir = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'api.md')))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "f.write('# API Reference')",
          "description": "Call f.write()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "f.write('# User Guide')",
          "description": "Call f.write()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Copies Reference Files To Source Dir",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_multi_source.py:218"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b086b95a74ac",
      "title": "Creates Subdirectory Per Repo",
      "overview": "Workflow: Test that each GitHub repo gets its own subdirectory.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5f9cac6a",
          "test_name": "test_creates_subdirectory_per_repo",
          "category": "workflow",
          "code": "'Test that each GitHub repo gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_github_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'org/repo1', 'repo_id': 'org_repo1', 'data': {'readme': '# Repo 1', 'issues': [], 'releases': [], 'repo_info': {}}}, {'repo': 'org/repo2', 'repo_id': 'org_repo2', 'data': {'readme': '# Repo 2', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\ngithub_dir = os.path.join(builder.skill_dir, 'references', 'github')\nself.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo1')))\nself.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
          "language": "Python",
          "description": "Workflow: Test that each GitHub repo gets its own subdirectory.",
          "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 269,
          "line_end": 297,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that each GitHub repo gets its own subdirectory.'",
          "description": "'Test that each GitHub repo gets its own subdirectory.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_github_refs', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'org/repo1', 'repo_id': 'org_repo1', 'data': {'readme': '# Repo 1', 'issues': [], 'releases': [], 'repo_info': {}}}, {'repo': 'org/repo2', 'repo_id': 'org_repo2', 'data': {'readme': '# Repo 2', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder._generate_github_references(scraped_data['github'])",
          "description": "Call builder._generate_github_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "github_dir = os.path.join(builder.skill_dir, 'references', 'github')",
          "description": "Assign github_dir = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo1')))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Subdirectory Per Repo",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_multi_source.py:269"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "abd1ee27b606",
      "title": "Creates Readme Per Repo",
      "overview": "Workflow: Test that README.md is created for each repo.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "80ec31f0",
          "test_name": "test_creates_readme_per_repo",
          "category": "workflow",
          "code": "'Test that README.md is created for each repo.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_readme', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'test/myrepo', 'repo_id': 'test_myrepo', 'data': {'readme': '# My Repository\\n\\nDescription here.', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nreadme_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_myrepo', 'README.md')\nself.assertTrue(os.path.exists(readme_path))\nwith open(readme_path) as f:\n    content = f.read()\n    self.assertIn('test/myrepo', content)",
          "language": "Python",
          "description": "Workflow: Test that README.md is created for each repo.",
          "expected_behavior": "self.assertTrue(os.path.exists(readme_path))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 299,
          "line_end": 332,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that README.md is created for each repo.'",
          "description": "'Test that README.md is created for each repo.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_readme', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'test/myrepo', 'repo_id': 'test_myrepo', 'data': {'readme': '# My Repository\\n\\nDescription here.', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder._generate_github_references(scraped_data['github'])",
          "description": "Call builder._generate_github_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "readme_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_myrepo', 'README.md')",
          "description": "Assign readme_path = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(os.path.exists(readme_path))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('test/myrepo', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Readme Per Repo",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_multi_source.py:299"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4edc4bb41b7d",
      "title": "Creates Issues File When Issues Exist",
      "overview": "Workflow: Test that issues.md is created when repo has issues.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "665633ca",
          "test_name": "test_creates_issues_file_when_issues_exist",
          "category": "workflow",
          "code": "'Test that issues.md is created when repo has issues.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_issues', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'data': {'readme': '# Repo', 'issues': [{'number': 1, 'title': 'Bug report', 'state': 'open', 'labels': ['bug'], 'url': 'https://github.com/test/repo/issues/1'}, {'number': 2, 'title': 'Feature request', 'state': 'closed', 'labels': ['enhancement'], 'url': 'https://github.com/test/repo/issues/2'}], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nissues_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_repo', 'issues.md')\nself.assertTrue(os.path.exists(issues_path))\nwith open(issues_path) as f:\n    content = f.read()\n    self.assertIn('Bug report', content)\n    self.assertIn('Feature request', content)",
          "language": "Python",
          "description": "Workflow: Test that issues.md is created when repo has issues.",
          "expected_behavior": "self.assertTrue(os.path.exists(issues_path))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 334,
          "line_end": 383,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that issues.md is created when repo has issues.'",
          "description": "'Test that issues.md is created when repo has issues.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_issues', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'data': {'readme': '# Repo', 'issues': [{'number': 1, 'title': 'Bug report', 'state': 'open', 'labels': ['bug'], 'url': 'https://github.com/test/repo/issues/1'}, {'number': 2, 'title': 'Feature request', 'state': 'closed', 'labels': ['enhancement'], 'url': 'https://github.com/test/repo/issues/2'}], 'releases': [], 'repo_info': {}}}], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder._generate_github_references(scraped_data['github'])",
          "description": "Call builder._generate_github_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "issues_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_repo', 'issues.md')",
          "description": "Assign issues_path = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(os.path.exists(issues_path))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('Bug report', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('Feature request', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Issues File When Issues Exist",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_multi_source.py:334"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e14e4e206a91",
      "title": "Creates Main Index Listing All Repos",
      "overview": "Workflow: Test that main index.md lists all GitHub repositories.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "262c48dd",
          "test_name": "test_creates_main_index_listing_all_repos",
          "category": "workflow",
          "code": "'Test that main index.md lists all GitHub repositories.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_github_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'org/first', 'repo_id': 'org_first', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 100}}}, {'repo': 'org/second', 'repo_id': 'org_second', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 50}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nmain_index = os.path.join(builder.skill_dir, 'references', 'github', 'index.md')\nself.assertTrue(os.path.exists(main_index))\nwith open(main_index) as f:\n    content = f.read()\n    self.assertIn('org/first', content)\n    self.assertIn('org/second', content)\n    self.assertIn('2 GitHub repositories', content)",
          "language": "Python",
          "description": "Workflow: Test that main index.md lists all GitHub repositories.",
          "expected_behavior": "self.assertTrue(os.path.exists(main_index))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 385,
          "line_end": 428,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that main index.md lists all GitHub repositories.'",
          "description": "'Test that main index.md lists all GitHub repositories.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_github_index', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'documentation': [], 'github': [{'repo': 'org/first', 'repo_id': 'org_first', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 100}}}, {'repo': 'org/second', 'repo_id': 'org_second', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 50}}}], 'pdf': []}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder._generate_github_references(scraped_data['github'])",
          "description": "Call builder._generate_github_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "main_index = os.path.join(builder.skill_dir, 'references', 'github', 'index.md')",
          "description": "Assign main_index = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(os.path.exists(main_index))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('org/first', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('org/second', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('2 GitHub repositories', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Main Index Listing All Repos",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_multi_source.py:385"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d1636799cf57",
      "title": "Creates Pdf Index With Count",
      "overview": "Workflow: Test that PDF index shows correct document count.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "faf6c58e",
          "test_name": "test_creates_pdf_index_with_count",
          "category": "workflow",
          "code": "'Test that PDF index shows correct document count.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_pdf', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [], 'pdf': [{'path': '/path/to/doc1.pdf'}, {'path': '/path/to/doc2.pdf'}, {'path': '/path/to/doc3.pdf'}]}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_pdf_references(scraped_data['pdf'])\npdf_index = os.path.join(builder.skill_dir, 'references', 'pdf', 'index.md')\nself.assertTrue(os.path.exists(pdf_index))\nwith open(pdf_index) as f:\n    content = f.read()\n    self.assertIn('3 PDF document', content)",
          "language": "Python",
          "description": "Workflow: Test that PDF index shows correct document count.",
          "expected_behavior": "self.assertTrue(os.path.exists(pdf_index))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
          "line_start": 446,
          "line_end": 470,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "tempfile",
            "unittest",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that PDF index shows correct document count.'",
          "description": "'Test that PDF index shows correct document count.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_pdf', 'description': 'Test', 'sources': []}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'documentation': [], 'github': [], 'pdf': [{'path': '/path/to/doc1.pdf'}, {'path': '/path/to/doc2.pdf'}, {'path': '/path/to/doc3.pdf'}]}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder._generate_pdf_references(scraped_data['pdf'])",
          "description": "Call builder._generate_pdf_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "pdf_index = os.path.join(builder.skill_dir, 'references', 'pdf', 'index.md')",
          "description": "Assign pdf_index = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(os.path.exists(pdf_index))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('3 PDF document', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Creates Pdf Index With Count",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_multi_source.py:446"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "8fa83cb98c73",
      "title": "Bootstrap Script Runs",
      "overview": "Workflow: Test that bootstrap script runs successfully.\n\nNote: This test is slow as it runs full codebase analysis.\nRun with: pytest -m slow",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "subprocess",
        "pathlib",
        "pytest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7e0f2c67",
          "test_name": "test_bootstrap_script_runs",
          "category": "workflow",
          "code": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '\nscript = project_root / 'scripts' / 'bootstrap_skill.sh'\nresult = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=600)\nassert result.returncode == 0, f'Script failed: {result.stderr}'\noutput_dir = project_root / 'output' / 'skill-seekers'\nassert output_dir.exists(), 'Output directory should be created'\nskill_md = output_dir / 'SKILL.md'\nassert skill_md.exists(), 'SKILL.md should be created'\ncontent = skill_md.read_text()\nassert '## Prerequisites' in content, 'SKILL.md should have header prepended'\nassert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
          "language": "Python",
          "description": "Workflow: Test that bootstrap script runs successfully.\n\nNote: This test is slow as it runs full codebase analysis.\nRun with: pytest -m slow",
          "expected_behavior": "assert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill.py",
          "line_start": 54,
          "line_end": 84,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: project_root",
          "tags": [
            "pytest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "subprocess",
            "pathlib",
            "pytest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '",
          "description": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '",
          "expected_result": null,
          "verification": "assert result.returncode == 0, f'Script failed: {result.stderr}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "script = project_root / 'scripts' / 'bootstrap_skill.sh'",
          "description": "Assign script = value",
          "expected_result": null,
          "verification": "assert output_dir.exists(), 'Output directory should be created'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=600)",
          "description": "Assign result = subprocess.run(...)",
          "expected_result": null,
          "verification": "assert skill_md.exists(), 'SKILL.md should be created'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_dir = project_root / 'output' / 'skill-seekers'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": "assert '## Prerequisites' in content, 'SKILL.md should have header prepended'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_md = output_dir / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": "assert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "content = skill_md.read_text()",
          "description": "Assign content = skill_md.read_text(...)",
          "expected_result": null,
          "verification": "assert '## Prerequisites' in content, 'SKILL.md should have header prepended'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Bootstrap Script Runs",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_bootstrap_skill.py:54"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "cd14c83d134e",
      "title": "Deduplicate Urls",
      "overview": "Workflow: Test that duplicate URLs are removed.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c75ec58f",
          "test_name": "test_deduplicate_urls",
          "category": "workflow",
          "code": "'Test that duplicate URLs are removed.'\nfrom skill_seekers.cli.llms_txt_parser import LlmsTxtParser\ncontent = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'\nparser = LlmsTxtParser(content)\nurls = parser.extract_urls()\ncount = sum((1 for u in urls if u == 'https://example.com/doc.md'))\nself.assertEqual(count, 1)",
          "language": "Python",
          "description": "Workflow: Test that duplicate URLs are removed.",
          "expected_behavior": "self.assertEqual(count, 1)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
          "line_start": 273,
          "line_end": 287,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "unittest",
            "skill_seekers.cli.doc_scraper",
            "skill_seekers.cli.doc_scraper",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.llms_txt_parser",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that duplicate URLs are removed.'",
          "description": "'Test that duplicate URLs are removed.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "content = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'",
          "description": "Assign content = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "parser = LlmsTxtParser(content)",
          "description": "Assign parser = LlmsTxtParser(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "urls = parser.extract_urls()",
          "description": "Assign urls = parser.extract_urls(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "count = sum((1 for u in urls if u == 'https://example.com/doc.md'))",
          "description": "Assign count = sum(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(count, 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Deduplicate Urls",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_markdown_parsing.py:273"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b73f4313da2b",
      "title": "Cache Set And Get",
      "overview": "Workflow: Test setting and getting cached values",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0d478cf7",
          "test_name": "test_cache_set_and_get",
          "category": "workflow",
          "code": "'Test setting and getting cached values'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ntest_data = {'page': 1, 'text': 'cached content'}\nextractor.set_cached('page_1', test_data)\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached, test_data)",
          "language": "Python",
          "description": "Workflow: Test setting and getting cached values",
          "expected_behavior": "self.assertEqual(cached, test_data)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
          "line_start": 339,
          "line_end": 352,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "io",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "unittest.mock",
            "fitz",
            "pytesseract",
            "PIL",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "os",
            "pdf_extractor_poc"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test setting and getting cached values'",
          "description": "'Test setting and getting cached values'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor._cache = {}",
          "description": "Assign extractor._cache = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "extractor.use_cache = True",
          "description": "Assign extractor.use_cache = True",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "test_data = {'page': 1, 'text': 'cached content'}",
          "description": "Assign test_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "extractor.set_cached('page_1', test_data)",
          "description": "Call extractor.set_cached()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "cached = extractor.get_cached('page_1')",
          "description": "Assign cached = extractor.get_cached(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(cached, test_data)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cache Set And Get",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_advanced_features.py:339"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c17c0a1e0de9",
      "title": "Cache Miss",
      "overview": "Workflow: Test cache miss returns None",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "79af8725",
          "test_name": "test_cache_miss",
          "category": "workflow",
          "code": "'Test cache miss returns None'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ncached = extractor.get_cached('nonexistent_key')\nself.assertIsNone(cached)",
          "language": "Python",
          "description": "Workflow: Test cache miss returns None",
          "expected_behavior": "self.assertIsNone(cached)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
          "line_start": 354,
          "line_end": 362,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "io",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "unittest.mock",
            "fitz",
            "pytesseract",
            "PIL",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "os",
            "pdf_extractor_poc"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test cache miss returns None'",
          "description": "'Test cache miss returns None'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor._cache = {}",
          "description": "Assign extractor._cache = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "extractor.use_cache = True",
          "description": "Assign extractor.use_cache = True",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "cached = extractor.get_cached('nonexistent_key')",
          "description": "Assign cached = extractor.get_cached(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIsNone(cached)",
          "description": "Call self.assertIsNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cache Miss",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_pdf_advanced_features.py:354"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "30cae67ea4d2",
      "title": "Cache Disabled",
      "overview": "Workflow: Test caching can be disabled",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4908a829",
          "test_name": "test_cache_disabled",
          "category": "workflow",
          "code": "'Test caching can be disabled'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = False\nextractor.set_cached('page_1', {'data': 'test'})\nself.assertEqual(len(extractor._cache), 0)\ncached = extractor.get_cached('page_1')\nself.assertIsNone(cached)",
          "language": "Python",
          "description": "Workflow: Test caching can be disabled",
          "expected_behavior": "self.assertIsNone(cached)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
          "line_start": 364,
          "line_end": 378,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "io",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "unittest.mock",
            "fitz",
            "pytesseract",
            "PIL",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "os",
            "pdf_extractor_poc"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test caching can be disabled'",
          "description": "'Test caching can be disabled'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor._cache = {}",
          "description": "Assign extractor._cache = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "extractor.use_cache = False",
          "description": "Assign extractor.use_cache = False",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "extractor.set_cached('page_1', {'data': 'test'})",
          "description": "Call extractor.set_cached()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(len(extractor._cache), 0)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "cached = extractor.get_cached('page_1')",
          "description": "Assign cached = extractor.get_cached(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIsNone(cached)",
          "description": "Call self.assertIsNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cache Disabled",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_advanced_features.py:364"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a3781a3b27ca",
      "title": "Cache Overwrite",
      "overview": "Workflow: Test cache can be overwritten",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "33222edf",
          "test_name": "test_cache_overwrite",
          "category": "workflow",
          "code": "'Test cache can be overwritten'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\nextractor.set_cached('page_1', {'version': 1})\nextractor.set_cached('page_1', {'version': 2})\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached['version'], 2)",
          "language": "Python",
          "description": "Workflow: Test cache can be overwritten",
          "expected_behavior": "self.assertEqual(cached['version'], 2)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
          "line_start": 380,
          "line_end": 395,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "io",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "unittest.mock",
            "fitz",
            "pytesseract",
            "PIL",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "pdf_extractor_poc",
            "os",
            "pdf_extractor_poc"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test cache can be overwritten'",
          "description": "'Test cache can be overwritten'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "extractor = self.PDFExtractor.__new__(self.PDFExtractor)",
          "description": "Assign extractor = self.PDFExtractor.__new__(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "extractor._cache = {}",
          "description": "Assign extractor._cache = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "extractor.use_cache = True",
          "description": "Assign extractor.use_cache = True",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "extractor.set_cached('page_1', {'version': 1})",
          "description": "Call extractor.set_cached()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "extractor.set_cached('page_1', {'version': 2})",
          "description": "Call extractor.set_cached()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "cached = extractor.get_cached('page_1')",
          "description": "Assign cached = extractor.get_cached(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(cached['version'], 2)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cache Overwrite",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_advanced_features.py:380"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "85e020d575ca",
      "title": "No Config No Logging",
      "overview": "Workflow: Test that default mode doesn't log exclude_dirs messages.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "addec59a",
          "test_name": "test_no_config_no_logging",
          "category": "workflow",
          "code": "\"Test that default mode doesn't log exclude_dirs messages.\"\nconfig = {'repo': 'owner/repo'}\n_scraper = GitHubScraper(config)\ninfo_calls = [str(call) for call in mock_logger.info.call_args_list]\nwarning_calls = [str(call) for call in mock_logger.warning.call_args_list]\nexclude_info = [c for c in info_calls if 'directory exclusion' in c]\nexclude_warnings = [c for c in warning_calls if 'directory exclusion' in c]\nself.assertEqual(len(exclude_info), 0)\nself.assertEqual(len(exclude_warnings), 0)",
          "language": "Python",
          "description": "Workflow: Test that default mode doesn't log exclude_dirs messages.",
          "expected_behavior": "self.assertEqual(len(exclude_warnings), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
          "line_start": 299,
          "line_end": 314,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_logger, _mock_github",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "unittest",
            "unittest.mock",
            "skill_seekers.cli.github_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test that default mode doesn't log exclude_dirs messages.\"",
          "description": "\"Test that default mode doesn't log exclude_dirs messages.\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'repo': 'owner/repo'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "_scraper = GitHubScraper(config)",
          "description": "Assign _scraper = GitHubScraper(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "info_calls = [str(call) for call in mock_logger.info.call_args_list]",
          "description": "Assign info_calls = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "warning_calls = [str(call) for call in mock_logger.warning.call_args_list]",
          "description": "Assign warning_calls = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "exclude_info = [c for c in info_calls if 'directory exclusion' in c]",
          "description": "Assign exclude_info = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "exclude_warnings = [c for c in warning_calls if 'directory exclusion' in c]",
          "description": "Assign exclude_warnings = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(len(exclude_info), 0)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertEqual(len(exclude_warnings), 0)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "No Config No Logging",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_excluded_dirs_config.py:299"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "53f2f5730d1f",
      "title": "Full Metadata",
      "overview": "Workflow: Test metadata with all fields",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2110f28e",
          "test_name": "test_full_metadata",
          "category": "workflow",
          "code": "'Test metadata with all fields'\nmetadata = SkillMetadata(name='react', description='React documentation', version='2.5.0', author='Test Author', tags=['react', 'javascript', 'web'])\nself.assertEqual(metadata.name, 'react')\nself.assertEqual(metadata.description, 'React documentation')\nself.assertEqual(metadata.version, '2.5.0')\nself.assertEqual(metadata.author, 'Test Author')\nself.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
          "language": "Python",
          "description": "Workflow: Test metadata with all fields",
          "expected_behavior": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
          "line_start": 30,
          "line_end": 44,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "unittest",
            "skill_seekers.cli.adaptors"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test metadata with all fields'",
          "description": "'Test metadata with all fields'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "metadata = SkillMetadata(name='react', description='React documentation', version='2.5.0', author='Test Author', tags=['react', 'javascript', 'web'])",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "self.assertEqual(metadata.name, 'react')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(metadata.description, 'React documentation')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(metadata.version, '2.5.0')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(metadata.author, 'Test Author')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Full Metadata",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_base.py:30"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "841726a5e139",
      "title": "Detect From Html Swift Class",
      "overview": "Workflow: Test HTML element with Swift CSS class",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "75ea9c0c",
          "test_name": "test_detect_from_html_swift_class",
          "category": "workflow",
          "code": "'Test HTML element with Swift CSS class'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-swift\">let x = 5</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'let x = 5')\nassert lang == 'swift'\nassert confidence == 1.0",
          "language": "Python",
          "description": "Workflow: Test HTML element with Swift CSS class",
          "expected_behavior": "assert confidence == 1.0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 44,
          "line_end": 53,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test HTML element with Swift CSS class'",
          "description": "'Test HTML element with Swift CSS class'",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence == 1.0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "html = '<code class=\"language-swift\">let x = 5</code>'",
          "description": "Assign html = '<code class=\"language-swift\">let x = 5</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "soup = BeautifulSoup(html, 'html.parser')",
          "description": "Assign soup = BeautifulSoup(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "elem = soup.find('code')",
          "description": "Assign elem = soup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "lang, confidence = detector.detect_from_html(elem, 'let x = 5')",
          "description": "Assign unknown = detector.detect_from_html(...)",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect From Html Swift Class",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:44"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7a25e90d4eba",
      "title": "Viewcontroller Lifecycle",
      "overview": "Workflow: Test UIViewController lifecycle methods",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "601881a3",
          "test_name": "test_viewcontroller_lifecycle",
          "category": "workflow",
          "code": "'Test UIViewController lifecycle methods'\ndetector = LanguageDetector()\ncode = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.9",
          "language": "Python",
          "description": "Workflow: Test UIViewController lifecycle methods",
          "expected_behavior": "assert confidence >= 0.9",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 342,
          "line_end": 365,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test UIViewController lifecycle methods'",
          "description": "'Test UIViewController lifecycle methods'",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.9",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '",
          "description": "Assign code = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Viewcontroller Lifecycle",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:342"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e4ea7daca24a",
      "title": "Nsviewcontroller Lifecycle",
      "overview": "Workflow: Test NSViewController lifecycle methods",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5942a2f1",
          "test_name": "test_nsviewcontroller_lifecycle",
          "category": "workflow",
          "code": "'Test NSViewController lifecycle methods'\ndetector = LanguageDetector()\ncode = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.9",
          "language": "Python",
          "description": "Workflow: Test NSViewController lifecycle methods",
          "expected_behavior": "assert confidence >= 0.9",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 468,
          "line_end": 491,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test NSViewController lifecycle methods'",
          "description": "'Test NSViewController lifecycle methods'",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.9",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '",
          "description": "Assign code = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Nsviewcontroller Lifecycle",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:468"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5d91d6addac9",
      "title": "High Confidence Full App",
      "overview": "Workflow: Test complete SwiftUI app (high confidence expected)",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "16e54dc7",
          "test_name": "test_high_confidence_full_app",
          "category": "workflow",
          "code": "'Test complete SwiftUI app (high confidence expected)'\ndetector = LanguageDetector()\ncode = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.95",
          "language": "Python",
          "description": "Workflow: Test complete SwiftUI app (high confidence expected)",
          "expected_behavior": "assert confidence >= 0.95",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 960,
          "line_end": 1002,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete SwiftUI app (high confidence expected)'",
          "description": "'Test complete SwiftUI app (high confidence expected)'",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.95",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '",
          "description": "Assign code = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'swift'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "High Confidence Full App",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:960"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "50a88b1d5eb3",
      "title": "Swift Vs Similar Languages",
      "overview": "Workflow: Test Swift doesn't false-positive for similar syntax in other languages.\n\nCritical for avoiding misclassification of:\n- Go: 'func', ':=' short declaration\n- Rust: 'fn', 'let mut', struct\n- TypeScript: 'let', 'const', type annotations with ':'\n\nThese languages share keywords or syntax patterns with Swift,\nso detection must use unique Swift patterns (guard let, @State, etc.)",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "89e4c403",
          "test_name": "test_swift_vs_similar_languages",
          "category": "workflow",
          "code": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"\ndetector = LanguageDetector()\ngo_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '\nlang, _ = detector.detect_from_code(go_code)\nassert lang == 'go', f\"Expected 'go', got '{lang}'\"\nrust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '\nlang, _ = detector.detect_from_code(rust_code)\nassert lang == 'rust', f\"Expected 'rust', got '{lang}'\"\nts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"\nlang, _ = detector.detect_from_code(ts_code)\nassert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
          "language": "Python",
          "description": "Workflow: Test Swift doesn't false-positive for similar syntax in other languages.\n\nCritical for avoiding misclassification of:\n- Go: 'func', ':=' short declaration\n- Rust: 'fn', 'let mut', struct\n- TypeScript: 'let', 'const', type annotations with ':'\n\nThese languages share keywords or syntax patterns with Swift,\nso detection must use unique Swift patterns (guard let, @State, etc.)",
          "expected_behavior": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 1004,
          "line_end": 1054,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"",
          "description": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"",
          "expected_result": null,
          "verification": "assert lang == 'go', f\"Expected 'go', got '{lang}'\"",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert lang == 'rust', f\"Expected 'rust', got '{lang}'\"",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "go_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '",
          "description": "Assign go_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '",
          "expected_result": null,
          "verification": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, _ = detector.detect_from_code(go_code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'go', f\"Expected 'go', got '{lang}'\"",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "rust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '",
          "description": "Assign rust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "lang, _ = detector.detect_from_code(rust_code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'rust', f\"Expected 'rust', got '{lang}'\"",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "ts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"",
          "description": "Assign ts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "lang, _ = detector.detect_from_code(ts_code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Swift Vs Similar Languages",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_swift_detection.py:1004"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2d632e98ebbf",
      "title": "Malformed Regex Patterns Are Skipped",
      "overview": "Workflow: Test that invalid regex patterns are logged and skipped without crashing",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7b4ca31c",
          "test_name": "test_malformed_regex_patterns_are_skipped",
          "category": "workflow",
          "code": "'Test that invalid regex patterns are logged and skipped without crashing'\nfrom unittest.mock import patch\nfrom skill_seekers.cli.language_detector import LanguageDetector\nwith patch('skill_seekers.cli.language_detector.logger') as mock_logger:\n    import skill_seekers.cli.language_detector as ld_module\n    original_patterns = ld_module.LANGUAGE_PATTERNS.copy()\n    try:\n        ld_module.LANGUAGE_PATTERNS['test_malformed'] = [('(?P<invalid)', 5), ('valid_pattern', 3)]\n        _detector = LanguageDetector()\n        assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'\n    finally:\n        ld_module.LANGUAGE_PATTERNS = original_patterns",
          "language": "Python",
          "description": "Workflow: Test that invalid regex patterns are logged and skipped without crashing",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 1289,
          "line_end": 1321,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that invalid regex patterns are logged and skipped without crashing'",
          "description": "'Test that invalid regex patterns are logged and skipped without crashing'",
          "expected_result": null,
          "verification": "assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "original_patterns = ld_module.LANGUAGE_PATTERNS.copy()",
          "description": "Assign original_patterns = ld_module.LANGUAGE_PATTERNS.copy(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "ld_module.LANGUAGE_PATTERNS['test_malformed'] = [('(?P<invalid)', 5), ('valid_pattern', 3)]",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "_detector = LanguageDetector()",
          "description": "Assign _detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "ld_module.LANGUAGE_PATTERNS = original_patterns",
          "description": "Assign ld_module.LANGUAGE_PATTERNS = original_patterns",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Malformed Regex Patterns Are Skipped",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:1289"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6e47d258aa05",
      "title": "Empty Swift Patterns Handled Gracefully",
      "overview": "Workflow: Test that empty SWIFT_PATTERNS dict doesn't crash detection",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "45643623",
          "test_name": "test_empty_swift_patterns_handled_gracefully",
          "category": "workflow",
          "code": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"\nimport sys\nfrom unittest.mock import patch\nfor mod in list(sys.modules.keys()):\n    if 'skill_seekers.cli' in mod:\n        del sys.modules[mod]\nwith patch.dict('sys.modules', {'skill_seekers.cli.swift_patterns': type('MockModule', (), {'SWIFT_PATTERNS': {}})}):\n    from skill_seekers.cli.language_detector import LanguageDetector\n    detector = LanguageDetector()\n    code = 'import SwiftUI\\nstruct MyView: View { }'\n    lang, confidence = detector.detect_from_code(code)\n    assert isinstance(lang, str)\n    assert isinstance(confidence, (int, float))",
          "language": "Python",
          "description": "Workflow: Test that empty SWIFT_PATTERNS dict doesn't crash detection",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 1323,
          "line_end": 1349,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"",
          "description": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"",
          "expected_result": null,
          "verification": "assert isinstance(lang, str)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert isinstance(confidence, (int, float))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = 'import SwiftUI\\nstruct MyView: View { }'",
          "description": "Assign code = 'import SwiftUI\\nstruct MyView: View { }'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert isinstance(lang, str)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Empty Swift Patterns Handled Gracefully",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:1323"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6100791e20a9",
      "title": "Non String Pattern Handled During Compilation",
      "overview": "Workflow: Test that non-string patterns are caught during compilation",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "298d3cb7",
          "test_name": "test_non_string_pattern_handled_during_compilation",
          "category": "workflow",
          "code": "'Test that non-string patterns are caught during compilation'\nfrom unittest.mock import patch\nfrom skill_seekers.cli.language_detector import LanguageDetector\nwith patch('skill_seekers.cli.language_detector.logger') as mock_logger:\n    import skill_seekers.cli.language_detector as ld_module\n    original = ld_module.LANGUAGE_PATTERNS.copy()\n    try:\n        ld_module.LANGUAGE_PATTERNS['test_nonstring'] = [(None, 5)]\n        _detector = LanguageDetector()\n        assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'\n    finally:\n        ld_module.LANGUAGE_PATTERNS = original",
          "language": "Python",
          "description": "Workflow: Test that non-string patterns are caught during compilation",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
          "line_start": 1351,
          "line_end": 1378,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "skill_seekers.cli.swift_patterns",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "sys",
            "unittest.mock",
            "unittest.mock",
            "skill_seekers.cli.language_detector",
            "inspect",
            "skill_seekers.cli",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that non-string patterns are caught during compilation'",
          "description": "'Test that non-string patterns are caught during compilation'",
          "expected_result": null,
          "verification": "assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "original = ld_module.LANGUAGE_PATTERNS.copy()",
          "description": "Assign original = ld_module.LANGUAGE_PATTERNS.copy(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "ld_module.LANGUAGE_PATTERNS['test_nonstring'] = [(None, 5)]",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "_detector = LanguageDetector()",
          "description": "Assign _detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "ld_module.LANGUAGE_PATTERNS = original",
          "description": "Assign ld_module.LANGUAGE_PATTERNS = original",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Non String Pattern Handled During Compilation",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_swift_detection.py:1351"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "99470dd2b670",
      "title": "Async Dry Run Completes",
      "overview": "Workflow: Test async dry run completes without errors",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "301275b9",
          "test_name": "test_async_dry_run_completes",
          "category": "workflow",
          "code": "'Test async dry run completes without errors'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'async_mode': True, 'max_pages': 5}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=True)\n        with patch.object(converter, '_try_llms_txt', return_value=False):\n            converter.scrape_all()\n            self.assertTrue(converter.dry_run)\n    finally:\n        os.chdir(self.original_cwd)",
          "language": "Python",
          "description": "Workflow: Test async dry run completes without errors",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
          "line_start": 205,
          "line_end": 227,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "asyncio",
            "inspect",
            "os",
            "tempfile",
            "unittest",
            "unittest.mock",
            "skill_seekers.cli.doc_scraper",
            "httpx"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test async dry run completes without errors'",
          "description": "'Test async dry run completes without errors'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'async_mode': True, 'max_pages': 5}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "os.chdir(tmpdir)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter = DocToSkillConverter(config, dry_run=True)",
          "description": "Assign converter = DocToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "os.chdir(self.original_cwd)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.scrape_all()",
          "description": "Call converter.scrape_all()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(converter.dry_run)",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Async Dry Run Completes",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_async_scraping.py:205"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e9e41d9f0aa8",
      "title": "Enhance Guide Error Fallback",
      "overview": "Workflow: Test graceful fallback on enhancement error",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b67909da",
          "test_name": "test_enhance_guide_error_fallback",
          "category": "workflow",
          "code": "'Test graceful fallback on enhancement error'\nenhancer = GuideEnhancer(mode='none')\nwith patch.object(enhancer, 'enhance_guide', side_effect=Exception('API error')):\n    guide_data = {'title': 'Test', 'steps': [], 'language': 'python', 'prerequisites': [], 'description': 'Test'}\n    try:\n        enhancer = GuideEnhancer(mode='none')\n        result = enhancer.enhance_guide(guide_data)\n        assert result['title'] == guide_data['title']\n    except Exception:\n        pytest.fail('Should handle errors gracefully')",
          "language": "Python",
          "description": "Workflow: Test graceful fallback on enhancement error",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
          "line_start": 444,
          "line_end": 464,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.guide_enhancer",
            "subprocess"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test graceful fallback on enhancement error'",
          "description": "'Test graceful fallback on enhancement error'",
          "expected_result": null,
          "verification": "assert result['title'] == guide_data['title']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "enhancer = GuideEnhancer(mode='none')",
          "description": "Assign enhancer = GuideEnhancer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "guide_data = {'title': 'Test', 'steps': [], 'language': 'python', 'prerequisites': [], 'description': 'Test'}",
          "description": "Assign guide_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "enhancer = GuideEnhancer(mode='none')",
          "description": "Assign enhancer = GuideEnhancer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = enhancer.enhance_guide(guide_data)",
          "description": "Assign result = enhancer.enhance_guide(...)",
          "expected_result": null,
          "verification": "assert result['title'] == guide_data['title']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "pytest.fail('Should handle errors gracefully')",
          "description": "Call pytest.fail()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Enhance Guide Error Fallback",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_guide_enhancer.py:444"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "72a3b1a4e84b",
      "title": "Call Claude Local Success",
      "overview": "Workflow: Test successful LOCAL mode call",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "df128142",
          "test_name": "test_call_claude_local_success",
          "category": "workflow",
          "code": "'Test successful LOCAL mode call'\nmock_run.return_value = MagicMock(returncode=0, stdout=json.dumps({'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}))\nenhancer = GuideEnhancer(mode='local')\nif enhancer.mode == 'local':\n    prompt = 'Test prompt'\n    result = enhancer._call_claude_local(prompt)\n    assert result is not None\n    assert mock_run.called",
          "language": "Python",
          "description": "Workflow: Test successful LOCAL mode call",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
          "line_start": 471,
          "line_end": 492,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_run",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.guide_enhancer",
            "subprocess"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test successful LOCAL mode call'",
          "description": "'Test successful LOCAL mode call'",
          "expected_result": null,
          "verification": "assert result is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "mock_run.return_value = MagicMock(returncode=0, stdout=json.dumps({'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}))",
          "description": "Assign mock_run.return_value = MagicMock(...)",
          "expected_result": null,
          "verification": "assert mock_run.called",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "enhancer = GuideEnhancer(mode='local')",
          "description": "Assign enhancer = GuideEnhancer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "prompt = 'Test prompt'",
          "description": "Assign prompt = 'Test prompt'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = enhancer._call_claude_local(prompt)",
          "description": "Assign result = enhancer._call_claude_local(...)",
          "expected_result": null,
          "verification": "assert result is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Call Claude Local Success",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_guide_enhancer.py:471"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d5e1884297c4",
      "title": "Call Claude Local Timeout",
      "overview": "Workflow: Test LOCAL mode timeout handling",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4d3e542e",
          "test_name": "test_call_claude_local_timeout",
          "category": "workflow",
          "code": "'Test LOCAL mode timeout handling'\nfrom subprocess import TimeoutExpired\nmock_run.side_effect = TimeoutExpired('claude', 300)\nenhancer = GuideEnhancer(mode='local')\nif enhancer.mode == 'local':\n    prompt = 'Test prompt'\n    result = enhancer._call_claude_local(prompt)\n    assert result is None",
          "language": "Python",
          "description": "Workflow: Test LOCAL mode timeout handling",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
          "line_start": 495,
          "line_end": 506,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_run",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.guide_enhancer",
            "subprocess"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test LOCAL mode timeout handling'",
          "description": "'Test LOCAL mode timeout handling'",
          "expected_result": null,
          "verification": "assert result is None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "mock_run.side_effect = TimeoutExpired('claude', 300)",
          "description": "Assign mock_run.side_effect = TimeoutExpired(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "enhancer = GuideEnhancer(mode='local')",
          "description": "Assign enhancer = GuideEnhancer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "prompt = 'Test prompt'",
          "description": "Assign prompt = 'Test prompt'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = enhancer._call_claude_local(prompt)",
          "description": "Assign result = enhancer._call_claude_local(...)",
          "expected_result": null,
          "verification": "assert result is None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Call Claude Local Timeout",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_guide_enhancer.py:495"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ce3ce0dcf8a5",
      "title": "Parse Enhancement Response Valid Json",
      "overview": "Workflow: Test parsing valid JSON response",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c9fbf074",
          "test_name": "test_parse_enhancement_response_valid_json",
          "category": "workflow",
          "code": "'Test parsing valid JSON response'\nenhancer = GuideEnhancer(mode='none')\nresponse = json.dumps({'step_descriptions': [{'step_index': 0, 'explanation': 'Test', 'variations': []}], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []})\nguide_data = {'title': 'Test', 'steps': [{'description': 'Test', 'code': 'test'}], 'language': 'python'}\nresult = enhancer._parse_enhancement_response(response, guide_data)\nassert 'step_enhancements' in result\nassert len(result['step_enhancements']) == 1",
          "language": "Python",
          "description": "Workflow: Test parsing valid JSON response",
          "expected_behavior": "assert len(result['step_enhancements']) == 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
          "line_start": 560,
          "line_end": 583,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.guide_enhancer",
            "subprocess"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parsing valid JSON response'",
          "description": "'Test parsing valid JSON response'",
          "expected_result": null,
          "verification": "assert 'step_enhancements' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "enhancer = GuideEnhancer(mode='none')",
          "description": "Assign enhancer = GuideEnhancer(...)",
          "expected_result": null,
          "verification": "assert len(result['step_enhancements']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "response = json.dumps({'step_descriptions': [{'step_index': 0, 'explanation': 'Test', 'variations': []}], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []})",
          "description": "Assign response = json.dumps(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "guide_data = {'title': 'Test', 'steps': [{'description': 'Test', 'code': 'test'}], 'language': 'python'}",
          "description": "Assign guide_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = enhancer._parse_enhancement_response(response, guide_data)",
          "description": "Assign result = enhancer._parse_enhancement_response(...)",
          "expected_result": null,
          "verification": "assert 'step_enhancements' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parse Enhancement Response Valid Json",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_guide_enhancer.py:560"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9167b09b3900",
      "title": "Parse Enhancement Response With Extra Text",
      "overview": "Workflow: Test parsing JSON embedded in text",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b07ea653",
          "test_name": "test_parse_enhancement_response_with_extra_text",
          "category": "workflow",
          "code": "'Test parsing JSON embedded in text'\nenhancer = GuideEnhancer(mode='none')\njson_data = {'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}\nresponse = f\"Here's the result:\\n{json.dumps(json_data)}\\nDone!\"\nguide_data = {'title': 'Test', 'steps': [], 'language': 'python'}\nresult = enhancer._parse_enhancement_response(response, guide_data)\nassert 'title' in result",
          "language": "Python",
          "description": "Workflow: Test parsing JSON embedded in text",
          "expected_behavior": "assert 'title' in result",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
          "line_start": 585,
          "line_end": 603,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.guide_enhancer",
            "subprocess"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parsing JSON embedded in text'",
          "description": "'Test parsing JSON embedded in text'",
          "expected_result": null,
          "verification": "assert 'title' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "enhancer = GuideEnhancer(mode='none')",
          "description": "Assign enhancer = GuideEnhancer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "json_data = {'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}",
          "description": "Assign json_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "response = f\"Here's the result:\\n{json.dumps(json_data)}\\nDone!\"",
          "description": "Assign response = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "guide_data = {'title': 'Test', 'steps': [], 'language': 'python'}",
          "description": "Assign guide_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "result = enhancer._parse_enhancement_response(response, guide_data)",
          "description": "Assign result = enhancer._parse_enhancement_response(...)",
          "expected_result": null,
          "verification": "assert 'title' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parse Enhancement Response With Extra Text",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_guide_enhancer.py:585"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ee88de2b3fe3",
      "title": "Compare Benchmarks",
      "overview": "Workflow: Test comparing benchmarks.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "41186b80",
          "test_name": "test_compare_benchmarks",
          "category": "workflow",
          "code": "'Test comparing benchmarks.'\nrunner = BenchmarkRunner(output_dir=tmp_path)\n\ndef baseline_bench(bench):\n    with bench.timer('operation'):\n        time.sleep(0.1)\nrunner.run('baseline', baseline_bench, save=True)\nbaseline_path = list(tmp_path.glob('baseline_*.json'))[0]\n\ndef improved_bench(bench):\n    with bench.timer('operation'):\n        time.sleep(0.05)\nrunner.run('improved', improved_bench, save=True)\nimproved_path = list(tmp_path.glob('improved_*.json'))[0]\nfrom skill_seekers.benchmark.models import ComparisonReport\ncomparison = runner.compare(baseline_path, improved_path)\nassert isinstance(comparison, ComparisonReport)\nassert comparison.speedup_factor > 1.0\nassert len(comparison.improvements) > 0",
          "language": "Python",
          "description": "Workflow: Test comparing benchmarks.",
          "expected_behavior": "assert len(comparison.improvements) > 0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
          "line_start": 368,
          "line_end": 395,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "time",
            "json",
            "datetime",
            "skill_seekers.benchmark",
            "skill_seekers.benchmark.models",
            "skill_seekers.benchmark.models",
            "os",
            "skill_seekers.benchmark.models",
            "skill_seekers.benchmark.models"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test comparing benchmarks.'",
          "description": "'Test comparing benchmarks.'",
          "expected_result": null,
          "verification": "assert isinstance(comparison, ComparisonReport)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "runner = BenchmarkRunner(output_dir=tmp_path)",
          "description": "Assign runner = BenchmarkRunner(...)",
          "expected_result": null,
          "verification": "assert comparison.speedup_factor > 1.0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "runner.run('baseline', baseline_bench, save=True)",
          "description": "Call runner.run()",
          "expected_result": null,
          "verification": "assert len(comparison.improvements) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "baseline_path = list(tmp_path.glob('baseline_*.json'))[0]",
          "description": "Assign baseline_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "runner.run('improved', improved_bench, save=True)",
          "description": "Call runner.run()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "improved_path = list(tmp_path.glob('improved_*.json'))[0]",
          "description": "Assign improved_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "comparison = runner.compare(baseline_path, improved_path)",
          "description": "Assign comparison = runner.compare(...)",
          "expected_result": null,
          "verification": "assert isinstance(comparison, ComparisonReport)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "time.sleep(0.1)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "time.sleep(0.05)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Compare Benchmarks",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_benchmark.py:368"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "bf9f6e872c3a",
      "title": "Cleanup Old",
      "overview": "Workflow: Test cleaning up old benchmarks.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ce3bc3cc",
          "test_name": "test_cleanup_old",
          "category": "workflow",
          "code": "'Test cleaning up old benchmarks.'\nimport os\nrunner = BenchmarkRunner(output_dir=tmp_path)\nbase_time = time.time()\nfor i in range(10):\n    filename = f'test_{i:08d}.json'\n    file_path = tmp_path / filename\n    report_data = {'name': 'test', 'started_at': datetime.utcnow().isoformat(), 'finished_at': datetime.utcnow().isoformat(), 'total_duration': 1.0, 'timings': [], 'memory': [], 'metrics': [], 'system_info': {}, 'recommendations': []}\n    with open(file_path, 'w') as f:\n        json.dump(report_data, f)\n    mtime = base_time - (10 - i) * 60\n    os.utime(file_path, (mtime, mtime))\nassert len(list(tmp_path.glob('test_*.json'))) == 10\nrunner.cleanup_old(keep_latest=3)\nremaining = list(tmp_path.glob('test_*.json'))\nassert len(remaining) == 3\nremaining_names = {f.stem for f in remaining}\nassert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
          "language": "Python",
          "description": "Workflow: Test cleaning up old benchmarks.",
          "expected_behavior": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
          "line_start": 441,
          "line_end": 484,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "time",
            "json",
            "datetime",
            "skill_seekers.benchmark",
            "skill_seekers.benchmark.models",
            "skill_seekers.benchmark.models",
            "os",
            "skill_seekers.benchmark.models",
            "skill_seekers.benchmark.models"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test cleaning up old benchmarks.'",
          "description": "'Test cleaning up old benchmarks.'",
          "expected_result": null,
          "verification": "assert len(list(tmp_path.glob('test_*.json'))) == 10",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "runner = BenchmarkRunner(output_dir=tmp_path)",
          "description": "Assign runner = BenchmarkRunner(...)",
          "expected_result": null,
          "verification": "assert len(remaining) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "base_time = time.time()",
          "description": "Assign base_time = time.time(...)",
          "expected_result": null,
          "verification": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "runner.cleanup_old(keep_latest=3)",
          "description": "Call runner.cleanup_old()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "remaining = list(tmp_path.glob('test_*.json'))",
          "description": "Assign remaining = list(...)",
          "expected_result": null,
          "verification": "assert len(remaining) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "remaining_names = {f.stem for f in remaining}",
          "description": "Assign remaining_names = value",
          "expected_result": null,
          "verification": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "filename = f'test_{i:08d}.json'",
          "description": "Assign filename = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "file_path = tmp_path / filename",
          "description": "Assign file_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "report_data = {'name': 'test', 'started_at': datetime.utcnow().isoformat(), 'finished_at': datetime.utcnow().isoformat(), 'total_duration': 1.0, 'timings': [], 'memory': [], 'metrics': [], 'system_info': {}, 'recommendations': []}",
          "description": "Assign report_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "mtime = base_time - (10 - i) * 60",
          "description": "Assign mtime = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "os.utime(file_path, (mtime, mtime))",
          "description": "Call os.utime()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "json.dump(report_data, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cleanup Old",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_benchmark.py:441"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7b8e9fe4d08b",
      "title": "Comparison Report Overall Improvement",
      "overview": "Workflow: Test ComparisonReport overall_improvement property.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d6c0efdf",
          "test_name": "test_comparison_report_overall_improvement",
          "category": "workflow",
          "code": "'Test ComparisonReport overall_improvement property.'\nfrom skill_seekers.benchmark.models import ComparisonReport\nbaseline = BenchmarkReport(name='baseline', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=10.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])\ncurrent = BenchmarkReport(name='current', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=5.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])\ncomparison = ComparisonReport(name='test', baseline=baseline, current=current, improvements=[], regressions=[], speedup_factor=2.0, memory_change_mb=0.0)\nimprovement = comparison.overall_improvement\nassert '100.0% faster' in improvement\nassert '\u2705' in improvement",
          "language": "Python",
          "description": "Workflow: Test ComparisonReport overall_improvement property.",
          "expected_behavior": "assert '\u2705' in improvement",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
          "line_start": 586,
          "line_end": 627,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "time",
            "json",
            "datetime",
            "skill_seekers.benchmark",
            "skill_seekers.benchmark.models",
            "skill_seekers.benchmark.models",
            "os",
            "skill_seekers.benchmark.models",
            "skill_seekers.benchmark.models"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test ComparisonReport overall_improvement property.'",
          "description": "'Test ComparisonReport overall_improvement property.'",
          "expected_result": null,
          "verification": "assert '100.0% faster' in improvement",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "baseline = BenchmarkReport(name='baseline', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=10.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])",
          "description": "Assign baseline = BenchmarkReport(...)",
          "expected_result": null,
          "verification": "assert '\u2705' in improvement",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "current = BenchmarkReport(name='current', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=5.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])",
          "description": "Assign current = BenchmarkReport(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "comparison = ComparisonReport(name='test', baseline=baseline, current=current, improvements=[], regressions=[], speedup_factor=2.0, memory_change_mb=0.0)",
          "description": "Assign comparison = ComparisonReport(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "improvement = comparison.overall_improvement",
          "description": "Assign improvement = value",
          "expected_result": null,
          "verification": "assert '100.0% faster' in improvement",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Comparison Report Overall Improvement",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_benchmark.py:586"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0019b5f5a687",
      "title": "Init Preserves Existing Registry",
      "overview": "Workflow: Test that initialization doesn't overwrite existing registry.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f6dc7925",
          "test_name": "test_init_preserves_existing_registry",
          "category": "workflow",
          "code": "\"Test that initialization doesn't overwrite existing registry.\"\nregistry_file = temp_config_dir / 'sources.json'\nexisting_data = {'version': '1.0', 'sources': [{'name': 'test', 'git_url': 'https://example.com/repo.git'}]}\nwith open(registry_file, 'w') as f:\n    json.dump(existing_data, f)\n_manager = SourceManager(config_dir=str(temp_config_dir))\nwith open(registry_file) as f:\n    data = json.load(f)\n    assert len(data['sources']) == 1",
          "language": "Python",
          "description": "Workflow: Test that initialization doesn't overwrite existing registry.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
          "line_start": 51,
          "line_end": 69,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_config_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "pytest",
            "skill_seekers.mcp.source_manager"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test that initialization doesn't overwrite existing registry.\"",
          "description": "\"Test that initialization doesn't overwrite existing registry.\"",
          "expected_result": null,
          "verification": "assert len(data['sources']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "registry_file = temp_config_dir / 'sources.json'",
          "description": "Assign registry_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "existing_data = {'version': '1.0', 'sources': [{'name': 'test', 'git_url': 'https://example.com/repo.git'}]}",
          "description": "Assign existing_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "_manager = SourceManager(config_dir=str(temp_config_dir))",
          "description": "Assign _manager = SourceManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "json.dump(existing_data, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": "assert len(data['sources']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Init Preserves Existing Registry",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_source_manager.py:51"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "8f092c2de71a",
      "title": "Add Source Full Parameters",
      "overview": "Workflow: Test adding source with all parameters.",
      "complexity_level": "beginner",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "efdb7dce",
          "test_name": "test_add_source_full_parameters",
          "category": "workflow",
          "code": "'Test adding source with all parameters.'\nsource = source_manager.add_source(name='company', git_url='https://gitlab.company.com/platform/configs.git', source_type='gitlab', token_env='CUSTOM_TOKEN', branch='develop', priority=1, enabled=False)\nassert source['name'] == 'company'\nassert source['type'] == 'gitlab'\nassert source['token_env'] == 'CUSTOM_TOKEN'\nassert source['branch'] == 'develop'\nassert source['priority'] == 1\nassert source['enabled'] is False",
          "language": "Python",
          "description": "Workflow: Test adding source with all parameters.",
          "expected_behavior": "assert source['enabled'] is False",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
          "line_start": 98,
          "line_end": 115,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "# Fixtures: source_manager",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "pytest",
            "skill_seekers.mcp.source_manager"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test adding source with all parameters.'",
          "description": "'Test adding source with all parameters.'",
          "expected_result": null,
          "verification": "assert source['name'] == 'company'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "source = source_manager.add_source(name='company', git_url='https://gitlab.company.com/platform/configs.git', source_type='gitlab', token_env='CUSTOM_TOKEN', branch='develop', priority=1, enabled=False)",
          "description": "Assign source = source_manager.add_source(...)",
          "expected_result": null,
          "verification": "assert source['type'] == 'gitlab'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Add Source Full Parameters",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_source_manager.py:98"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a5d66b13a89f",
      "title": "Sample Skill Dir",
      "overview": "Workflow: Create a sample skill for integration testing.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "cf3d2039",
          "test_name": "sample_skill_dir",
          "category": "workflow",
          "code": "'Create a sample skill for integration testing.'\nskill_dir = tmp_path / 'test_integration_skill'\nskill_dir.mkdir()\nskill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'\n(skill_dir / 'SKILL.md').write_text(skill_md)\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\nreferences = {'api_reference.md': '# API Reference\\n\\n## Core Functions\\n\\n### add_documents(documents, metadata)\\nAdd documents to the vector database.\\n\\n### query(text, limit=10)\\nQuery the database with semantic search.\\n\\n### delete_collection(name)\\nDelete a collection from the database.\\n', 'getting_started.md': '# Getting Started\\n\\n## Installation\\n\\n```bash\\npip install vector-db-client\\n```\\n\\n## Basic Usage\\n\\n```python\\nfrom vector_db import Client\\n\\nclient = Client(\"http://localhost:8080\")\\nclient.add_documents([\"doc1\", \"doc2\"])\\nresults = client.query(\"search query\")\\n```\\n', 'advanced_features.md': '# Advanced Features\\n\\n## Hybrid Search\\n\\nCombine keyword and vector search for better results.\\n\\n## Metadata Filtering\\n\\nFilter results based on metadata attributes.\\n\\n## Multi-modal Search\\n\\nSearch across text, images, and audio.\\n'}\nfor filename, content in references.items():\n    (refs_dir / filename).write_text(content)\nreturn skill_dir",
          "language": "Python",
          "description": "Workflow: Create a sample skill for integration testing.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
          "line_start": 29,
          "line_end": 109,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "pytest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "time",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "contextlib",
            "sys",
            "requests",
            "weaviate",
            "weaviate",
            "chromadb",
            "chromadb",
            "qdrant_client",
            "qdrant_client.models",
            "qdrant_client",
            "qdrant_client.models"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Create a sample skill for integration testing.'",
          "description": "'Create a sample skill for integration testing.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'test_integration_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'",
          "description": "Assign skill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "(skill_dir / 'SKILL.md').write_text(skill_md)",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "refs_dir = skill_dir / 'references'",
          "description": "Assign refs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "refs_dir.mkdir()",
          "description": "Call refs_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "references = {'api_reference.md': '# API Reference\\n\\n## Core Functions\\n\\n### add_documents(documents, metadata)\\nAdd documents to the vector database.\\n\\n### query(text, limit=10)\\nQuery the database with semantic search.\\n\\n### delete_collection(name)\\nDelete a collection from the database.\\n', 'getting_started.md': '# Getting Started\\n\\n## Installation\\n\\n```bash\\npip install vector-db-client\\n```\\n\\n## Basic Usage\\n\\n```python\\nfrom vector_db import Client\\n\\nclient = Client(\"http://localhost:8080\")\\nclient.add_documents([\"doc1\", \"doc2\"])\\nresults = client.query(\"search query\")\\n```\\n', 'advanced_features.md': '# Advanced Features\\n\\n## Hybrid Search\\n\\nCombine keyword and vector search for better results.\\n\\n## Metadata Filtering\\n\\nFilter results based on metadata attributes.\\n\\n## Multi-modal Search\\n\\nSearch across text, images, and audio.\\n'}",
          "description": "Assign references = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "(refs_dir / filename).write_text(content)",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Sample Skill Dir",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_integration_adaptors.py:29"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ebda02e94997",
      "title": "Chroma Query Filtering",
      "overview": "Workflow: Test metadata filtering in ChromaDB queries.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a2f1403c",
          "test_name": "test_chroma_query_filtering",
          "category": "workflow",
          "code": "'Test metadata filtering in ChromaDB queries.'\ntry:\n    import chromadb\nexcept ImportError:\n    pytest.skip('chromadb not installed')\nif not check_service_available('http://localhost:8000/api/v1/heartbeat'):\n    pytest.skip('ChromaDB not running')\ntry:\n    client = chromadb.HttpClient(host='localhost', port=8000)\n    client.heartbeat()\nexcept Exception as e:\n    pytest.skip(f'Cannot connect to ChromaDB: {e}')\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='chroma_filter_test', description='Test filtering capabilities')\npackage_path = adaptor.package(sample_skill_dir, tmp_path)\nwith open(package_path) as f:\n    data = json.load(f)\ncollection_name = data['collection_name']\ntry:\n    collection = client.get_or_create_collection(name=collection_name)\n    collection.add(documents=data['documents'], metadatas=data['metadatas'], ids=data['ids'])\n    time.sleep(1)\n    results = collection.get(where={'category': 'getting started'})\n    assert len(results['documents']) > 0, 'No documents matched filter'\n    for metadata in results['metadatas']:\n        assert metadata['category'] == 'getting started', 'Filter returned wrong category'\nfinally:\n    with contextlib.suppress(Exception):\n        client.delete_collection(name=collection_name)",
          "language": "Python",
          "description": "Workflow: Test metadata filtering in ChromaDB queries.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
          "line_start": 357,
          "line_end": 403,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "time",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "contextlib",
            "sys",
            "requests",
            "weaviate",
            "weaviate",
            "chromadb",
            "chromadb",
            "qdrant_client",
            "qdrant_client.models",
            "qdrant_client",
            "qdrant_client.models"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test metadata filtering in ChromaDB queries.'",
          "description": "'Test metadata filtering in ChromaDB queries.'",
          "expected_result": null,
          "verification": "assert len(results['documents']) > 0, 'No documents matched filter'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('chroma')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert metadata['category'] == 'getting started', 'Filter returned wrong category'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "metadata = SkillMetadata(name='chroma_filter_test', description='Test filtering capabilities')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(sample_skill_dir, tmp_path)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "collection_name = data['collection_name']",
          "description": "Assign collection_name = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "pytest.skip('ChromaDB not running')",
          "description": "Call pytest.skip()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "client = chromadb.HttpClient(host='localhost', port=8000)",
          "description": "Assign client = chromadb.HttpClient(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "client.heartbeat()",
          "description": "Call client.heartbeat()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "collection = client.get_or_create_collection(name=collection_name)",
          "description": "Assign collection = client.get_or_create_collection(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "collection.add(documents=data['documents'], metadatas=data['metadatas'], ids=data['ids'])",
          "description": "Call collection.add()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "time.sleep(1)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "results = collection.get(where={'category': 'getting started'})",
          "description": "Assign results = collection.get(...)",
          "expected_result": null,
          "verification": "assert len(results['documents']) > 0, 'No documents matched filter'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "pytest.skip('chromadb not installed')",
          "description": "Call pytest.skip()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "pytest.skip(f'Cannot connect to ChromaDB: {e}')",
          "description": "Call pytest.skip()",
          "expected_result": null,
          "verification": "assert metadata['category'] == 'getting started', 'Filter returned wrong category'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "client.delete_collection(name=collection_name)",
          "description": "Call client.delete_collection()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chroma Query Filtering",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_integration_adaptors.py:357"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b8a6e5c0455a",
      "title": "Factory Method Detection",
      "overview": "Workflow: Test detection of create/make methods",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "620cefa1",
          "test_name": "test_factory_method_detection",
          "category": "workflow",
          "code": "'Test detection of create/make methods'\ncode = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Factory']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertIn('create', ' '.join(pattern.evidence).lower())",
          "language": "Python",
          "description": "Workflow: Test detection of create/make methods",
          "expected_behavior": "self.assertIn('create', ' '.join(pattern.evidence).lower())",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
          "line_start": 135,
          "line_end": 153,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.pattern_recognizer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of create/make methods'",
          "description": "'Test detection of create/make methods'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"",
          "description": "Assign code = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "report = self.recognizer.analyze_file('test.py', code, 'Python')",
          "description": "Assign report = self.recognizer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "patterns = [p for p in report.patterns if p.pattern_type == 'Factory']",
          "description": "Assign patterns = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertGreater(len(patterns), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "pattern = patterns[0]",
          "description": "Assign pattern = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('create', ' '.join(pattern.evidence).lower())",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Factory Method Detection",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pattern_recognizer.py:135"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d6e468b92136",
      "title": "Observer Triplet Detection",
      "overview": "Workflow: Test classic attach/detach/notify triplet",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0f757575",
          "test_name": "test_observer_triplet_detection",
          "category": "workflow",
          "code": "'Test classic attach/detach/notify triplet'\ncode = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Observer']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertGreaterEqual(pattern.confidence, 0.8)\nevidence_str = ' '.join(pattern.evidence).lower()\nself.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
          "language": "Python",
          "description": "Workflow: Test classic attach/detach/notify triplet",
          "expected_behavior": "self.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
          "line_start": 199,
          "line_end": 225,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.pattern_recognizer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test classic attach/detach/notify triplet'",
          "description": "'Test classic attach/detach/notify triplet'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'",
          "description": "Assign code = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "report = self.recognizer.analyze_file('test.py', code, 'Python')",
          "description": "Assign report = self.recognizer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "patterns = [p for p in report.patterns if p.pattern_type == 'Observer']",
          "description": "Assign patterns = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertGreater(len(patterns), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "pattern = patterns[0]",
          "description": "Assign pattern = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreaterEqual(pattern.confidence, 0.8)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "evidence_str = ' '.join(pattern.evidence).lower()",
          "description": "Assign evidence_str = unknown.join.lower(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Observer Triplet Detection",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pattern_recognizer.py:199"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "fdb89246a395",
      "title": "Pattern Report Summary",
      "overview": "Workflow: Test PatternReport.get_summary() method",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "db79e8d6",
          "test_name": "test_pattern_report_summary",
          "category": "workflow",
          "code": "'Test PatternReport.get_summary() method'\ncode = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'\nreport = self.recognizer.analyze_file('logging.py', code, 'Python')\nsummary = report.get_summary()\nself.assertIsInstance(summary, dict)\nif summary:\n    total_count = sum(summary.values())\n    self.assertGreater(total_count, 0)",
          "language": "Python",
          "description": "Workflow: Test PatternReport.get_summary() method",
          "expected_behavior": "self.assertIsInstance(summary, dict)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
          "line_start": 329,
          "line_end": 350,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.pattern_recognizer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test PatternReport.get_summary() method'",
          "description": "'Test PatternReport.get_summary() method'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'",
          "description": "Assign code = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "report = self.recognizer.analyze_file('logging.py', code, 'Python')",
          "description": "Assign report = self.recognizer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "summary = report.get_summary()",
          "description": "Assign summary = report.get_summary(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertIsInstance(summary, dict)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "total_count = sum(summary.values())",
          "description": "Assign total_count = sum(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(total_count, 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Pattern Report Summary",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pattern_recognizer.py:329"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "db376c78a197",
      "title": "Generator Compute Hash",
      "overview": "Workflow: Test hash computation.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5eccf782",
          "test_name": "test_generator_compute_hash",
          "category": "workflow",
          "code": "'Test hash computation.'\nhash1 = EmbeddingGenerator.compute_hash('text1', 'model1')\nhash2 = EmbeddingGenerator.compute_hash('text1', 'model1')\nhash3 = EmbeddingGenerator.compute_hash('text2', 'model1')\nhash4 = EmbeddingGenerator.compute_hash('text1', 'model2')\nassert hash1 == hash2\nassert hash1 != hash3\nassert hash1 != hash4",
          "language": "Python",
          "description": "Workflow: Test hash computation.",
          "expected_behavior": "assert hash1 != hash4",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
          "line_start": 165,
          "line_end": 179,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "tempfile",
            "pathlib",
            "unittest.mock",
            "skill_seekers.embedding.models",
            "skill_seekers.embedding.generator",
            "skill_seekers.embedding.cache",
            "numpy"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test hash computation.'",
          "description": "'Test hash computation.'",
          "expected_result": null,
          "verification": "assert hash1 == hash2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "hash1 = EmbeddingGenerator.compute_hash('text1', 'model1')",
          "description": "Assign hash1 = EmbeddingGenerator.compute_hash(...)",
          "expected_result": null,
          "verification": "assert hash1 != hash3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "hash2 = EmbeddingGenerator.compute_hash('text1', 'model1')",
          "description": "Assign hash2 = EmbeddingGenerator.compute_hash(...)",
          "expected_result": null,
          "verification": "assert hash1 != hash4",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "hash3 = EmbeddingGenerator.compute_hash('text2', 'model1')",
          "description": "Assign hash3 = EmbeddingGenerator.compute_hash(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "hash4 = EmbeddingGenerator.compute_hash('text1', 'model2')",
          "description": "Assign hash4 = EmbeddingGenerator.compute_hash(...)",
          "expected_result": null,
          "verification": "assert hash1 == hash2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generator Compute Hash",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding.py:165"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d93527f0bc3f",
      "title": "Cache Persistence",
      "overview": "Workflow: Test cache persistence to file.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7c8131cf",
          "test_name": "test_cache_persistence",
          "category": "workflow",
          "code": "'Test cache persistence to file.'\nwith tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp:\n    tmp_path = tmp.name\ntry:\n    cache1 = EmbeddingCache(tmp_path)\n    cache1.set('hash1', [0.1, 0.2, 0.3], 'model1')\n    cache1.close()\n    cache2 = EmbeddingCache(tmp_path)\n    retrieved = cache2.get('hash1')\n    assert retrieved == [0.1, 0.2, 0.3]\n    cache2.close()\nfinally:\n    Path(tmp_path).unlink(missing_ok=True)",
          "language": "Python",
          "description": "Workflow: Test cache persistence to file.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
          "line_start": 349,
          "line_end": 367,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "tempfile",
            "pathlib",
            "unittest.mock",
            "skill_seekers.embedding.models",
            "skill_seekers.embedding.generator",
            "skill_seekers.embedding.cache",
            "numpy"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test cache persistence to file.'",
          "description": "'Test cache persistence to file.'",
          "expected_result": null,
          "verification": "assert retrieved == [0.1, 0.2, 0.3]",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "tmp_path = tmp.name",
          "description": "Assign tmp_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "cache1 = EmbeddingCache(tmp_path)",
          "description": "Assign cache1 = EmbeddingCache(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "cache1.set('hash1', [0.1, 0.2, 0.3], 'model1')",
          "description": "Call cache1.set()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "cache1.close()",
          "description": "Call cache1.close()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "cache2 = EmbeddingCache(tmp_path)",
          "description": "Assign cache2 = EmbeddingCache(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "retrieved = cache2.get('hash1')",
          "description": "Assign retrieved = cache2.get(...)",
          "expected_result": null,
          "verification": "assert retrieved == [0.1, 0.2, 0.3]",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "cache2.close()",
          "description": "Call cache2.close()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "Path(tmp_path).unlink(missing_ok=True)",
          "description": "Call Path.unlink()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cache Persistence",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_embedding.py:349"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "32bf598aac85",
      "title": "Walk With Subdirectories",
      "overview": "Workflow: Test walking nested directory structure.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "00c9a61d",
          "test_name": "test_walk_with_subdirectories",
          "category": "workflow",
          "code": "'Test walking nested directory structure.'\nsrc_dir = self.root / 'src'\nsrc_dir.mkdir()\n(src_dir / 'module.py').write_text('test')\ntests_dir = self.root / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_module.py').write_text('test')\nfiles = walk_directory(self.root)\nself.assertEqual(len(files), 2)\nfilenames = [f.name for f in files]\nself.assertIn('module.py', filenames)\nself.assertIn('test_module.py', filenames)",
          "language": "Python",
          "description": "Workflow: Test walking nested directory structure.",
          "expected_behavior": "self.assertIn('test_module.py', filenames)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
          "line_start": 159,
          "line_end": 176,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.codebase_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test walking nested directory structure.'",
          "description": "'Test walking nested directory structure.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "src_dir = self.root / 'src'",
          "description": "Assign src_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "src_dir.mkdir()",
          "description": "Call src_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(src_dir / 'module.py').write_text('test')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "tests_dir = self.root / 'tests'",
          "description": "Assign tests_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "tests_dir.mkdir()",
          "description": "Call tests_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "(tests_dir / 'test_module.py').write_text('test')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "files = walk_directory(self.root)",
          "description": "Assign files = walk_directory(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertEqual(len(files), 2)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "filenames = [f.name for f in files]",
          "description": "Assign filenames = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('module.py', filenames)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('test_module.py', filenames)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Walk With Subdirectories",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_codebase_scraper.py:159"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "8b62e02fc43c",
      "title": "No Duplicate Directories Created",
      "overview": "Workflow: Test that source directories are cleaned up after copying to references/ (Issue #279).",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "3c7c2450",
          "test_name": "test_no_duplicate_directories_created",
          "category": "workflow",
          "code": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'\ntest_dirs = ['documentation', 'api_reference', 'patterns']\nfor dir_name in test_dirs:\n    dir_path = self.output_dir / dir_name\n    dir_path.mkdir()\n    (dir_path / 'test.txt').write_text(f'Test content for {dir_name}')\n_generate_references(self.output_dir)\nreferences_dir = self.output_dir / 'references'\nself.assertTrue(references_dir.exists(), 'references/ should exist')\nfor dir_name in test_dirs:\n    ref_path = references_dir / dir_name\n    self.assertTrue(ref_path.exists(), f'references/{dir_name} should exist')\n    self.assertTrue((ref_path / 'test.txt').exists(), f'references/{dir_name}/test.txt should exist')\nfor dir_name in test_dirs:\n    source_path = self.output_dir / dir_name\n    self.assertFalse(source_path.exists(), f'Source directory {dir_name}/ should be cleaned up to avoid duplication')",
          "language": "Python",
          "description": "Workflow: Test that source directories are cleaned up after copying to references/ (Issue #279).",
          "expected_behavior": "self.assertTrue(references_dir.exists(), 'references/ should exist')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
          "line_start": 411,
          "line_end": 443,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.codebase_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'",
          "description": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "test_dirs = ['documentation', 'api_reference', 'patterns']",
          "description": "Assign test_dirs = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "_generate_references(self.output_dir)",
          "description": "Call _generate_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "references_dir = self.output_dir / 'references'",
          "description": "Assign references_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(references_dir.exists(), 'references/ should exist')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "dir_path = self.output_dir / dir_name",
          "description": "Assign dir_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "dir_path.mkdir()",
          "description": "Call dir_path.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "(dir_path / 'test.txt').write_text(f'Test content for {dir_name}')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "ref_path = references_dir / dir_name",
          "description": "Assign ref_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertTrue(ref_path.exists(), f'references/{dir_name} should exist')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue((ref_path / 'test.txt').exists(), f'references/{dir_name}/test.txt should exist')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "source_path = self.output_dir / dir_name",
          "description": "Assign source_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertFalse(source_path.exists(), f'Source directory {dir_name}/ should be cleaned up to avoid duplication')",
          "description": "Call self.assertFalse()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "No Duplicate Directories Created",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_codebase_scraper.py:411"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "43e332165dfa",
      "title": "No Disk Space Wasted",
      "overview": "Workflow: Test that disk space is not wasted by duplicate directories.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "6c4cfcff",
          "test_name": "test_no_disk_space_wasted",
          "category": "workflow",
          "code": "'Test that disk space is not wasted by duplicate directories.'\ndoc_dir = self.output_dir / 'documentation'\ndoc_dir.mkdir()\ntest_content = 'x' * 1000\n(doc_dir / 'large_file.txt').write_text(test_content)\n_generate_references(self.output_dir)\nref_doc_dir = self.output_dir / 'references' / 'documentation'\nsource_doc_dir = self.output_dir / 'documentation'\nself.assertTrue(ref_doc_dir.exists(), 'references/documentation/ should exist')\nself.assertFalse(source_doc_dir.exists(), 'Source documentation/ should not exist (cleaned up)')\nself.assertTrue((ref_doc_dir / 'large_file.txt').exists(), 'File should exist in references/')\nself.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
          "language": "Python",
          "description": "Workflow: Test that disk space is not wasted by duplicate directories.",
          "expected_behavior": "self.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
          "line_start": 445,
          "line_end": 473,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.codebase_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that disk space is not wasted by duplicate directories.'",
          "description": "'Test that disk space is not wasted by duplicate directories.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "doc_dir = self.output_dir / 'documentation'",
          "description": "Assign doc_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "doc_dir.mkdir()",
          "description": "Call doc_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "test_content = 'x' * 1000",
          "description": "Assign test_content = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "(doc_dir / 'large_file.txt').write_text(test_content)",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "_generate_references(self.output_dir)",
          "description": "Call _generate_references()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "ref_doc_dir = self.output_dir / 'references' / 'documentation'",
          "description": "Assign ref_doc_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "source_doc_dir = self.output_dir / 'documentation'",
          "description": "Assign source_doc_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(ref_doc_dir.exists(), 'references/documentation/ should exist')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertFalse(source_doc_dir.exists(), 'Source documentation/ should not exist (cleaned up)')",
          "description": "Call self.assertFalse()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue((ref_doc_dir / 'large_file.txt').exists(), 'File should exist in references/')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "No Disk Space Wasted",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_codebase_scraper.py:445"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "dc4afac68084",
      "title": "Build Agent Command Claude",
      "overview": "Workflow: Test Claude Code command building.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7757584e",
          "test_name": "test_build_agent_command_claude",
          "category": "workflow",
          "code": "'Test Claude Code command building.'\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='claude')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, True)\nassert cmd_parts[0] == 'claude'\nassert '--dangerously-skip-permissions' in cmd_parts\nassert prompt_file in cmd_parts\nassert uses_file is True",
          "language": "Python",
          "description": "Workflow: Test Claude Code command building.",
          "expected_behavior": "assert uses_file is True",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
          "line_start": 32,
          "line_end": 43,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "skill_seekers.cli.enhance_skill_local"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Claude Code command building.'",
          "description": "'Test Claude Code command building.'",
          "expected_result": null,
          "verification": "assert cmd_parts[0] == 'claude'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = _make_skill_dir(tmp_path)",
          "description": "Assign skill_dir = _make_skill_dir(...)",
          "expected_result": null,
          "verification": "assert '--dangerously-skip-permissions' in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='claude')",
          "description": "Assign enhancer = LocalSkillEnhancer(...)",
          "expected_result": null,
          "verification": "assert prompt_file in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "prompt_file = str(tmp_path / 'prompt.txt')",
          "description": "Assign prompt_file = str(...)",
          "expected_result": null,
          "verification": "assert uses_file is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, True)",
          "description": "Assign unknown = enhancer._build_agent_command(...)",
          "expected_result": null,
          "verification": "assert cmd_parts[0] == 'claude'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Agent Command Claude",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_enhance_skill_local.py:32"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9e312e137287",
      "title": "Build Agent Command Codex",
      "overview": "Workflow: Test Codex CLI command building.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7a9d3a78",
          "test_name": "test_build_agent_command_codex",
          "category": "workflow",
          "code": "'Test Codex CLI command building.'\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='codex')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)\nassert cmd_parts[0] == 'codex'\nassert 'exec' in cmd_parts\nassert '--full-auto' in cmd_parts\nassert '--skip-git-repo-check' in cmd_parts\nassert uses_file is False",
          "language": "Python",
          "description": "Workflow: Test Codex CLI command building.",
          "expected_behavior": "assert uses_file is False",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
          "line_start": 45,
          "line_end": 57,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "skill_seekers.cli.enhance_skill_local"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Codex CLI command building.'",
          "description": "'Test Codex CLI command building.'",
          "expected_result": null,
          "verification": "assert cmd_parts[0] == 'codex'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = _make_skill_dir(tmp_path)",
          "description": "Assign skill_dir = _make_skill_dir(...)",
          "expected_result": null,
          "verification": "assert 'exec' in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='codex')",
          "description": "Assign enhancer = LocalSkillEnhancer(...)",
          "expected_result": null,
          "verification": "assert '--full-auto' in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "prompt_file = str(tmp_path / 'prompt.txt')",
          "description": "Assign prompt_file = str(...)",
          "expected_result": null,
          "verification": "assert '--skip-git-repo-check' in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)",
          "description": "Assign unknown = enhancer._build_agent_command(...)",
          "expected_result": null,
          "verification": "assert uses_file is False",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Agent Command Codex",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_enhance_skill_local.py:45"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4e2b7c899f67",
      "title": "Build Agent Command Custom With Placeholder",
      "overview": "Workflow: Test custom command with {prompt_file} placeholder.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "75f0193a",
          "test_name": "test_build_agent_command_custom_with_placeholder",
          "category": "workflow",
          "code": "'Test custom command with {prompt_file} placeholder.'\n_allow_executable(monkeypatch, name='my-agent')\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='custom', agent_cmd='my-agent --input {prompt_file}')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)\nassert cmd_parts[0] == 'my-agent'\nassert '--input' in cmd_parts\nassert prompt_file in cmd_parts\nassert uses_file is True",
          "language": "Python",
          "description": "Workflow: Test custom command with {prompt_file} placeholder.",
          "expected_behavior": "assert uses_file is True",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
          "line_start": 59,
          "line_end": 75,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path, monkeypatch",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "skill_seekers.cli.enhance_skill_local"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test custom command with {prompt_file} placeholder.'",
          "description": "'Test custom command with {prompt_file} placeholder.'",
          "expected_result": null,
          "verification": "assert cmd_parts[0] == 'my-agent'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "_allow_executable(monkeypatch, name='my-agent')",
          "description": "Call _allow_executable()",
          "expected_result": null,
          "verification": "assert '--input' in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir = _make_skill_dir(tmp_path)",
          "description": "Assign skill_dir = _make_skill_dir(...)",
          "expected_result": null,
          "verification": "assert prompt_file in cmd_parts",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='custom', agent_cmd='my-agent --input {prompt_file}')",
          "description": "Assign enhancer = LocalSkillEnhancer(...)",
          "expected_result": null,
          "verification": "assert uses_file is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "prompt_file = str(tmp_path / 'prompt.txt')",
          "description": "Assign prompt_file = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)",
          "description": "Assign unknown = enhancer._build_agent_command(...)",
          "expected_result": null,
          "verification": "assert cmd_parts[0] == 'my-agent'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Agent Command Custom With Placeholder",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_enhance_skill_local.py:59"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "67fbe0b2ae94",
      "title": "Langchain No Chunking Default",
      "overview": "Workflow: Test that LangChain doesn't chunk by default.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "77e4d66e",
          "test_name": "test_langchain_no_chunking_default",
          "category": "workflow",
          "code": "\"Test that LangChain doesn't chunk by default.\"\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) == 2, f'Expected 2 docs, got {len(data)}'\nfor doc in data:\n    assert 'is_chunked' not in doc['metadata']\n    assert 'chunk_index' not in doc['metadata']",
          "language": "Python",
          "description": "Workflow: Test that LangChain doesn't chunk by default.",
          "expected_behavior": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 59,
          "line_end": 75,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test that LangChain doesn't chunk by default.\"",
          "description": "\"Test that LangChain doesn't chunk by default.\"",
          "expected_result": null,
          "verification": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
          "description": "Assign skill_dir = create_test_skill(...)",
          "expected_result": null,
          "verification": "assert 'is_chunked' not in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor('langchain')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert 'chunk_index' not in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(skill_dir, tmp_path)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": "assert 'is_chunked' not in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Langchain No Chunking Default",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:59"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f997215aef3f",
      "title": "Langchain Chunking Enabled",
      "overview": "Workflow: Test that LangChain chunks large documents when enabled.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "3e61e5d4",
          "test_name": "test_langchain_chunking_enabled",
          "category": "workflow",
          "code": "'Test that LangChain chunks large documents when enabled.'\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) > 2, f'Large doc should be chunked, got {len(data)} docs'\nchunked_docs = [doc for doc in data if doc['metadata'].get('is_chunked')]\nassert len(chunked_docs) > 0, 'Should have chunked documents'\nfor doc in chunked_docs:\n    assert 'chunk_index' in doc['metadata']\n    assert 'total_chunks' in doc['metadata']\n    assert 'chunk_id' in doc['metadata']",
          "language": "Python",
          "description": "Workflow: Test that LangChain chunks large documents when enabled.",
          "expected_behavior": "assert len(chunked_docs) > 0, 'Should have chunked documents'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 81,
          "line_end": 104,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that LangChain chunks large documents when enabled.'",
          "description": "'Test that LangChain chunks large documents when enabled.'",
          "expected_result": null,
          "verification": "assert len(data) > 2, f'Large doc should be chunked, got {len(data)} docs'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
          "description": "Assign skill_dir = create_test_skill(...)",
          "expected_result": null,
          "verification": "assert len(chunked_docs) > 0, 'Should have chunked documents'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor('langchain')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert 'chunk_index' in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": "assert 'total_chunks' in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunked_docs = [doc for doc in data if doc['metadata'].get('is_chunked')]",
          "description": "Assign chunked_docs = value",
          "expected_result": null,
          "verification": "assert 'chunk_id' in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": "assert 'chunk_index' in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Langchain Chunking Enabled",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:81"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a1674bf74c31",
      "title": "Chunking Preserves Small Docs",
      "overview": "Workflow: Test that small documents are not chunked.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5305693f",
          "test_name": "test_chunking_preserves_small_docs",
          "category": "workflow",
          "code": "'Test that small documents are not chunked.'\nskill_dir = create_test_skill(tmp_path, large_doc=False)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) == 2, 'Small docs should not be chunked'\nfor doc in data:\n    assert 'is_chunked' not in doc['metadata']",
          "language": "Python",
          "description": "Workflow: Test that small documents are not chunked.",
          "expected_behavior": "assert len(data) == 2, 'Small docs should not be chunked'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 106,
          "line_end": 122,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that small documents are not chunked.'",
          "description": "'Test that small documents are not chunked.'",
          "expected_result": null,
          "verification": "assert len(data) == 2, 'Small docs should not be chunked'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = create_test_skill(tmp_path, large_doc=False)",
          "description": "Assign skill_dir = create_test_skill(...)",
          "expected_result": null,
          "verification": "assert 'is_chunked' not in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor('langchain')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": "assert len(data) == 2, 'Small docs should not be chunked'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": "assert 'is_chunked' not in doc['metadata']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunking Preserves Small Docs",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:106"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "857202c22814",
      "title": "Preserve Code Blocks",
      "overview": "Workflow: Test code block preservation.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "12c916c2",
          "test_name": "test_preserve_code_blocks",
          "category": "workflow",
          "code": "'Test code block preservation.'\nchunker = RAGChunker(chunk_size=50, preserve_code_blocks=True)\ntext = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\nhas_code = any(('```' in chunk['page_content'] for chunk in chunks))\nassert has_code\ncode_chunks = [c for c in chunks if c['metadata']['has_code_block']]\nassert len(code_chunks) > 0",
          "language": "Python",
          "description": "Workflow: Test code block preservation.",
          "expected_behavior": "assert len(code_chunks) > 0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 85,
          "line_end": 108,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test code block preservation.'",
          "description": "'Test code block preservation.'",
          "expected_result": null,
          "verification": "assert has_code",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker(chunk_size=50, preserve_code_blocks=True)",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": "assert len(code_chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '",
          "description": "Assign text = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "chunks = chunker.chunk_document(text, {'source': 'test'})",
          "description": "Assign chunks = chunker.chunk_document(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "has_code = any(('```' in chunk['page_content'] for chunk in chunks))",
          "description": "Assign has_code = any(...)",
          "expected_result": null,
          "verification": "assert has_code",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "code_chunks = [c for c in chunks if c['metadata']['has_code_block']]",
          "description": "Assign code_chunks = value",
          "expected_result": null,
          "verification": "assert len(code_chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Preserve Code Blocks",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:85"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ccca78ab9721",
      "title": "Maybe Chunk Content Disabled",
      "overview": "Workflow: Test that _maybe_chunk_content returns single chunk when disabled.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e7e0e0d9",
          "test_name": "test_maybe_chunk_content_disabled",
          "category": "workflow",
          "code": "'Test that _maybe_chunk_content returns single chunk when disabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Test content ' * 1000\nmetadata = {'source': 'test'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=False)\nassert len(chunks) == 1\nassert chunks[0][0] == content\nassert chunks[0][1] == metadata",
          "language": "Python",
          "description": "Workflow: Test that _maybe_chunk_content returns single chunk when disabled.",
          "expected_behavior": "assert chunks[0][1] == metadata",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 225,
          "line_end": 239,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that _maybe_chunk_content returns single chunk when disabled.'",
          "description": "'Test that _maybe_chunk_content returns single chunk when disabled.'",
          "expected_result": null,
          "verification": "assert len(chunks) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = LangChainAdaptor()",
          "description": "Assign adaptor = LangChainAdaptor(...)",
          "expected_result": null,
          "verification": "assert chunks[0][0] == content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = 'Test content ' * 1000",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": "assert chunks[0][1] == metadata",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=False)",
          "description": "Assign chunks = adaptor._maybe_chunk_content(...)",
          "expected_result": null,
          "verification": "assert len(chunks) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Maybe Chunk Content Disabled",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:225"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "41deb1427e64",
      "title": "Maybe Chunk Content Small Doc",
      "overview": "Workflow: Test that small docs are not chunked even when enabled.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f61d3115",
          "test_name": "test_maybe_chunk_content_small_doc",
          "category": "workflow",
          "code": "'Test that small docs are not chunked even when enabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Small test content'\nmetadata = {'source': 'test'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512)\nassert len(chunks) == 1",
          "language": "Python",
          "description": "Workflow: Test that small docs are not chunked even when enabled.",
          "expected_behavior": "assert len(chunks) == 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 241,
          "line_end": 255,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that small docs are not chunked even when enabled.'",
          "description": "'Test that small docs are not chunked even when enabled.'",
          "expected_result": null,
          "verification": "assert len(chunks) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = LangChainAdaptor()",
          "description": "Assign adaptor = LangChainAdaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = 'Small test content'",
          "description": "Assign content = 'Small test content'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512)",
          "description": "Assign chunks = adaptor._maybe_chunk_content(...)",
          "expected_result": null,
          "verification": "assert len(chunks) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Maybe Chunk Content Small Doc",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:241"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "de5577f99cb0",
      "title": "Maybe Chunk Content Large Doc",
      "overview": "Workflow: Test that large docs are chunked when enabled.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "daf42b67",
          "test_name": "test_maybe_chunk_content_large_doc",
          "category": "workflow",
          "code": "'Test that large docs are chunked when enabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Lorem ipsum dolor sit amet. ' * 2000\nmetadata = {'source': 'test', 'file': 'test.md'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512, preserve_code_blocks=True, source_file='test.md')\nassert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'\nfor chunk_text, chunk_meta in chunks:\n    assert isinstance(chunk_text, str)\n    assert isinstance(chunk_meta, dict)\n    assert chunk_meta['is_chunked']\n    assert 'chunk_index' in chunk_meta\n    assert 'chunk_id' in chunk_meta\n    assert chunk_meta['source'] == 'test'\n    assert chunk_meta['file'] == 'test.md'",
          "language": "Python",
          "description": "Workflow: Test that large docs are chunked when enabled.",
          "expected_behavior": "assert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 257,
          "line_end": 287,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that large docs are chunked when enabled.'",
          "description": "'Test that large docs are chunked when enabled.'",
          "expected_result": null,
          "verification": "assert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = LangChainAdaptor()",
          "description": "Assign adaptor = LangChainAdaptor(...)",
          "expected_result": null,
          "verification": "assert isinstance(chunk_text, str)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = 'Lorem ipsum dolor sit amet. ' * 2000",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": "assert isinstance(chunk_meta, dict)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test', 'file': 'test.md'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": "assert chunk_meta['is_chunked']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512, preserve_code_blocks=True, source_file='test.md')",
          "description": "Assign chunks = adaptor._maybe_chunk_content(...)",
          "expected_result": null,
          "verification": "assert 'chunk_index' in chunk_meta",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Maybe Chunk Content Large Doc",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:257"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4646cb5e12c6",
      "title": "Chunk Tokens Parameter",
      "overview": "Workflow: Test --chunk-tokens parameter controls chunk size.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "94b738fe",
          "test_name": "test_chunk_tokens_parameter",
          "category": "workflow",
          "code": "'Test --chunk-tokens parameter controls chunk size.'\nfrom skill_seekers.cli.package_skill import package_skill\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nsuccess, package_path = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=256, preserve_code_blocks=True)\nassert success\nwith open(package_path) as f:\n    data_small = json.load(f)\nsuccess, package_path2 = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=1024, preserve_code_blocks=True)\nassert success\nwith open(package_path2) as f:\n    data_large = json.load(f)\nassert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
          "language": "Python",
          "description": "Workflow: Test --chunk-tokens parameter controls chunk size.",
          "expected_behavior": "assert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
          "line_start": 318,
          "line_end": 359,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.adaptors.langchain",
            "skill_seekers.cli.package_skill",
            "skill_seekers.cli.package_skill"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test --chunk-tokens parameter controls chunk size.'",
          "description": "'Test --chunk-tokens parameter controls chunk size.'",
          "expected_result": null,
          "verification": "assert success",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
          "description": "Assign skill_dir = create_test_skill(...)",
          "expected_result": null,
          "verification": "assert success",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "success, package_path = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=256, preserve_code_blocks=True)",
          "description": "Assign unknown = package_skill(...)",
          "expected_result": null,
          "verification": "assert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "success, package_path2 = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=1024, preserve_code_blocks=True)",
          "description": "Assign unknown = package_skill(...)",
          "expected_result": null,
          "verification": "assert success",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "data_small = json.load(f)",
          "description": "Assign data_small = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "data_large = json.load(f)",
          "description": "Assign data_large = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Tokens Parameter",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_chunking_integration.py:318"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "020c19cef7fd",
      "title": "Terminal Launch Error Handling",
      "overview": "Workflow: Test error handling when terminal launch fails.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "13d01943",
          "test_name": "test_terminal_launch_error_handling",
          "category": "workflow",
          "code": "'Test error handling when terminal launch fails.'\nif sys.platform != 'darwin':\n    self.skipTest('This test only runs on macOS')\nmock_popen.side_effect = Exception('Terminal not found')\nimport tempfile\nwith tempfile.TemporaryDirectory() as tmpdir:\n    skill_dir = Path(tmpdir) / 'test_skill'\n    skill_dir.mkdir()\n    (skill_dir / 'references').mkdir()\n    (skill_dir / 'references' / 'test.md').write_text('# Test')\n    (skill_dir / 'SKILL.md').write_text('---\\nname: test\\n---\\n# Test')\n    enhancer = LocalSkillEnhancer(skill_dir)\n    from io import StringIO\n    captured_output = StringIO()\n    old_stdout = sys.stdout\n    sys.stdout = captured_output\n    result = enhancer.run(headless=False)\n    sys.stdout = old_stdout\n    self.assertFalse(result)\n    output = captured_output.getvalue()\n    self.assertIn('Error launching', output)",
          "language": "Python",
          "description": "Workflow: Test error handling when terminal launch fails.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
          "line_start": 218,
          "line_end": 256,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_popen",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "pathlib",
            "unittest.mock",
            "skill_seekers.cli.enhance_skill_local",
            "tempfile",
            "tempfile",
            "tempfile",
            "skill_seekers.cli.enhance_skill_local",
            "io",
            "io"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test error handling when terminal launch fails.'",
          "description": "'Test error handling when terminal launch fails.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "mock_popen.side_effect = Exception('Terminal not found')",
          "description": "Assign mock_popen.side_effect = Exception(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "self.skipTest('This test only runs on macOS')",
          "description": "Call self.skipTest()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_dir = Path(tmpdir) / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(skill_dir / 'references').mkdir()",
          "description": "Call unknown.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "(skill_dir / 'references' / 'test.md').write_text('# Test')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "(skill_dir / 'SKILL.md').write_text('---\\nname: test\\n---\\n# Test')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "enhancer = LocalSkillEnhancer(skill_dir)",
          "description": "Assign enhancer = LocalSkillEnhancer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "captured_output = StringIO()",
          "description": "Assign captured_output = StringIO(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "old_stdout = sys.stdout",
          "description": "Assign old_stdout = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "sys.stdout = captured_output",
          "description": "Assign sys.stdout = captured_output",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "result = enhancer.run(headless=False)",
          "description": "Assign result = enhancer.run(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "sys.stdout = old_stdout",
          "description": "Assign sys.stdout = old_stdout",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "self.assertFalse(result)",
          "description": "Call self.assertFalse()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "output = captured_output.getvalue()",
          "description": "Assign output = captured_output.getvalue(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "self.assertIn('Error launching', output)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Terminal Launch Error Handling",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_terminal_detection.py:218"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "604b6e6d7bd5",
      "title": "Detect From Html With Css Class",
      "overview": "Workflow: Test HTML element with CSS class",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a326d5e1",
          "test_name": "test_detect_from_html_with_css_class",
          "category": "workflow",
          "code": "'Test HTML element with CSS class'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-python\">print(\"hello\")</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'print(\"hello\")')\nassert lang == 'python'\nassert confidence == 1.0",
          "language": "Python",
          "description": "Workflow: Test HTML element with CSS class",
          "expected_behavior": "assert confidence == 1.0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
          "line_start": 77,
          "line_end": 88,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test HTML element with CSS class'",
          "description": "'Test HTML element with CSS class'",
          "expected_result": null,
          "verification": "assert lang == 'python'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence == 1.0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "html = '<code class=\"language-python\">print(\"hello\")</code>'",
          "description": "Assign html = '<code class=\"language-python\">print(\"hello\")</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "soup = BeautifulSoup(html, 'html.parser')",
          "description": "Assign soup = BeautifulSoup(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "elem = soup.find('code')",
          "description": "Assign elem = soup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "lang, confidence = detector.detect_from_html(elem, 'print(\"hello\")')",
          "description": "Assign unknown = detector.detect_from_html(...)",
          "expected_result": null,
          "verification": "assert lang == 'python'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect From Html With Css Class",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_language_detector.py:77"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a8beda260695",
      "title": "Detect From Html With Parent Class",
      "overview": "Workflow: Test parent <pre> element with CSS class",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4f01d261",
          "test_name": "test_detect_from_html_with_parent_class",
          "category": "workflow",
          "code": "'Test parent <pre> element with CSS class'\ndetector = LanguageDetector()\nhtml = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'System.out.println(\"hello\");')\nassert lang == 'java'\nassert confidence == 1.0",
          "language": "Python",
          "description": "Workflow: Test parent <pre> element with CSS class",
          "expected_behavior": "assert confidence == 1.0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
          "line_start": 90,
          "line_end": 101,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parent <pre> element with CSS class'",
          "description": "'Test parent <pre> element with CSS class'",
          "expected_result": null,
          "verification": "assert lang == 'java'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence == 1.0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "html = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'",
          "description": "Assign html = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "soup = BeautifulSoup(html, 'html.parser')",
          "description": "Assign soup = BeautifulSoup(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "elem = soup.find('code')",
          "description": "Assign elem = soup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "lang, confidence = detector.detect_from_html(elem, 'System.out.println(\"hello\");')",
          "description": "Assign unknown = detector.detect_from_html(...)",
          "expected_result": null,
          "verification": "assert lang == 'java'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect From Html With Parent Class",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_language_detector.py:90"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9c27829a9f8d",
      "title": "Unity Lifecycle Methods",
      "overview": "Workflow: Test Unity lifecycle method detection",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0a9a9ea2",
          "test_name": "test_unity_lifecycle_methods",
          "category": "workflow",
          "code": "'Test Unity lifecycle method detection'\ndetector = LanguageDetector()\ncode = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5",
          "language": "Python",
          "description": "Workflow: Test Unity lifecycle method detection",
          "expected_behavior": "assert confidence >= 0.5",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
          "line_start": 128,
          "line_end": 142,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Unity lifecycle method detection'",
          "description": "'Test Unity lifecycle method detection'",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.5",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '",
          "description": "Assign code = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Unity Lifecycle Methods",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_language_detector.py:128"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e721b645377a",
      "title": "Unity Namespace",
      "overview": "Workflow: Test Unity namespace detection",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "fea31fb0",
          "test_name": "test_unity_namespace",
          "category": "workflow",
          "code": "'Test Unity namespace detection'\ndetector = LanguageDetector()\ncode = 'using UnityEngine;'\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5\ncode = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5",
          "language": "Python",
          "description": "Workflow: Test Unity namespace detection",
          "expected_behavior": "assert confidence >= 0.5",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
          "line_start": 190,
          "line_end": 209,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Unity namespace detection'",
          "description": "'Test Unity namespace detection'",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.5",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = 'using UnityEngine;'",
          "description": "Assign code = 'using UnityEngine;'",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.5",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "code = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '",
          "description": "Assign code = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Unity Namespace",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_language_detector.py:190"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "58064ee268f4",
      "title": "Unity Full Script",
      "overview": "Workflow: Test complete Unity script (high confidence expected)",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "aa0288ef",
          "test_name": "test_unity_full_script",
          "category": "workflow",
          "code": "'Test complete Unity script (high confidence expected)'\ndetector = LanguageDetector()\ncode = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.9",
          "language": "Python",
          "description": "Workflow: Test complete Unity script (high confidence expected)",
          "expected_behavior": "assert confidence >= 0.9",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
          "line_start": 256,
          "line_end": 297,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete Unity script (high confidence expected)'",
          "description": "'Test complete Unity script (high confidence expected)'",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert confidence >= 0.9",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '",
          "description": "Assign code = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lang, confidence = detector.detect_from_code(code)",
          "description": "Assign unknown = detector.detect_from_code(...)",
          "expected_result": null,
          "verification": "assert lang == 'csharp'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Unity Full Script",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_language_detector.py:256"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ab5381c4c49c",
      "title": "Backward Compatibility With Doc Scraper",
      "overview": "Workflow: Test that detector can be used as drop-in replacement",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "1bede1e3",
          "test_name": "test_backward_compatibility_with_doc_scraper",
          "category": "workflow",
          "code": "'Test that detector can be used as drop-in replacement'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\ncode = elem.get_text()\nlang, confidence = detector.detect_from_html(elem, code)\nassert isinstance(lang, str)\nassert isinstance(confidence, float)\nassert lang == 'python'\nassert 0.0 <= confidence <= 1.0",
          "language": "Python",
          "description": "Workflow: Test that detector can be used as drop-in replacement",
          "expected_behavior": "assert 0.0 <= confidence <= 1.0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
          "line_start": 688,
          "line_end": 705,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "bs4",
            "skill_seekers.cli.language_detector"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that detector can be used as drop-in replacement'",
          "description": "'Test that detector can be used as drop-in replacement'",
          "expected_result": null,
          "verification": "assert isinstance(lang, str)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "detector = LanguageDetector()",
          "description": "Assign detector = LanguageDetector(...)",
          "expected_result": null,
          "verification": "assert isinstance(confidence, float)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "html = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'",
          "description": "Assign html = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'",
          "expected_result": null,
          "verification": "assert lang == 'python'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "soup = BeautifulSoup(html, 'html.parser')",
          "description": "Assign soup = BeautifulSoup(...)",
          "expected_result": null,
          "verification": "assert 0.0 <= confidence <= 1.0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "elem = soup.find('code')",
          "description": "Assign elem = soup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "lang, confidence = detector.detect_from_html(elem, code)",
          "description": "Assign unknown = detector.detect_from_html(...)",
          "expected_result": null,
          "verification": "assert isinstance(lang, str)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Backward Compatibility With Doc Scraper",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_language_detector.py:688"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3c11a6471966",
      "title": "Local Provider Deterministic",
      "overview": "Workflow: Test local provider generates deterministic embeddings.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2f6a8729",
          "test_name": "test_local_provider_deterministic",
          "category": "workflow",
          "code": "'Test local provider generates deterministic embeddings.'\nprovider = LocalEmbeddingProvider(dimension=64)\ntext = 'same text'\nemb1 = provider.generate_embeddings([text])[0]\nemb2 = provider.generate_embeddings([text])[0]\nassert emb1 == emb2",
          "language": "Python",
          "description": "Workflow: Test local provider generates deterministic embeddings.",
          "expected_behavior": "assert emb1 == emb2",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 45,
          "line_end": 54,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test local provider generates deterministic embeddings.'",
          "description": "'Test local provider generates deterministic embeddings.'",
          "expected_result": null,
          "verification": "assert emb1 == emb2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "provider = LocalEmbeddingProvider(dimension=64)",
          "description": "Assign provider = LocalEmbeddingProvider(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = 'same text'",
          "description": "Assign text = 'same text'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "emb1 = provider.generate_embeddings([text])[0]",
          "description": "Assign emb1 = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "emb2 = provider.generate_embeddings([text])[0]",
          "description": "Assign emb2 = value",
          "expected_result": null,
          "verification": "assert emb1 == emb2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Local Provider Deterministic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:45"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "1a1efe6a58f7",
      "title": "Cache Memory",
      "overview": "Workflow: Test memory cache functionality.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a1116f14",
          "test_name": "test_cache_memory",
          "category": "workflow",
          "code": "'Test memory cache functionality.'\ncache = EmbeddingCache()\ntext = 'test text'\nmodel = 'test-model'\nembedding = [0.1, 0.2, 0.3]\ncache.set(text, model, embedding)\nretrieved = cache.get(text, model)\nassert retrieved == embedding",
          "language": "Python",
          "description": "Workflow: Test memory cache functionality.",
          "expected_behavior": "assert retrieved == embedding",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 65,
          "line_end": 77,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test memory cache functionality.'",
          "description": "'Test memory cache functionality.'",
          "expected_result": null,
          "verification": "assert retrieved == embedding",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "cache = EmbeddingCache()",
          "description": "Assign cache = EmbeddingCache(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = 'test text'",
          "description": "Assign text = 'test text'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "model = 'test-model'",
          "description": "Assign model = 'test-model'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "embedding = [0.1, 0.2, 0.3]",
          "description": "Assign embedding = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "cache.set(text, model, embedding)",
          "description": "Call cache.set()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "retrieved = cache.get(text, model)",
          "description": "Assign retrieved = cache.get(...)",
          "expected_result": null,
          "verification": "assert retrieved == embedding",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cache Memory",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_embedding_pipeline.py:65"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f6c1921e5140",
      "title": "Pipeline Initialization",
      "overview": "Workflow: Test pipeline initialization.",
      "complexity_level": "beginner",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "25a65715",
          "test_name": "test_pipeline_initialization",
          "category": "workflow",
          "code": "'Test pipeline initialization.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128, batch_size=10)\npipeline = EmbeddingPipeline(config)\nassert pipeline.config == config\nassert pipeline.provider is not None\nassert pipeline.cache is not None",
          "language": "Python",
          "description": "Workflow: Test pipeline initialization.",
          "expected_behavior": "assert pipeline.cache is not None",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 125,
          "line_end": 133,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test pipeline initialization.'",
          "description": "'Test pipeline initialization.'",
          "expected_result": null,
          "verification": "assert pipeline.config == config",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=128, batch_size=10)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": "assert pipeline.provider is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": "assert pipeline.cache is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Pipeline Initialization",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_embedding_pipeline.py:125"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b7ea572237d1",
      "title": "Pipeline Generate Batch",
      "overview": "Workflow: Test batch embedding generation.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c4af93c8",
          "test_name": "test_pipeline_generate_batch",
          "category": "workflow",
          "code": "'Test batch embedding generation.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=64, batch_size=2)\npipeline = EmbeddingPipeline(config)\ntexts = ['doc 1', 'doc 2', 'doc 3']\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert len(result.embeddings) == 3\nassert len(result.embeddings[0]) == 64\nassert result.generated_count == 3\nassert result.cached_count == 0",
          "language": "Python",
          "description": "Workflow: Test batch embedding generation.",
          "expected_behavior": "assert result.cached_count == 0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 136,
          "line_end": 148,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test batch embedding generation.'",
          "description": "'Test batch embedding generation.'",
          "expected_result": null,
          "verification": "assert len(result.embeddings) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=64, batch_size=2)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": "assert len(result.embeddings[0]) == 64",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": "assert result.generated_count == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "texts = ['doc 1', 'doc 2', 'doc 3']",
          "description": "Assign texts = value",
          "expected_result": null,
          "verification": "assert result.cached_count == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = pipeline.generate_batch(texts, show_progress=False)",
          "description": "Assign result = pipeline.generate_batch(...)",
          "expected_result": null,
          "verification": "assert len(result.embeddings) == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Pipeline Generate Batch",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:136"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ad453b2f8bcd",
      "title": "Pipeline Batch Processing",
      "overview": "Workflow: Test large batch is processed in chunks.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "407de5a9",
          "test_name": "test_pipeline_batch_processing",
          "category": "workflow",
          "code": "'Test large batch is processed in chunks.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=16, batch_size=3)\npipeline = EmbeddingPipeline(config)\ntexts = [f'doc {i}' for i in range(10)]\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert len(result.embeddings) == 10",
          "language": "Python",
          "description": "Workflow: Test large batch is processed in chunks.",
          "expected_behavior": "assert len(result.embeddings) == 10",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 177,
          "line_end": 192,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test large batch is processed in chunks.'",
          "description": "'Test large batch is processed in chunks.'",
          "expected_result": null,
          "verification": "assert len(result.embeddings) == 10",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=16, batch_size=3)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "texts = [f'doc {i}' for i in range(10)]",
          "description": "Assign texts = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = pipeline.generate_batch(texts, show_progress=False)",
          "description": "Assign result = pipeline.generate_batch(...)",
          "expected_result": null,
          "verification": "assert len(result.embeddings) == 10",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Pipeline Batch Processing",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:177"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "37fd9bbe50ec",
      "title": "Validate Dimensions Valid",
      "overview": "Workflow: Test dimension validation with valid embeddings.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a837031b",
          "test_name": "test_validate_dimensions_valid",
          "category": "workflow",
          "code": "'Test dimension validation with valid embeddings.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128)\npipeline = EmbeddingPipeline(config)\nembeddings = [[0.1] * 128, [0.2] * 128]\nis_valid = pipeline.validate_dimensions(embeddings)\nassert is_valid",
          "language": "Python",
          "description": "Workflow: Test dimension validation with valid embeddings.",
          "expected_behavior": "assert is_valid",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 195,
          "line_end": 204,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test dimension validation with valid embeddings.'",
          "description": "'Test dimension validation with valid embeddings.'",
          "expected_result": null,
          "verification": "assert is_valid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=128)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "embeddings = [[0.1] * 128, [0.2] * 128]",
          "description": "Assign embeddings = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "is_valid = pipeline.validate_dimensions(embeddings)",
          "description": "Assign is_valid = pipeline.validate_dimensions(...)",
          "expected_result": null,
          "verification": "assert is_valid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Validate Dimensions Valid",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:195"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4875231c2831",
      "title": "Validate Dimensions Invalid",
      "overview": "Workflow: Test dimension validation with invalid embeddings.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d25ca695",
          "test_name": "test_validate_dimensions_invalid",
          "category": "workflow",
          "code": "'Test dimension validation with invalid embeddings.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128)\npipeline = EmbeddingPipeline(config)\nembeddings = [[0.1] * 64, [0.2] * 128]\nis_valid = pipeline.validate_dimensions(embeddings)\nassert not is_valid",
          "language": "Python",
          "description": "Workflow: Test dimension validation with invalid embeddings.",
          "expected_behavior": "assert not is_valid",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 207,
          "line_end": 217,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test dimension validation with invalid embeddings.'",
          "description": "'Test dimension validation with invalid embeddings.'",
          "expected_result": null,
          "verification": "assert not is_valid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=128)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "embeddings = [[0.1] * 64, [0.2] * 128]",
          "description": "Assign embeddings = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "is_valid = pipeline.validate_dimensions(embeddings)",
          "description": "Assign is_valid = pipeline.validate_dimensions(...)",
          "expected_result": null,
          "verification": "assert not is_valid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Validate Dimensions Invalid",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:207"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "288718cc914a",
      "title": "Embedding Result Metadata",
      "overview": "Workflow: Test embedding result includes metadata.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "93a3469f",
          "test_name": "test_embedding_result_metadata",
          "category": "workflow",
          "code": "'Test embedding result includes metadata.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=256)\npipeline = EmbeddingPipeline(config)\ntexts = ['test']\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert 'provider' in result.metadata\nassert 'model' in result.metadata\nassert 'dimension' in result.metadata\nassert result.metadata['dimension'] == 256",
          "language": "Python",
          "description": "Workflow: Test embedding result includes metadata.",
          "expected_behavior": "assert result.metadata['dimension'] == 256",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 220,
          "line_end": 232,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test embedding result includes metadata.'",
          "description": "'Test embedding result includes metadata.'",
          "expected_result": null,
          "verification": "assert 'provider' in result.metadata",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=256)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": "assert 'model' in result.metadata",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": "assert 'dimension' in result.metadata",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "texts = ['test']",
          "description": "Assign texts = value",
          "expected_result": null,
          "verification": "assert result.metadata['dimension'] == 256",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = pipeline.generate_batch(texts, show_progress=False)",
          "description": "Assign result = pipeline.generate_batch(...)",
          "expected_result": null,
          "verification": "assert 'provider' in result.metadata",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Embedding Result Metadata",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:220"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0032a327212e",
      "title": "Cost Stats",
      "overview": "Workflow: Test cost statistics tracking.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "98b546c7",
          "test_name": "test_cost_stats",
          "category": "workflow",
          "code": "'Test cost statistics tracking.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=64)\npipeline = EmbeddingPipeline(config)\ntexts = ['doc 1', 'doc 2']\npipeline.generate_batch(texts, show_progress=False)\nstats = pipeline.get_cost_stats()\nassert 'total_requests' in stats\nassert 'cache_hits' in stats\nassert 'estimated_cost' in stats",
          "language": "Python",
          "description": "Workflow: Test cost statistics tracking.",
          "expected_behavior": "assert 'estimated_cost' in stats",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
          "line_start": 235,
          "line_end": 248,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.embedding_pipeline"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test cost statistics tracking.'",
          "description": "'Test cost statistics tracking.'",
          "expected_result": null,
          "verification": "assert 'total_requests' in stats",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=64)",
          "description": "Assign config = EmbeddingConfig(...)",
          "expected_result": null,
          "verification": "assert 'cache_hits' in stats",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "pipeline = EmbeddingPipeline(config)",
          "description": "Assign pipeline = EmbeddingPipeline(...)",
          "expected_result": null,
          "verification": "assert 'estimated_cost' in stats",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "texts = ['doc 1', 'doc 2']",
          "description": "Assign texts = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "pipeline.generate_batch(texts, show_progress=False)",
          "description": "Call pipeline.generate_batch()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "stats = pipeline.get_cost_stats()",
          "description": "Assign stats = pipeline.get_cost_stats(...)",
          "expected_result": null,
          "verification": "assert 'total_requests' in stats",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cost Stats",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_embedding_pipeline.py:235"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2675d0c07dc9",
      "title": "Categorize Issues Basic",
      "overview": "Workflow: Test basic issue categorization.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ad900c24",
          "test_name": "test_categorize_issues_basic",
          "category": "workflow",
          "code": "'Test basic issue categorization.'\nproblems = [{'title': 'OAuth setup fails', 'labels': ['bug', 'oauth'], 'number': 1, 'state': 'open', 'comments': 10}, {'title': 'Testing framework issue', 'labels': ['testing'], 'number': 2, 'state': 'open', 'comments': 5}]\nsolutions = [{'title': 'Fixed OAuth redirect', 'labels': ['oauth'], 'number': 3, 'state': 'closed', 'comments': 3}]\ntopics = ['oauth', 'testing', 'async']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized\nassert len(categorized['oauth']) == 2\nassert 'testing' in categorized\nassert len(categorized['testing']) == 1",
          "language": "Python",
          "description": "Workflow: Test basic issue categorization.",
          "expected_behavior": "assert len(categorized['testing']) == 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 24,
          "line_end": 59,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic issue categorization.'",
          "description": "'Test basic issue categorization.'",
          "expected_result": null,
          "verification": "assert 'oauth' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "problems = [{'title': 'OAuth setup fails', 'labels': ['bug', 'oauth'], 'number': 1, 'state': 'open', 'comments': 10}, {'title': 'Testing framework issue', 'labels': ['testing'], 'number': 2, 'state': 'open', 'comments': 5}]",
          "description": "Assign problems = value",
          "expected_result": null,
          "verification": "assert len(categorized['oauth']) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "solutions = [{'title': 'Fixed OAuth redirect', 'labels': ['oauth'], 'number': 3, 'state': 'closed', 'comments': 3}]",
          "description": "Assign solutions = value",
          "expected_result": null,
          "verification": "assert 'testing' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "topics = ['oauth', 'testing', 'async']",
          "description": "Assign topics = value",
          "expected_result": null,
          "verification": "assert len(categorized['testing']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
          "description": "Assign categorized = categorize_issues_by_topic(...)",
          "expected_result": null,
          "verification": "assert 'oauth' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Categorize Issues Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_merge_sources_github.py:24"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "205a97313313",
      "title": "Generate Hybrid Content Basic",
      "overview": "Workflow: Test basic hybrid content generation.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "90f3d018",
          "test_name": "test_generate_hybrid_content_basic",
          "category": "workflow",
          "code": "'Test basic hybrid content generation.'\napi_data = {'apis': {'oauth_login': {'name': 'oauth_login', 'status': 'matched'}}, 'summary': {'total_apis': 1}}\ngithub_docs = {'readme': '# Project README', 'contributing': None, 'docs_files': [{'path': 'docs/oauth.md', 'content': 'OAuth guide'}]}\ngithub_insights = {'metadata': {'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'Test project'}, 'common_problems': [{'title': 'OAuth fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug']}], 'known_solutions': [{'title': 'Fixed OAuth', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], 'top_labels': [{'label': 'bug', 'count': 10}, {'label': 'enhancement', 'count': 5}]}\nconflicts = []\nhybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)\nassert 'api_reference' in hybrid\nassert 'github_context' in hybrid\nassert 'conflict_summary' in hybrid\nassert 'issue_links' in hybrid\nassert hybrid['github_context']['docs']['readme'] == '# Project README'\nassert hybrid['github_context']['docs']['docs_files_count'] == 1\nassert hybrid['github_context']['metadata']['stars'] == 1234\nassert hybrid['github_context']['metadata']['language'] == 'Python'\nassert hybrid['github_context']['issues']['common_problems_count'] == 1\nassert hybrid['github_context']['issues']['known_solutions_count'] == 1\nassert len(hybrid['github_context']['issues']['top_problems']) == 1\nassert len(hybrid['github_context']['top_labels']) == 2",
          "language": "Python",
          "description": "Workflow: Test basic hybrid content generation.",
          "expected_behavior": "assert len(hybrid['github_context']['top_labels']) == 2",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 133,
          "line_end": 194,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic hybrid content generation.'",
          "description": "'Test basic hybrid content generation.'",
          "expected_result": null,
          "verification": "assert 'api_reference' in hybrid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "api_data = {'apis': {'oauth_login': {'name': 'oauth_login', 'status': 'matched'}}, 'summary': {'total_apis': 1}}",
          "description": "Assign api_data = value",
          "expected_result": null,
          "verification": "assert 'github_context' in hybrid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_docs = {'readme': '# Project README', 'contributing': None, 'docs_files': [{'path': 'docs/oauth.md', 'content': 'OAuth guide'}]}",
          "description": "Assign github_docs = value",
          "expected_result": null,
          "verification": "assert 'conflict_summary' in hybrid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "github_insights = {'metadata': {'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'Test project'}, 'common_problems': [{'title': 'OAuth fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug']}], 'known_solutions': [{'title': 'Fixed OAuth', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], 'top_labels': [{'label': 'bug', 'count': 10}, {'label': 'enhancement', 'count': 5}]}",
          "description": "Assign github_insights = value",
          "expected_result": null,
          "verification": "assert 'issue_links' in hybrid",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = []",
          "description": "Assign conflicts = value",
          "expected_result": null,
          "verification": "assert hybrid['github_context']['docs']['readme'] == '# Project README'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "hybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)",
          "description": "Assign hybrid = generate_hybrid_content(...)",
          "expected_result": null,
          "verification": "assert hybrid['github_context']['docs']['docs_files_count'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Hybrid Content Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_merge_sources_github.py:133"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "992cc9e319e0",
      "title": "Generate Hybrid Content With Conflicts",
      "overview": "Workflow: Test hybrid content with conflicts.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "06f6dd43",
          "test_name": "test_generate_hybrid_content_with_conflicts",
          "category": "workflow",
          "code": "'Test hybrid content with conflicts.'\napi_data = {'apis': {}, 'summary': {}}\ngithub_docs = None\ngithub_insights = None\nconflicts = [Conflict(api_name='test_api', type='signature_mismatch', severity='medium', difference='Parameter count differs', docs_info={'parameters': ['a', 'b']}, code_info={'parameters': ['a', 'b', 'c']}), Conflict(api_name='test_api_2', type='missing_in_docs', severity='low', difference='API not documented', docs_info=None, code_info={'name': 'test_api_2'})]\nhybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)\nassert hybrid['conflict_summary']['total_conflicts'] == 2\nassert hybrid['conflict_summary']['by_type']['signature_mismatch'] == 1\nassert hybrid['conflict_summary']['by_type']['missing_in_docs'] == 1\nassert hybrid['conflict_summary']['by_severity']['medium'] == 1\nassert hybrid['conflict_summary']['by_severity']['low'] == 1",
          "language": "Python",
          "description": "Workflow: Test hybrid content with conflicts.",
          "expected_behavior": "assert hybrid['conflict_summary']['by_severity']['low'] == 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 196,
          "line_end": 228,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test hybrid content with conflicts.'",
          "description": "'Test hybrid content with conflicts.'",
          "expected_result": null,
          "verification": "assert hybrid['conflict_summary']['total_conflicts'] == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "api_data = {'apis': {}, 'summary': {}}",
          "description": "Assign api_data = value",
          "expected_result": null,
          "verification": "assert hybrid['conflict_summary']['by_type']['signature_mismatch'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_docs = None",
          "description": "Assign github_docs = None",
          "expected_result": null,
          "verification": "assert hybrid['conflict_summary']['by_type']['missing_in_docs'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "github_insights = None",
          "description": "Assign github_insights = None",
          "expected_result": null,
          "verification": "assert hybrid['conflict_summary']['by_severity']['medium'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "conflicts = [Conflict(api_name='test_api', type='signature_mismatch', severity='medium', difference='Parameter count differs', docs_info={'parameters': ['a', 'b']}, code_info={'parameters': ['a', 'b', 'c']}), Conflict(api_name='test_api_2', type='missing_in_docs', severity='low', difference='API not documented', docs_info=None, code_info={'name': 'test_api_2'})]",
          "description": "Assign conflicts = value",
          "expected_result": null,
          "verification": "assert hybrid['conflict_summary']['by_severity']['low'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "hybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)",
          "description": "Assign hybrid = generate_hybrid_content(...)",
          "expected_result": null,
          "verification": "assert hybrid['conflict_summary']['total_conflicts'] == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Hybrid Content With Conflicts",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_merge_sources_github.py:196"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3c0dca885171",
      "title": "Match Issues To Apis Basic",
      "overview": "Workflow: Test basic issue to API matching.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [
        "api_client"
      ],
      "workflows": [
        {
          "example_id": "4a327bf9",
          "test_name": "test_match_issues_to_apis_basic",
          "category": "workflow",
          "code": "'Test basic issue to API matching.'\napis = {'oauth_login': {'name': 'oauth_login'}, 'async_fetch': {'name': 'async_fetch'}}\nproblems = [{'title': 'OAuth login fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug', 'oauth']}]\nsolutions = [{'title': 'Fixed async fetch timeout', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['async']}]\nissue_links = _match_issues_to_apis(apis, problems, solutions)\nassert 'oauth_login' in issue_links\nassert len(issue_links['oauth_login']) == 1\nassert issue_links['oauth_login'][0]['number'] == 42\nassert 'async_fetch' in issue_links\nassert len(issue_links['async_fetch']) == 1\nassert issue_links['async_fetch'][0]['number'] == 35",
          "language": "Python",
          "description": "Workflow: Test basic issue to API matching.",
          "expected_behavior": "assert issue_links['async_fetch'][0]['number'] == 35",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 246,
          "line_end": 280,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic issue to API matching.'",
          "description": "'Test basic issue to API matching.'",
          "expected_result": null,
          "verification": "assert 'oauth_login' in issue_links",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "apis = {'oauth_login': {'name': 'oauth_login'}, 'async_fetch': {'name': 'async_fetch'}}",
          "description": "Assign apis = value",
          "expected_result": null,
          "verification": "assert len(issue_links['oauth_login']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "problems = [{'title': 'OAuth login fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug', 'oauth']}]",
          "description": "Assign problems = value",
          "expected_result": null,
          "verification": "assert issue_links['oauth_login'][0]['number'] == 42",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "solutions = [{'title': 'Fixed async fetch timeout', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['async']}]",
          "description": "Assign solutions = value",
          "expected_result": null,
          "verification": "assert 'async_fetch' in issue_links",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "issue_links = _match_issues_to_apis(apis, problems, solutions)",
          "description": "Assign issue_links = _match_issues_to_apis(...)",
          "expected_result": null,
          "verification": "assert len(issue_links['async_fetch']) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Match Issues To Apis Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_merge_sources_github.py:246"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "56faf7802e20",
      "title": "Merger With Github Streams",
      "overview": "Workflow: Test merger with three-stream GitHub data.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ca735931",
          "test_name": "test_merger_with_github_streams",
          "category": "workflow",
          "code": "'Test merger with three-stream GitHub data.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\nconflicts = []\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# README', contributing='# Contributing', docs_files=[{'path': 'docs/guide.md', 'content': 'Guide content'}])\ninsights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python'}, common_problems=[{'title': 'Bug 1', 'number': 1, 'state': 'open', 'comments': 10, 'labels': ['bug']}], known_solutions=[{'title': 'Fix 1', 'number': 2, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], top_labels=[{'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)\nassert merger.github_streams is not None\nassert merger.github_docs is not None\nassert merger.github_insights is not None\nassert merger.github_docs['readme'] == '# README'\nassert merger.github_insights['metadata']['stars'] == 1234",
          "language": "Python",
          "description": "Workflow: Test merger with three-stream GitHub data.",
          "expected_behavior": "assert merger.github_insights['metadata']['stars'] == 1234",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 325,
          "line_end": 357,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test merger with three-stream GitHub data.'",
          "description": "'Test merger with three-stream GitHub data.'",
          "expected_result": null,
          "verification": "assert merger.github_streams is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': []}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert merger.github_docs is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'apis': {}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert merger.github_insights is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "conflicts = []",
          "description": "Assign conflicts = value",
          "expected_result": null,
          "verification": "assert merger.github_docs['readme'] == '# README'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": "assert merger.github_insights['metadata']['stars'] == 1234",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "docs_stream = DocsStream(readme='# README', contributing='# Contributing', docs_files=[{'path': 'docs/guide.md', 'content': 'Guide content'}])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "insights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python'}, common_problems=[{'title': 'Bug 1', 'number': 1, 'state': 'open', 'comments': 10, 'labels': ['bug']}], known_solutions=[{'title': 'Fix 1', 'number': 2, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], top_labels=[{'label': 'bug', 'count': 10}])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": "assert merger.github_streams is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Merger With Github Streams",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_merge_sources_github.py:325"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f611624daf53",
      "title": "Merger Merge All With Streams",
      "overview": "Workflow: Test merge_all() with GitHub streams.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e819cbda",
          "test_name": "test_merger_merge_all_with_streams",
          "category": "workflow",
          "code": "'Test merge_all() with GitHub streams.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\nconflicts = []\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# README', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 500}, common_problems=[], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)\nresult = merger.merge_all()\nassert 'github_context' in result\nassert 'conflict_summary' in result\nassert 'issue_links' in result\nassert result['github_context']['metadata']['stars'] == 500",
          "language": "Python",
          "description": "Workflow: Test merge_all() with GitHub streams.",
          "expected_behavior": "assert result['github_context']['metadata']['stars'] == 500",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 359,
          "line_end": 381,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test merge_all() with GitHub streams.'",
          "description": "'Test merge_all() with GitHub streams.'",
          "expected_result": null,
          "verification": "assert 'github_context' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': []}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert 'conflict_summary' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'apis': {}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert 'issue_links' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "conflicts = []",
          "description": "Assign conflicts = value",
          "expected_result": null,
          "verification": "assert result['github_context']['metadata']['stars'] == 500",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "docs_stream = DocsStream(readme='# README', contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "insights_stream = InsightsStream(metadata={'stars': 500}, common_problems=[], known_solutions=[], top_labels=[])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "merger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "result = merger.merge_all()",
          "description": "Assign result = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert 'github_context' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Merger Merge All With Streams",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_merge_sources_github.py:359"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "8a4d91b38f5a",
      "title": "Full Pipeline With Streams",
      "overview": "Workflow: Test complete pipeline with three-stream data.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "01f0d76f",
          "test_name": "test_full_pipeline_with_streams",
          "category": "workflow",
          "code": "'Test complete pipeline with three-stream data.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test Project\\n\\nA test project.', contributing='# Contributing\\n\\nPull requests welcome.', docs_files=[{'path': 'docs/quickstart.md', 'content': '# Quick Start'}, {'path': 'docs/api.md', 'content': '# API Reference'}])\ninsights_stream = InsightsStream(metadata={'stars': 2500, 'forks': 123, 'language': 'Python', 'description': 'Test framework'}, common_problems=[{'title': 'Installation fails on Windows', 'number': 150, 'state': 'open', 'comments': 25, 'labels': ['bug', 'windows']}, {'title': 'Memory leak in async mode', 'number': 142, 'state': 'open', 'comments': 18, 'labels': ['bug', 'async']}], known_solutions=[{'title': 'Fixed config loading', 'number': 130, 'state': 'closed', 'comments': 8, 'labels': ['bug']}, {'title': 'Resolved OAuth timeout', 'number': 125, 'state': 'closed', 'comments': 12, 'labels': ['oauth']}], top_labels=[{'label': 'bug', 'count': 45}, {'label': 'enhancement', 'count': 20}, {'label': 'question', 'count': 15}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, [], github_streams)\nresult = merger.merge_all()\nassert 'apis' in result\nassert 'github_context' in result\ngh_context = result['github_context']\nassert gh_context['docs']['readme'] == '# Test Project\\n\\nA test project.'\nassert gh_context['docs']['contributing'] == '# Contributing\\n\\nPull requests welcome.'\nassert gh_context['docs']['docs_files_count'] == 2\nassert gh_context['metadata']['stars'] == 2500\nassert gh_context['metadata']['language'] == 'Python'\nassert gh_context['issues']['common_problems_count'] == 2\nassert gh_context['issues']['known_solutions_count'] == 2\nassert len(gh_context['issues']['top_problems']) == 2\nassert len(gh_context['issues']['top_solutions']) == 2\nassert len(gh_context['top_labels']) == 3\nassert 'conflict_summary' in result\nassert result['conflict_summary']['total_conflicts'] == 0",
          "language": "Python",
          "description": "Workflow: Test complete pipeline with three-stream data.",
          "expected_behavior": "assert result['conflict_summary']['total_conflicts'] == 0",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
          "line_start": 407,
          "line_end": 495,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "skill_seekers.cli.conflict_detector",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete pipeline with three-stream data.'",
          "description": "'Test complete pipeline with three-stream data.'",
          "expected_result": null,
          "verification": "assert 'apis' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "docs_data = {'pages': []}",
          "description": "Assign docs_data = value",
          "expected_result": null,
          "verification": "assert 'github_context' in result",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_data = {'apis': {}}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert gh_context['docs']['readme'] == '# Test Project\\n\\nA test project.'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": "assert gh_context['docs']['contributing'] == '# Contributing\\n\\nPull requests welcome.'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme='# Test Project\\n\\nA test project.', contributing='# Contributing\\n\\nPull requests welcome.', docs_files=[{'path': 'docs/quickstart.md', 'content': '# Quick Start'}, {'path': 'docs/api.md', 'content': '# API Reference'}])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": "assert gh_context['docs']['docs_files_count'] == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={'stars': 2500, 'forks': 123, 'language': 'Python', 'description': 'Test framework'}, common_problems=[{'title': 'Installation fails on Windows', 'number': 150, 'state': 'open', 'comments': 25, 'labels': ['bug', 'windows']}, {'title': 'Memory leak in async mode', 'number': 142, 'state': 'open', 'comments': 18, 'labels': ['bug', 'async']}], known_solutions=[{'title': 'Fixed config loading', 'number': 130, 'state': 'closed', 'comments': 8, 'labels': ['bug']}, {'title': 'Resolved OAuth timeout', 'number': 125, 'state': 'closed', 'comments': 12, 'labels': ['oauth']}], top_labels=[{'label': 'bug', 'count': 45}, {'label': 'enhancement', 'count': 20}, {'label': 'question', 'count': 15}])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": "assert gh_context['metadata']['stars'] == 2500",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": "assert gh_context['metadata']['language'] == 'Python'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "merger = RuleBasedMerger(docs_data, github_data, [], github_streams)",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": "assert gh_context['issues']['common_problems_count'] == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "result = merger.merge_all()",
          "description": "Assign result = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert gh_context['issues']['known_solutions_count'] == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "gh_context = result['github_context']",
          "description": "Assign gh_context = value",
          "expected_result": null,
          "verification": "assert len(gh_context['issues']['top_problems']) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Full Pipeline With Streams",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_merge_sources_github.py:407"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "bfd723729c5e",
      "title": "Benchmark Format Skill Md All Adaptors",
      "overview": "Workflow: Benchmark format_skill_md across all adaptors",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "03aa860a",
          "test_name": "test_benchmark_format_skill_md_all_adaptors",
          "category": "workflow",
          "code": "'Benchmark format_skill_md across all adaptors'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: format_skill_md() - All Adaptors')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nmetadata = SkillMetadata(name='benchmark', description='Benchmark test')\nplatforms = ['claude', 'gemini', 'openai', 'markdown', 'langchain', 'llama-index', 'haystack', 'weaviate', 'chroma', 'faiss', 'qdrant']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    adaptor.format_skill_md(skill_dir, metadata)\n    times = []\n    for _ in range(5):\n        start = time.perf_counter()\n        formatted = adaptor.format_skill_md(skill_dir, metadata)\n        end = time.perf_counter()\n        times.append(end - start)\n        self.assertIsInstance(formatted, str)\n        self.assertGreater(len(formatted), 0)\n    avg_time = sum(times) / len(times)\n    min_time = min(times)\n    max_time = max(times)\n    results[platform] = {'avg': avg_time, 'min': min_time, 'max': max_time}\n    print(f'{platform:15} - Avg: {avg_time * 1000:6.2f}ms | Min: {min_time * 1000:6.2f}ms | Max: {max_time * 1000:6.2f}ms')\nfor platform, metrics in results.items():\n    self.assertLess(metrics['avg'], 0.5, f\"{platform} format_skill_md too slow: {metrics['avg'] * 1000:.2f}ms\")",
          "language": "Python",
          "description": "Workflow: Benchmark format_skill_md across all adaptors",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
          "line_start": 76,
          "line_end": 139,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tempfile",
            "time",
            "unittest",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Benchmark format_skill_md across all adaptors'",
          "description": "'Benchmark format_skill_md across all adaptors'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "print('\\n' + '=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "print('BENCHMARK: format_skill_md() - All Adaptors')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "print('=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_dir = self._create_skill_with_n_references(10)",
          "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "metadata = SkillMetadata(name='benchmark', description='Benchmark test')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "platforms = ['claude', 'gemini', 'openai', 'markdown', 'langchain', 'llama-index', 'haystack', 'weaviate', 'chroma', 'faiss', 'qdrant']",
          "description": "Assign platforms = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "results = {}",
          "description": "Assign results = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "adaptor.format_skill_md(skill_dir, metadata)",
          "description": "Call adaptor.format_skill_md()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "times = []",
          "description": "Assign times = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "avg_time = sum(times) / len(times)",
          "description": "Assign avg_time = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "min_time = min(times)",
          "description": "Assign min_time = min(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "max_time = max(times)",
          "description": "Assign max_time = max(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "results[platform] = {'avg': avg_time, 'min': min_time, 'max': max_time}",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "print(f'{platform:15} - Avg: {avg_time * 1000:6.2f}ms | Min: {min_time * 1000:6.2f}ms | Max: {max_time * 1000:6.2f}ms')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "self.assertLess(metrics['avg'], 0.5, f\"{platform} format_skill_md too slow: {metrics['avg'] * 1000:.2f}ms\")",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 19,
          "code": "formatted = adaptor.format_skill_md(skill_dir, metadata)",
          "description": "Assign formatted = adaptor.format_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 20,
          "code": "end = time.perf_counter()",
          "description": "Assign end = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 21,
          "code": "times.append(end - start)",
          "description": "Call times.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 22,
          "code": "self.assertIsInstance(formatted, str)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 23,
          "code": "self.assertGreater(len(formatted), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Benchmark Format Skill Md All Adaptors",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptor_benchmarks.py:76"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f3576d17e219",
      "title": "Benchmark Package Operations",
      "overview": "Workflow: Benchmark complete package operation",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2af4f94a",
          "test_name": "test_benchmark_package_operations",
          "category": "workflow",
          "code": "'Benchmark complete package operation'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: package() - Complete Operation')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nplatforms = ['claude', 'langchain', 'chroma', 'weaviate', 'faiss']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    start = time.perf_counter()\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    end = time.perf_counter()\n    elapsed = end - start\n    file_size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'time': elapsed, 'size_kb': file_size_kb}\n    print(f'{platform:15} - Time: {elapsed * 1000:7.2f}ms | Size: {file_size_kb:7.1f} KB')\n    self.assertTrue(package_path.exists())\nfor platform, metrics in results.items():\n    self.assertLess(metrics['time'], 1.0, f\"{platform} packaging too slow: {metrics['time'] * 1000:.2f}ms\")\n    self.assertLess(metrics['size_kb'], 1000, f\"{platform} package too large: {metrics['size_kb']:.1f}KB\")",
          "language": "Python",
          "description": "Workflow: Benchmark complete package operation",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
          "line_start": 141,
          "line_end": 186,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tempfile",
            "time",
            "unittest",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Benchmark complete package operation'",
          "description": "'Benchmark complete package operation'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "print('\\n' + '=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "print('BENCHMARK: package() - Complete Operation')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "print('=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_dir = self._create_skill_with_n_references(10)",
          "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "platforms = ['claude', 'langchain', 'chroma', 'weaviate', 'faiss']",
          "description": "Assign platforms = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "results = {}",
          "description": "Assign results = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "package_path = adaptor.package(skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "end = time.perf_counter()",
          "description": "Assign end = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "elapsed = end - start",
          "description": "Assign elapsed = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "file_size_kb = package_path.stat().st_size / 1024",
          "description": "Assign file_size_kb = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "results[platform] = {'time': elapsed, 'size_kb': file_size_kb}",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "print(f'{platform:15} - Time: {elapsed * 1000:7.2f}ms | Size: {file_size_kb:7.1f} KB')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "self.assertTrue(package_path.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "self.assertLess(metrics['time'], 1.0, f\"{platform} packaging too slow: {metrics['time'] * 1000:.2f}ms\")",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "self.assertLess(metrics['size_kb'], 1000, f\"{platform} package too large: {metrics['size_kb']:.1f}KB\")",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Benchmark Package Operations",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptor_benchmarks.py:141"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "767a6ec40cc6",
      "title": "Benchmark Scaling With Reference Count",
      "overview": "Workflow: Test how performance scales with reference count",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "779840e9",
          "test_name": "test_benchmark_scaling_with_reference_count",
          "category": "workflow",
          "code": "'Test how performance scales with reference count'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Scaling with Reference Count')\nprint('=' * 80)\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='scaling_test', description='Scaling benchmark test')\nreference_counts = [1, 5, 10, 25, 50]\nresults = []\nprint(f\"\\n{'Refs':>4} | {'Time (ms)':>10} | {'Time/Ref':>10} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor ref_count in reference_counts:\n    skill_dir = self._create_skill_with_n_references(ref_count)\n    start = time.perf_counter()\n    formatted = adaptor.format_skill_md(skill_dir, metadata)\n    end = time.perf_counter()\n    elapsed = end - start\n    time_per_ref = elapsed / ref_count\n    json.loads(formatted)\n    size_kb = len(formatted) / 1024\n    results.append({'count': ref_count, 'time': elapsed, 'time_per_ref': time_per_ref, 'size_kb': size_kb})\n    print(f'{ref_count:4} | {elapsed * 1000:10.2f} | {time_per_ref * 1000:10.3f} | {size_kb:10.1f}')\nfirst_per_ref = results[0]['time_per_ref']\nlast_per_ref = results[-1]['time_per_ref']\nscaling_factor = last_per_ref / first_per_ref\nprint(f'\\nScaling Factor: {scaling_factor:.2f}x')\nprint(f'(Time per ref at 50 refs / Time per ref at 1 ref)')\nself.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
          "language": "Python",
          "description": "Workflow: Test how performance scales with reference count",
          "expected_behavior": "self.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
          "line_start": 188,
          "line_end": 243,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tempfile",
            "time",
            "unittest",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test how performance scales with reference count'",
          "description": "'Test how performance scales with reference count'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "print('\\n' + '=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "print('BENCHMARK: Scaling with Reference Count')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "print('=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "adaptor = get_adaptor('langchain')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "metadata = SkillMetadata(name='scaling_test', description='Scaling benchmark test')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "reference_counts = [1, 5, 10, 25, 50]",
          "description": "Assign reference_counts = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "results = []",
          "description": "Assign results = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "print(f\"\\n{'Refs':>4} | {'Time (ms)':>10} | {'Time/Ref':>10} | {'Size (KB)':>10}\")",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "print('-' * 50)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "first_per_ref = results[0]['time_per_ref']",
          "description": "Assign first_per_ref = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "last_per_ref = results[-1]['time_per_ref']",
          "description": "Assign last_per_ref = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "scaling_factor = last_per_ref / first_per_ref",
          "description": "Assign scaling_factor = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "print(f'\\nScaling Factor: {scaling_factor:.2f}x')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "print(f'(Time per ref at 50 refs / Time per ref at 1 ref)')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "self.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "skill_dir = self._create_skill_with_n_references(ref_count)",
          "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 19,
          "code": "formatted = adaptor.format_skill_md(skill_dir, metadata)",
          "description": "Assign formatted = adaptor.format_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 20,
          "code": "end = time.perf_counter()",
          "description": "Assign end = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 21,
          "code": "elapsed = end - start",
          "description": "Assign elapsed = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 22,
          "code": "time_per_ref = elapsed / ref_count",
          "description": "Assign time_per_ref = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 23,
          "code": "json.loads(formatted)",
          "description": "Call json.loads()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 24,
          "code": "size_kb = len(formatted) / 1024",
          "description": "Assign size_kb = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 25,
          "code": "results.append({'count': ref_count, 'time': elapsed, 'time_per_ref': time_per_ref, 'size_kb': size_kb})",
          "description": "Call results.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 26,
          "code": "print(f'{ref_count:4} | {elapsed * 1000:10.2f} | {time_per_ref * 1000:10.3f} | {size_kb:10.1f}')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Benchmark Scaling With Reference Count",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptor_benchmarks.py:188"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "be770dd96ae5",
      "title": "Benchmark Json Vs Zip Size Comparison",
      "overview": "Workflow: Compare output sizes: JSON vs ZIP/tar.gz",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ac4a4955",
          "test_name": "test_benchmark_json_vs_zip_size_comparison",
          "category": "workflow",
          "code": "'Compare output sizes: JSON vs ZIP/tar.gz'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Output Size Comparison')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nformats = {'claude': ('ZIP', '.zip'), 'gemini': ('tar.gz', '.tar.gz'), 'langchain': ('JSON', '.json'), 'weaviate': ('JSON', '.json')}\nresults = {}\nprint(f\"\\n{'Platform':15} | {'Format':8} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor platform, (format_name, ext) in formats.items():\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'format': format_name, 'size_kb': size_kb}\n    print(f'{platform:15} | {format_name:8} | {size_kb:10.1f}')\njson_sizes = [v['size_kb'] for k, v in results.items() if v['format'] == 'JSON']\ncompressed_sizes = [v['size_kb'] for k, v in results.items() if v['format'] in ['ZIP', 'tar.gz']]\nif json_sizes and compressed_sizes:\n    avg_json = sum(json_sizes) / len(json_sizes)\n    avg_compressed = sum(compressed_sizes) / len(compressed_sizes)\n    print(f'\\nAverage JSON size: {avg_json:.1f} KB')\n    print(f'Average compressed size: {avg_compressed:.1f} KB')\n    print(f'Compression ratio: {avg_json / avg_compressed:.2f}x')",
          "language": "Python",
          "description": "Workflow: Compare output sizes: JSON vs ZIP/tar.gz",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
          "line_start": 245,
          "line_end": 289,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tempfile",
            "time",
            "unittest",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Compare output sizes: JSON vs ZIP/tar.gz'",
          "description": "'Compare output sizes: JSON vs ZIP/tar.gz'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "print('\\n' + '=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "print('BENCHMARK: Output Size Comparison')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "print('=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_dir = self._create_skill_with_n_references(10)",
          "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "formats = {'claude': ('ZIP', '.zip'), 'gemini': ('tar.gz', '.tar.gz'), 'langchain': ('JSON', '.json'), 'weaviate': ('JSON', '.json')}",
          "description": "Assign formats = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "results = {}",
          "description": "Assign results = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "print(f\"\\n{'Platform':15} | {'Format':8} | {'Size (KB)':>10}\")",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "print('-' * 50)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "json_sizes = [v['size_kb'] for k, v in results.items() if v['format'] == 'JSON']",
          "description": "Assign json_sizes = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "compressed_sizes = [v['size_kb'] for k, v in results.items() if v['format'] in ['ZIP', 'tar.gz']]",
          "description": "Assign compressed_sizes = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "package_path = adaptor.package(skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "size_kb = package_path.stat().st_size / 1024",
          "description": "Assign size_kb = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "results[platform] = {'format': format_name, 'size_kb': size_kb}",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "print(f'{platform:15} | {format_name:8} | {size_kb:10.1f}')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "avg_json = sum(json_sizes) / len(json_sizes)",
          "description": "Assign avg_json = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "avg_compressed = sum(compressed_sizes) / len(compressed_sizes)",
          "description": "Assign avg_compressed = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 19,
          "code": "print(f'\\nAverage JSON size: {avg_json:.1f} KB')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 20,
          "code": "print(f'Average compressed size: {avg_compressed:.1f} KB')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 21,
          "code": "print(f'Compression ratio: {avg_json / avg_compressed:.2f}x')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Benchmark Json Vs Zip Size Comparison",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptor_benchmarks.py:245"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3a69022c7418",
      "title": "Benchmark Metadata Overhead",
      "overview": "Workflow: Measure metadata processing overhead",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "eed3ef32",
          "test_name": "test_benchmark_metadata_overhead",
          "category": "workflow",
          "code": "'Measure metadata processing overhead'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Metadata Processing Overhead')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nminimal_meta = SkillMetadata(name='test', description='Test')\nrich_meta = SkillMetadata(name='test', description='A comprehensive test skill for benchmarking purposes', version='2.5.0', author='Benchmark Suite', tags=['test', 'benchmark', 'performance', 'validation', 'quality'])\nadaptor = get_adaptor('langchain')\ntimes_minimal = []\nfor _ in range(5):\n    start = time.perf_counter()\n    adaptor.format_skill_md(skill_dir, minimal_meta)\n    end = time.perf_counter()\n    times_minimal.append(end - start)\ntimes_rich = []\nfor _ in range(5):\n    start = time.perf_counter()\n    adaptor.format_skill_md(skill_dir, rich_meta)\n    end = time.perf_counter()\n    times_rich.append(end - start)\navg_minimal = sum(times_minimal) / len(times_minimal)\navg_rich = sum(times_rich) / len(times_rich)\noverhead = avg_rich - avg_minimal\noverhead_pct = overhead / avg_minimal * 100\nprint(f'\\nMinimal metadata: {avg_minimal * 1000:.2f}ms')\nprint(f'Rich metadata:    {avg_rich * 1000:.2f}ms')\nprint(f'Overhead:         {overhead * 1000:.2f}ms ({overhead_pct:.1f}%)')\nself.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
          "language": "Python",
          "description": "Workflow: Measure metadata processing overhead",
          "expected_behavior": "self.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
          "line_start": 291,
          "line_end": 340,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tempfile",
            "time",
            "unittest",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Measure metadata processing overhead'",
          "description": "'Measure metadata processing overhead'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "print('\\n' + '=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "print('BENCHMARK: Metadata Processing Overhead')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "print('=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_dir = self._create_skill_with_n_references(10)",
          "description": "Assign skill_dir = self._create_skill_with_n_references(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "minimal_meta = SkillMetadata(name='test', description='Test')",
          "description": "Assign minimal_meta = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "rich_meta = SkillMetadata(name='test', description='A comprehensive test skill for benchmarking purposes', version='2.5.0', author='Benchmark Suite', tags=['test', 'benchmark', 'performance', 'validation', 'quality'])",
          "description": "Assign rich_meta = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "adaptor = get_adaptor('langchain')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "times_minimal = []",
          "description": "Assign times_minimal = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "times_rich = []",
          "description": "Assign times_rich = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "avg_minimal = sum(times_minimal) / len(times_minimal)",
          "description": "Assign avg_minimal = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "avg_rich = sum(times_rich) / len(times_rich)",
          "description": "Assign avg_rich = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "overhead = avg_rich - avg_minimal",
          "description": "Assign overhead = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "overhead_pct = overhead / avg_minimal * 100",
          "description": "Assign overhead_pct = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "print(f'\\nMinimal metadata: {avg_minimal * 1000:.2f}ms')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "print(f'Rich metadata:    {avg_rich * 1000:.2f}ms')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "print(f'Overhead:         {overhead * 1000:.2f}ms ({overhead_pct:.1f}%)')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "self.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 19,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 20,
          "code": "adaptor.format_skill_md(skill_dir, minimal_meta)",
          "description": "Call adaptor.format_skill_md()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 21,
          "code": "end = time.perf_counter()",
          "description": "Assign end = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 22,
          "code": "times_minimal.append(end - start)",
          "description": "Call times_minimal.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 23,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 24,
          "code": "adaptor.format_skill_md(skill_dir, rich_meta)",
          "description": "Call adaptor.format_skill_md()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 25,
          "code": "end = time.perf_counter()",
          "description": "Assign end = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 26,
          "code": "times_rich.append(end - start)",
          "description": "Call times_rich.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Benchmark Metadata Overhead",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptor_benchmarks.py:291"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e15e92243558",
      "title": "Benchmark Empty Vs Full Skill",
      "overview": "Workflow: Compare performance: empty skill vs full skill",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "68aea8f2",
          "test_name": "test_benchmark_empty_vs_full_skill",
          "category": "workflow",
          "code": "'Compare performance: empty skill vs full skill'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Empty vs Full Skill')\nprint('=' * 80)\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='test', description='Test benchmark')\nempty_dir = Path(self.temp_dir.name) / 'empty'\nempty_dir.mkdir()\nstart = time.perf_counter()\nadaptor.format_skill_md(empty_dir, metadata)\nempty_time = time.perf_counter() - start\nfull_dir = self._create_skill_with_n_references(50)\nstart = time.perf_counter()\nadaptor.format_skill_md(full_dir, metadata)\nfull_time = time.perf_counter() - start\nprint(f'\\nEmpty skill: {empty_time * 1000:.2f}ms')\nprint(f'Full skill (50 refs): {full_time * 1000:.2f}ms')\nprint(f'Ratio: {full_time / empty_time:.1f}x')\nself.assertLess(empty_time, 0.01, 'Empty skill processing too slow')\nself.assertLess(full_time, 0.5, 'Full skill processing too slow')",
          "language": "Python",
          "description": "Workflow: Compare performance: empty skill vs full skill",
          "expected_behavior": "self.assertLess(full_time, 0.5, 'Full skill processing too slow')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
          "line_start": 342,
          "line_end": 374,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tempfile",
            "time",
            "unittest",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Compare performance: empty skill vs full skill'",
          "description": "'Compare performance: empty skill vs full skill'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "print('\\n' + '=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "print('BENCHMARK: Empty vs Full Skill')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "print('=' * 80)",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "adaptor = get_adaptor('chroma')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "metadata = SkillMetadata(name='test', description='Test benchmark')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "empty_dir = Path(self.temp_dir.name) / 'empty'",
          "description": "Assign empty_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "empty_dir.mkdir()",
          "description": "Call empty_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "adaptor.format_skill_md(empty_dir, metadata)",
          "description": "Call adaptor.format_skill_md()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "empty_time = time.perf_counter() - start",
          "description": "Assign empty_time = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "full_dir = self._create_skill_with_n_references(50)",
          "description": "Assign full_dir = self._create_skill_with_n_references(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "start = time.perf_counter()",
          "description": "Assign start = time.perf_counter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "adaptor.format_skill_md(full_dir, metadata)",
          "description": "Call adaptor.format_skill_md()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "full_time = time.perf_counter() - start",
          "description": "Assign full_time = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "print(f'\\nEmpty skill: {empty_time * 1000:.2f}ms')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "print(f'Full skill (50 refs): {full_time * 1000:.2f}ms')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "print(f'Ratio: {full_time / empty_time:.1f}x')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 19,
          "code": "self.assertLess(empty_time, 0.01, 'Empty skill processing too slow')",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 20,
          "code": "self.assertLess(full_time, 0.5, 'Full skill processing too slow')",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Benchmark Empty Vs Full Skill",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptor_benchmarks.py:342"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c04a99859eb3",
      "title": "Estimate Tokens",
      "overview": "Workflow: Test token estimation.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d446910c",
          "test_name": "test_estimate_tokens",
          "category": "workflow",
          "code": "'Test token estimation.'\nchunker = RAGChunker()\nassert chunker.estimate_tokens('') == 0\ntext = 'Hello world!'\ntokens = chunker.estimate_tokens(text)\nassert tokens == 3\ntext = 'A' * 1000\ntokens = chunker.estimate_tokens(text)\nassert tokens == 250",
          "language": "Python",
          "description": "Workflow: Test token estimation.",
          "expected_behavior": "assert tokens == 250",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 40,
          "line_end": 55,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test token estimation.'",
          "description": "'Test token estimation.'",
          "expected_result": null,
          "verification": "assert chunker.estimate_tokens('') == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker()",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": "assert tokens == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = 'Hello world!'",
          "description": "Assign text = 'Hello world!'",
          "expected_result": null,
          "verification": "assert tokens == 250",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "tokens = chunker.estimate_tokens(text)",
          "description": "Assign tokens = chunker.estimate_tokens(...)",
          "expected_result": null,
          "verification": "assert tokens == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "text = 'A' * 1000",
          "description": "Assign text = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "tokens = chunker.estimate_tokens(text)",
          "description": "Assign tokens = chunker.estimate_tokens(...)",
          "expected_result": null,
          "verification": "assert tokens == 250",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Estimate Tokens",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:40"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "109cfa8d3b4d",
      "title": "Chunk Document Simple",
      "overview": "Workflow: Test chunking simple document.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7e5bbcf1",
          "test_name": "test_chunk_document_simple",
          "category": "workflow",
          "code": "'Test chunking simple document.'\nchunker = RAGChunker(chunk_size=50, chunk_overlap=10)\ntext = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'\nmetadata = {'source': 'test', 'category': 'simple'}\nchunks = chunker.chunk_document(text, metadata)\nassert len(chunks) > 0\nassert all(('chunk_id' in chunk for chunk in chunks))\nassert all(('page_content' in chunk for chunk in chunks))\nassert all(('metadata' in chunk for chunk in chunks))\nfor i, chunk in enumerate(chunks):\n    assert chunk['metadata']['source'] == 'test'\n    assert chunk['metadata']['category'] == 'simple'\n    assert chunk['metadata']['chunk_index'] == i\n    assert chunk['metadata']['total_chunks'] == len(chunks)",
          "language": "Python",
          "description": "Workflow: Test chunking simple document.",
          "expected_behavior": "assert all(('metadata' in chunk for chunk in chunks))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 64,
          "line_end": 83,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test chunking simple document.'",
          "description": "'Test chunking simple document.'",
          "expected_result": null,
          "verification": "assert len(chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker(chunk_size=50, chunk_overlap=10)",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": "assert all(('chunk_id' in chunk for chunk in chunks))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'",
          "description": "Assign text = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'",
          "expected_result": null,
          "verification": "assert all(('page_content' in chunk for chunk in chunks))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test', 'category': 'simple'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": "assert all(('metadata' in chunk for chunk in chunks))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = chunker.chunk_document(text, metadata)",
          "description": "Assign chunks = chunker.chunk_document(...)",
          "expected_result": null,
          "verification": "assert chunk['metadata']['source'] == 'test'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Document Simple",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:64"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a2ddb728ec78",
      "title": "Code Block Not Split",
      "overview": "Workflow: Test that code blocks are not split across chunks.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ee4dd1d6",
          "test_name": "test_code_block_not_split",
          "category": "workflow",
          "code": "'Test that code blocks are not split across chunks.'\nchunker = RAGChunker(chunk_size=20, preserve_code_blocks=True)\ntext = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\ncode_chunks = [c for c in chunks if '```python' in c['page_content']]\nif code_chunks:\n    code_chunk = code_chunks[0]\n    assert code_chunk['page_content'].count('```') >= 2",
          "language": "Python",
          "description": "Workflow: Test that code blocks are not split across chunks.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 110,
          "line_end": 138,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that code blocks are not split across chunks.'",
          "description": "'Test that code blocks are not split across chunks.'",
          "expected_result": null,
          "verification": "assert code_chunk['page_content'].count('```') >= 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker(chunk_size=20, preserve_code_blocks=True)",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '",
          "description": "Assign text = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "chunks = chunker.chunk_document(text, {'source': 'test'})",
          "description": "Assign chunks = chunker.chunk_document(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "code_chunks = [c for c in chunks if '```python' in c['page_content']]",
          "description": "Assign code_chunks = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "code_chunk = code_chunks[0]",
          "description": "Assign code_chunk = value",
          "expected_result": null,
          "verification": "assert code_chunk['page_content'].count('```') >= 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Code Block Not Split",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:110"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9c8b61112c2b",
      "title": "Semantic Boundaries",
      "overview": "Workflow: Test that chunks respect paragraph boundaries.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d3918756",
          "test_name": "test_semantic_boundaries",
          "category": "workflow",
          "code": "'Test that chunks respect paragraph boundaries.'\nchunker = RAGChunker(chunk_size=50, preserve_paragraphs=True)\ntext = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\nfor chunk in chunks:\n    content = chunk['page_content']\n    if content.strip():\n        assert not content.strip().endswith(',')",
          "language": "Python",
          "description": "Workflow: Test that chunks respect paragraph boundaries.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 140,
          "line_end": 162,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that chunks respect paragraph boundaries.'",
          "description": "'Test that chunks respect paragraph boundaries.'",
          "expected_result": null,
          "verification": "assert not content.strip().endswith(',')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker(chunk_size=50, preserve_paragraphs=True)",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '",
          "description": "Assign text = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "chunks = chunker.chunk_document(text, {'source': 'test'})",
          "description": "Assign chunks = chunker.chunk_document(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "content = chunk['page_content']",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": "assert not content.strip().endswith(',')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Semantic Boundaries",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:140"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "88027111d27e",
      "title": "Chunk Skill Directory",
      "overview": "Workflow: Test chunking entire skill directory.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9c1e7df4",
          "test_name": "test_chunk_skill_directory",
          "category": "workflow",
          "code": "'Test chunking entire skill directory.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Main Skill\\n\\nThis is the main skill content.\\n\\nWith multiple paragraphs.')\nreferences_dir = skill_dir / 'references'\nreferences_dir.mkdir()\n(references_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start guide.')\n(references_dir / 'api.md').write_text('# API Reference\\n\\nAPI documentation.')\nchunker = RAGChunker(chunk_size=50)\nchunks = chunker.chunk_skill(skill_dir)\nassert len(chunks) > 0\ncategories = {chunk['metadata']['category'] for chunk in chunks}\nassert 'overview' in categories\nassert 'getting_started' in categories or 'api' in categories",
          "language": "Python",
          "description": "Workflow: Test chunking entire skill directory.",
          "expected_behavior": "assert 'getting_started' in categories or 'api' in categories",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 175,
          "line_end": 206,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test chunking entire skill directory.'",
          "description": "'Test chunking entire skill directory.'",
          "expected_result": null,
          "verification": "assert len(chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "skill_dir = tmp_path / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": "assert 'overview' in categories",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": "assert 'getting_started' in categories or 'api' in categories",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_md = skill_dir / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_md.write_text('# Main Skill\\n\\nThis is the main skill content.\\n\\nWith multiple paragraphs.')",
          "description": "Call skill_md.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "references_dir = skill_dir / 'references'",
          "description": "Assign references_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "references_dir.mkdir()",
          "description": "Call references_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "(references_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start guide.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "(references_dir / 'api.md').write_text('# API Reference\\n\\nAPI documentation.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "chunker = RAGChunker(chunk_size=50)",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "chunks = chunker.chunk_skill(skill_dir)",
          "description": "Assign chunks = chunker.chunk_skill(...)",
          "expected_result": null,
          "verification": "assert len(chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "categories = {chunk['metadata']['category'] for chunk in chunks}",
          "description": "Assign categories = value",
          "expected_result": null,
          "verification": "assert 'overview' in categories",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Skill Directory",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_rag_chunker.py:175"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7daeab4315ad",
      "title": "Save Chunks",
      "overview": "Workflow: Test saving chunks to JSON file.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "31b13860",
          "test_name": "test_save_chunks",
          "category": "workflow",
          "code": "'Test saving chunks to JSON file.'\nchunker = RAGChunker()\nchunks = [{'chunk_id': 'test_0', 'page_content': 'Test content', 'metadata': {'source': 'test', 'chunk_index': 0}}]\noutput_path = tmp_path / 'chunks.json'\nchunker.save_chunks(chunks, output_path)\nassert output_path.exists()\nwith open(output_path) as f:\n    loaded = json.load(f)\nassert len(loaded) == 1\nassert loaded[0]['chunk_id'] == 'test_0'",
          "language": "Python",
          "description": "Workflow: Test saving chunks to JSON file.",
          "expected_behavior": "assert loaded[0]['chunk_id'] == 'test_0'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 208,
          "line_end": 231,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test saving chunks to JSON file.'",
          "description": "'Test saving chunks to JSON file.'",
          "expected_result": null,
          "verification": "assert output_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker()",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": "assert len(loaded) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "chunks = [{'chunk_id': 'test_0', 'page_content': 'Test content', 'metadata': {'source': 'test', 'chunk_index': 0}}]",
          "description": "Assign chunks = value",
          "expected_result": null,
          "verification": "assert loaded[0]['chunk_id'] == 'test_0'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_path = tmp_path / 'chunks.json'",
          "description": "Assign output_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunker.save_chunks(chunks, output_path)",
          "description": "Call chunker.save_chunks()",
          "expected_result": null,
          "verification": "assert output_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "loaded = json.load(f)",
          "description": "Assign loaded = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Save Chunks",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:208"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2b6704eeecc9",
      "title": "Real World Documentation",
      "overview": "Workflow: Test with realistic documentation content.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9cfb2366",
          "test_name": "test_real_world_documentation",
          "category": "workflow",
          "code": "'Test with realistic documentation content.'\nchunker = RAGChunker(chunk_size=512, chunk_overlap=50)\ntext = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '\nmetadata = {'source': 'react-docs', 'category': 'hooks', 'url': 'https://react.dev/reference/react'}\nchunks = chunker.chunk_document(text, metadata)\nassert len(chunks) > 0\ncode_chunks = [c for c in chunks if c['metadata']['has_code_block']]\nassert len(code_chunks) >= 1\nfor chunk in chunks:\n    assert chunk['metadata']['source'] == 'react-docs'\n    assert chunk['metadata']['category'] == 'hooks'\n    assert chunk['metadata']['estimated_tokens'] > 0",
          "language": "Python",
          "description": "Workflow: Test with realistic documentation content.",
          "expected_behavior": "assert len(code_chunks) >= 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 293,
          "line_end": 363,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test with realistic documentation content.'",
          "description": "'Test with realistic documentation content.'",
          "expected_result": null,
          "verification": "assert len(chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "chunker = RAGChunker(chunk_size=512, chunk_overlap=50)",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": "assert len(code_chunks) >= 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "text = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '",
          "description": "Assign text = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '",
          "expected_result": null,
          "verification": "assert chunk['metadata']['source'] == 'react-docs'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'react-docs', 'category': 'hooks', 'url': 'https://react.dev/reference/react'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": "assert chunk['metadata']['category'] == 'hooks'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = chunker.chunk_document(text, metadata)",
          "description": "Assign chunks = chunker.chunk_document(...)",
          "expected_result": null,
          "verification": "assert chunk['metadata']['estimated_tokens'] > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "code_chunks = [c for c in chunks if c['metadata']['has_code_block']]",
          "description": "Assign code_chunks = value",
          "expected_result": null,
          "verification": "assert len(code_chunks) >= 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Real World Documentation",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_rag_chunker.py:293"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "14e6720e9fb4",
      "title": "Chunk Then Load With Langchain",
      "overview": "Workflow: Test that chunks can be loaded by LangChain.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "01bb21ce",
          "test_name": "test_chunk_then_load_with_langchain",
          "category": "workflow",
          "code": "'Test that chunks can be loaded by LangChain.'\npytest.importorskip('langchain')\nfrom langchain.schema import Document\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LangChain.')\nchunker = RAGChunker()\nchunks = chunker.chunk_skill(skill_dir)\ndocs = [Document(page_content=chunk['page_content'], metadata=chunk['metadata']) for chunk in chunks]\nassert len(docs) > 0\nassert all((isinstance(doc, Document) for doc in docs))",
          "language": "Python",
          "description": "Workflow: Test that chunks can be loaded by LangChain.",
          "expected_behavior": "assert all((isinstance(doc, Document) for doc in docs))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 369,
          "line_end": 392,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that chunks can be loaded by LangChain.'",
          "description": "'Test that chunks can be loaded by LangChain.'",
          "expected_result": null,
          "verification": "assert len(docs) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "pytest.importorskip('langchain')",
          "description": "Call pytest.importorskip()",
          "expected_result": null,
          "verification": "assert all((isinstance(doc, Document) for doc in docs))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir = tmp_path / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LangChain.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "chunker = RAGChunker()",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "chunks = chunker.chunk_skill(skill_dir)",
          "description": "Assign chunks = chunker.chunk_skill(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "docs = [Document(page_content=chunk['page_content'], metadata=chunk['metadata']) for chunk in chunks]",
          "description": "Assign docs = value",
          "expected_result": null,
          "verification": "assert len(docs) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Then Load With Langchain",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_rag_chunker.py:369"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a70c9327c88c",
      "title": "Chunk Then Load With Llamaindex",
      "overview": "Workflow: Test that chunks can be loaded by LlamaIndex.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "98c630e0",
          "test_name": "test_chunk_then_load_with_llamaindex",
          "category": "workflow",
          "code": "'Test that chunks can be loaded by LlamaIndex.'\npytest.importorskip('llama_index')\nfrom llama_index.core.schema import TextNode\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LlamaIndex.')\nchunker = RAGChunker()\nchunks = chunker.chunk_skill(skill_dir)\nnodes = [TextNode(text=chunk['page_content'], metadata=chunk['metadata'], id_=chunk['chunk_id']) for chunk in chunks]\nassert len(nodes) > 0\nassert all((isinstance(node, TextNode) for node in nodes))",
          "language": "Python",
          "description": "Workflow: Test that chunks can be loaded by LlamaIndex.",
          "expected_behavior": "assert all((isinstance(node, TextNode) for node in nodes))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
          "line_start": 394,
          "line_end": 417,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "json",
            "skill_seekers.cli.rag_chunker",
            "langchain.schema",
            "llama_index.core.schema"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that chunks can be loaded by LlamaIndex.'",
          "description": "'Test that chunks can be loaded by LlamaIndex.'",
          "expected_result": null,
          "verification": "assert len(nodes) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "pytest.importorskip('llama_index')",
          "description": "Call pytest.importorskip()",
          "expected_result": null,
          "verification": "assert all((isinstance(node, TextNode) for node in nodes))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_dir = tmp_path / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_dir.mkdir()",
          "description": "Call skill_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LlamaIndex.')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "chunker = RAGChunker()",
          "description": "Assign chunker = RAGChunker(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "chunks = chunker.chunk_skill(skill_dir)",
          "description": "Assign chunks = chunker.chunk_skill(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "nodes = [TextNode(text=chunk['page_content'], metadata=chunk['metadata'], id_=chunk['chunk_id']) for chunk in chunks]",
          "description": "Assign nodes = value",
          "expected_result": null,
          "verification": "assert len(nodes) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Then Load With Llamaindex",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_rag_chunker.py:394"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2c6623f4c216",
      "title": "Detect Python From Heuristics",
      "overview": "Workflow: Test Python detection from code content",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4199eada",
          "test_name": "test_detect_python_from_heuristics",
          "category": "workflow",
          "code": "'Test Python detection from code content'\nhtml = '<code>import os\\nfrom pathlib import Path</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'python')",
          "language": "Python",
          "description": "Workflow: Test Python detection from code content",
          "expected_behavior": "self.assertEqual(lang, 'python')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 111,
          "line_end": 117,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Python detection from code content'",
          "description": "'Test Python detection from code content'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>import os\\nfrom pathlib import Path</code>'",
          "description": "Assign html = '<code>import os\\nfrom pathlib import Path</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'python')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Python From Heuristics",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:111"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "06e0e91b973c",
      "title": "Detect Javascript From Const",
      "overview": "Workflow: Test JavaScript detection from const keyword",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "974d5840",
          "test_name": "test_detect_javascript_from_const",
          "category": "workflow",
          "code": "'Test JavaScript detection from const keyword'\nhtml = '<code>const myVar = 10;</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'javascript')",
          "language": "Python",
          "description": "Workflow: Test JavaScript detection from const keyword",
          "expected_behavior": "self.assertEqual(lang, 'javascript')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 127,
          "line_end": 133,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test JavaScript detection from const keyword'",
          "description": "'Test JavaScript detection from const keyword'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>const myVar = 10;</code>'",
          "description": "Assign html = '<code>const myVar = 10;</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'javascript')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Javascript From Const",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:127"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b6ed46e04dc9",
      "title": "Detect Javascript From Arrow",
      "overview": "Workflow: Test JavaScript detection from arrow function",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c65ab030",
          "test_name": "test_detect_javascript_from_arrow",
          "category": "workflow",
          "code": "'Test JavaScript detection from arrow function'\nhtml = '<code>const add = (a, b) => a + b;</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'javascript')",
          "language": "Python",
          "description": "Workflow: Test JavaScript detection from arrow function",
          "expected_behavior": "self.assertEqual(lang, 'javascript')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 135,
          "line_end": 141,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test JavaScript detection from arrow function'",
          "description": "'Test JavaScript detection from arrow function'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>const add = (a, b) => a + b;</code>'",
          "description": "Assign html = '<code>const add = (a, b) => a + b;</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'javascript')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Javascript From Arrow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:135"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "55933d78bd8c",
      "title": "Detect Gdscript",
      "overview": "Workflow: Test GDScript detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "02a40f20",
          "test_name": "test_detect_gdscript",
          "category": "workflow",
          "code": "'Test GDScript detection'\nhtml = '<code>func _ready():\\n    var x = 5</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'gdscript')",
          "language": "Python",
          "description": "Workflow: Test GDScript detection",
          "expected_behavior": "self.assertEqual(lang, 'gdscript')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 143,
          "line_end": 149,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test GDScript detection'",
          "description": "'Test GDScript detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>func _ready():\\n    var x = 5</code>'",
          "description": "Assign html = '<code>func _ready():\\n    var x = 5</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'gdscript')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Gdscript",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:143"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0670aa9e7702",
      "title": "Detect Cpp",
      "overview": "Workflow: Test C++ detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "eba50aa8",
          "test_name": "test_detect_cpp",
          "category": "workflow",
          "code": "'Test C++ detection'\nhtml = '<code>#include <iostream>\\nint main() { return 0; }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'cpp')",
          "language": "Python",
          "description": "Workflow: Test C++ detection",
          "expected_behavior": "self.assertEqual(lang, 'cpp')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 151,
          "line_end": 157,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test C++ detection'",
          "description": "'Test C++ detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>#include <iostream>\\nint main() { return 0; }</code>'",
          "description": "Assign html = '<code>#include <iostream>\\nint main() { return 0; }</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'cpp')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Cpp",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:151"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0ee92df64448",
      "title": "Detect Unknown",
      "overview": "Workflow: Test unknown language detection",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "aca8c16c",
          "test_name": "test_detect_unknown",
          "category": "workflow",
          "code": "'Test unknown language detection'\nhtml = '<code>some random text without clear indicators</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'unknown')",
          "language": "Python",
          "description": "Workflow: Test unknown language detection",
          "expected_behavior": "self.assertEqual(lang, 'unknown')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 159,
          "line_end": 165,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test unknown language detection'",
          "description": "'Test unknown language detection'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>some random text without clear indicators</code>'",
          "description": "Assign html = '<code>some random text without clear indicators</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'unknown')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Unknown",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:159"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "09213194f843",
      "title": "Detect Csharp From Using System",
      "overview": "Workflow: Test C# detection from 'using System' keyword",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2a54cc7a",
          "test_name": "test_detect_csharp_from_using_system",
          "category": "workflow",
          "code": "\"Test C# detection from 'using System' keyword\"\nhtml = '<code>using System;\\nnamespace MyApp { }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
          "language": "Python",
          "description": "Workflow: Test C# detection from 'using System' keyword",
          "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 188,
          "line_end": 194,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test C# detection from 'using System' keyword\"",
          "description": "\"Test C# detection from 'using System' keyword\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>using System;\\nnamespace MyApp { }</code>'",
          "description": "Assign html = '<code>using System;\\nnamespace MyApp { }</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Csharp From Using System",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:188"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "65a89675ff68",
      "title": "Detect Csharp From Namespace",
      "overview": "Workflow: Test C# detection from 'namespace' keyword",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "228736e8",
          "test_name": "test_detect_csharp_from_namespace",
          "category": "workflow",
          "code": "\"Test C# detection from 'namespace' keyword\"\nhtml = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
          "language": "Python",
          "description": "Workflow: Test C# detection from 'namespace' keyword",
          "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 196,
          "line_end": 202,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test C# detection from 'namespace' keyword\"",
          "description": "\"Test C# detection from 'namespace' keyword\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'",
          "description": "Assign html = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Csharp From Namespace",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:196"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "dee29708c79c",
      "title": "Detect Csharp From Property Syntax",
      "overview": "Workflow: Test C# detection from property syntax",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c7a14a7a",
          "test_name": "test_detect_csharp_from_property_syntax",
          "category": "workflow",
          "code": "'Test C# detection from property syntax'\nhtml = '<code>public string Name { get; set; }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
          "language": "Python",
          "description": "Workflow: Test C# detection from property syntax",
          "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 204,
          "line_end": 210,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test C# detection from property syntax'",
          "description": "'Test C# detection from property syntax'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>public string Name { get; set; }</code>'",
          "description": "Assign html = '<code>public string Name { get; set; }</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Csharp From Property Syntax",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:204"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b1aad196488a",
      "title": "Detect Csharp From Public Class",
      "overview": "Workflow: Test C# detection from 'public class' keyword",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b9045a34",
          "test_name": "test_detect_csharp_from_public_class",
          "category": "workflow",
          "code": "\"Test C# detection from 'public class' keyword\"\nhtml = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
          "language": "Python",
          "description": "Workflow: Test C# detection from 'public class' keyword",
          "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
          "line_start": 212,
          "line_end": 218,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "bs4",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "\"Test C# detection from 'public class' keyword\"",
          "description": "\"Test C# detection from 'public class' keyword\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "html = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'",
          "description": "Assign html = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "elem = BeautifulSoup(html, 'html.parser').find('code')",
          "description": "Assign elem = BeautifulSoup.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code = elem.get_text()",
          "description": "Assign code = elem.get_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lang = self.converter.detect_language(elem, code)",
          "description": "Assign lang = self.converter.detect_language(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Csharp From Public Class",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_scraper_features.py:212"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "ff39300ecae5",
      "title": "Add And Retrieve Github Profile",
      "overview": "Workflow: Test adding and retrieving GitHub profiles.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bde90d3d",
          "test_name": "test_add_and_retrieve_github_profile",
          "category": "workflow",
          "code": "'Test adding and retrieving GitHub profiles.'\nconfig_dir = tmp_path / '.config' / 'skill-seekers'\nmonkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)\nmonkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')\nmonkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', tmp_path / '.local' / 'share' / 'skill-seekers' / 'progress')\nconfig = ConfigManager()\nconfig.add_github_profile(name='test-profile', token='ghp_test123', description='Test profile', rate_limit_strategy='wait', timeout_minutes=45, set_as_default=True)\ntoken = config.get_github_token(profile_name='test-profile')\nassert token == 'ghp_test123'\nprofiles = config.list_github_profiles()\nassert len(profiles) == 1\nassert profiles[0]['is_default'] is True\nassert profiles[0]['name'] == 'test-profile'",
          "language": "Python",
          "description": "Workflow: Test adding and retrieving GitHub profiles.",
          "expected_behavior": "assert profiles[0]['name'] == 'test-profile'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
          "line_start": 224,
          "line_end": 255,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path, monkeypatch",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "datetime",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_manager",
            "skill_seekers.cli.rate_limit_handler"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test adding and retrieving GitHub profiles.'",
          "description": "'Test adding and retrieving GitHub profiles.'",
          "expected_result": null,
          "verification": "assert token == 'ghp_test123'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config_dir = tmp_path / '.config' / 'skill-seekers'",
          "description": "Assign config_dir = value",
          "expected_result": null,
          "verification": "assert len(profiles) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": "assert profiles[0]['is_default'] is True",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": "assert profiles[0]['name'] == 'test-profile'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "monkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', tmp_path / '.local' / 'share' / 'skill-seekers' / 'progress')",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "config = ConfigManager()",
          "description": "Assign config = ConfigManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "config.add_github_profile(name='test-profile', token='ghp_test123', description='Test profile', rate_limit_strategy='wait', timeout_minutes=45, set_as_default=True)",
          "description": "Call config.add_github_profile()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "token = config.get_github_token(profile_name='test-profile')",
          "description": "Assign token = config.get_github_token(...)",
          "expected_result": null,
          "verification": "assert token == 'ghp_test123'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "profiles = config.list_github_profiles()",
          "description": "Assign profiles = config.list_github_profiles(...)",
          "expected_result": null,
          "verification": "assert len(profiles) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Add And Retrieve Github Profile",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_rate_limit_handler.py:224"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f6f4ec005d51",
      "title": "Get Next Profile",
      "overview": "Workflow: Test profile switching.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "578bb227",
          "test_name": "test_get_next_profile",
          "category": "workflow",
          "code": "'Test profile switching.'\ntest_dir = tmp_path / 'test_switching'\nconfig_dir = test_dir / '.config' / 'skill-seekers'\nmonkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)\nmonkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')\nmonkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', test_dir / '.local' / 'share' / 'skill-seekers' / 'progress')\nmonkeypatch.setattr(ConfigManager, 'WELCOME_FLAG', config_dir / '.welcomed')\nconfig = ConfigManager()\nconfig.config['github']['profiles'] = {}\nconfig.add_github_profile('profile1', 'ghp_token1', set_as_default=True)\nconfig.add_github_profile('profile2', 'ghp_token2', set_as_default=False)\nprofiles = config.list_github_profiles()\nassert len(profiles) == 2\nnext_data = config.get_next_profile('ghp_token1')\nassert next_data is not None\nname, token = next_data\nassert name == 'profile2'\nassert token == 'ghp_token2'\nnext_data = config.get_next_profile('ghp_token2')\nassert next_data is not None\nname, token = next_data\nassert name == 'profile1'\nassert token == 'ghp_token1'",
          "language": "Python",
          "description": "Workflow: Test profile switching.",
          "expected_behavior": "assert token == 'ghp_token1'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
          "line_start": 257,
          "line_end": 296,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path, monkeypatch",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "datetime",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_manager",
            "skill_seekers.cli.rate_limit_handler"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test profile switching.'",
          "description": "'Test profile switching.'",
          "expected_result": null,
          "verification": "assert len(profiles) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "test_dir = tmp_path / 'test_switching'",
          "description": "Assign test_dir = value",
          "expected_result": null,
          "verification": "assert next_data is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_dir = test_dir / '.config' / 'skill-seekers'",
          "description": "Assign config_dir = value",
          "expected_result": null,
          "verification": "assert name == 'profile2'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": "assert token == 'ghp_token2'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "monkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": "assert next_data is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "monkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', test_dir / '.local' / 'share' / 'skill-seekers' / 'progress')",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": "assert name == 'profile1'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "monkeypatch.setattr(ConfigManager, 'WELCOME_FLAG', config_dir / '.welcomed')",
          "description": "Call monkeypatch.setattr()",
          "expected_result": null,
          "verification": "assert token == 'ghp_token1'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "config = ConfigManager()",
          "description": "Assign config = ConfigManager(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "config.config['github']['profiles'] = {}",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "config.add_github_profile('profile1', 'ghp_token1', set_as_default=True)",
          "description": "Call config.add_github_profile()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "config.add_github_profile('profile2', 'ghp_token2', set_as_default=False)",
          "description": "Call config.add_github_profile()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "profiles = config.list_github_profiles()",
          "description": "Assign profiles = config.list_github_profiles(...)",
          "expected_result": null,
          "verification": "assert len(profiles) == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "next_data = config.get_next_profile('ghp_token1')",
          "description": "Assign next_data = config.get_next_profile(...)",
          "expected_result": null,
          "verification": "assert next_data is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "name, token = next_data",
          "description": "Assign unknown = next_data",
          "expected_result": null,
          "verification": "assert name == 'profile2'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "next_data = config.get_next_profile('ghp_token2')",
          "description": "Assign next_data = config.get_next_profile(...)",
          "expected_result": null,
          "verification": "assert next_data is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "name, token = next_data",
          "description": "Assign unknown = next_data",
          "expected_result": null,
          "verification": "assert name == 'profile1'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Get Next Profile",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_rate_limit_handler.py:257"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2218a1937afb",
      "title": "Parse Json Config",
      "overview": "Workflow: Test parsing JSON configuration",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e82c288d",
          "test_name": "test_parse_json_config",
          "category": "workflow",
          "code": "'Test parsing JSON configuration'\njson_content = {'database': {'host': 'localhost', 'port': 5432}, 'api_key': 'secret'}\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'config.json'), relative_path='config.json', config_type='json', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'config.json'\nfile_path.write_text(json.dumps(json_content))\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_settings = [s for s in config_file.settings if 'database' in s.key]\nself.assertGreater(len(db_settings), 0)",
          "language": "Python",
          "description": "Workflow: Test parsing JSON configuration",
          "expected_behavior": "self.assertGreater(len(db_settings), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
          "line_start": 116,
          "line_end": 135,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.config_extractor",
            "shutil",
            "shutil",
            "shutil",
            "shutil"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parsing JSON configuration'",
          "description": "'Test parsing JSON configuration'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "json_content = {'database': {'host': 'localhost', 'port': 5432}, 'api_key': 'secret'}",
          "description": "Assign json_content = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'config.json'), relative_path='config.json', config_type='json', purpose='unknown')",
          "description": "Assign config_file = ConfigFile(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "file_path = Path(self.temp_dir) / 'config.json'",
          "description": "Assign file_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "file_path.write_text(json.dumps(json_content))",
          "description": "Call file_path.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.parser.parse_config_file(config_file)",
          "description": "Call self.parser.parse_config_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(len(config_file.settings), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "db_settings = [s for s in config_file.settings if 'database' in s.key]",
          "description": "Assign db_settings = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreater(len(db_settings), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parse Json Config",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_config_extractor.py:116"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b9a9bec930f5",
      "title": "Parse Env File",
      "overview": "Workflow: Test parsing .env file",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "70942543",
          "test_name": "test_parse_env_file",
          "category": "workflow",
          "code": "'Test parsing .env file'\nenv_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / '.env'), relative_path='.env', config_type='env', purpose='unknown')\nfile_path = Path(self.temp_dir) / '.env'\nfile_path.write_text(env_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_url = [s for s in config_file.settings if s.key == 'DATABASE_URL']\nself.assertEqual(len(db_url), 1)\nself.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
          "language": "Python",
          "description": "Workflow: Test parsing .env file",
          "expected_behavior": "self.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
          "line_start": 165,
          "line_end": 191,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.config_extractor",
            "shutil",
            "shutil",
            "shutil",
            "shutil"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parsing .env file'",
          "description": "'Test parsing .env file'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "env_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'",
          "description": "Assign env_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / '.env'), relative_path='.env', config_type='env', purpose='unknown')",
          "description": "Assign config_file = ConfigFile(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "file_path = Path(self.temp_dir) / '.env'",
          "description": "Assign file_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "file_path.write_text(env_content)",
          "description": "Call file_path.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.parser.parse_config_file(config_file)",
          "description": "Call self.parser.parse_config_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(len(config_file.settings), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "db_url = [s for s in config_file.settings if s.key == 'DATABASE_URL']",
          "description": "Assign db_url = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertEqual(len(db_url), 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parse Env File",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_config_extractor.py:165"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6e224803ebaf",
      "title": "Parse Python Config",
      "overview": "Workflow: Test parsing Python config module",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "160b409c",
          "test_name": "test_parse_python_config",
          "category": "workflow",
          "code": "'Test parsing Python config module'\npython_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'settings.py'), relative_path='settings.py', config_type='python', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'settings.py'\nfile_path.write_text(python_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_host = [s for s in config_file.settings if s.key == 'DATABASE_HOST']\nself.assertGreaterEqual(len(db_host), 1)",
          "language": "Python",
          "description": "Workflow: Test parsing Python config module",
          "expected_behavior": "self.assertGreaterEqual(len(db_host), 1)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
          "line_start": 217,
          "line_end": 240,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.config_extractor",
            "shutil",
            "shutil",
            "shutil",
            "shutil"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parsing Python config module'",
          "description": "'Test parsing Python config module'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "python_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"",
          "description": "Assign python_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'settings.py'), relative_path='settings.py', config_type='python', purpose='unknown')",
          "description": "Assign config_file = ConfigFile(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "file_path = Path(self.temp_dir) / 'settings.py'",
          "description": "Assign file_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "file_path.write_text(python_content)",
          "description": "Call file_path.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.parser.parse_config_file(config_file)",
          "description": "Call self.parser.parse_config_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(len(config_file.settings), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "db_host = [s for s in config_file.settings if s.key == 'DATABASE_HOST']",
          "description": "Assign db_host = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreaterEqual(len(db_host), 1)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parse Python Config",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_config_extractor.py:217"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7a7fce5e9321",
      "title": "Parse Dockerfile",
      "overview": "Workflow: Test parsing Dockerfile for ENV vars",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "61a8dd02",
          "test_name": "test_parse_dockerfile",
          "category": "workflow",
          "code": "'Test parsing Dockerfile for ENV vars'\ndockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'Dockerfile'), relative_path='Dockerfile', config_type='dockerfile', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'Dockerfile'\nfile_path.write_text(dockerfile_content)\nself.parser.parse_config_file(config_file)\nenv_settings = [s for s in config_file.settings if s.env_var]\nself.assertGreater(len(env_settings), 0)",
          "language": "Python",
          "description": "Workflow: Test parsing Dockerfile for ENV vars",
          "expected_behavior": "self.assertGreater(len(env_settings), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
          "line_start": 242,
          "line_end": 263,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.config_extractor",
            "shutil",
            "shutil",
            "shutil",
            "shutil"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parsing Dockerfile for ENV vars'",
          "description": "'Test parsing Dockerfile for ENV vars'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "dockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'",
          "description": "Assign dockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'Dockerfile'), relative_path='Dockerfile', config_type='dockerfile', purpose='unknown')",
          "description": "Assign config_file = ConfigFile(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "file_path = Path(self.temp_dir) / 'Dockerfile'",
          "description": "Assign file_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "file_path.write_text(dockerfile_content)",
          "description": "Call file_path.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.parser.parse_config_file(config_file)",
          "description": "Call self.parser.parse_config_file()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "env_settings = [s for s in config_file.settings if s.env_var]",
          "description": "Assign env_settings = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertGreater(len(env_settings), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parse Dockerfile",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_config_extractor.py:242"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d0d4520a04b5",
      "title": "Analyze Python Workflow",
      "overview": "Workflow: Test analysis of Python workflow with multiple steps",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d61033bb",
          "test_name": "test_analyze_python_workflow",
          "category": "workflow",
          "code": "'Test analysis of Python workflow with multiple steps'\nworkflow = {'code': \"\\ndef test_user_creation_workflow():\\n    # Step 1: Create database\\n    db = Database('test.db')\\n\\n    # Step 2: Create user\\n    user = User(name='Alice', email='alice@example.com')\\n    db.save(user)\\n\\n    # Step 3: Verify creation\\n    assert db.get_user('Alice').email == 'alice@example.com'\\n\", 'language': 'python', 'category': 'workflow', 'test_name': 'test_user_creation_workflow', 'file_path': 'tests/test_user.py'}\nsteps, metadata = self.analyzer.analyze_workflow(workflow)\nself.assertGreaterEqual(len(steps), 2)\nself.assertIsInstance(steps[0], WorkflowStep)\nself.assertEqual(steps[0].step_number, 1)\nself.assertIsNotNone(steps[0].description)\nself.assertIn('complexity_level', metadata)\nself.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
          "language": "Python",
          "description": "Workflow: Test analysis of Python workflow with multiple steps",
          "expected_behavior": "self.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 42,
          "line_end": 75,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "self.analyzer = WorkflowAnalyzer()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test analysis of Python workflow with multiple steps'",
          "description": "'Test analysis of Python workflow with multiple steps'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "workflow = {'code': \"\\ndef test_user_creation_workflow():\\n    # Step 1: Create database\\n    db = Database('test.db')\\n\\n    # Step 2: Create user\\n    user = User(name='Alice', email='alice@example.com')\\n    db.save(user)\\n\\n    # Step 3: Verify creation\\n    assert db.get_user('Alice').email == 'alice@example.com'\\n\", 'language': 'python', 'category': 'workflow', 'test_name': 'test_user_creation_workflow', 'file_path': 'tests/test_user.py'}",
          "description": "Assign workflow = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "steps, metadata = self.analyzer.analyze_workflow(workflow)",
          "description": "Assign unknown = self.analyzer.analyze_workflow(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertGreaterEqual(len(steps), 2)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertIsInstance(steps[0], WorkflowStep)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(steps[0].step_number, 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIsNotNone(steps[0].description)",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('complexity_level', metadata)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Analyze Python Workflow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:42"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "85f56a624add",
      "title": "Calculate Complexity",
      "overview": "Workflow: Test complexity level calculation",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "123790b8",
          "test_name": "test_calculate_complexity",
          "category": "workflow",
          "code": "'Test complexity level calculation'\nsimple_steps = [WorkflowStep(1, 'x = 1', 'Assign variable'), WorkflowStep(2, 'print(x)', 'Print variable')]\nsimple_workflow = {'code': 'x = 1\\nprint(x)', 'category': 'workflow'}\ncomplexity_simple = self.analyzer._calculate_complexity(simple_steps, simple_workflow)\nself.assertEqual(complexity_simple, 'beginner')\ncomplex_steps = [WorkflowStep(i, f'step{i}', f'Step {i}') for i in range(1, 8)]\ncomplex_workflow = {'code': '\\n'.join([f'async def step{i}(): await complex_operation()' for i in range(7)]), 'category': 'workflow'}\ncomplexity_complex = self.analyzer._calculate_complexity(complex_steps, complex_workflow)\nself.assertIn(complexity_complex, ['intermediate', 'advanced'])",
          "language": "Python",
          "description": "Workflow: Test complexity level calculation",
          "expected_behavior": "self.assertIn(complexity_complex, ['intermediate', 'advanced'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 121,
          "line_end": 141,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "self.analyzer = WorkflowAnalyzer()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complexity level calculation'",
          "description": "'Test complexity level calculation'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "simple_steps = [WorkflowStep(1, 'x = 1', 'Assign variable'), WorkflowStep(2, 'print(x)', 'Print variable')]",
          "description": "Assign simple_steps = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "simple_workflow = {'code': 'x = 1\\nprint(x)', 'category': 'workflow'}",
          "description": "Assign simple_workflow = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "complexity_simple = self.analyzer._calculate_complexity(simple_steps, simple_workflow)",
          "description": "Assign complexity_simple = self.analyzer._calculate_complexity(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(complexity_simple, 'beginner')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "complex_steps = [WorkflowStep(i, f'step{i}', f'Step {i}') for i in range(1, 8)]",
          "description": "Assign complex_steps = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "complex_workflow = {'code': '\\n'.join([f'async def step{i}(): await complex_operation()' for i in range(7)]), 'category': 'workflow'}",
          "description": "Assign complex_workflow = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "complexity_complex = self.analyzer._calculate_complexity(complex_steps, complex_workflow)",
          "description": "Assign complexity_complex = self.analyzer._calculate_complexity(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn(complexity_complex, ['intermediate', 'advanced'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Calculate Complexity",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:121"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5b9403e61fb5",
      "title": "Create Complete Example",
      "overview": "Workflow: Test complete example generation",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "50490a77",
          "test_name": "test_create_complete_example",
          "category": "workflow",
          "code": "'Test complete example generation'\nguide = HowToGuide(guide_id='test-1', title='Test', overview='Test', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Assign'), WorkflowStep(2, 'print(x)', 'Print')], workflows=[{'code': 'x = 1\\nprint(x)', 'language': 'python'}])\nexample_md = self.generator._create_complete_example(guide)\nself.assertIn('## Complete Example', example_md)\nself.assertIn('```python', example_md)",
          "language": "Python",
          "description": "Workflow: Test complete example generation",
          "expected_behavior": "self.assertIn('```python', example_md)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 373,
          "line_end": 387,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": "self.generator = GuideGenerator()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete example generation'",
          "description": "'Test complete example generation'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "guide = HowToGuide(guide_id='test-1', title='Test', overview='Test', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Assign'), WorkflowStep(2, 'print(x)', 'Print')], workflows=[{'code': 'x = 1\\nprint(x)', 'language': 'python'}])",
          "description": "Assign guide = HowToGuide(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "example_md = self.generator._create_complete_example(guide)",
          "description": "Assign example_md = self.generator._create_complete_example(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIn('## Complete Example', example_md)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertIn('```python', example_md)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Create Complete Example",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:373"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "117472ac1efb",
      "title": "Extract Workflow Examples",
      "overview": "Workflow: Test extraction of workflow examples from mixed examples",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "852de058",
          "test_name": "test_extract_workflow_examples",
          "category": "workflow",
          "code": "'Test extraction of workflow examples from mixed examples'\nexamples = [{'category': 'workflow', 'code': 'db = Database()\\nuser = User()\\ndb.save(user)', 'test_name': 'test_user_workflow', 'file_path': 'tests/test_user.py', 'language': 'python'}, {'category': 'instantiation', 'code': 'db = Database()', 'test_name': 'test_db', 'file_path': 'tests/test_db.py', 'language': 'python'}]\nworkflows = self.builder._extract_workflow_examples(examples)\nself.assertEqual(len(workflows), 1)\nself.assertEqual(workflows[0]['category'], 'workflow')",
          "language": "Python",
          "description": "Workflow: Test extraction of workflow examples from mixed examples",
          "expected_behavior": "self.assertEqual(workflows[0]['category'], 'workflow')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 427,
          "line_end": 450,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test extraction of workflow examples from mixed examples'",
          "description": "'Test extraction of workflow examples from mixed examples'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "examples = [{'category': 'workflow', 'code': 'db = Database()\\nuser = User()\\ndb.save(user)', 'test_name': 'test_user_workflow', 'file_path': 'tests/test_user.py', 'language': 'python'}, {'category': 'instantiation', 'code': 'db = Database()', 'test_name': 'test_db', 'file_path': 'tests/test_db.py', 'language': 'python'}]",
          "description": "Assign examples = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "workflows = self.builder._extract_workflow_examples(examples)",
          "description": "Assign workflows = self.builder._extract_workflow_examples(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(len(workflows), 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(workflows[0]['category'], 'workflow')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Workflow Examples",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:427"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7f74bebd0366",
      "title": "Create Guide From Workflows",
      "overview": "Workflow: Test guide creation from grouped workflows",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "6af04b0b",
          "test_name": "test_create_guide_from_workflows",
          "category": "workflow",
          "code": "'Test guide creation from grouped workflows'\nworkflows = [{'code': 'user = User(name=\"Alice\")\\ndb.save(user)', 'test_name': 'test_create_user', 'file_path': 'tests/test_user.py', 'language': 'python', 'category': 'workflow'}]\nguide = self.builder._create_guide('User Management', workflows)\nself.assertIsInstance(guide, HowToGuide)\nself.assertEqual(guide.title, 'User Management')\nself.assertGreater(len(guide.steps), 0)\nself.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
          "language": "Python",
          "description": "Workflow: Test guide creation from grouped workflows",
          "expected_behavior": "self.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 452,
          "line_end": 469,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test guide creation from grouped workflows'",
          "description": "'Test guide creation from grouped workflows'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "workflows = [{'code': 'user = User(name=\"Alice\")\\ndb.save(user)', 'test_name': 'test_create_user', 'file_path': 'tests/test_user.py', 'language': 'python', 'category': 'workflow'}]",
          "description": "Assign workflows = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "guide = self.builder._create_guide('User Management', workflows)",
          "description": "Assign guide = self.builder._create_guide(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIsInstance(guide, HowToGuide)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(guide.title, 'User Management')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertGreater(len(guide.steps), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Create Guide From Workflows",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:452"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "339f11c6e5d2",
      "title": "Save Guides To Files",
      "overview": "Workflow: Test saving guides to markdown files",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ecc0bb12",
          "test_name": "test_save_guides_to_files",
          "category": "workflow",
          "code": "'Test saving guides to markdown files'\nguides = [HowToGuide(guide_id='test-guide', title='Test Guide', overview='Test overview', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Test step')])]\ncollection = GuideCollection(total_guides=1, guides=guides, guides_by_complexity={'beginner': 1}, guides_by_use_case={})\noutput_dir = Path(self.temp_dir)\nself.builder._save_guides_to_files(collection, output_dir)\nself.assertTrue((output_dir / 'index.md').exists())\nindex_content = (output_dir / 'index.md').read_text()\nself.assertIn('Test Guide', index_content)\nmd_files = list(output_dir.glob('*.md'))\nself.assertGreaterEqual(len(md_files), 1)",
          "language": "Python",
          "description": "Workflow: Test saving guides to markdown files",
          "expected_behavior": "self.assertGreaterEqual(len(md_files), 1)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 490,
          "line_end": 522,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test saving guides to markdown files'",
          "description": "'Test saving guides to markdown files'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "guides = [HowToGuide(guide_id='test-guide', title='Test Guide', overview='Test overview', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Test step')])]",
          "description": "Assign guides = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "collection = GuideCollection(total_guides=1, guides=guides, guides_by_complexity={'beginner': 1}, guides_by_use_case={})",
          "description": "Assign collection = GuideCollection(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_dir = Path(self.temp_dir)",
          "description": "Assign output_dir = Path(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.builder._save_guides_to_files(collection, output_dir)",
          "description": "Call self.builder._save_guides_to_files()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertTrue((output_dir / 'index.md').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "index_content = (output_dir / 'index.md').read_text()",
          "description": "Assign index_content = unknown.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('Test Guide', index_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "md_files = list(output_dir.glob('*.md'))",
          "description": "Assign md_files = list(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreaterEqual(len(md_files), 1)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Save Guides To Files",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:490"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "bc461b6a4336",
      "title": "Build With Ai Enhancement Disabled",
      "overview": "Workflow: Test building guides WITHOUT AI enhancement (backward compatibility)",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "285f6c98",
          "test_name": "test_build_with_ai_enhancement_disabled",
          "category": "workflow",
          "code": "'Test building guides WITHOUT AI enhancement (backward compatibility)'\nexamples = [{'example_id': 'test_001', 'test_name': 'test_user_registration', 'category': 'workflow', 'code': '\\ndef test_user_registration():\\n    user = User.create(username=\"test\", email=\"test@example.com\")\\n    assert user.id is not None\\n    assert user.is_active is True\\n                ', 'language': 'python', 'file_path': 'tests/test_user.py', 'line_start': 10, 'tags': ['authentication', 'user'], 'ai_analysis': {'tutorial_group': 'User Management', 'best_practices': ['Validate email format'], 'common_mistakes': ['Not checking uniqueness']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides'\ncollection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=False, ai_mode='none')\nself.assertIsInstance(collection, GuideCollection)\nself.assertGreater(collection.total_guides, 0)\nself.assertTrue(output_dir.exists())\nself.assertTrue((output_dir / 'index.md').exists())",
          "language": "Python",
          "description": "Workflow: Test building guides WITHOUT AI enhancement (backward compatibility)",
          "expected_behavior": "self.assertTrue((output_dir / 'index.md').exists())",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 653,
          "line_end": 696,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test building guides WITHOUT AI enhancement (backward compatibility)'",
          "description": "'Test building guides WITHOUT AI enhancement (backward compatibility)'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "examples = [{'example_id': 'test_001', 'test_name': 'test_user_registration', 'category': 'workflow', 'code': '\\ndef test_user_registration():\\n    user = User.create(username=\"test\", email=\"test@example.com\")\\n    assert user.id is not None\\n    assert user.is_active is True\\n                ', 'language': 'python', 'file_path': 'tests/test_user.py', 'line_start': 10, 'tags': ['authentication', 'user'], 'ai_analysis': {'tutorial_group': 'User Management', 'best_practices': ['Validate email format'], 'common_mistakes': ['Not checking uniqueness']}}]",
          "description": "Assign examples = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = HowToGuideBuilder()",
          "description": "Assign builder = HowToGuideBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_dir = Path(self.temp_dir) / 'guides'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=False, ai_mode='none')",
          "description": "Assign collection = builder.build_guides_from_examples(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIsInstance(collection, GuideCollection)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(collection.total_guides, 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(output_dir.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue((output_dir / 'index.md').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build With Ai Enhancement Disabled",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:653"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0c352bf713b5",
      "title": "Build With Ai Enhancement Api Mode Mocked",
      "overview": "Workflow: Test building guides WITH AI enhancement in API mode (mocked)",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [
        "api_client"
      ],
      "workflows": [
        {
          "example_id": "ffc85d58",
          "test_name": "test_build_with_ai_enhancement_api_mode_mocked",
          "category": "workflow",
          "code": "'Test building guides WITH AI enhancement in API mode (mocked)'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_002', 'test_name': 'test_data_scraping', 'category': 'workflow', 'code': '\\ndef test_data_scraping():\\n    scraper = DocumentationScraper()\\n    result = scraper.scrape(\"https://example.com/docs\")\\n    assert result.pages > 0\\n                ', 'language': 'python', 'file_path': 'tests/test_scraper.py', 'line_start': 20, 'tags': ['scraping', 'documentation'], 'ai_analysis': {'tutorial_group': 'Data Collection', 'best_practices': ['Handle rate limiting'], 'common_mistakes': ['Not handling SSL errors']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_enhanced'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'api'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = [StepEnhancement(step_index=0, explanation='Test explanation', variations=[])]\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='api')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='api')",
          "language": "Python",
          "description": "Workflow: Test building guides WITH AI enhancement in API mode (mocked)",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 698,
          "line_end": 762,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test building guides WITH AI enhancement in API mode (mocked)'",
          "description": "'Test building guides WITH AI enhancement in API mode (mocked)'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "examples = [{'example_id': 'test_002', 'test_name': 'test_data_scraping', 'category': 'workflow', 'code': '\\ndef test_data_scraping():\\n    scraper = DocumentationScraper()\\n    result = scraper.scrape(\"https://example.com/docs\")\\n    assert result.pages > 0\\n                ', 'language': 'python', 'file_path': 'tests/test_scraper.py', 'line_start': 20, 'tags': ['scraping', 'documentation'], 'ai_analysis': {'tutorial_group': 'Data Collection', 'best_practices': ['Handle rate limiting'], 'common_mistakes': ['Not handling SSL errors']}}]",
          "description": "Assign examples = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = HowToGuideBuilder()",
          "description": "Assign builder = HowToGuideBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_dir = Path(self.temp_dir) / 'guides_enhanced'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "mock_enhancer = MockEnhancer.return_value",
          "description": "Assign mock_enhancer = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "mock_enhancer.mode = 'api'",
          "description": "Assign mock_enhancer.mode = 'api'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "mock_enhancer.enhance_guide = mock_enhance_guide",
          "description": "Assign mock_enhancer.enhance_guide = mock_enhance_guide",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='api')",
          "description": "Assign collection = builder.build_guides_from_examples(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIsInstance(collection, GuideCollection)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreater(collection.total_guides, 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "MockEnhancer.assert_called_once_with(mode='api')",
          "description": "Call MockEnhancer.assert_called_once_with()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "enhanced = guide_data.copy()",
          "description": "Assign enhanced = guide_data.copy(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "enhanced['step_enhancements'] = [StepEnhancement(step_index=0, explanation='Test explanation', variations=[])]",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "enhanced['troubleshooting_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "enhanced['prerequisites_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "enhanced['next_steps_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "enhanced['use_cases'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build With Ai Enhancement Api Mode Mocked",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:698"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "cd64eb3ec6b3",
      "title": "Build With Ai Enhancement Local Mode Mocked",
      "overview": "Workflow: Test building guides WITH AI enhancement in LOCAL mode (mocked)",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "830c1fe1",
          "test_name": "test_build_with_ai_enhancement_local_mode_mocked",
          "category": "workflow",
          "code": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_003', 'test_name': 'test_api_integration', 'category': 'workflow', 'code': '\\ndef test_api_integration():\\n    client = APIClient(base_url=\"https://api.example.com\")\\n    response = client.get(\"/users\")\\n    assert response.status_code == 200\\n                ', 'language': 'python', 'file_path': 'tests/test_api.py', 'line_start': 30, 'tags': ['api', 'integration'], 'ai_analysis': {'tutorial_group': 'API Testing', 'best_practices': ['Use environment variables'], 'common_mistakes': ['Hardcoded credentials']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_local'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'local'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = []\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='local')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='local')",
          "language": "Python",
          "description": "Workflow: Test building guides WITH AI enhancement in LOCAL mode (mocked)",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 764,
          "line_end": 825,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'",
          "description": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "examples = [{'example_id': 'test_003', 'test_name': 'test_api_integration', 'category': 'workflow', 'code': '\\ndef test_api_integration():\\n    client = APIClient(base_url=\"https://api.example.com\")\\n    response = client.get(\"/users\")\\n    assert response.status_code == 200\\n                ', 'language': 'python', 'file_path': 'tests/test_api.py', 'line_start': 30, 'tags': ['api', 'integration'], 'ai_analysis': {'tutorial_group': 'API Testing', 'best_practices': ['Use environment variables'], 'common_mistakes': ['Hardcoded credentials']}}]",
          "description": "Assign examples = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = HowToGuideBuilder()",
          "description": "Assign builder = HowToGuideBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_dir = Path(self.temp_dir) / 'guides_local'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "mock_enhancer = MockEnhancer.return_value",
          "description": "Assign mock_enhancer = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "mock_enhancer.mode = 'local'",
          "description": "Assign mock_enhancer.mode = 'local'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "mock_enhancer.enhance_guide = mock_enhance_guide",
          "description": "Assign mock_enhancer.enhance_guide = mock_enhance_guide",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='local')",
          "description": "Assign collection = builder.build_guides_from_examples(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIsInstance(collection, GuideCollection)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreater(collection.total_guides, 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "MockEnhancer.assert_called_once_with(mode='local')",
          "description": "Call MockEnhancer.assert_called_once_with()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "enhanced = guide_data.copy()",
          "description": "Assign enhanced = guide_data.copy(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "enhanced['step_enhancements'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "enhanced['troubleshooting_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "enhanced['prerequisites_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "enhanced['next_steps_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "enhanced['use_cases'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build With Ai Enhancement Local Mode Mocked",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:764"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "efa6fd8ee314",
      "title": "Build With Ai Enhancement Auto Mode",
      "overview": "Workflow: Test building guides WITH AI enhancement in AUTO mode",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "6b4b2d61",
          "test_name": "test_build_with_ai_enhancement_auto_mode",
          "category": "workflow",
          "code": "'Test building guides WITH AI enhancement in AUTO mode'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_004', 'test_name': 'test_database_migration', 'category': 'workflow', 'code': '\\ndef test_database_migration():\\n    migrator = DatabaseMigrator()\\n    migrator.run_migrations()\\n    assert migrator.current_version == \"2.0\"\\n                ', 'language': 'python', 'file_path': 'tests/test_db.py', 'line_start': 40, 'tags': ['database', 'migration'], 'ai_analysis': {'tutorial_group': 'Database Operations', 'best_practices': ['Backup before migration'], 'common_mistakes': ['Not testing rollback']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_auto'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'local'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = []\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='auto')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='auto')",
          "language": "Python",
          "description": "Workflow: Test building guides WITH AI enhancement in AUTO mode",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
          "line_start": 827,
          "line_end": 887,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.guide_enhancer",
            "skill_seekers.cli.how_to_guide_builder",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "unittest.mock",
            "ast",
            "ast"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test building guides WITH AI enhancement in AUTO mode'",
          "description": "'Test building guides WITH AI enhancement in AUTO mode'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "examples = [{'example_id': 'test_004', 'test_name': 'test_database_migration', 'category': 'workflow', 'code': '\\ndef test_database_migration():\\n    migrator = DatabaseMigrator()\\n    migrator.run_migrations()\\n    assert migrator.current_version == \"2.0\"\\n                ', 'language': 'python', 'file_path': 'tests/test_db.py', 'line_start': 40, 'tags': ['database', 'migration'], 'ai_analysis': {'tutorial_group': 'Database Operations', 'best_practices': ['Backup before migration'], 'common_mistakes': ['Not testing rollback']}}]",
          "description": "Assign examples = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = HowToGuideBuilder()",
          "description": "Assign builder = HowToGuideBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "output_dir = Path(self.temp_dir) / 'guides_auto'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "mock_enhancer = MockEnhancer.return_value",
          "description": "Assign mock_enhancer = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "mock_enhancer.mode = 'local'",
          "description": "Assign mock_enhancer.mode = 'local'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "mock_enhancer.enhance_guide = mock_enhance_guide",
          "description": "Assign mock_enhancer.enhance_guide = mock_enhance_guide",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='auto')",
          "description": "Assign collection = builder.build_guides_from_examples(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIsInstance(collection, GuideCollection)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreater(collection.total_guides, 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "MockEnhancer.assert_called_once_with(mode='auto')",
          "description": "Call MockEnhancer.assert_called_once_with()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "enhanced = guide_data.copy()",
          "description": "Assign enhanced = guide_data.copy(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "enhanced['step_enhancements'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "enhanced['troubleshooting_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "enhanced['prerequisites_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "enhanced['next_steps_detailed'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "enhanced['use_cases'] = []",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build With Ai Enhancement Auto Mode",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_how_to_guide_builder.py:827"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4bbe506a618c",
      "title": "Detect Modified File",
      "overview": "Workflow: Test detection of modified files.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2e536985",
          "test_name": "test_detect_modified_file",
          "category": "workflow",
          "code": "'Test detection of modified files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\nskill_md = temp_skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nModified content')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.modified) == 1\nassert len(change_set.added) == 0\nassert len(change_set.deleted) == 0\nassert change_set.modified[0].file_path == 'SKILL.md'\nassert change_set.modified[0].version == 2",
          "language": "Python",
          "description": "Workflow: Test detection of modified files.",
          "expected_behavior": "assert change_set.modified[0].version == 2",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 80,
          "line_end": 101,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of modified files.'",
          "description": "'Test detection of modified files.'",
          "expected_result": null,
          "verification": "assert len(change_set.modified) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert len(change_set.added) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": "assert len(change_set.deleted) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": "assert change_set.modified[0].file_path == 'SKILL.md'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "time.sleep(0.01)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": "assert change_set.modified[0].version == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "skill_md = temp_skill_dir / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "skill_md.write_text('# Test Skill\\n\\nModified content')",
          "description": "Call skill_md.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "change_set = updater2.detect_changes()",
          "description": "Assign change_set = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": "assert len(change_set.modified) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Modified File",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_incremental_updates.py:80"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0603c0d5b30d",
      "title": "Detect Added File",
      "overview": "Workflow: Test detection of new files.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "31b88c27",
          "test_name": "test_detect_added_file",
          "category": "workflow",
          "code": "'Test detection of new files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nrefs_dir = temp_skill_dir / 'references'\nnew_ref = refs_dir / 'api_reference.md'\nnew_ref.write_text('# API Reference\\n\\nNew documentation')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.added) == 1\nassert len(change_set.modified) == 0\nassert len(change_set.deleted) == 0\nassert change_set.added[0].file_path == 'references/api_reference.md'",
          "language": "Python",
          "description": "Workflow: Test detection of new files.",
          "expected_behavior": "assert change_set.added[0].file_path == 'references/api_reference.md'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 104,
          "line_end": 124,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of new files.'",
          "description": "'Test detection of new files.'",
          "expected_result": null,
          "verification": "assert len(change_set.added) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert len(change_set.modified) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": "assert len(change_set.deleted) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": "assert change_set.added[0].file_path == 'references/api_reference.md'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "refs_dir = temp_skill_dir / 'references'",
          "description": "Assign refs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "new_ref = refs_dir / 'api_reference.md'",
          "description": "Assign new_ref = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "new_ref.write_text('# API Reference\\n\\nNew documentation')",
          "description": "Call new_ref.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "change_set = updater2.detect_changes()",
          "description": "Assign change_set = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": "assert len(change_set.added) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Added File",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_incremental_updates.py:104"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "064b50685afb",
      "title": "Detect Deleted File",
      "overview": "Workflow: Test detection of deleted files.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "da7dec84",
          "test_name": "test_detect_deleted_file",
          "category": "workflow",
          "code": "'Test detection of deleted files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nref_file = temp_skill_dir / 'references' / 'getting_started.md'\nref_file.unlink()\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.deleted) == 1\nassert len(change_set.added) == 0\nassert len(change_set.modified) == 0\nassert 'references/getting_started.md' in change_set.deleted",
          "language": "Python",
          "description": "Workflow: Test detection of deleted files.",
          "expected_behavior": "assert 'references/getting_started.md' in change_set.deleted",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 127,
          "line_end": 146,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of deleted files.'",
          "description": "'Test detection of deleted files.'",
          "expected_result": null,
          "verification": "assert len(change_set.deleted) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert len(change_set.added) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": "assert len(change_set.modified) == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": "assert 'references/getting_started.md' in change_set.deleted",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "ref_file = temp_skill_dir / 'references' / 'getting_started.md'",
          "description": "Assign ref_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "ref_file.unlink()",
          "description": "Call ref_file.unlink()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "change_set = updater2.detect_changes()",
          "description": "Assign change_set = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": "assert len(change_set.deleted) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Detect Deleted File",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_incremental_updates.py:127"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4b7c3a78eeb7",
      "title": "Mixed Changes",
      "overview": "Workflow: Test detection of multiple types of changes.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "06aa74e5",
          "test_name": "test_mixed_changes",
          "category": "workflow",
          "code": "'Test detection of multiple types of changes.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Test Skill\\n\\nModified')\nrefs_dir = temp_skill_dir / 'references'\n(refs_dir / 'new_file.md').write_text('# New File')\n(refs_dir / 'getting_started.md').unlink()\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.modified) == 1\nassert len(change_set.added) == 1\nassert len(change_set.deleted) == 1\nassert change_set.total_changes == 3",
          "language": "Python",
          "description": "Workflow: Test detection of multiple types of changes.",
          "expected_behavior": "assert change_set.total_changes == 3",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 149,
          "line_end": 177,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test detection of multiple types of changes.'",
          "description": "'Test detection of multiple types of changes.'",
          "expected_result": null,
          "verification": "assert len(change_set.modified) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert len(change_set.added) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": "assert len(change_set.deleted) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": "assert change_set.total_changes == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "time.sleep(0.01)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(temp_skill_dir / 'SKILL.md').write_text('# Test Skill\\n\\nModified')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "refs_dir = temp_skill_dir / 'references'",
          "description": "Assign refs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "(refs_dir / 'new_file.md').write_text('# New File')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "(refs_dir / 'getting_started.md').unlink()",
          "description": "Call unknown.unlink()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "change_set = updater2.detect_changes()",
          "description": "Assign change_set = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": "assert len(change_set.modified) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Mixed Changes",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_incremental_updates.py:149"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6b70a93b5f76",
      "title": "Generate Update Package",
      "overview": "Workflow: Test update package generation.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a16387fa",
          "test_name": "test_generate_update_package",
          "category": "workflow",
          "code": "'Test update package generation.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Modified')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    package_path = Path(tmpdir) / 'update.json'\n    result_path = updater2.generate_update_package(change_set, package_path)\n    assert result_path.exists()\n    package_data = json.loads(result_path.read_text())\n    assert 'metadata' in package_data\n    assert 'changes' in package_data\n    assert package_data['metadata']['total_changes'] == 1\n    assert 'SKILL.md' in package_data['changes']\n    assert package_data['changes']['SKILL.md']['action'] == 'modify'",
          "language": "Python",
          "description": "Workflow: Test update package generation.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 180,
          "line_end": 209,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test update package generation.'",
          "description": "'Test update package generation.'",
          "expected_result": null,
          "verification": "assert result_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert 'metadata' in package_data",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": "assert 'changes' in package_data",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": "assert package_data['metadata']['total_changes'] == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "time.sleep(0.01)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": "assert 'SKILL.md' in package_data['changes']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(temp_skill_dir / 'SKILL.md').write_text('# Modified')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert package_data['changes']['SKILL.md']['action'] == 'modify'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "change_set = updater2.detect_changes()",
          "description": "Assign change_set = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "package_path = Path(tmpdir) / 'update.json'",
          "description": "Assign package_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "result_path = updater2.generate_update_package(change_set, package_path)",
          "description": "Assign result_path = updater2.generate_update_package(...)",
          "expected_result": null,
          "verification": "assert result_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "package_data = json.loads(result_path.read_text())",
          "description": "Assign package_data = json.loads(...)",
          "expected_result": null,
          "verification": "assert 'metadata' in package_data",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Generate Update Package",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_incremental_updates.py:180"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "37b1b62dd4a6",
      "title": "Diff Report Generation",
      "overview": "Workflow: Test diff report generation.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0815fd04",
          "test_name": "test_diff_report_generation",
          "category": "workflow",
          "code": "'Test diff report generation.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Modified content')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nreport = updater2.generate_diff_report(change_set)\nassert 'INCREMENTAL UPDATE REPORT' in report\nassert 'Modified: 1 files' in report\nassert 'SKILL.md' in report",
          "language": "Python",
          "description": "Workflow: Test diff report generation.",
          "expected_behavior": "assert 'SKILL.md' in report",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 212,
          "line_end": 231,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test diff report generation.'",
          "description": "'Test diff report generation.'",
          "expected_result": null,
          "verification": "assert 'INCREMENTAL UPDATE REPORT' in report",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert 'Modified: 1 files' in report",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": "assert 'SKILL.md' in report",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "time.sleep(0.01)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(temp_skill_dir / 'SKILL.md').write_text('# Modified content')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "change_set = updater2.detect_changes()",
          "description": "Assign change_set = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "report = updater2.generate_diff_report(change_set)",
          "description": "Assign report = updater2.generate_diff_report(...)",
          "expected_result": null,
          "verification": "assert 'INCREMENTAL UPDATE REPORT' in report",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Diff Report Generation",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_incremental_updates.py:212"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "cc341c50b999",
      "title": "Version Increment",
      "overview": "Workflow: Test version numbers increment correctly.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "46c630fc",
          "test_name": "test_version_increment",
          "category": "workflow",
          "code": "'Test version numbers increment correctly.'\nupdater = IncrementalUpdater(temp_skill_dir)\nchange_set1 = updater.detect_changes()\nupdater.save_current_versions()\nfor doc in change_set1.added:\n    assert doc.version == 1\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('Modified once')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set2 = updater2.detect_changes()\nupdater2.save_current_versions()\nassert change_set2.modified[0].version == 2\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('Modified twice')\nupdater3 = IncrementalUpdater(temp_skill_dir)\nchange_set3 = updater3.detect_changes()\nassert change_set3.modified[0].version == 3",
          "language": "Python",
          "description": "Workflow: Test version numbers increment correctly.",
          "expected_behavior": "assert change_set3.modified[0].version == 3",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 234,
          "line_end": 263,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test version numbers increment correctly.'",
          "description": "'Test version numbers increment correctly.'",
          "expected_result": null,
          "verification": "assert doc.version == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert change_set2.modified[0].version == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "change_set1 = updater.detect_changes()",
          "description": "Assign change_set1 = updater.detect_changes(...)",
          "expected_result": null,
          "verification": "assert change_set3.modified[0].version == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "time.sleep(0.01)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(temp_skill_dir / 'SKILL.md').write_text('Modified once')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "updater2 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater2 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "change_set2 = updater2.detect_changes()",
          "description": "Assign change_set2 = updater2.detect_changes(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "updater2.save_current_versions()",
          "description": "Call updater2.save_current_versions()",
          "expected_result": null,
          "verification": "assert change_set2.modified[0].version == 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "time.sleep(0.01)",
          "description": "Call time.sleep()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "(temp_skill_dir / 'SKILL.md').write_text('Modified twice')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "updater3 = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater3 = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "change_set3 = updater3.detect_changes()",
          "description": "Assign change_set3 = updater3.detect_changes(...)",
          "expected_result": null,
          "verification": "assert change_set3.modified[0].version == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Version Increment",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_incremental_updates.py:234"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "830031e152a0",
      "title": "Apply Update Package",
      "overview": "Workflow: Test applying an update package.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "6f4fe178",
          "test_name": "test_apply_update_package",
          "category": "workflow",
          "code": "'Test applying an update package.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    package_path = Path(tmpdir) / 'update.json'\n    update_data = {'metadata': {'timestamp': '2026-02-05T12:00:00', 'skill_name': 'test_skill', 'change_summary': {'modified': 1}, 'total_changes': 1}, 'changes': {'SKILL.md': {'action': 'modify', 'version': 2, 'content': '# Updated Content\\n\\nApplied from package'}}}\n    package_path.write_text(json.dumps(update_data))\n    success = updater.apply_update_package(package_path)\n    assert success\n    assert (temp_skill_dir / 'SKILL.md').read_text() == '# Updated Content\\n\\nApplied from package'",
          "language": "Python",
          "description": "Workflow: Test applying an update package.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 266,
          "line_end": 301,
          "complexity_score": 0.5,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test applying an update package.'",
          "description": "'Test applying an update package.'",
          "expected_result": null,
          "verification": "assert success",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": "assert (temp_skill_dir / 'SKILL.md').read_text() == '# Updated Content\\n\\nApplied from package'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updater.detect_changes()",
          "description": "Call updater.detect_changes()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "updater.save_current_versions()",
          "description": "Call updater.save_current_versions()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "package_path = Path(tmpdir) / 'update.json'",
          "description": "Assign package_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "update_data = {'metadata': {'timestamp': '2026-02-05T12:00:00', 'skill_name': 'test_skill', 'change_summary': {'modified': 1}, 'total_changes': 1}, 'changes': {'SKILL.md': {'action': 'modify', 'version': 2, 'content': '# Updated Content\\n\\nApplied from package'}}}",
          "description": "Assign update_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "package_path.write_text(json.dumps(update_data))",
          "description": "Call package_path.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "success = updater.apply_update_package(package_path)",
          "description": "Assign success = updater.apply_update_package(...)",
          "expected_result": null,
          "verification": "assert success",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Apply Update Package",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_incremental_updates.py:266"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2f3b64159cc2",
      "title": "Content Hash Consistency",
      "overview": "Workflow: Test content hash is consistent for same content.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "afda60d8",
          "test_name": "test_content_hash_consistency",
          "category": "workflow",
          "code": "'Test content hash is consistent for same content.'\nupdater = IncrementalUpdater(temp_skill_dir)\nskill_md = temp_skill_dir / 'SKILL.md'\nhash1 = updater._compute_file_hash(skill_md)\ncontent = skill_md.read_text()\nskill_md.write_text(content)\nhash2 = updater._compute_file_hash(skill_md)\nassert hash1 == hash2",
          "language": "Python",
          "description": "Workflow: Test content hash is consistent for same content.",
          "expected_behavior": "assert hash1 == hash2",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
          "line_start": 304,
          "line_end": 319,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "time",
            "skill_seekers.cli.incremental_updater"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test content hash is consistent for same content.'",
          "description": "'Test content hash is consistent for same content.'",
          "expected_result": null,
          "verification": "assert hash1 == hash2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "updater = IncrementalUpdater(temp_skill_dir)",
          "description": "Assign updater = IncrementalUpdater(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "skill_md = temp_skill_dir / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "hash1 = updater._compute_file_hash(skill_md)",
          "description": "Assign hash1 = updater._compute_file_hash(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "content = skill_md.read_text()",
          "description": "Assign content = skill_md.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "skill_md.write_text(content)",
          "description": "Call skill_md.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "hash2 = updater._compute_file_hash(skill_md)",
          "description": "Assign hash2 = updater._compute_file_hash(...)",
          "expected_result": null,
          "verification": "assert hash1 == hash2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Content Hash Consistency",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_incremental_updates.py:304"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f6aa73dcd536",
      "title": "Scraping Proceeds When Llms Txt Skipped",
      "overview": "Workflow: Test that HTML scraping proceeds normally when llms.txt is skipped.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [
        "api_client"
      ],
      "workflows": [
        {
          "example_id": "4dbd32f6",
          "test_name": "test_scraping_proceeds_when_llms_txt_skipped",
          "category": "workflow",
          "code": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'skip_llms_txt': True}\noriginal_cwd = os.getcwd()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=False)\n        scrape_called = []\n\n        def mock_scrape(url):\n            scrape_called.append(url)\n            return None\n        with patch.object(converter, 'scrape_page', side_effect=mock_scrape), patch.object(converter, 'save_summary'):\n            converter.scrape_all()\n            self.assertTrue(len(scrape_called) > 0)\n    finally:\n        os.chdir(original_cwd)",
          "language": "Python",
          "description": "Workflow: Test that HTML scraping proceeds normally when llms.txt is skipped.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
          "line_start": 295,
          "line_end": 325,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "tempfile",
            "unittest",
            "unittest.mock",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'",
          "description": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'skip_llms_txt': True}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "original_cwd = os.getcwd()",
          "description": "Assign original_cwd = os.getcwd(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "os.chdir(tmpdir)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter = DocToSkillConverter(config, dry_run=False)",
          "description": "Assign converter = DocToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "scrape_called = []",
          "description": "Assign scrape_called = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "os.chdir(original_cwd)",
          "description": "Call os.chdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "scrape_called.append(url)",
          "description": "Call scrape_called.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "converter.scrape_all()",
          "description": "Call converter.scrape_all()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertTrue(len(scrape_called) > 0)",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scraping Proceeds When Llms Txt Skipped",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_skip_llms_txt.py:295"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3b36cb41e9dc",
      "title": "Issue Categorization By Topic",
      "overview": "Workflow: Test that issues are correctly categorized by topic keywords.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0b398609",
          "test_name": "test_issue_categorization_by_topic",
          "category": "workflow",
          "code": "'Test that issues are correctly categorized by topic keywords.'\nproblems = [{'title': 'OAuth fails on redirect', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token refresh issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth', 'token']}, {'title': 'Async deadlock', 'number': 40, 'state': 'open', 'comments': 12, 'labels': ['async', 'bug']}, {'title': 'Database connection lost', 'number': 35, 'state': 'open', 'comments': 10, 'labels': ['database']}]\nsolutions = [{'title': 'Fixed OAuth flow', 'number': 30, 'state': 'closed', 'comments': 8, 'labels': ['oauth']}, {'title': 'Resolved async race', 'number': 25, 'state': 'closed', 'comments': 6, 'labels': ['async']}]\ntopics = ['oauth', 'auth', 'authentication']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized\noauth_issues = categorized.get('oauth', []) + categorized.get('auth', []) + categorized.get('authentication', [])\nassert len(oauth_issues) >= 2\noauth_titles = [issue['title'] for issue in oauth_issues]\nassert any(('OAuth' in title for title in oauth_titles))",
          "language": "Python",
          "description": "Workflow: Test that issues are correctly categorized by topic keywords.",
          "expected_behavior": "assert any(('OAuth' in title for title in oauth_titles))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
          "line_start": 154,
          "line_end": 222,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that issues are correctly categorized by topic keywords.'",
          "description": "'Test that issues are correctly categorized by topic keywords.'",
          "expected_result": null,
          "verification": "assert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "problems = [{'title': 'OAuth fails on redirect', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token refresh issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth', 'token']}, {'title': 'Async deadlock', 'number': 40, 'state': 'open', 'comments': 12, 'labels': ['async', 'bug']}, {'title': 'Database connection lost', 'number': 35, 'state': 'open', 'comments': 10, 'labels': ['database']}]",
          "description": "Assign problems = value",
          "expected_result": null,
          "verification": "assert len(oauth_issues) >= 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "solutions = [{'title': 'Fixed OAuth flow', 'number': 30, 'state': 'closed', 'comments': 8, 'labels': ['oauth']}, {'title': 'Resolved async race', 'number': 25, 'state': 'closed', 'comments': 6, 'labels': ['async']}]",
          "description": "Assign solutions = value",
          "expected_result": null,
          "verification": "assert any(('OAuth' in title for title in oauth_titles))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "topics = ['oauth', 'auth', 'authentication']",
          "description": "Assign topics = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
          "description": "Assign categorized = categorize_issues_by_topic(...)",
          "expected_result": null,
          "verification": "assert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "oauth_issues = categorized.get('oauth', []) + categorized.get('auth', []) + categorized.get('authentication', [])",
          "description": "Assign oauth_issues = value",
          "expected_result": null,
          "verification": "assert len(oauth_issues) >= 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "oauth_titles = [issue['title'] for issue in oauth_issues]",
          "description": "Assign oauth_titles = value",
          "expected_result": null,
          "verification": "assert any(('OAuth' in title for title in oauth_titles))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Issue Categorization By Topic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_e2e_three_stream_pipeline.py:154"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7fec3f8d3619",
      "title": "Github Overhead Within Limits",
      "overview": "Workflow: Test that GitHub integration adds ~30-50 lines per skill (not more).\n\nQuality metric: GitHub overhead should be minimal.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e2c9a8d6",
          "test_name": "test_github_overhead_within_limits",
          "category": "workflow",
          "code": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '\nconfig = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://github.com/test/repo', 'categories': {'api': ['api']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test\\n\\nA short README.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 100, 'forks': 10, 'language': 'Python', 'description': 'Test'}, common_problems=[{'title': 'Issue 1', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['bug']}, {'title': 'Issue 2', 'number': 2, 'state': 'open', 'comments': 3, 'labels': ['bug']}], known_solutions=[], top_labels=[{'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator_no_github = RouterGenerator([str(config_path)])\nskill_md_no_github = generator_no_github.generate_skill_md()\nlines_no_github = len(skill_md_no_github.split('\\n'))\ngenerator_with_github = RouterGenerator([str(config_path)], github_streams=github_streams)\nskill_md_with_github = generator_with_github.generate_skill_md()\nlines_with_github = len(skill_md_with_github.split('\\n'))\ngithub_overhead = lines_with_github - lines_no_github\nassert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
          "language": "Python",
          "description": "Workflow: Test that GitHub integration adds ~30-50 lines per skill (not more).\n\nQuality metric: GitHub overhead should be minimal.",
          "expected_behavior": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
          "line_start": 407,
          "line_end": 469,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '",
          "description": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '",
          "expected_result": null,
          "verification": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://github.com/test/repo', 'categories': {'api': ['api']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "docs_stream = DocsStream(readme='# Test\\n\\nA short README.', contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "insights_stream = InsightsStream(metadata={'stars': 100, 'forks': 10, 'language': 'Python', 'description': 'Test'}, common_problems=[{'title': 'Issue 1', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['bug']}, {'title': 'Issue 2', 'number': 2, 'state': 'open', 'comments': 3, 'labels': ['bug']}], known_solutions=[], top_labels=[{'label': 'bug', 'count': 10}])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "github_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "generator_no_github = RouterGenerator([str(config_path)])",
          "description": "Assign generator_no_github = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "skill_md_no_github = generator_no_github.generate_skill_md()",
          "description": "Assign skill_md_no_github = generator_no_github.generate_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "lines_no_github = len(skill_md_no_github.split('\\n'))",
          "description": "Assign lines_no_github = len(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "generator_with_github = RouterGenerator([str(config_path)], github_streams=github_streams)",
          "description": "Assign generator_with_github = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "skill_md_with_github = generator_with_github.generate_skill_md()",
          "description": "Assign skill_md_with_github = generator_with_github.generate_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "lines_with_github = len(skill_md_with_github.split('\\n'))",
          "description": "Assign lines_with_github = len(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "github_overhead = lines_with_github - lines_no_github",
          "description": "Assign github_overhead = value",
          "expected_result": null,
          "verification": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Github Overhead Within Limits",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_e2e_three_stream_pipeline.py:407"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "82d13a230834",
      "title": "Router Size Within Limits",
      "overview": "Workflow: Test that router SKILL.md is ~150 lines (\u00b120).\n\nQuality metric: Router should be concise overview, not exhaustive.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a65c1251",
          "test_name": "test_router_size_within_limits",
          "category": "workflow",
          "code": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '\nconfigs = []\nfor i in range(4):\n    config = {'name': f'test-skill-{i}', 'description': f'Test skill {i}', 'base_url': 'https://github.com/test/repo', 'categories': {f'topic{i}': [f'topic{i}']}}\n    config_path = tmp_path / f'config{i}.json'\n    with open(config_path, 'w') as f:\n        json.dump(config, f)\n    configs.append(str(config_path))\ngenerator = RouterGenerator(configs)\nskill_md = generator.generate_skill_md()\nlines = len(skill_md.split('\\n'))\nassert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
          "language": "Python",
          "description": "Workflow: Test that router SKILL.md is ~150 lines (\u00b120).\n\nQuality metric: Router should be concise overview, not exhaustive.",
          "expected_behavior": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
          "line_start": 471,
          "line_end": 498,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '",
          "description": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '",
          "expected_result": null,
          "verification": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "configs = []",
          "description": "Assign configs = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "generator = RouterGenerator(configs)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "skill_md = generator.generate_skill_md()",
          "description": "Assign skill_md = generator.generate_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "lines = len(skill_md.split('\\n'))",
          "description": "Assign lines = len(...)",
          "expected_result": null,
          "verification": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "config = {'name': f'test-skill-{i}', 'description': f'Test skill {i}', 'base_url': 'https://github.com/test/repo', 'categories': {f'topic{i}': [f'topic{i}']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "config_path = tmp_path / f'config{i}.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "configs.append(str(config_path))",
          "description": "Call configs.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Router Size Within Limits",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_e2e_three_stream_pipeline.py:471"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "fb1f881f8e7d",
      "title": "Router Without Github Streams",
      "overview": "Workflow: Test that router generation works without GitHub streams (backward compat).",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "be77a796",
          "test_name": "test_router_without_github_streams",
          "category": "workflow",
          "code": "'Test that router generation works without GitHub streams (backward compat).'\nconfig = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://example.com', 'categories': {'api': ['api']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nassert generator.github_metadata is None\nassert generator.github_docs is None\nassert generator.github_issues is None\nskill_md = generator.generate_skill_md()\nassert 'When to Use This Skill' in skill_md\nassert 'How It Works' in skill_md\nassert '\u2b50' not in skill_md\nassert 'Repository Info' not in skill_md\nassert 'Quick Start (from README)' not in skill_md\nassert 'Common Issues (from GitHub)' not in skill_md",
          "language": "Python",
          "description": "Workflow: Test that router generation works without GitHub streams (backward compat).",
          "expected_behavior": "assert 'Common Issues (from GitHub)' not in skill_md",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
          "line_start": 504,
          "line_end": 534,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that router generation works without GitHub streams (backward compat).'",
          "description": "'Test that router generation works without GitHub streams (backward compat).'",
          "expected_result": null,
          "verification": "assert generator.github_metadata is None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://example.com', 'categories': {'api': ['api']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": "assert generator.github_docs is None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = tmp_path / 'config.json'",
          "description": "Assign config_path = value",
          "expected_result": null,
          "verification": "assert generator.github_issues is None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generator = RouterGenerator([str(config_path)])",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert 'When to Use This Skill' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_md = generator.generate_skill_md()",
          "description": "Assign skill_md = generator.generate_skill_md(...)",
          "expected_result": null,
          "verification": "assert 'How It Works' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "json.dump(config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": "assert '\u2b50' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Router Without Github Streams",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_e2e_three_stream_pipeline.py:504"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b08a6d8f862d",
      "title": "Three Stream Produces Compact Output",
      "overview": "Workflow: Test that three-stream architecture produces compact, efficient output.\n\nThis is a qualitative test - we verify that output is structured and\nnot duplicated across streams.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a4166214",
          "test_name": "test_three_stream_produces_compact_output",
          "category": "workflow",
          "code": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '\n(tmp_path / 'main.py').write_text(\"import os\\nprint('test')\")\ncode_stream = CodeStream(directory=tmp_path, files=[tmp_path / 'main.py'])\ndocs_stream = DocsStream(readme='# Test\\n\\nQuick start guide.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 100}, common_problems=[], known_solutions=[], top_labels=[])\n_three_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nassert code_stream.directory == tmp_path\nassert docs_stream.readme is not None\nassert insights_stream.metadata is not None\nassert 'Quick start guide' not in str(code_stream.files)\nassert str(tmp_path) not in docs_stream.readme",
          "language": "Python",
          "description": "Workflow: Test that three-stream architecture produces compact, efficient output.\n\nThis is a qualitative test - we verify that output is structured and\nnot duplicated across streams.",
          "expected_behavior": "assert str(tmp_path) not in docs_stream.readme",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
          "line_start": 567,
          "line_end": 594,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '",
          "description": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '",
          "expected_result": null,
          "verification": "assert code_stream.directory == tmp_path",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "(tmp_path / 'main.py').write_text(\"import os\\nprint('test')\")",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": "assert docs_stream.readme is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code_stream = CodeStream(directory=tmp_path, files=[tmp_path / 'main.py'])",
          "description": "Assign code_stream = CodeStream(...)",
          "expected_result": null,
          "verification": "assert insights_stream.metadata is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "docs_stream = DocsStream(readme='# Test\\n\\nQuick start guide.', contributing=None, docs_files=[])",
          "description": "Assign docs_stream = DocsStream(...)",
          "expected_result": null,
          "verification": "assert 'Quick start guide' not in str(code_stream.files)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "insights_stream = InsightsStream(metadata={'stars': 100}, common_problems=[], known_solutions=[], top_labels=[])",
          "description": "Assign insights_stream = InsightsStream(...)",
          "expected_result": null,
          "verification": "assert str(tmp_path) not in docs_stream.readme",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "_three_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
          "description": "Assign _three_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": "assert code_stream.directory == tmp_path",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Three Stream Produces Compact Output",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_e2e_three_stream_pipeline.py:567"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "891a0f7b95b5",
      "title": "Preset Flag Preferred",
      "overview": "Workflow: Test that --preset flag is the recommended way.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bd12e11a",
          "test_name": "test_preset_flag_preferred",
          "category": "workflow",
          "code": "'Test that --preset flag is the recommended way.'\nargs = {'preset': 'quick'}\nupdated = PresetManager.apply_preset('quick', args)\nassert updated['depth'] == 'surface'\nargs = {'preset': 'standard'}\nupdated = PresetManager.apply_preset('standard', args)\nassert updated['depth'] == 'deep'\nargs = {'preset': 'comprehensive'}\nupdated = PresetManager.apply_preset('comprehensive', args)\nassert updated['depth'] == 'full'",
          "language": "Python",
          "description": "Workflow: Test that --preset flag is the recommended way.",
          "expected_behavior": "assert updated['depth'] == 'full'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
          "line_start": 319,
          "line_end": 334,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "skill_seekers.cli.presets",
            "skill_seekers.cli.codebase_scraper",
            "argparse",
            "skill_seekers.cli.codebase_scraper",
            "argparse",
            "skill_seekers.cli.codebase_scraper",
            "argparse",
            "skill_seekers.cli.codebase_scraper",
            "argparse",
            "skill_seekers.cli.codebase_scraper",
            "argparse",
            "skill_seekers.cli.codebase_scraper",
            "argparse"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that --preset flag is the recommended way.'",
          "description": "'Test that --preset flag is the recommended way.'",
          "expected_result": null,
          "verification": "assert updated['depth'] == 'surface'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "args = {'preset': 'quick'}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": "assert updated['depth'] == 'deep'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "updated = PresetManager.apply_preset('quick', args)",
          "description": "Assign updated = PresetManager.apply_preset(...)",
          "expected_result": null,
          "verification": "assert updated['depth'] == 'full'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "args = {'preset': 'standard'}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "updated = PresetManager.apply_preset('standard', args)",
          "description": "Assign updated = PresetManager.apply_preset(...)",
          "expected_result": null,
          "verification": "assert updated['depth'] == 'deep'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "args = {'preset': 'comprehensive'}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "updated = PresetManager.apply_preset('comprehensive', args)",
          "description": "Assign updated = PresetManager.apply_preset(...)",
          "expected_result": null,
          "verification": "assert updated['depth'] == 'full'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Preset Flag Preferred",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_preset_system.py:319"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7d2940fc6a26",
      "title": "Completeness Full",
      "overview": "Workflow: Test completeness analysis with complete skill.",
      "complexity_level": "beginner",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f368a9d1",
          "test_name": "test_completeness_full",
          "category": "workflow",
          "code": "'Test completeness analysis with complete skill.'\nanalyzer = QualityAnalyzer(complete_skill_dir)\nscore = analyzer.analyze_completeness()\nassert score >= 70",
          "language": "Python",
          "description": "Workflow: Test completeness analysis with complete skill.",
          "expected_behavior": "assert score >= 70",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
          "line_start": 60,
          "line_end": 65,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": "# Fixtures: complete_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.quality_metrics"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test completeness analysis with complete skill.'",
          "description": "'Test completeness analysis with complete skill.'",
          "expected_result": null,
          "verification": "assert score >= 70",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "analyzer = QualityAnalyzer(complete_skill_dir)",
          "description": "Assign analyzer = QualityAnalyzer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "score = analyzer.analyze_completeness()",
          "description": "Assign score = analyzer.analyze_completeness(...)",
          "expected_result": null,
          "verification": "assert score >= 70",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Completeness Full",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_quality_metrics.py:60"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "862e0a58d213",
      "title": "Completeness Minimal",
      "overview": "Workflow: Test completeness analysis with minimal skill.",
      "complexity_level": "beginner",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "632eb543",
          "test_name": "test_completeness_minimal",
          "category": "workflow",
          "code": "'Test completeness analysis with minimal skill.'\nanalyzer = QualityAnalyzer(minimal_skill_dir)\nscore = analyzer.analyze_completeness()\nassert score < 80",
          "language": "Python",
          "description": "Workflow: Test completeness analysis with minimal skill.",
          "expected_behavior": "assert score < 80",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
          "line_start": 68,
          "line_end": 73,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": "# Fixtures: minimal_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.quality_metrics"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test completeness analysis with minimal skill.'",
          "description": "'Test completeness analysis with minimal skill.'",
          "expected_result": null,
          "verification": "assert score < 80",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "analyzer = QualityAnalyzer(minimal_skill_dir)",
          "description": "Assign analyzer = QualityAnalyzer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "score = analyzer.analyze_completeness()",
          "description": "Assign score = analyzer.analyze_completeness(...)",
          "expected_result": null,
          "verification": "assert score < 80",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Completeness Minimal",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_quality_metrics.py:68"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "cd78a2a0e35d",
      "title": "Mock Github Repo",
      "overview": "Workflow: Create mock GitHub repository structure.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e05661ef",
          "test_name": "mock_github_repo",
          "category": "workflow",
          "code": "'Create mock GitHub repository structure.'\nrepo_dir = tmp_path / 'fastmcp'\nrepo_dir.mkdir()\nsrc_dir = repo_dir / 'src'\nsrc_dir.mkdir()\n(src_dir / 'auth.py').write_text(\"\\n# OAuth authentication\\ndef google_provider(client_id, client_secret):\\n    '''Google OAuth provider'''\\n    return Provider('google', client_id, client_secret)\\n\\ndef azure_provider(tenant_id, client_id):\\n    '''Azure OAuth provider'''\\n    return Provider('azure', tenant_id, client_id)\\n\")\n(src_dir / 'async_tools.py').write_text('\\nimport asyncio\\n\\nasync def async_tool():\\n    \\'\\'\\'Async tool decorator\\'\\'\\'\\n    await asyncio.sleep(1)\\n    return \"result\"\\n')\ntests_dir = repo_dir / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")\n(repo_dir / 'README.md').write_text('\\n# FastMCP\\n\\nFastMCP is a Python framework for building MCP servers.\\n\\n## Quick Start\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Features\\n- OAuth authentication (Google, Azure, GitHub)\\n- Async/await support\\n- Easy testing with pytest\\n')\n(repo_dir / 'CONTRIBUTING.md').write_text('\\n# Contributing\\n\\nPlease follow these guidelines when contributing.\\n')\ndocs_dir = repo_dir / 'docs'\ndocs_dir.mkdir()\n(docs_dir / 'oauth.md').write_text('\\n# OAuth Guide\\n\\nHow to set up OAuth providers.\\n')\n(docs_dir / 'async.md').write_text('\\n# Async Guide\\n\\nHow to use async tools.\\n')\nreturn repo_dir",
          "language": "Python",
          "description": "Workflow: Create mock GitHub repository structure.",
          "expected_behavior": "(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 65,
          "line_end": 157,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "mock",
            "pytest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Create mock GitHub repository structure.'",
          "description": "'Create mock GitHub repository structure.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "repo_dir = tmp_path / 'fastmcp'",
          "description": "Assign repo_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "repo_dir.mkdir()",
          "description": "Call repo_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "src_dir = repo_dir / 'src'",
          "description": "Assign src_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "src_dir.mkdir()",
          "description": "Call src_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(src_dir / 'auth.py').write_text(\"\\n# OAuth authentication\\ndef google_provider(client_id, client_secret):\\n    '''Google OAuth provider'''\\n    return Provider('google', client_id, client_secret)\\n\\ndef azure_provider(tenant_id, client_id):\\n    '''Azure OAuth provider'''\\n    return Provider('azure', tenant_id, client_id)\\n\")",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "(src_dir / 'async_tools.py').write_text('\\nimport asyncio\\n\\nasync def async_tool():\\n    \\'\\'\\'Async tool decorator\\'\\'\\'\\n    await asyncio.sleep(1)\\n    return \"result\"\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "tests_dir = repo_dir / 'tests'",
          "description": "Assign tests_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "tests_dir.mkdir()",
          "description": "Call tests_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "(repo_dir / 'README.md').write_text('\\n# FastMCP\\n\\nFastMCP is a Python framework for building MCP servers.\\n\\n## Quick Start\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Features\\n- OAuth authentication (Google, Azure, GitHub)\\n- Async/await support\\n- Easy testing with pytest\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "(repo_dir / 'CONTRIBUTING.md').write_text('\\n# Contributing\\n\\nPlease follow these guidelines when contributing.\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "docs_dir = repo_dir / 'docs'",
          "description": "Assign docs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "docs_dir.mkdir()",
          "description": "Call docs_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "(docs_dir / 'oauth.md').write_text('\\n# OAuth Guide\\n\\nHow to set up OAuth providers.\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "(docs_dir / 'async.md').write_text('\\n# Async Guide\\n\\nHow to use async tools.\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Mock Github Repo",
      "tags": [
        "mock",
        "pytest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_architecture_scenarios.py:65"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7890bb5135bc",
      "title": "Scenario 1 Quality Metrics",
      "overview": "Workflow: Test quality metrics meet architecture targets.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2013ef2a",
          "test_name": "test_scenario_1_quality_metrics",
          "category": "workflow",
          "code": "'Test quality metrics meet architecture targets.'\nrouter_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'\nlines = router_md.strip().split('\\n')\nassert len(lines) <= 200, f'Router too large: {len(lines)} lines (max 200)'\ngithub_lines = 0\nif 'Repository:' in router_md:\n    github_lines += 1\nif 'Stars:' in router_md or '\u2b50' in router_md:\n    github_lines += 1\nif 'Common Issues' in router_md:\n    github_lines += router_md.count('Issue #')\nassert github_lines >= 3, f'GitHub overhead too small: {github_lines} lines'\nassert github_lines <= 60, f'GitHub overhead too large: {github_lines} lines'\nassert 'Issue #42' in router_md, 'Missing issue references'\nassert '\u2b50' in router_md or 'Stars:' in router_md, 'Missing GitHub metadata'\nassert 'Quick Start' in router_md or 'README' in router_md, 'Missing README content'",
          "language": "Python",
          "description": "Workflow: Test quality metrics meet architecture targets.",
          "expected_behavior": "assert 'Quick Start' in router_md or 'README' in router_md, 'Missing README content'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 427,
          "line_end": 482,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test quality metrics meet architecture targets.'",
          "description": "'Test quality metrics meet architecture targets.'",
          "expected_result": null,
          "verification": "assert len(lines) <= 200, f'Router too large: {len(lines)} lines (max 200)'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "router_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'",
          "description": "Assign router_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'",
          "expected_result": null,
          "verification": "assert github_lines >= 3, f'GitHub overhead too small: {github_lines} lines'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "lines = router_md.strip().split('\\n')",
          "description": "Assign lines = router_md.strip.split(...)",
          "expected_result": null,
          "verification": "assert github_lines <= 60, f'GitHub overhead too large: {github_lines} lines'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "github_lines = 0",
          "description": "Assign github_lines = 0",
          "expected_result": null,
          "verification": "assert 'Issue #42' in router_md, 'Missing issue references'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 1 Quality Metrics",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_architecture_scenarios.py:427"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f8f890371ff0",
      "title": "Scenario 2 Issue Categorization",
      "overview": "Workflow: Test categorizing GitHub issues by topic.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "16d35564",
          "test_name": "test_scenario_2_issue_categorization",
          "category": "workflow",
          "code": "'Test categorizing GitHub issues by topic.'\nproblems = [{'number': 42, 'title': 'OAuth setup fails', 'labels': ['oauth', 'bug']}, {'number': 38, 'title': 'Async tools not working', 'labels': ['async', 'question']}, {'number': 35, 'title': 'Testing with pytest', 'labels': ['testing', 'question']}, {'number': 30, 'title': 'Google OAuth redirect', 'labels': ['oauth', 'question']}]\nsolutions = [{'number': 25, 'title': 'Fixed OAuth redirect', 'labels': ['oauth', 'bug']}, {'number': 20, 'title': 'Async timeout solution', 'labels': ['async', 'bug']}]\ntopics = ['oauth', 'async', 'testing']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized\nassert 'async' in categorized\nassert 'testing' in categorized\noauth_issues = categorized['oauth']\nassert len(oauth_issues) >= 2\noauth_numbers = [i['number'] for i in oauth_issues]\nassert 42 in oauth_numbers\nasync_issues = categorized['async']\nassert len(async_issues) >= 2\nasync_numbers = [i['number'] for i in async_issues]\nassert 38 in async_numbers\ntesting_issues = categorized['testing']\nassert len(testing_issues) >= 1",
          "language": "Python",
          "description": "Workflow: Test categorizing GitHub issues by topic.",
          "expected_behavior": "assert len(testing_issues) >= 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 519,
          "line_end": 572,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test categorizing GitHub issues by topic.'",
          "description": "'Test categorizing GitHub issues by topic.'",
          "expected_result": null,
          "verification": "assert 'oauth' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "problems = [{'number': 42, 'title': 'OAuth setup fails', 'labels': ['oauth', 'bug']}, {'number': 38, 'title': 'Async tools not working', 'labels': ['async', 'question']}, {'number': 35, 'title': 'Testing with pytest', 'labels': ['testing', 'question']}, {'number': 30, 'title': 'Google OAuth redirect', 'labels': ['oauth', 'question']}]",
          "description": "Assign problems = value",
          "expected_result": null,
          "verification": "assert 'async' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "solutions = [{'number': 25, 'title': 'Fixed OAuth redirect', 'labels': ['oauth', 'bug']}, {'number': 20, 'title': 'Async timeout solution', 'labels': ['async', 'bug']}]",
          "description": "Assign solutions = value",
          "expected_result": null,
          "verification": "assert 'testing' in categorized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "topics = ['oauth', 'async', 'testing']",
          "description": "Assign topics = value",
          "expected_result": null,
          "verification": "assert len(oauth_issues) >= 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
          "description": "Assign categorized = categorize_issues_by_topic(...)",
          "expected_result": null,
          "verification": "assert 42 in oauth_numbers",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "oauth_issues = categorized['oauth']",
          "description": "Assign oauth_issues = value",
          "expected_result": null,
          "verification": "assert len(async_issues) >= 2",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "oauth_numbers = [i['number'] for i in oauth_issues]",
          "description": "Assign oauth_numbers = value",
          "expected_result": null,
          "verification": "assert 38 in async_numbers",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "async_issues = categorized['async']",
          "description": "Assign async_issues = value",
          "expected_result": null,
          "verification": "assert len(testing_issues) >= 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "async_numbers = [i['number'] for i in async_issues]",
          "description": "Assign async_numbers = value",
          "expected_result": null,
          "verification": "assert 38 in async_numbers",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "testing_issues = categorized['testing']",
          "description": "Assign testing_issues = value",
          "expected_result": null,
          "verification": "assert len(testing_issues) >= 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 2 Issue Categorization",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_architecture_scenarios.py:519"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "55f3090c122c",
      "title": "Scenario 2 Conflict Detection",
      "overview": "Workflow: Test conflict detection between docs and code.",
      "complexity_level": "beginner",
      "prerequisites": [],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "15777a62",
          "test_name": "test_scenario_2_conflict_detection",
          "category": "workflow",
          "code": "'Test conflict detection between docs and code.'\napi_data = {'GoogleProvider': {'params': ['app_id', 'app_secret'], 'source': 'html_docs'}}\ngithub_docs = {'readme': 'Use client_id and client_secret for Google OAuth'}\nassert 'GoogleProvider' in api_data\nassert 'params' in api_data['GoogleProvider']\nassert github_docs is not None",
          "language": "Python",
          "description": "Workflow: Test conflict detection between docs and code.",
          "expected_behavior": "assert github_docs is not None",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 574,
          "line_end": 595,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test conflict detection between docs and code.'",
          "description": "'Test conflict detection between docs and code.'",
          "expected_result": null,
          "verification": "assert 'GoogleProvider' in api_data",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "api_data = {'GoogleProvider': {'params': ['app_id', 'app_secret'], 'source': 'html_docs'}}",
          "description": "Assign api_data = value",
          "expected_result": null,
          "verification": "assert 'params' in api_data['GoogleProvider']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "github_docs = {'readme': 'Use client_id and client_secret for Google OAuth'}",
          "description": "Assign github_docs = value",
          "expected_result": null,
          "verification": "assert github_docs is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 2 Conflict Detection",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_architecture_scenarios.py:574"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "fbb1e020fb2e",
      "title": "Scenario 2 Multi Layer Merge",
      "overview": "Workflow: Test multi-layer source merging priority.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "32affc6b",
          "test_name": "test_scenario_2_multi_layer_merge",
          "category": "workflow",
          "code": "'Test multi-layer source merging priority.'\nsource1_data = {'api': [{'name': 'GoogleProvider', 'params': ['app_id', 'app_secret']}]}\nsource2_data = {'api': [{'name': 'GoogleProvider', 'params': ['client_id', 'client_secret']}]}\n_github_streams = ThreeStreamData(code_stream=CodeStream(directory=Path('/tmp'), files=[]), docs_stream=DocsStream(readme='Use client_id and client_secret', contributing=None, docs_files=[]), insights_stream=InsightsStream(metadata={'stars': 1000}, common_problems=[{'number': 42, 'title': 'OAuth parameter confusion', 'labels': ['oauth']}], known_solutions=[], top_labels=[]))\nmerger = RuleBasedMerger(docs_data=source1_data, github_data=source2_data, conflicts=[])\nmerged = merger.merge_all()\nassert merged is not None\nassert isinstance(merged, dict)",
          "language": "Python",
          "description": "Workflow: Test multi-layer source merging priority.",
          "expected_behavior": "assert isinstance(merged, dict)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 597,
          "line_end": 643,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test multi-layer source merging priority.'",
          "description": "'Test multi-layer source merging priority.'",
          "expected_result": null,
          "verification": "assert merged is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "source1_data = {'api': [{'name': 'GoogleProvider', 'params': ['app_id', 'app_secret']}]}",
          "description": "Assign source1_data = value",
          "expected_result": null,
          "verification": "assert isinstance(merged, dict)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "source2_data = {'api': [{'name': 'GoogleProvider', 'params': ['client_id', 'client_secret']}]}",
          "description": "Assign source2_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "_github_streams = ThreeStreamData(code_stream=CodeStream(directory=Path('/tmp'), files=[]), docs_stream=DocsStream(readme='Use client_id and client_secret', contributing=None, docs_files=[]), insights_stream=InsightsStream(metadata={'stars': 1000}, common_problems=[{'number': 42, 'title': 'OAuth parameter confusion', 'labels': ['oauth']}], known_solutions=[], top_labels=[]))",
          "description": "Assign _github_streams = ThreeStreamData(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "merger = RuleBasedMerger(docs_data=source1_data, github_data=source2_data, conflicts=[])",
          "description": "Assign merger = RuleBasedMerger(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "merged = merger.merge_all()",
          "description": "Assign merged = merger.merge_all(...)",
          "expected_result": null,
          "verification": "assert merged is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 2 Multi Layer Merge",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_architecture_scenarios.py:597"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "026ad04a523b",
      "title": "Scenario 3 Local Analysis Basic",
      "overview": "Workflow: Test basic analysis of local codebase.",
      "complexity_level": "beginner",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "41b21168",
          "test_name": "test_scenario_3_local_analysis_basic",
          "category": "workflow",
          "code": "'Test basic analysis of local codebase.'\nanalyzer = UnifiedCodebaseAnalyzer()\nresult = analyzer.analyze(source=str(local_codebase), depth='basic', fetch_github_metadata=False)\nassert isinstance(result, AnalysisResult)\nassert result.source_type == 'local'\nassert result.analysis_depth == 'basic'\nassert result.code_analysis is not None\nassert 'files' in result.code_analysis\nassert len(result.code_analysis['files']) >= 2\nassert result.github_docs is None\nassert result.github_insights is None",
          "language": "Python",
          "description": "Workflow: Test basic analysis of local codebase.",
          "expected_behavior": "assert result.github_insights is None",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 720,
          "line_end": 740,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: local_codebase",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic analysis of local codebase.'",
          "description": "'Test basic analysis of local codebase.'",
          "expected_result": null,
          "verification": "assert isinstance(result, AnalysisResult)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "analyzer = UnifiedCodebaseAnalyzer()",
          "description": "Assign analyzer = UnifiedCodebaseAnalyzer(...)",
          "expected_result": null,
          "verification": "assert result.source_type == 'local'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = analyzer.analyze(source=str(local_codebase), depth='basic', fetch_github_metadata=False)",
          "description": "Assign result = analyzer.analyze(...)",
          "expected_result": null,
          "verification": "assert result.analysis_depth == 'basic'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 3 Local Analysis Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_architecture_scenarios.py:720"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "73c421970825",
      "title": "Scenario 3 Local Analysis C3X",
      "overview": "Workflow: Test C3.x analysis of local codebase.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "393c5e0e",
          "test_name": "test_scenario_3_local_analysis_c3x",
          "category": "workflow",
          "code": "'Test C3.x analysis of local codebase.'\nanalyzer = UnifiedCodebaseAnalyzer()\nwith patch('skill_seekers.cli.unified_codebase_analyzer.UnifiedCodebaseAnalyzer.c3x_analysis') as mock_c3x:\n    mock_c3x.return_value = {'files': ['database.py', 'api.py'], 'analysis_type': 'c3x', 'c3_1_patterns': [{'name': 'Singleton', 'count': 1, 'file': 'database.py'}], 'c3_2_examples': [{'name': 'test_connection', 'file': 'test_database.py'}], 'c3_2_examples_count': 1, 'c3_3_guides': [], 'c3_4_configs': [], 'c3_7_architecture': []}\n    result = analyzer.analyze(source=str(local_codebase), depth='c3x', fetch_github_metadata=False)\n    assert result.source_type == 'local'\n    assert result.analysis_depth == 'c3x'\n    assert result.code_analysis['analysis_type'] == 'c3x'\n    assert 'c3_1_patterns' in result.code_analysis\n    assert 'c3_2_examples' in result.code_analysis\n    assert result.github_docs is None\n    assert result.github_insights is None",
          "language": "Python",
          "description": "Workflow: Test C3.x analysis of local codebase.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 742,
          "line_end": 776,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": "# Fixtures: local_codebase",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test C3.x analysis of local codebase.'",
          "description": "'Test C3.x analysis of local codebase.'",
          "expected_result": null,
          "verification": "assert result.source_type == 'local'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "analyzer = UnifiedCodebaseAnalyzer()",
          "description": "Assign analyzer = UnifiedCodebaseAnalyzer(...)",
          "expected_result": null,
          "verification": "assert result.analysis_depth == 'c3x'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "mock_c3x.return_value = {'files': ['database.py', 'api.py'], 'analysis_type': 'c3x', 'c3_1_patterns': [{'name': 'Singleton', 'count': 1, 'file': 'database.py'}], 'c3_2_examples': [{'name': 'test_connection', 'file': 'test_database.py'}], 'c3_2_examples_count': 1, 'c3_3_guides': [], 'c3_4_configs': [], 'c3_7_architecture': []}",
          "description": "Assign mock_c3x.return_value = value",
          "expected_result": null,
          "verification": "assert result.code_analysis['analysis_type'] == 'c3x'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = analyzer.analyze(source=str(local_codebase), depth='c3x', fetch_github_metadata=False)",
          "description": "Assign result = analyzer.analyze(...)",
          "expected_result": null,
          "verification": "assert 'c3_1_patterns' in result.code_analysis",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 3 Local Analysis C3X",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_architecture_scenarios.py:742"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "46561e5fecd4",
      "title": "Scenario 3 Router Without Github",
      "overview": "Workflow: Test router generation without GitHub data.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "634f58a2",
          "test_name": "test_scenario_3_router_without_github",
          "category": "workflow",
          "code": "'Test router generation without GitHub data.'\nconfig1 = tmp_path / 'internal-database.json'\nconfig1.write_text(json.dumps({'name': 'internal-database', 'description': 'Database layer', 'categories': {'database': ['db', 'sql', 'connection']}}))\nconfig2 = tmp_path / 'internal-api.json'\nconfig2.write_text(json.dumps({'name': 'internal-api', 'description': 'API endpoints', 'categories': {'api': ['api', 'endpoint', 'route']}}))\ngenerator = RouterGenerator(config_paths=[str(config1), str(config2)], router_name='internal-tool', github_streams=None)\nskill_md = generator.generate_skill_md()\nassert 'internal-tool' in skill_md.lower()\nassert 'Repository:' not in skill_md\nassert 'Stars:' not in skill_md\nassert '\u2b50' not in skill_md\nassert 'Common Issues' not in skill_md\nassert 'Issue #' not in skill_md\nassert 'internal-database' in skill_md\nassert 'internal-api' in skill_md",
          "language": "Python",
          "description": "Workflow: Test router generation without GitHub data.",
          "expected_behavior": "assert 'internal-api' in skill_md",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 778,
          "line_end": 826,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test router generation without GitHub data.'",
          "description": "'Test router generation without GitHub data.'",
          "expected_result": null,
          "verification": "assert 'internal-tool' in skill_md.lower()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config1 = tmp_path / 'internal-database.json'",
          "description": "Assign config1 = value",
          "expected_result": null,
          "verification": "assert 'Repository:' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config1.write_text(json.dumps({'name': 'internal-database', 'description': 'Database layer', 'categories': {'database': ['db', 'sql', 'connection']}}))",
          "description": "Call config1.write_text()",
          "expected_result": null,
          "verification": "assert 'Stars:' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "config2 = tmp_path / 'internal-api.json'",
          "description": "Assign config2 = value",
          "expected_result": null,
          "verification": "assert '\u2b50' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config2.write_text(json.dumps({'name': 'internal-api', 'description': 'API endpoints', 'categories': {'api': ['api', 'endpoint', 'route']}}))",
          "description": "Call config2.write_text()",
          "expected_result": null,
          "verification": "assert 'Common Issues' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "generator = RouterGenerator(config_paths=[str(config1), str(config2)], router_name='internal-tool', github_streams=None)",
          "description": "Assign generator = RouterGenerator(...)",
          "expected_result": null,
          "verification": "assert 'Issue #' not in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "skill_md = generator.generate_skill_md()",
          "description": "Assign skill_md = generator.generate_skill_md(...)",
          "expected_result": null,
          "verification": "assert 'internal-database' in skill_md",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Scenario 3 Router Without Github",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_architecture_scenarios.py:778"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "57228da4881c",
      "title": "Token Efficiency Calculation",
      "overview": "Workflow: Calculate token efficiency with GitHub overhead.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bab78031",
          "test_name": "test_token_efficiency_calculation",
          "category": "workflow",
          "code": "'Calculate token efficiency with GitHub overhead.'\nmonolithic_size = 666 + 50\nrouter_size = 150 + 50\navg_subskill_size = (250 + 200 + 250 + 400) / 4\navg_subskill_with_github = avg_subskill_size + 30\navg_router_query = router_size + avg_subskill_with_github\nreduction = (monolithic_size - avg_router_query) / monolithic_size\nreduction_percent = reduction * 100\nprint('\\n=== Token Efficiency Calculation ===')\nprint(f'Monolithic: {monolithic_size} lines')\nprint(f'Router: {router_size} lines')\nprint(f'Avg Sub-skill: {avg_subskill_with_github} lines')\nprint(f'Avg Query: {avg_router_query} lines')\nprint(f'Reduction: {reduction_percent:.1f}%')\nprint('Target: 35-40%')\nassert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
          "language": "Python",
          "description": "Workflow: Calculate token efficiency with GitHub overhead.",
          "expected_behavior": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
          "line_start": 1025,
          "line_end": 1054,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.generate_router",
            "skill_seekers.cli.github_fetcher",
            "skill_seekers.cli.merge_sources",
            "skill_seekers.cli.unified_codebase_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Calculate token efficiency with GitHub overhead.'",
          "description": "'Calculate token efficiency with GitHub overhead.'",
          "expected_result": null,
          "verification": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "monolithic_size = 666 + 50",
          "description": "Assign monolithic_size = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "router_size = 150 + 50",
          "description": "Assign router_size = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "avg_subskill_size = (250 + 200 + 250 + 400) / 4",
          "description": "Assign avg_subskill_size = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "avg_subskill_with_github = avg_subskill_size + 30",
          "description": "Assign avg_subskill_with_github = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "avg_router_query = router_size + avg_subskill_with_github",
          "description": "Assign avg_router_query = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "reduction = (monolithic_size - avg_router_query) / monolithic_size",
          "description": "Assign reduction = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "reduction_percent = reduction * 100",
          "description": "Assign reduction_percent = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "print('\\n=== Token Efficiency Calculation ===')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "print(f'Monolithic: {monolithic_size} lines')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "print(f'Router: {router_size} lines')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "print(f'Avg Sub-skill: {avg_subskill_with_github} lines')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "print(f'Avg Query: {avg_router_query} lines')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "print(f'Reduction: {reduction_percent:.1f}%')",
          "description": "Call print()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "print('Target: 35-40%')",
          "description": "Call print()",
          "expected_result": null,
          "verification": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Token Efficiency Calculation",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_architecture_scenarios.py:1025"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "68f4257389a6",
      "title": "Bootstrap Validates Yaml Frontmatter",
      "overview": "Workflow: Verify generated SKILL.md has valid YAML frontmatter",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "82685bf1",
          "test_name": "test_bootstrap_validates_yaml_frontmatter",
          "category": "workflow",
          "code": "'Verify generated SKILL.md has valid YAML frontmatter'\nresult = run_bootstrap()\nassert result.returncode == 0\ncontent = (output_skill_dir / 'SKILL.md').read_text()\nassert content.startswith('---'), 'Missing frontmatter start'\nlines = content.split('\\n')\nclosing_found = False\nfor _i, line in enumerate(lines[1:], 1):\n    if line.strip() == '---':\n        closing_found = True\n        break\nassert closing_found, 'Missing frontmatter closing delimiter'\nassert 'name:' in content[:500], 'Missing name field'\nassert 'description:' in content[:500], 'Missing description field'",
          "language": "Python",
          "description": "Workflow: Verify generated SKILL.md has valid YAML frontmatter",
          "expected_behavior": "assert 'description:' in content[:500], 'Missing description field'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
          "line_start": 85,
          "line_end": 107,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: run_bootstrap, output_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "subprocess",
            "sys",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Verify generated SKILL.md has valid YAML frontmatter'",
          "description": "'Verify generated SKILL.md has valid YAML frontmatter'",
          "expected_result": null,
          "verification": "assert result.returncode == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "result = run_bootstrap()",
          "description": "Assign result = run_bootstrap(...)",
          "expected_result": null,
          "verification": "assert content.startswith('---'), 'Missing frontmatter start'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = (output_skill_dir / 'SKILL.md').read_text()",
          "description": "Assign content = unknown.read_text(...)",
          "expected_result": null,
          "verification": "assert closing_found, 'Missing frontmatter closing delimiter'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "lines = content.split('\\n')",
          "description": "Assign lines = content.split(...)",
          "expected_result": null,
          "verification": "assert 'name:' in content[:500], 'Missing name field'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "closing_found = False",
          "description": "Assign closing_found = False",
          "expected_result": null,
          "verification": "assert 'description:' in content[:500], 'Missing description field'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "closing_found = True",
          "description": "Assign closing_found = True",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Bootstrap Validates Yaml Frontmatter",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_bootstrap_skill_e2e.py:85"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0f8bfeb7d956",
      "title": "Skill Installable In Venv",
      "overview": "Workflow: Test skill is installable in clean virtual environment",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0aae0187",
          "test_name": "test_skill_installable_in_venv",
          "category": "workflow",
          "code": "'Test skill is installable in clean virtual environment'\nresult = run_bootstrap()\nassert result.returncode == 0\nvenv_path = tmp_path / 'test_venv'\nsubprocess.run([sys.executable, '-m', 'venv', str(venv_path)], check=True, timeout=60)\npip_path = venv_path / 'bin' / 'pip'\nresult = subprocess.run([str(pip_path), 'install', '-e', '.'], cwd=output_skill_dir.parent.parent, capture_output=True, text=True, timeout=120)\nassert result.returncode == 0, f'Install failed: {result.stderr}'",
          "language": "Python",
          "description": "Workflow: Test skill is installable in clean virtual environment",
          "expected_behavior": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
          "line_start": 122,
          "line_end": 143,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "# Fixtures: run_bootstrap, output_skill_dir, tmp_path",
          "tags": [
            "pytest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "subprocess",
            "sys",
            "pathlib",
            "pytest",
            "skill_seekers.cli.adaptors"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test skill is installable in clean virtual environment'",
          "description": "'Test skill is installable in clean virtual environment'",
          "expected_result": null,
          "verification": "assert result.returncode == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "result = run_bootstrap()",
          "description": "Assign result = run_bootstrap(...)",
          "expected_result": null,
          "verification": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "venv_path = tmp_path / 'test_venv'",
          "description": "Assign venv_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "subprocess.run([sys.executable, '-m', 'venv', str(venv_path)], check=True, timeout=60)",
          "description": "Call subprocess.run()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "pip_path = venv_path / 'bin' / 'pip'",
          "description": "Assign pip_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "result = subprocess.run([str(pip_path), 'install', '-e', '.'], cwd=output_skill_dir.parent.parent, capture_output=True, text=True, timeout=120)",
          "description": "Assign result = subprocess.run(...)",
          "expected_result": null,
          "verification": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Skill Installable In Venv",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_bootstrap_skill_e2e.py:122"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c03a43b63541",
      "title": "Analyze Quick Preset",
      "overview": "Workflow: Test quick analysis preset (real execution).",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b3823f05",
          "test_name": "test_analyze_quick_preset",
          "category": "workflow",
          "code": "'Test quick analysis preset (real execution).'\noutput_dir = self.test_dir / 'output_quick'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Quick analysis failed:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}')\nself.assertTrue(output_dir.exists(), 'Output directory not created')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not generated')\nskill_content = skill_file.read_text()\nself.assertGreater(len(skill_content), 100, 'SKILL.md is too short')\nself.assertIn('Codebase', skill_content, 'Missing codebase header')\nself.assertIn('Analysis', skill_content, 'Missing analysis section')\nself.assertTrue(skill_content.startswith('---'), 'Missing YAML frontmatter')\nself.assertIn('name:', skill_content, 'Missing name in frontmatter')",
          "language": "Python",
          "description": "Workflow: Test quick analysis preset (real execution).",
          "expected_behavior": "self.assertIn('name:', skill_content, 'Missing name in frontmatter')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
          "line_start": 106,
          "line_end": 138,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "subprocess",
            "sys",
            "tempfile",
            "unittest",
            "pathlib"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test quick analysis preset (real execution).'",
          "description": "'Test quick analysis preset (real execution).'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = self.test_dir / 'output_quick'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')",
          "description": "Assign result = self.run_command(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(result.returncode, 0, f'Quick analysis failed:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(output_dir.exists(), 'Output directory not created')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "skill_file = output_dir / 'SKILL.md'",
          "description": "Assign skill_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(skill_file.exists(), 'SKILL.md not generated')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "skill_content = skill_file.read_text()",
          "description": "Assign skill_content = skill_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreater(len(skill_content), 100, 'SKILL.md is too short')",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('Codebase', skill_content, 'Missing codebase header')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('Analysis', skill_content, 'Missing analysis section')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertTrue(skill_content.startswith('---'), 'Missing YAML frontmatter')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertIn('name:', skill_content, 'Missing name in frontmatter')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Analyze Quick Preset",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_analyze_e2e.py:106"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "35a688f57b3a",
      "title": "Analyze Output Structure",
      "overview": "Workflow: Test that output has expected structure.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4db84019",
          "test_name": "test_analyze_output_structure",
          "category": "workflow",
          "code": "'Test that output has expected structure.'\noutput_dir = self.test_dir / 'output_structure'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nself.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')\nanalysis_file = output_dir / 'code_analysis.json'\nif analysis_file.exists():\n    with open(analysis_file) as f:\n        data = json.load(f)\n        self.assertIsInstance(data, (dict, list), 'code_analysis.json is not valid JSON')",
          "language": "Python",
          "description": "Workflow: Test that output has expected structure.",
          "expected_behavior": "self.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
          "line_start": 228,
          "line_end": 247,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "subprocess",
            "sys",
            "tempfile",
            "unittest",
            "pathlib"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that output has expected structure.'",
          "description": "'Test that output has expected structure.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = self.test_dir / 'output_structure'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')",
          "description": "Assign result = self.run_command(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "analysis_file = output_dir / 'code_analysis.json'",
          "description": "Assign analysis_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIsInstance(data, (dict, list), 'code_analysis.json is not valid JSON')",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Analyze Output Structure",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_analyze_e2e.py:228"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "361de2024a8d",
      "title": "Analyze Then Check Output",
      "overview": "Workflow: Test analyzing and verifying output can be read.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c431e62b",
          "test_name": "test_analyze_then_check_output",
          "category": "workflow",
          "code": "'Test analyzing and verifying output can be read.'\noutput_dir = self.test_dir / 'output'\nresult = subprocess.run(['skill-seekers', 'analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick'], capture_output=True, text=True, timeout=120)\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not created')\ncontent = skill_file.read_text()\nself.assertGreater(len(content), 50, 'Output too short')\nself.assertIn('Codebase', content, 'Missing codebase header')\nself.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
          "language": "Python",
          "description": "Workflow: Test analyzing and verifying output can be read.",
          "expected_behavior": "self.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
          "line_start": 283,
          "line_end": 314,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "subprocess",
            "sys",
            "tempfile",
            "unittest",
            "pathlib"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test analyzing and verifying output can be read.'",
          "description": "'Test analyzing and verifying output can be read.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = self.test_dir / 'output'",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = subprocess.run(['skill-seekers', 'analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick'], capture_output=True, text=True, timeout=120)",
          "description": "Assign result = subprocess.run(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "skill_file = output_dir / 'SKILL.md'",
          "description": "Assign skill_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertTrue(skill_file.exists(), 'SKILL.md not created')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "content = skill_file.read_text()",
          "description": "Assign content = skill_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertGreater(len(content), 50, 'Output too short')",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('Codebase', content, 'Missing codebase header')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Analyze Then Check Output",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_analyze_e2e.py:283"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9cef025ada5d",
      "title": "E2E All Platforms From Same Skill",
      "overview": "Workflow: Test that all platforms can package the same skill",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "91db06e1",
          "test_name": "test_e2e_all_platforms_from_same_skill",
          "category": "workflow",
          "code": "'Test that all platforms can package the same skill'\nplatforms = ['claude', 'gemini', 'openai', 'markdown']\npackages = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    self.assertTrue(package_path.exists(), f'Package not created for {platform}')\n    packages[platform] = package_path\nself.assertEqual(len(packages), 4)\nself.assertTrue(str(packages['claude']).endswith('.zip'))\nself.assertTrue(str(packages['gemini']).endswith('.tar.gz'))\nself.assertTrue(str(packages['openai']).endswith('.zip'))\nself.assertTrue(str(packages['markdown']).endswith('.zip'))",
          "language": "Python",
          "description": "Workflow: Test that all platforms can package the same skill",
          "expected_behavior": "self.assertTrue(str(packages['markdown']).endswith('.zip'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 129,
          "line_end": 153,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that all platforms can package the same skill'",
          "description": "'Test that all platforms can package the same skill'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "platforms = ['claude', 'gemini', 'openai', 'markdown']",
          "description": "Assign platforms = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "packages = {}",
          "description": "Assign packages = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(len(packages), 4)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(str(packages['claude']).endswith('.zip'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertTrue(str(packages['gemini']).endswith('.tar.gz'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(str(packages['openai']).endswith('.zip'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(str(packages['markdown']).endswith('.zip'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue(package_path.exists(), f'Package not created for {platform}')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "packages[platform] = package_path",
          "description": "Assign unknown = package_path",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E All Platforms From Same Skill",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptors_e2e.py:129"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2335bec7aae7",
      "title": "E2E Claude Workflow",
      "overview": "Workflow: Test complete Claude workflow: package + verify structure",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "62dfc4ba",
          "test_name": "test_e2e_claude_workflow",
          "category": "workflow",
          "code": "'Test complete Claude workflow: package + verify structure'\nadaptor = get_adaptor('claude')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('SKILL.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    skill_content = zf.read('SKILL.md').decode('utf-8')\n    self.assertGreater(len(skill_content), 0)",
          "language": "Python",
          "description": "Workflow: Test complete Claude workflow: package + verify structure",
          "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 155,
          "line_end": 180,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete Claude workflow: package + verify structure'",
          "description": "'Test complete Claude workflow: package + verify structure'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('claude')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertTrue(package_path.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(str(package_path).endswith('.zip'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "names = zf.namelist()",
          "description": "Assign names = zf.namelist(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('SKILL.md', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(any(('references/' in name for name in names)))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "skill_content = zf.read('SKILL.md').decode('utf-8')",
          "description": "Assign skill_content = zf.read.decode(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreater(len(skill_content), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Claude Workflow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_adaptors_e2e.py:155"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c576abb575e3",
      "title": "E2E Gemini Workflow",
      "overview": "Workflow: Test complete Gemini workflow: package + verify structure",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7a17248a",
          "test_name": "test_e2e_gemini_workflow",
          "category": "workflow",
          "code": "'Test complete Gemini workflow: package + verify structure'\nadaptor = get_adaptor('gemini')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.tar.gz'))\nwith tarfile.open(package_path, 'r:gz') as tar:\n    names = tar.getnames()\n    self.assertIn('system_instructions.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    self.assertIn('gemini_metadata.json', names)\n    metadata_member = tar.getmember('gemini_metadata.json')\n    metadata_file = tar.extractfile(metadata_member)\n    metadata = json.loads(metadata_file.read().decode('utf-8'))\n    self.assertEqual(metadata['platform'], 'gemini')\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertIn('created_with', metadata)",
          "language": "Python",
          "description": "Workflow: Test complete Gemini workflow: package + verify structure",
          "expected_behavior": "self.assertTrue(str(package_path).endswith('.tar.gz'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 182,
          "line_end": 213,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete Gemini workflow: package + verify structure'",
          "description": "'Test complete Gemini workflow: package + verify structure'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('gemini')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertTrue(package_path.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(str(package_path).endswith('.tar.gz'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "names = tar.getnames()",
          "description": "Assign names = tar.getnames(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('system_instructions.md', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(any(('references/' in name for name in names)))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('gemini_metadata.json', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "metadata_member = tar.getmember('gemini_metadata.json')",
          "description": "Assign metadata_member = tar.getmember(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "metadata_file = tar.extractfile(metadata_member)",
          "description": "Assign metadata_file = tar.extractfile(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "metadata = json.loads(metadata_file.read().decode('utf-8'))",
          "description": "Assign metadata = json.loads(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertEqual(metadata['platform'], 'gemini')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "self.assertEqual(metadata['name'], 'test-skill')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "self.assertIn('created_with', metadata)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Gemini Workflow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptors_e2e.py:182"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "1760c5590ae0",
      "title": "E2E Openai Workflow",
      "overview": "Workflow: Test complete OpenAI workflow: package + verify structure",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "500562d5",
          "test_name": "test_e2e_openai_workflow",
          "category": "workflow",
          "code": "'Test complete OpenAI workflow: package + verify structure'\nadaptor = get_adaptor('openai')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('assistant_instructions.txt', names)\n    self.assertTrue(any(('vector_store_files/' in name for name in names)))\n    self.assertIn('openai_metadata.json', names)\n    metadata_content = zf.read('openai_metadata.json').decode('utf-8')\n    metadata = json.loads(metadata_content)\n    self.assertEqual(metadata['platform'], 'openai')\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertEqual(metadata['model'], 'gpt-4o')\n    self.assertIn('file_search', metadata['tools'])",
          "language": "Python",
          "description": "Workflow: Test complete OpenAI workflow: package + verify structure",
          "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 215,
          "line_end": 246,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete OpenAI workflow: package + verify structure'",
          "description": "'Test complete OpenAI workflow: package + verify structure'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('openai')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertTrue(package_path.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(str(package_path).endswith('.zip'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "names = zf.namelist()",
          "description": "Assign names = zf.namelist(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('assistant_instructions.txt', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(any(('vector_store_files/' in name for name in names)))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('openai_metadata.json', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "metadata_content = zf.read('openai_metadata.json').decode('utf-8')",
          "description": "Assign metadata_content = zf.read.decode(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "metadata = json.loads(metadata_content)",
          "description": "Assign metadata = json.loads(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertEqual(metadata['platform'], 'openai')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertEqual(metadata['name'], 'test-skill')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "self.assertEqual(metadata['model'], 'gpt-4o')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "self.assertIn('file_search', metadata['tools'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Openai Workflow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptors_e2e.py:215"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "732d51639142",
      "title": "E2E Markdown Workflow",
      "overview": "Workflow: Test complete Markdown workflow: package + verify structure",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "dec94e70",
          "test_name": "test_e2e_markdown_workflow",
          "category": "workflow",
          "code": "'Test complete Markdown workflow: package + verify structure'\nadaptor = get_adaptor('markdown')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('README.md', names)\n    self.assertIn('DOCUMENTATION.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    self.assertIn('metadata.json', names)\n    doc_content = zf.read('DOCUMENTATION.md').decode('utf-8')\n    self.assertIn('Getting Started', doc_content)\n    self.assertIn('React Hooks', doc_content)\n    self.assertIn('Components', doc_content)",
          "language": "Python",
          "description": "Workflow: Test complete Markdown workflow: package + verify structure",
          "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 248,
          "line_end": 281,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete Markdown workflow: package + verify structure'",
          "description": "'Test complete Markdown workflow: package + verify structure'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('markdown')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertTrue(package_path.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(str(package_path).endswith('.zip'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "names = zf.namelist()",
          "description": "Assign names = zf.namelist(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('README.md', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('DOCUMENTATION.md', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(any(('references/' in name for name in names)))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('metadata.json', names)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "doc_content = zf.read('DOCUMENTATION.md').decode('utf-8')",
          "description": "Assign doc_content = zf.read.decode(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('Getting Started', doc_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertIn('React Hooks', doc_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "self.assertIn('Components', doc_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Markdown Workflow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptors_e2e.py:248"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7dca11399660",
      "title": "E2E Package Format Validation",
      "overview": "Workflow: Test that each platform creates correct package format",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "13e57c58",
          "test_name": "test_e2e_package_format_validation",
          "category": "workflow",
          "code": "'Test that each platform creates correct package format'\ntest_cases = [('claude', '.zip'), ('gemini', '.tar.gz'), ('openai', '.zip'), ('markdown', '.zip')]\nfor platform, expected_ext in test_cases:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if expected_ext == '.tar.gz':\n        self.assertTrue(str(package_path).endswith('.tar.gz'), f'{platform} should create .tar.gz file')\n    else:\n        self.assertTrue(str(package_path).endswith('.zip'), f'{platform} should create .zip file')",
          "language": "Python",
          "description": "Workflow: Test that each platform creates correct package format",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 283,
          "line_end": 304,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that each platform creates correct package format'",
          "description": "'Test that each platform creates correct package format'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "test_cases = [('claude', '.zip'), ('gemini', '.tar.gz'), ('openai', '.zip'), ('markdown', '.zip')]",
          "description": "Assign test_cases = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertTrue(str(package_path).endswith('.tar.gz'), f'{platform} should create .tar.gz file')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertTrue(str(package_path).endswith('.zip'), f'{platform} should create .zip file')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Package Format Validation",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_adaptors_e2e.py:283"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f6abb97012e1",
      "title": "E2E Package Filename Convention",
      "overview": "Workflow: Test that package filenames follow convention",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a20b3287",
          "test_name": "test_e2e_package_filename_convention",
          "category": "workflow",
          "code": "'Test that package filenames follow convention'\ntest_cases = [('claude', 'test-skill.zip'), ('gemini', 'test-skill-gemini.tar.gz'), ('openai', 'test-skill-openai.zip'), ('markdown', 'test-skill-markdown.zip')]\nfor platform, expected_name in test_cases:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    self.assertEqual(package_path.name, expected_name, f'{platform} package filename incorrect')",
          "language": "Python",
          "description": "Workflow: Test that package filenames follow convention",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 306,
          "line_end": 322,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that package filenames follow convention'",
          "description": "'Test that package filenames follow convention'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "test_cases = [('claude', 'test-skill.zip'), ('gemini', 'test-skill-gemini.tar.gz'), ('openai', 'test-skill-openai.zip'), ('markdown', 'test-skill-markdown.zip')]",
          "description": "Assign test_cases = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(package_path.name, expected_name, f'{platform} package filename incorrect')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Package Filename Convention",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_adaptors_e2e.py:306"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0f9576266a85",
      "title": "E2E All Platforms Preserve References",
      "overview": "Workflow: Test that all platforms preserve reference files",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "7c83641e",
          "test_name": "test_e2e_all_platforms_preserve_references",
          "category": "workflow",
          "code": "'Test that all platforms preserve reference files'\nref_files = ['getting_started.md', 'hooks.md', 'components.md']\nfor platform in ['claude', 'gemini', 'openai', 'markdown']:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if platform == 'gemini':\n        with tarfile.open(package_path, 'r:gz') as tar:\n            names = tar.getnames()\n            for ref_file in ref_files:\n                self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')\n    else:\n        with zipfile.ZipFile(package_path, 'r') as zf:\n            names = zf.namelist()\n            for ref_file in ref_files:\n                if platform == 'openai':\n                    self.assertTrue(any((f'vector_store_files/{ref_file}' in name for name in names)), f'{platform}: {ref_file} not found in vector_store_files/')\n                else:\n                    self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
          "language": "Python",
          "description": "Workflow: Test that all platforms preserve reference files",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 324,
          "line_end": 355,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that all platforms preserve reference files'",
          "description": "'Test that all platforms preserve reference files'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "ref_files = ['getting_started.md', 'hooks.md', 'components.md']",
          "description": "Assign ref_files = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "names = tar.getnames()",
          "description": "Assign names = tar.getnames(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "names = zf.namelist()",
          "description": "Assign names = zf.namelist(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue(any((f'vector_store_files/{ref_file}' in name for name in names)), f'{platform}: {ref_file} not found in vector_store_files/')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E All Platforms Preserve References",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_adaptors_e2e.py:324"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "31d0911f4584",
      "title": "E2E Metadata Consistency",
      "overview": "Workflow: Test that metadata is consistent across platforms",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "baaebdb2",
          "test_name": "test_e2e_metadata_consistency",
          "category": "workflow",
          "code": "'Test that metadata is consistent across platforms'\nplatforms_with_metadata = ['gemini', 'openai', 'markdown']\nfor platform in platforms_with_metadata:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if platform == 'gemini':\n        with tarfile.open(package_path, 'r:gz') as tar:\n            metadata_member = tar.getmember('gemini_metadata.json')\n            metadata_file = tar.extractfile(metadata_member)\n            metadata = json.loads(metadata_file.read().decode('utf-8'))\n    else:\n        with zipfile.ZipFile(package_path, 'r') as zf:\n            metadata_filename = f'{platform}_metadata.json' if platform == 'openai' else 'metadata.json'\n            metadata_content = zf.read(metadata_filename).decode('utf-8')\n            metadata = json.loads(metadata_content)\n    self.assertEqual(metadata['platform'], platform)\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertIn('created_with', metadata)",
          "language": "Python",
          "description": "Workflow: Test that metadata is consistent across platforms",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 357,
          "line_end": 382,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that metadata is consistent across platforms'",
          "description": "'Test that metadata is consistent across platforms'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "platforms_with_metadata = ['gemini', 'openai', 'markdown']",
          "description": "Assign platforms_with_metadata = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "package_path = adaptor.package(self.skill_dir, self.output_dir)",
          "description": "Assign package_path = adaptor.package(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(metadata['platform'], platform)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(metadata['name'], 'test-skill')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('created_with', metadata)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "metadata_member = tar.getmember('gemini_metadata.json')",
          "description": "Assign metadata_member = tar.getmember(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "metadata_file = tar.extractfile(metadata_member)",
          "description": "Assign metadata_file = tar.extractfile(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "metadata = json.loads(metadata_file.read().decode('utf-8'))",
          "description": "Assign metadata = json.loads(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "metadata_filename = f'{platform}_metadata.json' if platform == 'openai' else 'metadata.json'",
          "description": "Assign metadata_filename = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "metadata_content = zf.read(metadata_filename).decode('utf-8')",
          "description": "Assign metadata_content = zf.read.decode(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "metadata = json.loads(metadata_content)",
          "description": "Assign metadata = json.loads(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Metadata Consistency",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptors_e2e.py:357"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "22a8553ab2e9",
      "title": "E2E Format Skill Md Differences",
      "overview": "Workflow: Test that each platform formats SKILL.md differently",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "cd0700dc",
          "test_name": "test_e2e_format_skill_md_differences",
          "category": "workflow",
          "code": "'Test that each platform formats SKILL.md differently'\nmetadata = SkillMetadata(name='test-skill', description='Test skill for E2E testing')\nformats = {}\nfor platform in ['claude', 'gemini', 'openai', 'markdown']:\n    adaptor = get_adaptor(platform)\n    formatted = adaptor.format_skill_md(self.skill_dir, metadata)\n    formats[platform] = formatted\nself.assertTrue(formats['claude'].startswith('---'))\nself.assertFalse(formats['gemini'].startswith('---'))\nself.assertFalse(formats['markdown'].startswith('---'))\nfor platform, formatted in formats.items():\n    self.assertIn('react', formatted.lower(), f'{platform} should contain skill content')\n    self.assertGreater(len(formatted), 100, f'{platform} should have substantial content')",
          "language": "Python",
          "description": "Workflow: Test that each platform formats SKILL.md differently",
          "expected_behavior": "self.assertFalse(formats['markdown'].startswith('---'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
          "line_start": 384,
          "line_end": 406,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "tarfile",
            "tempfile",
            "unittest",
            "zipfile",
            "pathlib",
            "skill_seekers.cli.adaptors",
            "skill_seekers.cli.adaptors.base",
            "chromadb"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that each platform formats SKILL.md differently'",
          "description": "'Test that each platform formats SKILL.md differently'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "metadata = SkillMetadata(name='test-skill', description='Test skill for E2E testing')",
          "description": "Assign metadata = SkillMetadata(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "formats = {}",
          "description": "Assign formats = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertTrue(formats['claude'].startswith('---'))",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertFalse(formats['gemini'].startswith('---'))",
          "description": "Call self.assertFalse()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertFalse(formats['markdown'].startswith('---'))",
          "description": "Call self.assertFalse()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "adaptor = get_adaptor(platform)",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "formatted = adaptor.format_skill_md(self.skill_dir, metadata)",
          "description": "Assign formatted = adaptor.format_skill_md(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "formats[platform] = formatted",
          "description": "Assign unknown = formatted",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('react', formatted.lower(), f'{platform} should contain skill content')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertGreater(len(formatted), 100, f'{platform} should have substantial content')",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "E2E Format Skill Md Differences",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_adaptors_e2e.py:384"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9c54e465506d",
      "title": "Comprehensive Preset Implies Full Depth",
      "overview": "Workflow: Test that --comprehensive preset should trigger full depth.",
      "complexity_level": "beginner",
      "prerequisites": [],
      "required_imports": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "4bd3db24",
          "test_name": "test_comprehensive_preset_implies_full_depth",
          "category": "workflow",
          "code": "'Test that --comprehensive preset should trigger full depth.'\nargs = self.parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nself.assertTrue(args.comprehensive)",
          "language": "Python",
          "description": "Workflow: Test that --comprehensive preset should trigger full depth.",
          "expected_behavior": "self.assertTrue(args.comprehensive)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
          "line_start": 170,
          "line_end": 173,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "sys",
            "unittest",
            "pathlib",
            "skill_seekers.cli.main"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that --comprehensive preset should trigger full depth.'",
          "description": "'Test that --comprehensive preset should trigger full depth.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "args = self.parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])",
          "description": "Assign args = self.parser.parse_args(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "self.assertTrue(args.comprehensive)",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Comprehensive Preset Implies Full Depth",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "5 minutes",
      "source_files": [
        "test_analyze_command.py:170"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "e5e03ff108b5",
      "title": "Codebase Analysis Enabled By Default",
      "overview": "Workflow: Test that enable_codebase_analysis defaults to True.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "ad73a5fc",
          "test_name": "test_codebase_analysis_enabled_by_default",
          "category": "workflow",
          "code": "'Test that enable_codebase_analysis defaults to True.'\nconfig_without_flag = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'github', 'repo': 'test/repo', 'local_repo_path': temp_dir}]}\nconfig_path = os.path.join(temp_dir, 'config.json')\nwith open(config_path, 'w') as f:\n    json.dump(config_without_flag, f)\nscraper = UnifiedScraper(config_path)\ngithub_source = scraper.config['sources'][0]\nassert github_source.get('enable_codebase_analysis', True)",
          "language": "Python",
          "description": "Workflow: Test that enable_codebase_analysis defaults to True.",
          "expected_behavior": "assert github_source.get('enable_codebase_analysis', True)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
          "line_start": 139,
          "line_end": 158,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_config, temp_dir",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that enable_codebase_analysis defaults to True.'",
          "description": "'Test that enable_codebase_analysis defaults to True.'",
          "expected_result": null,
          "verification": "assert github_source.get('enable_codebase_analysis', True)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config_without_flag = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'github', 'repo': 'test/repo', 'local_repo_path': temp_dir}]}",
          "description": "Assign config_without_flag = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config_path = os.path.join(temp_dir, 'config.json')",
          "description": "Assign config_path = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "scraper = UnifiedScraper(config_path)",
          "description": "Assign scraper = UnifiedScraper(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "github_source = scraper.config['sources'][0]",
          "description": "Assign github_source = value",
          "expected_result": null,
          "verification": "assert github_source.get('enable_codebase_analysis', True)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "json.dump(config_without_flag, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Codebase Analysis Enabled By Default",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_c3_integration.py:139"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2466861affd0",
      "title": "Skip Codebase Analysis Flag",
      "overview": "Workflow: Test --skip-codebase-analysis CLI flag disables analysis.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "999a84fb",
          "test_name": "test_skip_codebase_analysis_flag",
          "category": "workflow",
          "code": "'Test --skip-codebase-analysis CLI flag disables analysis.'\nconfig_path = os.path.join(temp_dir, 'config.json')\nwith open(config_path, 'w') as f:\n    json.dump(mock_config, f)\nscraper = UnifiedScraper(config_path)\nfor source in scraper.config.get('sources', []):\n    if source['type'] == 'github':\n        source['enable_codebase_analysis'] = False\ngithub_source = scraper.config['sources'][0]\nassert not github_source['enable_codebase_analysis']",
          "language": "Python",
          "description": "Workflow: Test --skip-codebase-analysis CLI flag disables analysis.",
          "expected_behavior": "assert not github_source['enable_codebase_analysis']",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
          "line_start": 160,
          "line_end": 177,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_config, temp_dir",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test --skip-codebase-analysis CLI flag disables analysis.'",
          "description": "'Test --skip-codebase-analysis CLI flag disables analysis.'",
          "expected_result": null,
          "verification": "assert not github_source['enable_codebase_analysis']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config_path = os.path.join(temp_dir, 'config.json')",
          "description": "Assign config_path = os.path.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraper = UnifiedScraper(config_path)",
          "description": "Assign scraper = UnifiedScraper(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "github_source = scraper.config['sources'][0]",
          "description": "Assign github_source = value",
          "expected_result": null,
          "verification": "assert not github_source['enable_codebase_analysis']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "json.dump(mock_config, f)",
          "description": "Call json.dump()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "source['enable_codebase_analysis'] = False",
          "description": "Assign unknown = False",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Skip Codebase Analysis Flag",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_c3_integration.py:160"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "db4d4e027f57",
      "title": "Architecture Md Generation",
      "overview": "Workflow: Test ARCHITECTURE.md is generated with all 8 sections.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "eb6091e1",
          "test_name": "test_architecture_md_generation",
          "category": "workflow",
          "code": "'Test ARCHITECTURE.md is generated with all 8 sections.'\ngithub_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}\nscraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nc3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')\nos.makedirs(c3_dir, exist_ok=True)\nbuilder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)\narch_file = os.path.join(c3_dir, 'ARCHITECTURE.md')\nassert os.path.exists(arch_file)\nwith open(arch_file) as f:\n    content = f.read()\nassert '## 1. Overview' in content\nassert '## 2. Architectural Patterns' in content\nassert '## 3. Technology Stack' in content\nassert '## 4. Design Patterns' in content\nassert '## 5. Configuration Overview' in content\nassert '## 6. Common Workflows' in content\nassert '## 7. Usage Examples' in content\nassert '## 8. Entry Points & Directory Structure' in content\nassert 'MVC' in content\nassert 'Flask' in content\nassert 'Factory' in content\nassert '15 usage example(s)' in content or '15 total' in content\nassert 'Security Alert' in content",
          "language": "Python",
          "description": "Workflow: Test ARCHITECTURE.md is generated with all 8 sections.",
          "expected_behavior": "assert 'Security Alert' in content",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
          "line_start": 179,
          "line_end": 218,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test ARCHITECTURE.md is generated with all 8 sections.'",
          "description": "'Test ARCHITECTURE.md is generated with all 8 sections.'",
          "expected_result": null,
          "verification": "assert os.path.exists(arch_file)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "github_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert '## 1. Overview' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": "assert '## 2. Architectural Patterns' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(mock_config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": "assert '## 3. Technology Stack' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder.skill_dir = temp_dir",
          "description": "Assign builder.skill_dir = temp_dir",
          "expected_result": null,
          "verification": "assert '## 4. Design Patterns' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "c3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')",
          "description": "Assign c3_dir = os.path.join(...)",
          "expected_result": null,
          "verification": "assert '## 5. Configuration Overview' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "os.makedirs(c3_dir, exist_ok=True)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": "assert '## 6. Common Workflows' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "builder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)",
          "description": "Call builder._generate_architecture_overview()",
          "expected_result": null,
          "verification": "assert '## 7. Usage Examples' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "arch_file = os.path.join(c3_dir, 'ARCHITECTURE.md')",
          "description": "Assign arch_file = os.path.join(...)",
          "expected_result": null,
          "verification": "assert '## 8. Entry Points & Directory Structure' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": "assert 'MVC' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Architecture Md Generation",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_c3_integration.py:179"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "1eb38bee1b88",
      "title": "C3 Reference Directory Structure",
      "overview": "Workflow: Test correct C3.x reference directory structure is created.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e20cfa94",
          "test_name": "test_c3_reference_directory_structure",
          "category": "workflow",
          "code": "'Test correct C3.x reference directory structure is created.'\ngithub_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}\nscraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nc3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')\nos.makedirs(c3_dir, exist_ok=True)\nbuilder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)\nbuilder._generate_pattern_references(c3_dir, mock_c3_data.get('patterns'))\nbuilder._generate_example_references(c3_dir, mock_c3_data.get('test_examples'))\nbuilder._generate_guide_references(c3_dir, mock_c3_data.get('how_to_guides'))\nbuilder._generate_config_references(c3_dir, mock_c3_data.get('config_patterns'))\nbuilder._copy_architecture_details(c3_dir, mock_c3_data.get('architecture'))\nassert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns'))\nassert os.path.exists(os.path.join(c3_dir, 'examples'))\nassert os.path.exists(os.path.join(c3_dir, 'guides'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration'))\nassert os.path.exists(os.path.join(c3_dir, 'architecture_details'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'examples', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'guides', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'architecture_details', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns', 'detected_patterns.json'))\nassert os.path.exists(os.path.join(c3_dir, 'examples', 'test_examples.json'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration', 'config_patterns.json'))",
          "language": "Python",
          "description": "Workflow: Test correct C3.x reference directory structure is created.",
          "expected_behavior": "assert os.path.exists(os.path.join(c3_dir, 'configuration', 'config_patterns.json'))",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
          "line_start": 220,
          "line_end": 260,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test correct C3.x reference directory structure is created.'",
          "description": "'Test correct C3.x reference directory structure is created.'",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "github_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}",
          "description": "Assign github_data = value",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'patterns'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "scraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'examples'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder = UnifiedSkillBuilder(mock_config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'guides'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder.skill_dir = temp_dir",
          "description": "Assign builder.skill_dir = temp_dir",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'configuration'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "c3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')",
          "description": "Assign c3_dir = os.path.join(...)",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'architecture_details'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "os.makedirs(c3_dir, exist_ok=True)",
          "description": "Call os.makedirs()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'patterns', 'index.md'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "builder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)",
          "description": "Call builder._generate_architecture_overview()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'examples', 'index.md'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "builder._generate_pattern_references(c3_dir, mock_c3_data.get('patterns'))",
          "description": "Call builder._generate_pattern_references()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'guides', 'index.md'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "builder._generate_example_references(c3_dir, mock_c3_data.get('test_examples'))",
          "description": "Call builder._generate_example_references()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'configuration', 'index.md'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "builder._generate_guide_references(c3_dir, mock_c3_data.get('how_to_guides'))",
          "description": "Call builder._generate_guide_references()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'architecture_details', 'index.md'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "builder._generate_config_references(c3_dir, mock_c3_data.get('config_patterns'))",
          "description": "Call builder._generate_config_references()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'patterns', 'detected_patterns.json'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "builder._copy_architecture_details(c3_dir, mock_c3_data.get('architecture'))",
          "description": "Call builder._copy_architecture_details()",
          "expected_result": null,
          "verification": "assert os.path.exists(os.path.join(c3_dir, 'examples', 'test_examples.json'))",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "C3 Reference Directory Structure",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_c3_integration.py:220"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9faccc35c712",
      "title": "Skill Md Includes C3 Summary",
      "overview": "Workflow: Test SKILL.md includes C3.x architecture summary.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "3720510e",
          "test_name": "test_skill_md_includes_c3_summary",
          "category": "workflow",
          "code": "'Test SKILL.md includes C3.x architecture summary.'\nscraped_data = {'github': {'data': {'readme': 'Test README', 'c3_analysis': mock_c3_data}}}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nbuilder._generate_skill_md()\nskill_file = os.path.join(temp_dir, 'SKILL.md')\nwith open(skill_file) as f:\n    content = f.read()\nassert '## \ud83c\udfd7\ufe0f Architecture & Code Analysis' in content\nassert 'Primary Architecture' in content\nassert 'MVC' in content\nassert 'Design Patterns' in content\nassert 'Factory' in content\nassert 'references/codebase_analysis/ARCHITECTURE.md' in content",
          "language": "Python",
          "description": "Workflow: Test SKILL.md includes C3.x architecture summary.",
          "expected_behavior": "assert 'references/codebase_analysis/ARCHITECTURE.md' in content",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
          "line_start": 339,
          "line_end": 358,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
          "tags": [
            "mock",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "os",
            "shutil",
            "tempfile",
            "unittest.mock",
            "pytest",
            "skill_seekers.cli.config_validator",
            "skill_seekers.cli.unified_scraper",
            "skill_seekers.cli.unified_skill_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test SKILL.md includes C3.x architecture summary.'",
          "description": "'Test SKILL.md includes C3.x architecture summary.'",
          "expected_result": null,
          "verification": "assert '## \ud83c\udfd7\ufe0f Architecture & Code Analysis' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "scraped_data = {'github': {'data': {'readme': 'Test README', 'c3_analysis': mock_c3_data}}}",
          "description": "Assign scraped_data = value",
          "expected_result": null,
          "verification": "assert 'Primary Architecture' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = UnifiedSkillBuilder(mock_config, scraped_data)",
          "description": "Assign builder = UnifiedSkillBuilder(...)",
          "expected_result": null,
          "verification": "assert 'MVC' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "builder.skill_dir = temp_dir",
          "description": "Assign builder.skill_dir = temp_dir",
          "expected_result": null,
          "verification": "assert 'Design Patterns' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "builder._generate_skill_md()",
          "description": "Call builder._generate_skill_md()",
          "expected_result": null,
          "verification": "assert 'Factory' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "skill_file = os.path.join(temp_dir, 'SKILL.md')",
          "description": "Assign skill_file = os.path.join(...)",
          "expected_result": null,
          "verification": "assert 'references/codebase_analysis/ARCHITECTURE.md' in content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "content = f.read()",
          "description": "Assign content = f.read(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Skill Md Includes C3 Summary",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_c3_integration.py:339"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "00b4a37be209",
      "title": "Get Config In Subdir",
      "overview": "Workflow: Test loading config from subdirectory.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9c566935",
          "test_name": "test_get_config_in_subdir",
          "category": "workflow",
          "code": "'Test loading config from subdirectory.'\nrepo_path = temp_cache_dir / 'test-repo'\nconfigs_dir = repo_path / 'configs'\nconfigs_dir.mkdir(parents=True)\nconfig_data = {'name': 'nestjs'}\n(configs_dir / 'nestjs.json').write_text(json.dumps(config_data))\nresult = git_repo.get_config(repo_path, 'nestjs')\nassert result == config_data",
          "language": "Python",
          "description": "Workflow: Test loading config from subdirectory.",
          "expected_behavior": "assert result == config_data",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
          "line_start": 370,
          "line_end": 381,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "# Fixtures: git_repo, temp_cache_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pathlib",
            "unittest.mock",
            "pytest",
            "git.exc",
            "skill_seekers.mcp.git_repo"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test loading config from subdirectory.'",
          "description": "'Test loading config from subdirectory.'",
          "expected_result": null,
          "verification": "assert result == config_data",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "repo_path = temp_cache_dir / 'test-repo'",
          "description": "Assign repo_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "configs_dir = repo_path / 'configs'",
          "description": "Assign configs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "configs_dir.mkdir(parents=True)",
          "description": "Call configs_dir.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "config_data = {'name': 'nestjs'}",
          "description": "Assign config_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "(configs_dir / 'nestjs.json').write_text(json.dumps(config_data))",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "result = git_repo.get_config(repo_path, 'nestjs')",
          "description": "Assign result = git_repo.get_config(...)",
          "expected_result": null,
          "verification": "assert result == config_data",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Get Config In Subdir",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_git_repo.py:370"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "68fc662ee0ee",
      "title": "Valid Complete Config",
      "overview": "Workflow: Test valid complete configuration",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "32f8dabf",
          "test_name": "test_valid_complete_config",
          "category": "workflow",
          "code": "'Test valid complete configuration'\nconfig = {'name': 'godot', 'base_url': 'https://docs.godotengine.org/en/stable/', 'description': 'Godot Engine documentation', 'selectors': {'main_content': 'div[role=\"main\"]', 'title': 'title', 'code_blocks': 'pre code'}, 'url_patterns': {'include': ['/guide/', '/api/'], 'exclude': ['/blog/']}, 'categories': {'getting_started': ['intro', 'tutorial'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 500}\nerrors, _ = validate_config(config)\nself.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
          "language": "Python",
          "description": "Workflow: Test valid complete configuration",
          "expected_behavior": "self.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
          "line_start": 27,
          "line_end": 44,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test valid complete configuration'",
          "description": "'Test valid complete configuration'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'godot', 'base_url': 'https://docs.godotengine.org/en/stable/', 'description': 'Godot Engine documentation', 'selectors': {'main_content': 'div[role=\"main\"]', 'title': 'title', 'code_blocks': 'pre code'}, 'url_patterns': {'include': ['/guide/', '/api/'], 'exclude': ['/blog/']}, 'categories': {'getting_started': ['intro', 'tutorial'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 500}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "errors, _ = validate_config(config)",
          "description": "Assign unknown = validate_config(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Valid Complete Config",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_config_validation.py:27"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "722cacd154d6",
      "title": "Valid Name Formats",
      "overview": "Workflow: Test various valid name formats",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a6fc1ff6",
          "test_name": "test_valid_name_formats",
          "category": "workflow",
          "code": "'Test various valid name formats'\nvalid_names = ['test', 'test-skill', 'test_skill', 'TestSkill123', 'my-awesome-skill_v2']\nfor name in valid_names:\n    config = {'name': name, 'base_url': 'https://example.com/'}\n    errors, _ = validate_config(config)\n    name_errors = [e for e in errors if 'invalid name' in e.lower()]\n    self.assertEqual(len(name_errors), 0, f\"Name '{name}' should be valid\")",
          "language": "Python",
          "description": "Workflow: Test various valid name formats",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
          "line_start": 64,
          "line_end": 71,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test various valid name formats'",
          "description": "'Test various valid name formats'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "valid_names = ['test', 'test-skill', 'test_skill', 'TestSkill123', 'my-awesome-skill_v2']",
          "description": "Assign valid_names = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "config = {'name': name, 'base_url': 'https://example.com/'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "errors, _ = validate_config(config)",
          "description": "Assign unknown = validate_config(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "name_errors = [e for e in errors if 'invalid name' in e.lower()]",
          "description": "Assign name_errors = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(len(name_errors), 0, f\"Name '{name}' should be valid\")",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Valid Name Formats",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_config_validation.py:64"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2eb52e8ee916",
      "title": "Class Formatting",
      "overview": "Workflow: Test markdown formatting for class signatures.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "cb8d825e",
          "test_name": "test_class_formatting",
          "category": "workflow",
          "code": "'Test markdown formatting for class signatures.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'docstring': 'A simple calculator class.', 'base_classes': ['object'], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'int', 'default': None}, {'name': 'b', 'type_hint': 'int', 'default': None}], 'return_type': 'int', 'docstring': 'Add two numbers.', 'is_async': False, 'is_method': True, 'decorators': []}]}], 'functions': []}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 1)\noutput_file = list(generated.values())[0]\nself.assertTrue(output_file.exists())\ncontent = output_file.read_text()\nself.assertIn('### Calculator', content)\nself.assertIn('A simple calculator class', content)\nself.assertIn('**Inherits from**: object', content)\nself.assertIn('##### add', content)\nself.assertIn('Add two numbers', content)",
          "language": "Python",
          "description": "Workflow: Test markdown formatting for class signatures.",
          "expected_behavior": "self.assertIn('Add two numbers', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
          "line_start": 38,
          "line_end": 85,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.api_reference_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test markdown formatting for class signatures.'",
          "description": "'Test markdown formatting for class signatures.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'docstring': 'A simple calculator class.', 'base_classes': ['object'], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'int', 'default': None}, {'name': 'b', 'type_hint': 'int', 'default': None}], 'return_type': 'int', 'docstring': 'Add two numbers.', 'is_async': False, 'is_method': True, 'decorators': []}]}], 'functions': []}]}",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = APIReferenceBuilder(code_analysis)",
          "description": "Assign builder = APIReferenceBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generated = builder.build_reference(self.output_dir)",
          "description": "Assign generated = builder.build_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(len(generated), 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "output_file = list(generated.values())[0]",
          "description": "Assign output_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertTrue(output_file.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = output_file.read_text()",
          "description": "Assign content = output_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('### Calculator', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('A simple calculator class', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('**Inherits from**: object', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('##### add', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertIn('Add two numbers', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Class Formatting",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_api_reference_builder.py:38"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0a8628b5d419",
      "title": "Function Formatting",
      "overview": "Workflow: Test markdown formatting for function signatures.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "0ccbbef2",
          "test_name": "test_function_formatting",
          "category": "workflow",
          "code": "'Test markdown formatting for function signatures.'\ncode_analysis = {'files': [{'file': 'utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'calculate_sum', 'parameters': [{'name': 'numbers', 'type_hint': 'list', 'default': None}], 'return_type': 'int', 'docstring': 'Calculate sum of numbers.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('## Functions', content)\nself.assertIn('### calculate_sum', content)\nself.assertIn('Calculate sum of numbers', content)\nself.assertIn('**Returns**: `int`', content)",
          "language": "Python",
          "description": "Workflow: Test markdown formatting for function signatures.",
          "expected_behavior": "self.assertIn('**Returns**: `int`', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
          "line_start": 87,
          "line_end": 122,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.api_reference_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test markdown formatting for function signatures.'",
          "description": "'Test markdown formatting for function signatures.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code_analysis = {'files': [{'file': 'utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'calculate_sum', 'parameters': [{'name': 'numbers', 'type_hint': 'list', 'default': None}], 'return_type': 'int', 'docstring': 'Calculate sum of numbers.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = APIReferenceBuilder(code_analysis)",
          "description": "Assign builder = APIReferenceBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generated = builder.build_reference(self.output_dir)",
          "description": "Assign generated = builder.build_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "output_file = list(generated.values())[0]",
          "description": "Assign output_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "content = output_file.read_text()",
          "description": "Assign content = output_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('## Functions', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('### calculate_sum', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('Calculate sum of numbers', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('**Returns**: `int`', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Function Formatting",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_api_reference_builder.py:87"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3923abb18bdf",
      "title": "Parameter Table Generation",
      "overview": "Workflow: Test parameter table formatting.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "176f53b5",
          "test_name": "test_parameter_table_generation",
          "category": "workflow",
          "code": "'Test parameter table formatting.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'create_user', 'parameters': [{'name': 'name', 'type_hint': 'str', 'default': None}, {'name': 'age', 'type_hint': 'int', 'default': '18'}, {'name': 'active', 'type_hint': 'bool', 'default': 'True'}], 'return_type': 'dict', 'docstring': 'Create a user object.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Parameters**:', content)\nself.assertIn('| Name | Type | Default | Description |', content)\nself.assertIn('| name | str | - |', content)\nself.assertIn('| age | int | 18 |', content)\nself.assertIn('| active | bool | True |', content)",
          "language": "Python",
          "description": "Workflow: Test parameter table formatting.",
          "expected_behavior": "self.assertIn('| active | bool | True |', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
          "line_start": 124,
          "line_end": 162,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.api_reference_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test parameter table formatting.'",
          "description": "'Test parameter table formatting.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'create_user', 'parameters': [{'name': 'name', 'type_hint': 'str', 'default': None}, {'name': 'age', 'type_hint': 'int', 'default': '18'}, {'name': 'active', 'type_hint': 'bool', 'default': 'True'}], 'return_type': 'dict', 'docstring': 'Create a user object.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = APIReferenceBuilder(code_analysis)",
          "description": "Assign builder = APIReferenceBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generated = builder.build_reference(self.output_dir)",
          "description": "Assign generated = builder.build_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "output_file = list(generated.values())[0]",
          "description": "Assign output_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "content = output_file.read_text()",
          "description": "Assign content = output_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('**Parameters**:', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('| Name | Type | Default | Description |', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('| name | str | - |', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('| age | int | 18 |', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('| active | bool | True |', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Parameter Table Generation",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_api_reference_builder.py:124"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4266be2eedb3",
      "title": "Markdown Output Structure",
      "overview": "Workflow: Test overall markdown document structure.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "002fab06",
          "test_name": "test_markdown_output_structure",
          "category": "workflow",
          "code": "'Test overall markdown document structure.'\ncode_analysis = {'files': [{'file': 'module.py', 'language': 'Python', 'classes': [{'name': 'TestClass', 'docstring': 'Test class.', 'base_classes': [], 'methods': []}], 'functions': [{'name': 'test_func', 'parameters': [], 'return_type': None, 'docstring': 'Test function.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('# API Reference: module.py', content)\nself.assertIn('**Language**: Python', content)\nself.assertIn('**Source**: `module.py`', content)\nclasses_pos = content.find('## Classes')\nfunctions_pos = content.find('## Functions')\nself.assertNotEqual(classes_pos, -1)\nself.assertNotEqual(functions_pos, -1)\nself.assertLess(classes_pos, functions_pos)",
          "language": "Python",
          "description": "Workflow: Test overall markdown document structure.",
          "expected_behavior": "self.assertLess(classes_pos, functions_pos)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
          "line_start": 164,
          "line_end": 212,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.api_reference_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test overall markdown document structure.'",
          "description": "'Test overall markdown document structure.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code_analysis = {'files': [{'file': 'module.py', 'language': 'Python', 'classes': [{'name': 'TestClass', 'docstring': 'Test class.', 'base_classes': [], 'methods': []}], 'functions': [{'name': 'test_func', 'parameters': [], 'return_type': None, 'docstring': 'Test function.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = APIReferenceBuilder(code_analysis)",
          "description": "Assign builder = APIReferenceBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generated = builder.build_reference(self.output_dir)",
          "description": "Assign generated = builder.build_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "output_file = list(generated.values())[0]",
          "description": "Assign output_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "content = output_file.read_text()",
          "description": "Assign content = output_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('# API Reference: module.py', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('**Language**: Python', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('**Source**: `module.py`', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "classes_pos = content.find('## Classes')",
          "description": "Assign classes_pos = content.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "functions_pos = content.find('## Functions')",
          "description": "Assign functions_pos = content.find(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertNotEqual(classes_pos, -1)",
          "description": "Call self.assertNotEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertNotEqual(functions_pos, -1)",
          "description": "Call self.assertNotEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "self.assertLess(classes_pos, functions_pos)",
          "description": "Call self.assertLess()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Markdown Output Structure",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_api_reference_builder.py:164"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "39b49a6b3f00",
      "title": "Integration With Code Analyzer",
      "overview": "Workflow: Test integration with actual code analyzer output format.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "required_fixtures": [
        "api_client"
      ],
      "workflows": [
        {
          "example_id": "8dba195d",
          "test_name": "test_integration_with_code_analyzer",
          "category": "workflow",
          "code": "'Test integration with actual code analyzer output format.'\ncode_analysis = {'files': [{'file': 'calculator.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'base_classes': [], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'float', 'default': None}, {'name': 'b', 'type_hint': 'float', 'default': None}], 'return_type': 'float', 'docstring': 'Add two numbers.', 'decorators': [], 'is_async': False, 'is_method': True}], 'docstring': 'Calculator class.', 'line_number': 1}], 'functions': []}, {'file': 'utils.js', 'language': 'JavaScript', 'classes': [], 'functions': [{'name': 'formatDate', 'parameters': [{'name': 'date', 'type_hint': None, 'default': None}], 'return_type': None, 'docstring': None, 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 2)\nfilenames = [f.name for f in generated.values()]\nself.assertIn('calculator.md', filenames)\nself.assertIn('utils.md', filenames)\npy_file = next((f for f in generated.values() if f.name == 'calculator.md'))\npy_content = py_file.read_text()\nself.assertIn('Calculator class', py_content)\nself.assertIn('add(a: float, b: float) \u2192 float', py_content)\njs_file = next((f for f in generated.values() if f.name == 'utils.md'))\njs_content = js_file.read_text()\nself.assertIn('formatDate', js_content)\nself.assertIn('**Language**: JavaScript', js_content)",
          "language": "Python",
          "description": "Workflow: Test integration with actual code analyzer output format.",
          "expected_behavior": "self.assertIn('**Language**: JavaScript', js_content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
          "line_start": 214,
          "line_end": 286,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.api_reference_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test integration with actual code analyzer output format.'",
          "description": "'Test integration with actual code analyzer output format.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code_analysis = {'files': [{'file': 'calculator.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'base_classes': [], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'float', 'default': None}, {'name': 'b', 'type_hint': 'float', 'default': None}], 'return_type': 'float', 'docstring': 'Add two numbers.', 'decorators': [], 'is_async': False, 'is_method': True}], 'docstring': 'Calculator class.', 'line_number': 1}], 'functions': []}, {'file': 'utils.js', 'language': 'JavaScript', 'classes': [], 'functions': [{'name': 'formatDate', 'parameters': [{'name': 'date', 'type_hint': None, 'default': None}], 'return_type': None, 'docstring': None, 'is_async': False, 'is_method': False, 'decorators': []}]}]}",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = APIReferenceBuilder(code_analysis)",
          "description": "Assign builder = APIReferenceBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generated = builder.build_reference(self.output_dir)",
          "description": "Assign generated = builder.build_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(len(generated), 2)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "filenames = [f.name for f in generated.values()]",
          "description": "Assign filenames = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('calculator.md', filenames)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('utils.md', filenames)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "py_file = next((f for f in generated.values() if f.name == 'calculator.md'))",
          "description": "Assign py_file = next(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "py_content = py_file.read_text()",
          "description": "Assign py_content = py_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('Calculator class', py_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('add(a: float, b: float) \u2192 float', py_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "js_file = next((f for f in generated.values() if f.name == 'utils.md'))",
          "description": "Assign js_file = next(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "js_content = js_file.read_text()",
          "description": "Assign js_content = js_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "self.assertIn('formatDate', js_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "self.assertIn('**Language**: JavaScript', js_content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Integration With Code Analyzer",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_api_reference_builder.py:214"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "06f1f42a0531",
      "title": "Async Function Indicator",
      "overview": "Workflow: Test that async functions are marked in output.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "required_fixtures": [
        "api_client"
      ],
      "workflows": [
        {
          "example_id": "a2d82022",
          "test_name": "test_async_function_indicator",
          "category": "workflow",
          "code": "'Test that async functions are marked in output.'\ncode_analysis = {'files': [{'file': 'async_utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'fetch_data', 'parameters': [{'name': 'url', 'type_hint': 'str', 'default': None}], 'return_type': 'dict', 'docstring': 'Fetch data from URL.', 'is_async': True, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Async function**', content)\nself.assertIn('fetch_data', content)",
          "language": "Python",
          "description": "Workflow: Test that async functions are marked in output.",
          "expected_behavior": "self.assertIn('fetch_data', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
          "line_start": 288,
          "line_end": 319,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.api_reference_builder"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that async functions are marked in output.'",
          "description": "'Test that async functions are marked in output.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code_analysis = {'files': [{'file': 'async_utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'fetch_data', 'parameters': [{'name': 'url', 'type_hint': 'str', 'default': None}], 'return_type': 'dict', 'docstring': 'Fetch data from URL.', 'is_async': True, 'is_method': False, 'decorators': []}]}]}",
          "description": "Assign code_analysis = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "builder = APIReferenceBuilder(code_analysis)",
          "description": "Assign builder = APIReferenceBuilder(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "generated = builder.build_reference(self.output_dir)",
          "description": "Assign generated = builder.build_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "output_file = list(generated.values())[0]",
          "description": "Assign output_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "content = output_file.read_text()",
          "description": "Assign content = output_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('**Async function**', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('fetch_data', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Async Function Indicator",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_api_reference_builder.py:288"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "39793d362284",
      "title": "Export To Weaviate",
      "overview": "Workflow: Test Weaviate export tool.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "67934803",
          "test_name": "test_export_to_weaviate",
          "category": "workflow",
          "code": "'Test Weaviate export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_weaviate_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Weaviate Export Complete!' in text\nassert 'test_skill-weaviate.json' in text\nassert 'weaviate.Client' in text",
          "language": "Python",
          "description": "Workflow: Test Weaviate export tool.",
          "expected_behavior": "assert 'weaviate.Client' in text",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
          "line_start": 60,
          "line_end": 80,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: test_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "asyncio",
            "skill_seekers.mcp.tools.vector_db_tools"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Weaviate export tool.'",
          "description": "'Test Weaviate export tool.'",
          "expected_result": null,
          "verification": "assert isinstance(result, list)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = test_skill_dir.parent",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": "assert len(result) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": "assert hasattr(result[0], 'text')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = run_async(export_to_weaviate_impl(args))",
          "description": "Assign result = run_async(...)",
          "expected_result": null,
          "verification": "assert '\u2705 Weaviate Export Complete!' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "text = result[0].text",
          "description": "Assign text = value",
          "expected_result": null,
          "verification": "assert 'test_skill-weaviate.json' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Export To Weaviate",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_mcp_vector_dbs.py:60"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "de3f589af9b1",
      "title": "Export To Chroma",
      "overview": "Workflow: Test Chroma export tool.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "03bf9106",
          "test_name": "test_export_to_chroma",
          "category": "workflow",
          "code": "'Test Chroma export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_chroma_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Chroma Export Complete!' in text\nassert 'test_skill-chroma.json' in text\nassert 'chromadb' in text",
          "language": "Python",
          "description": "Workflow: Test Chroma export tool.",
          "expected_behavior": "assert 'chromadb' in text",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
          "line_start": 83,
          "line_end": 103,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: test_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "asyncio",
            "skill_seekers.mcp.tools.vector_db_tools"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Chroma export tool.'",
          "description": "'Test Chroma export tool.'",
          "expected_result": null,
          "verification": "assert isinstance(result, list)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = test_skill_dir.parent",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": "assert len(result) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": "assert hasattr(result[0], 'text')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = run_async(export_to_chroma_impl(args))",
          "description": "Assign result = run_async(...)",
          "expected_result": null,
          "verification": "assert '\u2705 Chroma Export Complete!' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "text = result[0].text",
          "description": "Assign text = value",
          "expected_result": null,
          "verification": "assert 'test_skill-chroma.json' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Export To Chroma",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_mcp_vector_dbs.py:83"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "979530b58380",
      "title": "Export To Faiss",
      "overview": "Workflow: Test FAISS export tool.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d0cc1231",
          "test_name": "test_export_to_faiss",
          "category": "workflow",
          "code": "'Test FAISS export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_faiss_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 FAISS Export Complete!' in text\nassert 'test_skill-faiss.json' in text\nassert 'import faiss' in text",
          "language": "Python",
          "description": "Workflow: Test FAISS export tool.",
          "expected_behavior": "assert 'import faiss' in text",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
          "line_start": 106,
          "line_end": 126,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: test_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "asyncio",
            "skill_seekers.mcp.tools.vector_db_tools"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test FAISS export tool.'",
          "description": "'Test FAISS export tool.'",
          "expected_result": null,
          "verification": "assert isinstance(result, list)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = test_skill_dir.parent",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": "assert len(result) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": "assert hasattr(result[0], 'text')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = run_async(export_to_faiss_impl(args))",
          "description": "Assign result = run_async(...)",
          "expected_result": null,
          "verification": "assert '\u2705 FAISS Export Complete!' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "text = result[0].text",
          "description": "Assign text = value",
          "expected_result": null,
          "verification": "assert 'test_skill-faiss.json' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Export To Faiss",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_mcp_vector_dbs.py:106"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "314d01af3e71",
      "title": "Export To Qdrant",
      "overview": "Workflow: Test Qdrant export tool.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d678d20a",
          "test_name": "test_export_to_qdrant",
          "category": "workflow",
          "code": "'Test Qdrant export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_qdrant_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Qdrant Export Complete!' in text\nassert 'test_skill-qdrant.json' in text\nassert 'QdrantClient' in text",
          "language": "Python",
          "description": "Workflow: Test Qdrant export tool.",
          "expected_behavior": "assert 'QdrantClient' in text",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
          "line_start": 129,
          "line_end": 149,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: test_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "asyncio",
            "skill_seekers.mcp.tools.vector_db_tools"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test Qdrant export tool.'",
          "description": "'Test Qdrant export tool.'",
          "expected_result": null,
          "verification": "assert isinstance(result, list)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = test_skill_dir.parent",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": "assert len(result) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": "assert hasattr(result[0], 'text')",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = run_async(export_to_qdrant_impl(args))",
          "description": "Assign result = run_async(...)",
          "expected_result": null,
          "verification": "assert '\u2705 Qdrant Export Complete!' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "text = result[0].text",
          "description": "Assign text = value",
          "expected_result": null,
          "verification": "assert 'test_skill-qdrant.json' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Export To Qdrant",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_mcp_vector_dbs.py:129"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "661843b03aa3",
      "title": "All Exports Create Files",
      "overview": "Workflow: Test that all export tools create output files.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a9129e6d",
          "test_name": "test_all_exports_create_files",
          "category": "workflow",
          "code": "'Test that all export tools create output files.'\noutput_dir = test_skill_dir.parent\nexports = [('weaviate', export_to_weaviate_impl), ('chroma', export_to_chroma_impl), ('faiss', export_to_faiss_impl), ('qdrant', export_to_qdrant_impl)]\nfor target, export_func in exports:\n    args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\n    result = run_async(export_func(args))\n    assert isinstance(result, list)\n    text = result[0].text\n    assert '\u2705' in text\n    expected_file = output_dir / f'test_skill-{target}.json'\n    assert expected_file.exists(), f'{target} export file not created'\n    with open(expected_file) as f:\n        data = json.load(f)\n        assert isinstance(data, dict)",
          "language": "Python",
          "description": "Workflow: Test that all export tools create output files.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
          "line_start": 179,
          "line_end": 211,
          "complexity_score": 0.4,
          "confidence": 0.9,
          "setup_code": "# Fixtures: test_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "json",
            "asyncio",
            "skill_seekers.mcp.tools.vector_db_tools"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that all export tools create output files.'",
          "description": "'Test that all export tools create output files.'",
          "expected_result": null,
          "verification": "assert isinstance(result, list)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "output_dir = test_skill_dir.parent",
          "description": "Assign output_dir = value",
          "expected_result": null,
          "verification": "assert '\u2705' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "exports = [('weaviate', export_to_weaviate_impl), ('chroma', export_to_chroma_impl), ('faiss', export_to_faiss_impl), ('qdrant', export_to_qdrant_impl)]",
          "description": "Assign exports = value",
          "expected_result": null,
          "verification": "assert expected_file.exists(), f'{target} export file not created'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}",
          "description": "Assign args = value",
          "expected_result": null,
          "verification": "assert isinstance(data, dict)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "result = run_async(export_func(args))",
          "description": "Assign result = run_async(...)",
          "expected_result": null,
          "verification": "assert isinstance(result, list)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "text = result[0].text",
          "description": "Assign text = value",
          "expected_result": null,
          "verification": "assert '\u2705' in text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "expected_file = output_dir / f'test_skill-{target}.json'",
          "description": "Assign expected_file = value",
          "expected_result": null,
          "verification": "assert expected_file.exists(), f'{target} export file not created'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "data = json.load(f)",
          "description": "Assign data = json.load(...)",
          "expected_result": null,
          "verification": "assert isinstance(data, dict)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "All Exports Create Files",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_mcp_vector_dbs.py:179"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a7ef126dbf60",
      "title": "Chroma Upload Without Chromadb Installed",
      "overview": "Workflow: Test upload fails gracefully without chromadb installed.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "b0e0cc26",
          "test_name": "test_chroma_upload_without_chromadb_installed",
          "category": "workflow",
          "code": "'Test upload fails gracefully without chromadb installed.'\nadaptor = get_adaptor('chroma')\nimport sys\nchromadb_backup = sys.modules.get('chromadb')\nif 'chromadb' in sys.modules:\n    del sys.modules['chromadb']\ntry:\n    result = adaptor.upload(sample_chroma_package)\n    assert result['success'] is False\n    assert 'chromadb not installed' in result['message']\n    assert 'pip install chromadb' in result['message']\nfinally:\n    if chromadb_backup:\n        sys.modules['chromadb'] = chromadb_backup",
          "language": "Python",
          "description": "Workflow: Test upload fails gracefully without chromadb installed.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
          "line_start": 79,
          "line_end": 98,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "# Fixtures: sample_chroma_package",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "sys",
            "sys",
            "skill_seekers.cli.upload_skill",
            "inspect"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test upload fails gracefully without chromadb installed.'",
          "description": "'Test upload fails gracefully without chromadb installed.'",
          "expected_result": null,
          "verification": "assert result['success'] is False",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('chroma')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert 'chromadb not installed' in result['message']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "chromadb_backup = sys.modules.get('chromadb')",
          "description": "Assign chromadb_backup = sys.modules.get(...)",
          "expected_result": null,
          "verification": "assert 'pip install chromadb' in result['message']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = adaptor.upload(sample_chroma_package)",
          "description": "Assign result = adaptor.upload(...)",
          "expected_result": null,
          "verification": "assert result['success'] is False",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "sys.modules['chromadb'] = chromadb_backup",
          "description": "Assign unknown = chromadb_backup",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chroma Upload Without Chromadb Installed",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_upload_integration.py:79"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "369a8df570c3",
      "title": "Weaviate Upload Without Weaviate Installed",
      "overview": "Workflow: Test upload fails gracefully without weaviate-client installed.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "d7180035",
          "test_name": "test_weaviate_upload_without_weaviate_installed",
          "category": "workflow",
          "code": "'Test upload fails gracefully without weaviate-client installed.'\nadaptor = get_adaptor('weaviate')\nimport sys\nweaviate_backup = sys.modules.get('weaviate')\nif 'weaviate' in sys.modules:\n    del sys.modules['weaviate']\ntry:\n    result = adaptor.upload(sample_weaviate_package)\n    assert result['success'] is False\n    assert 'weaviate-client not installed' in result['message']\n    assert 'pip install weaviate-client' in result['message']\nfinally:\n    if weaviate_backup:\n        sys.modules['weaviate'] = weaviate_backup",
          "language": "Python",
          "description": "Workflow: Test upload fails gracefully without weaviate-client installed.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
          "line_start": 121,
          "line_end": 140,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "# Fixtures: sample_weaviate_package",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "pytest",
            "skill_seekers.cli.adaptors",
            "sys",
            "sys",
            "skill_seekers.cli.upload_skill",
            "inspect"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test upload fails gracefully without weaviate-client installed.'",
          "description": "'Test upload fails gracefully without weaviate-client installed.'",
          "expected_result": null,
          "verification": "assert result['success'] is False",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "adaptor = get_adaptor('weaviate')",
          "description": "Assign adaptor = get_adaptor(...)",
          "expected_result": null,
          "verification": "assert 'weaviate-client not installed' in result['message']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "weaviate_backup = sys.modules.get('weaviate')",
          "description": "Assign weaviate_backup = sys.modules.get(...)",
          "expected_result": null,
          "verification": "assert 'pip install weaviate-client' in result['message']",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = adaptor.upload(sample_weaviate_package)",
          "description": "Assign result = adaptor.upload(...)",
          "expected_result": null,
          "verification": "assert result['success'] is False",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "sys.modules['weaviate'] = weaviate_backup",
          "description": "Assign unknown = weaviate_backup",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Weaviate Upload Without Weaviate Installed",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_upload_integration.py:121"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a93a5569faef",
      "title": "Chunk Document Single Chunk",
      "overview": "Workflow: Test chunking when document fits in single chunk.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "f7cb18da",
          "test_name": "test_chunk_document_single_chunk",
          "category": "workflow",
          "code": "'Test chunking when document fits in single chunk.'\ningester = StreamingIngester(chunk_size=1000, chunk_overlap=100)\ncontent = 'Small document'\nmetadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}\nchunks = list(ingester.chunk_document(content, metadata))\nassert len(chunks) == 1\nchunk_text, chunk_meta = chunks[0]\nassert chunk_text == content\nassert chunk_meta.chunk_index == 0\nassert chunk_meta.total_chunks == 1\nassert chunk_meta.source == 'test'",
          "language": "Python",
          "description": "Workflow: Test chunking when document fits in single chunk.",
          "expected_behavior": "assert chunk_meta.source == 'test'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
          "line_start": 48,
          "line_end": 63,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.streaming_ingest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test chunking when document fits in single chunk.'",
          "description": "'Test chunking when document fits in single chunk.'",
          "expected_result": null,
          "verification": "assert len(chunks) == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "ingester = StreamingIngester(chunk_size=1000, chunk_overlap=100)",
          "description": "Assign ingester = StreamingIngester(...)",
          "expected_result": null,
          "verification": "assert chunk_text == content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = 'Small document'",
          "description": "Assign content = 'Small document'",
          "expected_result": null,
          "verification": "assert chunk_meta.chunk_index == 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": "assert chunk_meta.total_chunks == 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = list(ingester.chunk_document(content, metadata))",
          "description": "Assign chunks = list(...)",
          "expected_result": null,
          "verification": "assert chunk_meta.source == 'test'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "chunk_text, chunk_meta = chunks[0]",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": "assert chunk_text == content",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Document Single Chunk",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_streaming_ingestion.py:48"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "6995f78dac8a",
      "title": "Chunk Document Multiple Chunks",
      "overview": "Workflow: Test chunking with multiple chunks.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2e944c86",
          "test_name": "test_chunk_document_multiple_chunks",
          "category": "workflow",
          "code": "'Test chunking with multiple chunks.'\ningester = StreamingIngester(chunk_size=100, chunk_overlap=20)\ncontent = 'A' * 250\nmetadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}\nchunks = list(ingester.chunk_document(content, metadata))\nassert len(chunks) > 1\nfor i in range(len(chunks) - 1):\n    chunk1_text, chunk1_meta = chunks[i]\n    chunk2_text, chunk2_meta = chunks[i + 1]\n    assert chunk2_meta.char_start < chunk1_meta.char_end",
          "language": "Python",
          "description": "Workflow: Test chunking with multiple chunks.",
          "expected_behavior": "assert len(chunks) > 1",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
          "line_start": 66,
          "line_end": 84,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.streaming_ingest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test chunking with multiple chunks.'",
          "description": "'Test chunking with multiple chunks.'",
          "expected_result": null,
          "verification": "assert len(chunks) > 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "ingester = StreamingIngester(chunk_size=100, chunk_overlap=20)",
          "description": "Assign ingester = StreamingIngester(...)",
          "expected_result": null,
          "verification": "assert chunk2_meta.char_start < chunk1_meta.char_end",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = 'A' * 250",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = list(ingester.chunk_document(content, metadata))",
          "description": "Assign chunks = list(...)",
          "expected_result": null,
          "verification": "assert len(chunks) > 1",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "chunk1_text, chunk1_meta = chunks[i]",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "chunk2_text, chunk2_meta = chunks[i + 1]",
          "description": "Assign unknown = value",
          "expected_result": null,
          "verification": "assert chunk2_meta.char_start < chunk1_meta.char_end",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Document Multiple Chunks",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_streaming_ingestion.py:66"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "931a806df1f7",
      "title": "Chunk Document Metadata",
      "overview": "Workflow: Test chunk metadata is correct.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e804f7e6",
          "test_name": "test_chunk_document_metadata",
          "category": "workflow",
          "code": "'Test chunk metadata is correct.'\ningester = StreamingIngester(chunk_size=100, chunk_overlap=20)\ncontent = 'B' * 250\nmetadata = {'source': 'test_source', 'file': 'test_file.md', 'category': 'test_cat'}\nchunks = list(ingester.chunk_document(content, metadata))\nfor i, (chunk_text, chunk_meta) in enumerate(chunks):\n    assert chunk_meta.chunk_index == i\n    assert chunk_meta.total_chunks == len(chunks)\n    assert chunk_meta.source == 'test_source'\n    assert chunk_meta.file == 'test_file.md'\n    assert chunk_meta.category == 'test_cat'\n    assert len(chunk_meta.chunk_id) == 32",
          "language": "Python",
          "description": "Workflow: Test chunk metadata is correct.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
          "line_start": 87,
          "line_end": 102,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.streaming_ingest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test chunk metadata is correct.'",
          "description": "'Test chunk metadata is correct.'",
          "expected_result": null,
          "verification": "assert chunk_meta.chunk_index == i",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "ingester = StreamingIngester(chunk_size=100, chunk_overlap=20)",
          "description": "Assign ingester = StreamingIngester(...)",
          "expected_result": null,
          "verification": "assert chunk_meta.total_chunks == len(chunks)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "content = 'B' * 250",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": "assert chunk_meta.source == 'test_source'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "metadata = {'source': 'test_source', 'file': 'test_file.md', 'category': 'test_cat'}",
          "description": "Assign metadata = value",
          "expected_result": null,
          "verification": "assert chunk_meta.file == 'test_file.md'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "chunks = list(ingester.chunk_document(content, metadata))",
          "description": "Assign chunks = list(...)",
          "expected_result": null,
          "verification": "assert chunk_meta.category == 'test_cat'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Document Metadata",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_streaming_ingestion.py:87"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4f53309d901d",
      "title": "Stream Skill Directory",
      "overview": "Workflow: Test streaming entire skill directory.",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "00f58fd0",
          "test_name": "test_stream_skill_directory",
          "category": "workflow",
          "code": "'Test streaming entire skill directory.'\ningester = StreamingIngester(chunk_size=500, chunk_overlap=50)\nchunks = list(ingester.stream_skill_directory(temp_skill_dir))\nassert len(chunks) > 0\nassert ingester.progress is not None\nassert ingester.progress.total_documents == 3\nassert ingester.progress.processed_documents == 3\nassert ingester.progress.total_chunks > 0\nassert ingester.progress.processed_chunks == len(chunks)\nsources = set()\ncategories = set()\nfor chunk_text, chunk_meta in chunks:\n    assert chunk_text\n    assert chunk_meta['chunk_id']\n    sources.add(chunk_meta['source'])\n    categories.add(chunk_meta['category'])\nassert 'test_skill' in sources\nassert 'overview' in categories",
          "language": "Python",
          "description": "Workflow: Test streaming entire skill directory.",
          "expected_behavior": "assert 'overview' in categories",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
          "line_start": 105,
          "line_end": 132,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: temp_skill_dir",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.streaming_ingest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test streaming entire skill directory.'",
          "description": "'Test streaming entire skill directory.'",
          "expected_result": null,
          "verification": "assert len(chunks) > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "ingester = StreamingIngester(chunk_size=500, chunk_overlap=50)",
          "description": "Assign ingester = StreamingIngester(...)",
          "expected_result": null,
          "verification": "assert ingester.progress is not None",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "chunks = list(ingester.stream_skill_directory(temp_skill_dir))",
          "description": "Assign chunks = list(...)",
          "expected_result": null,
          "verification": "assert ingester.progress.total_documents == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "sources = set()",
          "description": "Assign sources = set(...)",
          "expected_result": null,
          "verification": "assert ingester.progress.processed_documents == 3",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categories = set()",
          "description": "Assign categories = set(...)",
          "expected_result": null,
          "verification": "assert ingester.progress.total_chunks > 0",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "sources.add(chunk_meta['source'])",
          "description": "Call sources.add()",
          "expected_result": null,
          "verification": "assert ingester.progress.processed_chunks == len(chunks)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "categories.add(chunk_meta['category'])",
          "description": "Call categories.add()",
          "expected_result": null,
          "verification": "assert chunk_text",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Stream Skill Directory",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_streaming_ingestion.py:105"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "41e6f06843df",
      "title": "Checkpoint Save Load",
      "overview": "Workflow: Test checkpoint save and load.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "facc692d",
          "test_name": "test_checkpoint_save_load",
          "category": "workflow",
          "code": "'Test checkpoint save and load.'\ningester = StreamingIngester()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    checkpoint_path = Path(tmpdir) / 'checkpoint.json'\n    ingester.progress = IngestionProgress(total_documents=10, processed_documents=5, total_chunks=100, processed_chunks=50, failed_chunks=2, bytes_processed=10000, start_time=1234567890.0)\n    state = {'last_processed_file': 'test.md', 'batch_number': 3}\n    ingester.save_checkpoint(checkpoint_path, state)\n    assert checkpoint_path.exists()\n    loaded_state = ingester.load_checkpoint(checkpoint_path)\n    assert loaded_state == state",
          "language": "Python",
          "description": "Workflow: Test checkpoint save and load.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
          "line_start": 178,
          "line_end": 205,
          "complexity_score": 0.3,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.streaming_ingest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test checkpoint save and load.'",
          "description": "'Test checkpoint save and load.'",
          "expected_result": null,
          "verification": "assert checkpoint_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "ingester = StreamingIngester()",
          "description": "Assign ingester = StreamingIngester(...)",
          "expected_result": null,
          "verification": "assert loaded_state == state",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "checkpoint_path = Path(tmpdir) / 'checkpoint.json'",
          "description": "Assign checkpoint_path = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "ingester.progress = IngestionProgress(total_documents=10, processed_documents=5, total_chunks=100, processed_chunks=50, failed_chunks=2, bytes_processed=10000, start_time=1234567890.0)",
          "description": "Assign ingester.progress = IngestionProgress(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "state = {'last_processed_file': 'test.md', 'batch_number': 3}",
          "description": "Assign state = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "ingester.save_checkpoint(checkpoint_path, state)",
          "description": "Call ingester.save_checkpoint()",
          "expected_result": null,
          "verification": "assert checkpoint_path.exists()",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "loaded_state = ingester.load_checkpoint(checkpoint_path)",
          "description": "Assign loaded_state = ingester.load_checkpoint(...)",
          "expected_result": null,
          "verification": "assert loaded_state == state",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Checkpoint Save Load",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_streaming_ingestion.py:178"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "b32ee1a6cfb5",
      "title": "Chunk Size Validation",
      "overview": "Workflow: Test different chunk sizes.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "6531de8b",
          "test_name": "test_chunk_size_validation",
          "category": "workflow",
          "code": "'Test different chunk sizes.'\ncontent = 'X' * 1000\ningester_small = StreamingIngester(chunk_size=100, chunk_overlap=10)\nchunks_small = list(ingester_small.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))\ningester_large = StreamingIngester(chunk_size=500, chunk_overlap=50)\nchunks_large = list(ingester_large.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))\nassert len(chunks_small) > len(chunks_large)",
          "language": "Python",
          "description": "Workflow: Test different chunk sizes.",
          "expected_behavior": "assert len(chunks_small) > len(chunks_large)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
          "line_start": 243,
          "line_end": 264,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "pathlib",
            "sys",
            "tempfile",
            "skill_seekers.cli.streaming_ingest"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test different chunk sizes.'",
          "description": "'Test different chunk sizes.'",
          "expected_result": null,
          "verification": "assert len(chunks_small) > len(chunks_large)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "content = 'X' * 1000",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "ingester_small = StreamingIngester(chunk_size=100, chunk_overlap=10)",
          "description": "Assign ingester_small = StreamingIngester(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "chunks_small = list(ingester_small.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))",
          "description": "Assign chunks_small = list(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "ingester_large = StreamingIngester(chunk_size=500, chunk_overlap=50)",
          "description": "Assign ingester_large = StreamingIngester(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "chunks_large = list(ingester_large.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))",
          "description": "Assign chunks_large = list(...)",
          "expected_result": null,
          "verification": "assert len(chunks_small) > len(chunks_large)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Chunk Size Validation",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_streaming_ingestion.py:243"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "9a815d8ec214",
      "title": "Categorize By Keywords",
      "overview": "Workflow: Test categorization using keyword matching",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e89f472c",
          "test_name": "test_categorize_by_keywords",
          "category": "workflow",
          "code": "'Test categorization using keyword matching'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf', 'categories': {'getting_started': ['introduction', 'getting started'], 'api': ['api', 'reference', 'function']}}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Introduction to the API', 'chapter': 'Chapter 1: Getting Started'}, {'page_number': 2, 'text': 'API reference for functions', 'chapter': None}]}\ncategories = converter.categorize_content()\nself.assertIn('test', categories)\nself.assertEqual(len(categories), 1)\nself.assertEqual(len(categories['test']['pages']), 2)",
          "language": "Python",
          "description": "Workflow: Test categorization using keyword matching",
          "expected_behavior": "self.assertEqual(len(categories['test']['pages']), 2)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 90,
          "line_end": 121,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test categorization using keyword matching'",
          "description": "'Test categorization using keyword matching'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test', 'pdf_path': 'test.pdf', 'categories': {'getting_started': ['introduction', 'getting started'], 'api': ['api', 'reference', 'function']}}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Introduction to the API', 'chapter': 'Chapter 1: Getting Started'}, {'page_number': 2, 'text': 'API reference for functions', 'chapter': None}]}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categories = converter.categorize_content()",
          "description": "Assign categories = converter.categorize_content(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIn('test', categories)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertEqual(len(categories), 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(len(categories['test']['pages']), 2)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Categorize By Keywords",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_scraper.py:90"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "c1f062a0f13a",
      "title": "Categorize By Chapters",
      "overview": "Workflow: Test categorization using chapter information",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "bf742326",
          "test_name": "test_categorize_by_chapters",
          "category": "workflow",
          "code": "'Test categorization using chapter information'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Content here', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 2, 'text': 'More content', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 3, 'text': 'New chapter', 'chapter': 'Chapter 2: Advanced Topics'}]}\ncategories = converter.categorize_content()\nself.assertIsInstance(categories, dict)\nself.assertGreater(len(categories), 0)",
          "language": "Python",
          "description": "Workflow: Test categorization using chapter information",
          "expected_behavior": "self.assertGreater(len(categories), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 123,
          "line_end": 141,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test categorization using chapter information'",
          "description": "'Test categorization using chapter information'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Content here', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 2, 'text': 'More content', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 3, 'text': 'New chapter', 'chapter': 'Chapter 2: Advanced Topics'}]}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categories = converter.categorize_content()",
          "description": "Assign categories = converter.categorize_content(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIsInstance(categories, dict)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(len(categories), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Categorize By Chapters",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_scraper.py:123"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4a384a49631e",
      "title": "Categorize Handles No Chapters",
      "overview": "Workflow: Test categorization when no chapters are detected",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "06381c0f",
          "test_name": "test_categorize_handles_no_chapters",
          "category": "workflow",
          "code": "'Test categorization when no chapters are detected'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Some content', 'chapter': None}]}\ncategories = converter.categorize_content()\nself.assertIsInstance(categories, dict)",
          "language": "Python",
          "description": "Workflow: Test categorization when no chapters are detected",
          "expected_behavior": "self.assertIsInstance(categories, dict)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 143,
          "line_end": 156,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test categorization when no chapters are detected'",
          "description": "'Test categorization when no chapters are detected'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Some content', 'chapter': None}]}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "categories = converter.categorize_content()",
          "description": "Assign categories = converter.categorize_content(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIsInstance(categories, dict)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Categorize Handles No Chapters",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_pdf_scraper.py:143"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2773de75271b",
      "title": "Build Skill Creates Structure",
      "overview": "Workflow: Test that build_skill creates required directory structure",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e4fdbc9d",
          "test_name": "test_build_skill_creates_structure",
          "category": "workflow",
          "code": "'Test that build_skill creates required directory structure'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test content', 'code_blocks': [], 'images': []}], 'total_pages': 1}\nconverter.categories = {'getting_started': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nskill_dir = Path(self.temp_dir) / 'test_skill'\nself.assertTrue(skill_dir.exists())\nself.assertTrue((skill_dir / 'references').exists())\nself.assertTrue((skill_dir / 'scripts').exists())\nself.assertTrue((skill_dir / 'assets').exists())",
          "language": "Python",
          "description": "Workflow: Test that build_skill creates required directory structure",
          "expected_behavior": "self.assertTrue((skill_dir / 'assets').exists())",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 173,
          "line_end": 197,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that build_skill creates required directory structure'",
          "description": "'Test that build_skill creates required directory structure'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test content', 'code_blocks': [], 'images': []}], 'total_pages': 1}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.categories = {'getting_started': [converter.extracted_data['pages'][0]]}",
          "description": "Assign converter.categories = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "skill_dir = Path(self.temp_dir) / 'test_skill'",
          "description": "Assign skill_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(skill_dir.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertTrue((skill_dir / 'references').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertTrue((skill_dir / 'scripts').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertTrue((skill_dir / 'assets').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Skill Creates Structure",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_pdf_scraper.py:173"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "a7ac157a9827",
      "title": "Build Skill Creates Skill Md",
      "overview": "Workflow: Test that SKILL.md is created",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "6ee4a77e",
          "test_name": "test_build_skill_creates_skill_md",
          "category": "workflow",
          "code": "'Test that SKILL.md is created'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf', 'description': 'Test description'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test', 'code_blocks': [], 'images': []}], 'total_pages': 1}\nconverter.categories = {'test': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nskill_md = Path(self.temp_dir) / 'test_skill' / 'SKILL.md'\nself.assertTrue(skill_md.exists())\ncontent = skill_md.read_text()\nself.assertIn('test_skill', content)\nself.assertIn('Test description', content)",
          "language": "Python",
          "description": "Workflow: Test that SKILL.md is created",
          "expected_behavior": "self.assertIn('Test description', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 199,
          "line_end": 221,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that SKILL.md is created'",
          "description": "'Test that SKILL.md is created'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf', 'description': 'Test description'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test', 'code_blocks': [], 'images': []}], 'total_pages': 1}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.categories = {'test': [converter.extracted_data['pages'][0]]}",
          "description": "Assign converter.categories = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "skill_md = Path(self.temp_dir) / 'test_skill' / 'SKILL.md'",
          "description": "Assign skill_md = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(skill_md.exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "content = skill_md.read_text()",
          "description": "Assign content = skill_md.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('test_skill', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIn('Test description', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Skill Creates Skill Md",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_pdf_scraper.py:199"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f497f3eb5acb",
      "title": "Build Skill Creates Reference Files",
      "overview": "Workflow: Test that reference files are created for categories",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e94d8fca",
          "test_name": "test_build_skill_creates_reference_files",
          "category": "workflow",
          "code": "'Test that reference files are created for categories'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Getting started', 'code_blocks': [], 'images': []}, {'page_number': 2, 'text': 'API reference', 'code_blocks': [], 'images': []}], 'total_pages': 2}\nconverter.build_skill()\nrefs_dir = Path(self.temp_dir) / 'test_skill' / 'references'\nself.assertTrue((refs_dir / 'test.md').exists())\nself.assertTrue((refs_dir / 'index.md').exists())",
          "language": "Python",
          "description": "Workflow: Test that reference files are created for categories",
          "expected_behavior": "self.assertTrue((refs_dir / 'index.md').exists())",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 223,
          "line_end": 245,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that reference files are created for categories'",
          "description": "'Test that reference files are created for categories'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Getting started', 'code_blocks': [], 'images': []}, {'page_number': 2, 'text': 'API reference', 'code_blocks': [], 'images': []}], 'total_pages': 2}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "refs_dir = Path(self.temp_dir) / 'test_skill' / 'references'",
          "description": "Assign refs_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertTrue((refs_dir / 'test.md').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue((refs_dir / 'index.md').exists())",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Build Skill Creates Reference Files",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_scraper.py:223"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4eaf1387d3c5",
      "title": "Code Blocks Included In References",
      "overview": "Workflow: Test that code blocks are included in reference files",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "85d89c03",
          "test_name": "test_code_blocks_included_in_references",
          "category": "workflow",
          "code": "'Test that code blocks are included in reference files'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Example code', 'code_blocks': [{'code': \"def hello():\\n    print('world')\", 'language': 'python', 'quality': 8.0}], 'images': []}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('```python', content)\nself.assertIn('def hello()', content)\nself.assertIn(\"print('world')\", content)",
          "language": "Python",
          "description": "Workflow: Test that code blocks are included in reference files",
          "expected_behavior": "self.assertIn(\"print('world')\", content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 262,
          "line_end": 298,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that code blocks are included in reference files'",
          "description": "'Test that code blocks are included in reference files'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Example code', 'code_blocks': [{'code': \"def hello():\\n    print('world')\", 'language': 'python', 'quality': 8.0}], 'images': []}], 'total_pages': 1}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "ref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'",
          "description": "Assign ref_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = ref_file.read_text()",
          "description": "Assign content = ref_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('```python', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('def hello()', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn(\"print('world')\", content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Code Blocks Included In References",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_pdf_scraper.py:262"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3dec7674c88d",
      "title": "High Quality Code Preferred",
      "overview": "Workflow: Test that high-quality code blocks are prioritized",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "69471952",
          "test_name": "test_high_quality_code_preferred",
          "category": "workflow",
          "code": "'Test that high-quality code blocks are prioritized'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Code examples', 'code_blocks': [{'code': 'x = 1', 'language': 'python', 'quality': 2.0}, {'code': 'def process():\\n    return result', 'language': 'python', 'quality': 9.0}], 'images': []}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('def process()', content)",
          "language": "Python",
          "description": "Workflow: Test that high-quality code blocks are prioritized",
          "expected_behavior": "self.assertIn('def process()', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 300,
          "line_end": 335,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that high-quality code blocks are prioritized'",
          "description": "'Test that high-quality code blocks are prioritized'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Code examples', 'code_blocks': [{'code': 'x = 1', 'language': 'python', 'quality': 2.0}, {'code': 'def process():\\n    return result', 'language': 'python', 'quality': 9.0}], 'images': []}], 'total_pages': 1}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "ref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'",
          "description": "Assign ref_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "content = ref_file.read_text()",
          "description": "Assign content = ref_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('def process()', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "High Quality Code Preferred",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_pdf_scraper.py:300"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "d1535bf4a940",
      "title": "Images Saved To Assets",
      "overview": "Workflow: Test that images are saved to assets directory",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "dbbdbb69",
          "test_name": "test_images_saved_to_assets",
          "category": "workflow",
          "code": "'Test that images are saved to assets directory'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nmock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'See diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 100, 'height': 100, 'data': mock_image_bytes}]}], 'total_pages': 1}\nconverter.categories = {'diagrams': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nassets_dir = Path(self.temp_dir) / 'test_skill' / 'assets'\nimage_files = list(assets_dir.glob('*.png'))\nself.assertGreater(len(image_files), 0)",
          "language": "Python",
          "description": "Workflow: Test that images are saved to assets directory",
          "expected_behavior": "self.assertGreater(len(image_files), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 352,
          "line_end": 389,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that images are saved to assets directory'",
          "description": "'Test that images are saved to assets directory'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
          "description": "Assign mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'See diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 100, 'height': 100, 'data': mock_image_bytes}]}], 'total_pages': 1}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "converter.categories = {'diagrams': [converter.extracted_data['pages'][0]]}",
          "description": "Assign converter.categories = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "assets_dir = Path(self.temp_dir) / 'test_skill' / 'assets'",
          "description": "Assign assets_dir = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "image_files = list(assets_dir.glob('*.png'))",
          "description": "Assign image_files = list(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertGreater(len(image_files), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Images Saved To Assets",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_pdf_scraper.py:352"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "358147205750",
      "title": "Image References In Markdown",
      "overview": "Workflow: Test that images are referenced in markdown files",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "e8478fb4",
          "test_name": "test_image_references_in_markdown",
          "category": "workflow",
          "code": "'Test that images are referenced in markdown files'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nmock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Architecture diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 200, 'height': 150, 'data': mock_image_bytes}]}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('![', content)\nself.assertIn('../assets/', content)",
          "language": "Python",
          "description": "Workflow: Test that images are referenced in markdown files",
          "expected_behavior": "self.assertIn('../assets/', content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
          "line_start": 391,
          "line_end": 429,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
          "tags": [
            "mock",
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "json",
            "shutil",
            "tempfile",
            "unittest",
            "pathlib",
            "fitz",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper",
            "skill_seekers.cli.pdf_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that images are referenced in markdown files'",
          "description": "'Test that images are referenced in markdown files'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "config = {'name': 'test_skill', 'pdf_path': 'test.pdf'}",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "converter = self.PDFToSkillConverter(config)",
          "description": "Assign converter = self.PDFToSkillConverter(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "converter.skill_dir = str(Path(self.temp_dir) / 'test_skill')",
          "description": "Assign converter.skill_dir = str(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
          "description": "Assign mock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "converter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Architecture diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 200, 'height': 150, 'data': mock_image_bytes}]}], 'total_pages': 1}",
          "description": "Assign converter.extracted_data = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "converter.build_skill()",
          "description": "Call converter.build_skill()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "ref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'",
          "description": "Assign ref_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "content = ref_file.read_text()",
          "description": "Assign content = ref_file.read_text(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('![', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertIn('../assets/', content)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Image References In Markdown",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_pdf_scraper.py:391"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "4b680b43b793",
      "title": "Summarize Reference Basic",
      "overview": "Workflow: Test basic summarization preserves structure",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5f8a4852",
          "test_name": "test_summarize_reference_basic",
          "category": "workflow",
          "code": "'Test basic summarization preserves structure'\nenhancer = LocalSkillEnhancer(tmp_path)\nsections = []\nfor i in range(20):\n    sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with detailed explanation that would benefit from summarization.\\nWe add multiple paragraphs to make the content more realistic and substantial.\\nThis content explains various aspects of the framework in detail.\\n\\nAnother paragraph with more information about this specific topic.\\nTechnical details and explanations continue here with examples and use cases.\\n\\n```python\\n# Example code for section {i}\\ndef function_{i}():\\n    print(\"Section {i}\")\\n    return {i}\\n```\\n\\nFinal paragraph wrapping up this section with concluding remarks.\\n')\ncontent = '# Introduction\\n\\nThis is the framework introduction.\\n' + '\\n'.join(sections)\nsummarized = enhancer.summarize_reference(content, target_ratio=0.3)\nassert '# Introduction' in summarized\nassert '```python' in summarized\nassert '[Content intelligently summarized' in summarized\nassert len(summarized) < len(content)",
          "language": "Python",
          "description": "Workflow: Test basic summarization preserves structure",
          "expected_behavior": "assert len(summarized) < len(content)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
          "line_start": 16,
          "line_end": 53,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "skill_seekers.cli.enhance_skill_local"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test basic summarization preserves structure'",
          "description": "'Test basic summarization preserves structure'",
          "expected_result": null,
          "verification": "assert '# Introduction' in summarized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "enhancer = LocalSkillEnhancer(tmp_path)",
          "description": "Assign enhancer = LocalSkillEnhancer(...)",
          "expected_result": null,
          "verification": "assert '```python' in summarized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "sections = []",
          "description": "Assign sections = value",
          "expected_result": null,
          "verification": "assert '[Content intelligently summarized' in summarized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "content = '# Introduction\\n\\nThis is the framework introduction.\\n' + '\\n'.join(sections)",
          "description": "Assign content = value",
          "expected_result": null,
          "verification": "assert len(summarized) < len(content)",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.3)",
          "description": "Assign summarized = enhancer.summarize_reference(...)",
          "expected_result": null,
          "verification": "assert '# Introduction' in summarized",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with detailed explanation that would benefit from summarization.\\nWe add multiple paragraphs to make the content more realistic and substantial.\\nThis content explains various aspects of the framework in detail.\\n\\nAnother paragraph with more information about this specific topic.\\nTechnical details and explanations continue here with examples and use cases.\\n\\n```python\\n# Example code for section {i}\\ndef function_{i}():\\n    print(\"Section {i}\")\\n    return {i}\\n```\\n\\nFinal paragraph wrapping up this section with concluding remarks.\\n')",
          "description": "Call sections.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Summarize Reference Basic",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "10 minutes",
      "source_files": [
        "test_smart_summarization.py:16"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "0f757c58bad2",
      "title": "Summarize Large Content",
      "overview": "Workflow: Test summarization with very large content",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "fecb1f6d",
          "test_name": "test_summarize_large_content",
          "category": "workflow",
          "code": "'Test summarization with very large content'\nenhancer = LocalSkillEnhancer(tmp_path)\nsections = []\nfor i in range(50):\n    sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with lots of content that needs to be summarized.\\nWe add multiple paragraphs to make it realistic.\\n\\n```python\\n# Code example {i}\\ndef function_{i}():\\n    return {i}\\n```\\n\\nMore explanatory text follows here.\\nAnother paragraph of content.\\n')\ncontent = '\\n'.join(sections)\noriginal_size = len(content)\nsummarized = enhancer.summarize_reference(content, target_ratio=0.3)\nsummarized_size = len(summarized)\nassert summarized_size < original_size\nratio = summarized_size / original_size\nassert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
          "language": "Python",
          "description": "Workflow: Test summarization with very large content",
          "expected_behavior": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
          "line_start": 94,
          "line_end": 128,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "# Fixtures: tmp_path",
          "tags": [
            "workflow",
            "integration"
          ],
          "dependencies": [
            "pytest",
            "skill_seekers.cli.enhance_skill_local"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test summarization with very large content'",
          "description": "'Test summarization with very large content'",
          "expected_result": null,
          "verification": "assert summarized_size < original_size",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "enhancer = LocalSkillEnhancer(tmp_path)",
          "description": "Assign enhancer = LocalSkillEnhancer(...)",
          "expected_result": null,
          "verification": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "sections = []",
          "description": "Assign sections = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "content = '\\n'.join(sections)",
          "description": "Assign content = unknown.join(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "original_size = len(content)",
          "description": "Assign original_size = len(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.3)",
          "description": "Assign summarized = enhancer.summarize_reference(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "summarized_size = len(summarized)",
          "description": "Assign summarized_size = len(...)",
          "expected_result": null,
          "verification": "assert summarized_size < original_size",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "ratio = summarized_size / original_size",
          "description": "Assign ratio = value",
          "expected_result": null,
          "verification": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with lots of content that needs to be summarized.\\nWe add multiple paragraphs to make it realistic.\\n\\n```python\\n# Code example {i}\\ndef function_{i}():\\n    return {i}\\n```\\n\\nMore explanatory text follows here.\\nAnother paragraph of content.\\n')",
          "description": "Call sections.append()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Summarize Large Content",
      "tags": [
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_smart_summarization.py:94"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "3a740d6bc441",
      "title": "Python Docstring Extraction",
      "overview": "Workflow: Test docstring extraction for functions and classes.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "c8c19ef1",
          "test_name": "test_python_docstring_extraction",
          "category": "workflow",
          "code": "'Test docstring extraction for functions and classes.'\ncode = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'\nresult = self.analyzer.analyze_file('test.py', code, 'Python')\ncalc_class = result['classes'][0]\nself.assertIn('A simple calculator class', calc_class['docstring'])\nself.assertIn('Supports basic arithmetic operations', calc_class['docstring'])\nadd_method = calc_class['methods'][0]\nself.assertIn('Add two numbers', add_method['docstring'])\nself.assertIn('Args:', add_method['docstring'])\nself.assertIn('Returns:', add_method['docstring'])",
          "language": "Python",
          "description": "Workflow: Test docstring extraction for functions and classes.",
          "expected_behavior": "self.assertIn('Returns:', add_method['docstring'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 134,
          "line_end": 166,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test docstring extraction for functions and classes.'",
          "description": "'Test docstring extraction for functions and classes.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'",
          "description": "Assign code = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.py', code, 'Python')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "calc_class = result['classes'][0]",
          "description": "Assign calc_class = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertIn('A simple calculator class', calc_class['docstring'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertIn('Supports basic arithmetic operations', calc_class['docstring'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "add_method = calc_class['methods'][0]",
          "description": "Assign add_method = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('Add two numbers', add_method['docstring'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertIn('Args:', add_method['docstring'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('Returns:', add_method['docstring'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Python Docstring Extraction",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:134"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "42e77f7b8db1",
      "title": "Javascript Class Methods",
      "overview": "Workflow: Test ES6 class method extraction.\n\nNote: Regex-based parser has limitations in extracting all methods.\nThis test verifies basic method extraction works.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a692fb42",
          "test_name": "test_javascript_class_methods",
          "category": "workflow",
          "code": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '\ncode = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\nself.assertIn('classes', result)\nuser_class = result['classes'][0]\nself.assertEqual(user_class['name'], 'User')\nself.assertGreaterEqual(len(user_class['methods']), 1)\nmethod_names = [m['name'] for m in user_class['methods']]\nself.assertGreater(len(method_names), 0)",
          "language": "Python",
          "description": "Workflow: Test ES6 class method extraction.\n\nNote: Regex-based parser has limitations in extracting all methods.\nThis test verifies basic method extraction works.",
          "expected_behavior": "self.assertGreater(len(method_names), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 253,
          "line_end": 286,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '",
          "description": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"",
          "description": "Assign code = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIn('classes', result)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "user_class = result['classes'][0]",
          "description": "Assign user_class = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(user_class['name'], 'User')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreaterEqual(len(user_class['methods']), 1)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "method_names = [m['name'] for m in user_class['methods']]",
          "description": "Assign method_names = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreater(len(method_names), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Javascript Class Methods",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:253"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7b6f05348140",
      "title": "Typescript Type Annotations",
      "overview": "Workflow: Test TypeScript type annotation extraction.\n\nNote: Current regex-based parser extracts parameter type hints\nbut NOT return types. Return type extraction requires a proper\nTypeScript parser (ts-morph or typescript library).",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "39ad407d",
          "test_name": "test_typescript_type_annotations",
          "category": "workflow",
          "code": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '\ncode = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'\nresult = self.analyzer.analyze_file('test.ts', code, 'TypeScript')\nself.assertIn('functions', result)\ncalc_func = result['functions'][0]\nself.assertEqual(calc_func['name'], 'calculate')\nself.assertEqual(calc_func['parameters'][0]['type_hint'], 'number')\nself.assertIsNone(calc_func['return_type'])\ncreate_func = result['functions'][1]\nself.assertEqual(create_func['name'], 'createUser')\nself.assertEqual(create_func['parameters'][1]['default'], '18')\nself.assertIsNone(create_func['return_type'])",
          "language": "Python",
          "description": "Workflow: Test TypeScript type annotation extraction.\n\nNote: Current regex-based parser extracts parameter type hints\nbut NOT return types. Return type extraction requires a proper\nTypeScript parser (ts-morph or typescript library).",
          "expected_behavior": "self.assertIsNone(create_func['return_type'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 288,
          "line_end": 325,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '",
          "description": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'",
          "description": "Assign code = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.ts', code, 'TypeScript')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIn('functions', result)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "calc_func = result['functions'][0]",
          "description": "Assign calc_func = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(calc_func['name'], 'calculate')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertEqual(calc_func['parameters'][0]['type_hint'], 'number')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIsNone(calc_func['return_type'])",
          "description": "Call self.assertIsNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "create_func = result['functions'][1]",
          "description": "Assign create_func = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertEqual(create_func['name'], 'createUser')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertEqual(create_func['parameters'][1]['default'], '18')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIsNone(create_func['return_type'])",
          "description": "Call self.assertIsNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Typescript Type Annotations",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_code_analyzer.py:288"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2abe9e258c1d",
      "title": "Cpp Class Extraction",
      "overview": "Workflow: Test C++ class extraction with inheritance.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "3d148051",
          "test_name": "test_cpp_class_extraction",
          "category": "workflow",
          "code": "'Test C++ class extraction with inheritance.'\ncode = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'\nresult = self.analyzer.analyze_file('test.h', code, 'C++')\nself.assertIn('classes', result)\nself.assertEqual(len(result['classes']), 2)\nanimal_class = result['classes'][0]\nself.assertEqual(animal_class['name'], 'Animal')\ndog_class = result['classes'][1]\nself.assertEqual(dog_class['name'], 'Dog')\nself.assertIn('Animal', dog_class['base_classes'])",
          "language": "Python",
          "description": "Workflow: Test C++ class extraction with inheritance.",
          "expected_behavior": "self.assertIn('Animal', dog_class['base_classes'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 376,
          "line_end": 404,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test C++ class extraction with inheritance.'",
          "description": "'Test C++ class extraction with inheritance.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'",
          "description": "Assign code = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.h', code, 'C++')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIn('classes', result)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(len(result['classes']), 2)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "animal_class = result['classes'][0]",
          "description": "Assign animal_class = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertEqual(animal_class['name'], 'Animal')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "dog_class = result['classes'][1]",
          "description": "Assign dog_class = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertEqual(dog_class['name'], 'Dog')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertIn('Animal', dog_class['base_classes'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cpp Class Extraction",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:376"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "276f9514e9e9",
      "title": "Deep Depth Extracts Signatures",
      "overview": "Workflow: Test that deep depth extracts full signatures.",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "fe9f26b5",
          "test_name": "test_deep_depth_extracts_signatures",
          "category": "workflow",
          "code": "'Test that deep depth extracts full signatures.'\nanalyzer = CodeAnalyzer(depth='deep')\ncode = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'\nresult = analyzer.analyze_file('test.py', code, 'Python')\nself.assertIn('functions', result)\nself.assertEqual(len(result['functions']), 1)\nfunc = result['functions'][0]\nself.assertEqual(func['name'], 'calculate')\nself.assertEqual(func['return_type'], 'int')",
          "language": "Python",
          "description": "Workflow: Test that deep depth extracts full signatures.",
          "expected_behavior": "self.assertEqual(func['return_type'], 'int')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 459,
          "line_end": 474,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test that deep depth extracts full signatures.'",
          "description": "'Test that deep depth extracts full signatures.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "analyzer = CodeAnalyzer(depth='deep')",
          "description": "Assign analyzer = CodeAnalyzer(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "code = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'",
          "description": "Assign code = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = analyzer.analyze_file('test.py', code, 'Python')",
          "description": "Assign result = analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertIn('functions', result)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertEqual(len(result['functions']), 1)",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "func = result['functions'][0]",
          "description": "Assign func = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(func['name'], 'calculate')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertEqual(func['return_type'], 'int')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Deep Depth Extracts Signatures",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:459"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "f04cd8a6be30",
      "title": "Javascript Inline Comments",
      "overview": "Workflow: Test JavaScript // comment extraction.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5c7f9d11",
          "test_name": "test_javascript_inline_comments",
          "category": "workflow",
          "code": "'Test JavaScript // comment extraction.'\ncode = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\nself.assertIn('comments', result)\ncomments = result['comments']\nself.assertGreaterEqual(len(comments), 3)\ninline_comments = [c for c in comments if c['type'] == 'inline']\nself.assertGreaterEqual(len(inline_comments), 3)",
          "language": "Python",
          "description": "Workflow: Test JavaScript // comment extraction.",
          "expected_behavior": "self.assertGreaterEqual(len(inline_comments), 3)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 627,
          "line_end": 650,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test JavaScript // comment extraction.'",
          "description": "'Test JavaScript // comment extraction.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'",
          "description": "Assign code = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIn('comments', result)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "comments = result['comments']",
          "description": "Assign comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertGreaterEqual(len(comments), 3)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "inline_comments = [c for c in comments if c['type'] == 'inline']",
          "description": "Assign inline_comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertGreaterEqual(len(inline_comments), 3)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Javascript Inline Comments",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:627"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "32a8eb6a4a20",
      "title": "Javascript Block Comments",
      "overview": "Workflow: Test JavaScript /* */ block comment extraction.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "885c9e6b",
          "test_name": "test_javascript_block_comments",
          "category": "workflow",
          "code": "'Test JavaScript /* */ block comment extraction.'\ncode = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\ncomments = result['comments']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(block_comments), 2)\nfirst_block = next((c for c in comments if 'multi-line' in c['text']))\nself.assertIn('multi-line', first_block['text'])",
          "language": "Python",
          "description": "Workflow: Test JavaScript /* */ block comment extraction.",
          "expected_behavior": "self.assertIn('multi-line', first_block['text'])",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 652,
          "line_end": 673,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test JavaScript /* */ block comment extraction.'",
          "description": "'Test JavaScript /* */ block comment extraction.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'",
          "description": "Assign code = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "comments = result['comments']",
          "description": "Assign comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "block_comments = [c for c in comments if c['type'] == 'block']",
          "description": "Assign block_comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertGreaterEqual(len(block_comments), 2)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "first_block = next((c for c in comments if 'multi-line' in c['text']))",
          "description": "Assign first_block = next(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('multi-line', first_block['text'])",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Javascript Block Comments",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:652"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "5e8fd494ddbd",
      "title": "Javascript Mixed Comments",
      "overview": "Workflow: Test JavaScript mixed inline and block comments.",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "86bdbb68",
          "test_name": "test_javascript_mixed_comments",
          "category": "workflow",
          "code": "'Test JavaScript mixed inline and block comments.'\ncode = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\ncomments = result['comments']\ninline_comments = [c for c in comments if c['type'] == 'inline']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(inline_comments), 2)\nself.assertGreaterEqual(len(block_comments), 2)",
          "language": "Python",
          "description": "Workflow: Test JavaScript mixed inline and block comments.",
          "expected_behavior": "self.assertGreaterEqual(len(block_comments), 2)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 675,
          "line_end": 695,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test JavaScript mixed inline and block comments.'",
          "description": "'Test JavaScript mixed inline and block comments.'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'",
          "description": "Assign code = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.js', code, 'JavaScript')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "comments = result['comments']",
          "description": "Assign comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "inline_comments = [c for c in comments if c['type'] == 'inline']",
          "description": "Assign inline_comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "block_comments = [c for c in comments if c['type'] == 'block']",
          "description": "Assign block_comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreaterEqual(len(inline_comments), 2)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertGreaterEqual(len(block_comments), 2)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Javascript Mixed Comments",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:675"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "fffb839997c1",
      "title": "Cpp Comment Extraction",
      "overview": "Workflow: Test C++ comment extraction (uses same logic as JavaScript).",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2e6f1fe6",
          "test_name": "test_cpp_comment_extraction",
          "category": "workflow",
          "code": "'Test C++ comment extraction (uses same logic as JavaScript).'\ncode = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'\nresult = self.analyzer.analyze_file('test.h', code, 'C++')\nself.assertIn('comments', result)\ncomments = result['comments']\nself.assertGreaterEqual(len(comments), 3)\ninline_comments = [c for c in comments if c['type'] == 'inline']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(inline_comments), 2)\nself.assertGreaterEqual(len(block_comments), 1)",
          "language": "Python",
          "description": "Workflow: Test C++ comment extraction (uses same logic as JavaScript).",
          "expected_behavior": "self.assertGreaterEqual(len(block_comments), 1)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
          "line_start": 697,
          "line_end": 723,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "sys",
            "unittest",
            "skill_seekers.cli.code_analyzer"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test C++ comment extraction (uses same logic as JavaScript).'",
          "description": "'Test C++ comment extraction (uses same logic as JavaScript).'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'",
          "description": "Assign code = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "result = self.analyzer.analyze_file('test.h', code, 'C++')",
          "description": "Assign result = self.analyzer.analyze_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertIn('comments', result)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "comments = result['comments']",
          "description": "Assign comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertGreaterEqual(len(comments), 3)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "inline_comments = [c for c in comments if c['type'] == 'inline']",
          "description": "Assign inline_comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "block_comments = [c for c in comments if c['type'] == 'block']",
          "description": "Assign block_comments = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreaterEqual(len(inline_comments), 2)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertGreaterEqual(len(block_comments), 1)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Cpp Comment Extraction",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_code_analyzer.py:697"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "25c59001e10d",
      "title": "Extract Instantiation",
      "overview": "Workflow: Test extraction of object instantiation patterns",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "a7e11ae3",
          "test_name": "test_extract_instantiation",
          "category": "workflow",
          "code": "'Test extraction of object instantiation patterns'\ncode = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'\nexamples = self.analyzer.extract('test_db.py', code)\ninstantiations = [ex for ex in examples if ex.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\ninst = instantiations[0]\nself.assertIn('Database', inst.code)\nself.assertIn('host', inst.code)\nself.assertGreaterEqual(inst.confidence, 0.7)",
          "language": "Python",
          "description": "Workflow: Test extraction of object instantiation patterns",
          "expected_behavior": "self.assertGreaterEqual(inst.confidence, 0.7)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 40,
          "line_end": 60,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test extraction of object instantiation patterns'",
          "description": "'Test extraction of object instantiation patterns'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'",
          "description": "Assign code = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "examples = self.analyzer.extract('test_db.py', code)",
          "description": "Assign examples = self.analyzer.extract(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "instantiations = [ex for ex in examples if ex.category == 'instantiation']",
          "description": "Assign instantiations = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertGreater(len(instantiations), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "inst = instantiations[0]",
          "description": "Assign inst = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('Database', inst.code)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('host', inst.code)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreaterEqual(inst.confidence, 0.7)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Instantiation",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:40"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "613b8ce15119",
      "title": "Extract Method Call With Assertion",
      "overview": "Workflow: Test extraction of method calls followed by assertions",
      "complexity_level": "advanced",
      "prerequisites": [],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "04c960f6",
          "test_name": "test_extract_method_call_with_assertion",
          "category": "workflow",
          "code": "'Test extraction of method calls followed by assertions'\ncode = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'\nexamples = self.analyzer.extract('test_api.py', code)\nself.assertGreater(len(examples), 0)\nmethod_calls = [ex for ex in examples if ex.category == 'method_call']\nif method_calls:\n    call = method_calls[0]\n    self.assertIn('get', call.code)\n    self.assertGreaterEqual(call.confidence, 0.7)",
          "language": "Python",
          "description": "Workflow: Test extraction of method calls followed by assertions",
          "expected_behavior": "self.assertGreater(len(examples), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 62,
          "line_end": 83,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test extraction of method calls followed by assertions'",
          "description": "'Test extraction of method calls followed by assertions'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'",
          "description": "Assign code = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "examples = self.analyzer.extract('test_api.py', code)",
          "description": "Assign examples = self.analyzer.extract(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertGreater(len(examples), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "method_calls = [ex for ex in examples if ex.category == 'method_call']",
          "description": "Assign method_calls = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "call = method_calls[0]",
          "description": "Assign call = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('get', call.code)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertGreaterEqual(call.confidence, 0.7)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Method Call With Assertion",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:62"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "060ad49799fb",
      "title": "Extract Config Dict",
      "overview": "Workflow: Test extraction of configuration dictionaries",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2107235c",
          "test_name": "test_extract_config_dict",
          "category": "workflow",
          "code": "'Test extraction of configuration dictionaries'\ncode = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'\nexamples = self.analyzer.extract('test_config.py', code)\nconfigs = [ex for ex in examples if ex.category == 'config']\nself.assertGreater(len(configs), 0)\nconfig = configs[0]\nself.assertIn('debug', config.code)\nself.assertIn('database_url', config.code)\nself.assertGreaterEqual(config.confidence, 0.7)",
          "language": "Python",
          "description": "Workflow: Test extraction of configuration dictionaries",
          "expected_behavior": "self.assertGreaterEqual(config.confidence, 0.7)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 85,
          "line_end": 108,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "self.analyzer = PythonTestAnalyzer()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test extraction of configuration dictionaries'",
          "description": "'Test extraction of configuration dictionaries'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'",
          "description": "Assign code = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "examples = self.analyzer.extract('test_config.py', code)",
          "description": "Assign examples = self.analyzer.extract(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "configs = [ex for ex in examples if ex.category == 'config']",
          "description": "Assign configs = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertGreater(len(configs), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "config = configs[0]",
          "description": "Assign config = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn('debug', config.code)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIn('database_url', config.code)",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreaterEqual(config.confidence, 0.7)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Config Dict",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:85"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "646a64f2ec7e",
      "title": "Confidence Scoring",
      "overview": "Workflow: Test confidence scores are calculated correctly",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "2bc519d6",
          "test_name": "test_confidence_scoring",
          "category": "workflow",
          "code": "'Test confidence scores are calculated correctly'\nsimple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'\nsimple_examples = self.analyzer.extract('test_simple.py', simple_code)\ncomplex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'\ncomplex_examples = self.analyzer.extract('test_complex.py', complex_code)\nif simple_examples and complex_examples:\n    simple_complexity = max((ex.complexity_score for ex in simple_examples))\n    complex_complexity = max((ex.complexity_score for ex in complex_examples))\n    self.assertGreater(complex_complexity, simple_complexity)",
          "language": "Python",
          "description": "Workflow: Test confidence scores are calculated correctly",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 209,
          "line_end": 238,
          "complexity_score": 0.6,
          "confidence": 0.9,
          "setup_code": "self.analyzer = PythonTestAnalyzer()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test confidence scores are calculated correctly'",
          "description": "'Test confidence scores are calculated correctly'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "simple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'",
          "description": "Assign simple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "simple_examples = self.analyzer.extract('test_simple.py', simple_code)",
          "description": "Assign simple_examples = self.analyzer.extract(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "complex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'",
          "description": "Assign complex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "complex_examples = self.analyzer.extract('test_complex.py', complex_code)",
          "description": "Assign complex_examples = self.analyzer.extract(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "simple_complexity = max((ex.complexity_score for ex in simple_examples))",
          "description": "Assign simple_complexity = max(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "complex_complexity = max((ex.complexity_score for ex in complex_examples))",
          "description": "Assign complex_complexity = max(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertGreater(complex_complexity, simple_complexity)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Confidence Scoring",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:209"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "10a9afe7c2e6",
      "title": "Extract Gdscript Gut Tests",
      "overview": "Workflow: Test GDScript GUT/gdUnit4 test extraction",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "3017fb5b",
          "test_name": "test_extract_gdscript_gut_tests",
          "category": "workflow",
          "code": "'Test GDScript GUT/gdUnit4 test extraction'\ncode = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'\nexamples = self.analyzer.extract('test_game.gd', code, 'GDScript')\nself.assertGreater(len(examples), 0)\nself.assertEqual(examples[0].language, 'GDScript')\ninstantiations = [e for e in examples if e.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\nhas_preload = any(('preload' in e.code or 'load' in e.code for e in instantiations))\nself.assertTrue(has_preload or len(instantiations) > 0)",
          "language": "Python",
          "description": "Workflow: Test GDScript GUT/gdUnit4 test extraction",
          "expected_behavior": "self.assertTrue(has_preload or len(instantiations) > 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 386,
          "line_end": 443,
          "complexity_score": 0.9,
          "confidence": 0.9,
          "setup_code": "self.analyzer = GenericTestAnalyzer()",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test GDScript GUT/gdUnit4 test extraction'",
          "description": "'Test GDScript GUT/gdUnit4 test extraction'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "code = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'",
          "description": "Assign code = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "examples = self.analyzer.extract('test_game.gd', code, 'GDScript')",
          "description": "Assign examples = self.analyzer.extract(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "self.assertGreater(len(examples), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "self.assertEqual(examples[0].language, 'GDScript')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "instantiations = [e for e in examples if e.category == 'instantiation']",
          "description": "Assign instantiations = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertGreater(len(instantiations), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "has_preload = any(('preload' in e.code or 'load' in e.code for e in instantiations))",
          "description": "Assign has_preload = any(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertTrue(has_preload or len(instantiations) > 0)",
          "description": "Call self.assertTrue()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Extract Gdscript Gut Tests",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:386"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "7625a7957c13",
      "title": "Language Filtering",
      "overview": "Workflow: Test filtering by programming language",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "8286b6de",
          "test_name": "test_language_filtering",
          "category": "workflow",
          "code": "'Test filtering by programming language'\npy_file = self.temp_dir / 'test_py.py'\npy_file.write_text('\\ndef test_python():\\n    obj = MyClass(param=\"value\")\\n    assert obj is not None\\n')\njs_file = self.temp_dir / 'test_js.js'\njs_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')\npython_extractor = TestExampleExtractor(languages=['python'])\nreport = python_extractor.extract_from_directory(self.temp_dir)\nfor example in report.examples:\n    self.assertEqual(example.language, 'Python')",
          "language": "Python",
          "description": "Workflow: Test filtering by programming language",
          "expected_behavior": "js_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 622,
          "line_end": 647,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test filtering by programming language'",
          "description": "'Test filtering by programming language'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "py_file = self.temp_dir / 'test_py.py'",
          "description": "Assign py_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "py_file.write_text('\\ndef test_python():\\n    obj = MyClass(param=\"value\")\\n    assert obj is not None\\n')",
          "description": "Call py_file.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "js_file = self.temp_dir / 'test_js.js'",
          "description": "Assign js_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "js_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')",
          "description": "Call js_file.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "python_extractor = TestExampleExtractor(languages=['python'])",
          "description": "Assign python_extractor = TestExampleExtractor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "report = python_extractor.extract_from_directory(self.temp_dir)",
          "description": "Assign report = python_extractor.extract_from_directory(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertEqual(example.language, 'Python')",
          "description": "Call self.assertEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Language Filtering",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:622"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "44881a0fe949",
      "title": "Max Examples Limit",
      "overview": "Workflow: Test max examples per file limit",
      "complexity_level": "intermediate",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9784e155",
          "test_name": "test_max_examples_limit",
          "category": "workflow",
          "code": "'Test max examples per file limit'\ntest_file = self.temp_dir / 'test_many.py'\ntest_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'\nfor i in range(20):\n    test_code += f'\\n    def test_example_{i}(self):\\n        \"\"\"Test {i}\"\"\"\\n        obj = MyClass(id={i}, name=\"test_{i}\")\\n        self.assertIsNotNone(obj)\\n'\ntest_file.write_text(test_code)\nlimited_extractor = TestExampleExtractor(max_per_file=5)\nexamples = limited_extractor.extract_from_file(test_file)\nself.assertLessEqual(len(examples), 5)",
          "language": "Python",
          "description": "Workflow: Test max examples per file limit",
          "expected_behavior": "self.assertLessEqual(len(examples), 5)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 649,
          "line_end": 668,
          "complexity_score": 0.8,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test max examples per file limit'",
          "description": "'Test max examples per file limit'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "test_file = self.temp_dir / 'test_many.py'",
          "description": "Assign test_file = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "test_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'",
          "description": "Assign test_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "test_file.write_text(test_code)",
          "description": "Call test_file.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "limited_extractor = TestExampleExtractor(max_per_file=5)",
          "description": "Assign limited_extractor = TestExampleExtractor(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "examples = limited_extractor.extract_from_file(test_file)",
          "description": "Assign examples = limited_extractor.extract_from_file(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertLessEqual(len(examples), 5)",
          "description": "Call self.assertLessEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Max Examples Limit",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_test_example_extractor.py:649"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "2494640e0a93",
      "title": "End To End Workflow",
      "overview": "Workflow: Test complete extraction workflow",
      "complexity_level": "advanced",
      "prerequisites": [
        "Setup code must be executed first"
      ],
      "required_imports": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "5e3da05f",
          "test_name": "test_end_to_end_workflow",
          "category": "workflow",
          "code": "'Test complete extraction workflow'\n(self.temp_dir / 'tests').mkdir()\n(self.temp_dir / 'tests' / 'test_unit.py').write_text('\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test API connection\"\"\"\\n        api = APIClient(url=\"https://api.example.com\", timeout=30)\\n        self.assertTrue(api.connect())\\n')\n(self.temp_dir / 'tests' / 'test_integration.py').write_text('\\ndef test_workflow():\\n    \"\"\"Test complete workflow\"\"\"\\n    user = User(name=\"John\", email=\"john@example.com\")\\n    user.save()\\n    user.verify()\\n    assert user.is_active\\n')\nreport = self.extractor.extract_from_directory(self.temp_dir / 'tests')\nself.assertGreater(report.total_examples, 0)\nself.assertIsInstance(report.examples_by_category, dict)\nself.assertIsInstance(report.examples_by_language, dict)\nself.assertGreaterEqual(report.avg_complexity, 0.0)\nself.assertLessEqual(report.avg_complexity, 1.0)\nself.assertGreater(len(report.examples_by_category), 0)\nfor example in report.examples:\n    self.assertIsNotNone(example.example_id)\n    self.assertIsNotNone(example.test_name)\n    self.assertIsNotNone(example.category)\n    self.assertIsNotNone(example.code)\n    self.assertIsNotNone(example.language)\n    self.assertGreaterEqual(example.confidence, 0.0)\n    self.assertLessEqual(example.confidence, 1.0)",
          "language": "Python",
          "description": "Workflow: Test complete extraction workflow",
          "expected_behavior": "self.assertGreater(len(report.examples_by_category), 0)",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
          "line_start": 670,
          "line_end": 717,
          "complexity_score": 1.0,
          "confidence": 0.9,
          "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "os",
            "shutil",
            "sys",
            "tempfile",
            "unittest",
            "pathlib",
            "skill_seekers.cli.test_example_extractor"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'Test complete extraction workflow'",
          "description": "'Test complete extraction workflow'",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "(self.temp_dir / 'tests').mkdir()",
          "description": "Call unknown.mkdir()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "(self.temp_dir / 'tests' / 'test_unit.py').write_text('\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test API connection\"\"\"\\n        api = APIClient(url=\"https://api.example.com\", timeout=30)\\n        self.assertTrue(api.connect())\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "(self.temp_dir / 'tests' / 'test_integration.py').write_text('\\ndef test_workflow():\\n    \"\"\"Test complete workflow\"\"\"\\n    user = User(name=\"John\", email=\"john@example.com\")\\n    user.save()\\n    user.verify()\\n    assert user.is_active\\n')",
          "description": "Call unknown.write_text()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "report = self.extractor.extract_from_directory(self.temp_dir / 'tests')",
          "description": "Assign report = self.extractor.extract_from_directory(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertGreater(report.total_examples, 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIsInstance(report.examples_by_category, dict)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 8,
          "code": "self.assertIsInstance(report.examples_by_language, dict)",
          "description": "Call self.assertIsInstance()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 9,
          "code": "self.assertGreaterEqual(report.avg_complexity, 0.0)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 10,
          "code": "self.assertLessEqual(report.avg_complexity, 1.0)",
          "description": "Call self.assertLessEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 11,
          "code": "self.assertGreater(len(report.examples_by_category), 0)",
          "description": "Call self.assertGreater()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 12,
          "code": "self.assertIsNotNone(example.example_id)",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 13,
          "code": "self.assertIsNotNone(example.test_name)",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 14,
          "code": "self.assertIsNotNone(example.category)",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 15,
          "code": "self.assertIsNotNone(example.code)",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 16,
          "code": "self.assertIsNotNone(example.language)",
          "description": "Call self.assertIsNotNone()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 17,
          "code": "self.assertGreaterEqual(example.confidence, 0.0)",
          "description": "Call self.assertGreaterEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 18,
          "code": "self.assertLessEqual(example.confidence, 1.0)",
          "description": "Call self.assertLessEqual()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "End To End Workflow",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "20 minutes",
      "source_files": [
        "test_test_example_extractor.py:670"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    },
    {
      "guide_id": "011f77eaa181",
      "title": "Issue 277 Error Message Urls",
      "overview": "Workflow: Test the exact URLs that appeared in error messages from the issue report.\nThese were the actual 404-causing URLs that need to be fixed.",
      "complexity_level": "intermediate",
      "prerequisites": [],
      "required_imports": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "required_fixtures": [],
      "workflows": [
        {
          "example_id": "9bb44f09",
          "test_name": "test_issue_277_error_message_urls",
          "category": "workflow",
          "code": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '\nerror_urls_with_anchors = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization/index.html.md', 'https://mikro-orm.io/docs/defining-entities#formulas/index.html.md', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums/index.html.md']\ninput_urls = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization', 'https://mikro-orm.io/docs/propagation', 'https://mikro-orm.io/docs/defining-entities#formulas', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums']\nresult = self.converter._convert_to_md_urls(input_urls)\nfor error_url in error_urls_with_anchors:\n    self.assertNotIn(error_url, result, f'Should not generate the 404-causing URL: {error_url}')\ncorrect_urls = ['https://mikro-orm.io/docs/quick-start/index.html.md', 'https://mikro-orm.io/docs/propagation/index.html.md', 'https://mikro-orm.io/docs/defining-entities/index.html.md']\nfor correct_url in correct_urls:\n    self.assertIn(correct_url, result, f'Should generate the correct URL: {correct_url}')",
          "language": "Python",
          "description": "Workflow: Test the exact URLs that appeared in error messages from the issue report.\nThese were the actual 404-causing URLs that need to be fixed.",
          "expected_behavior": "",
          "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
          "line_start": 213,
          "line_end": 255,
          "complexity_score": 0.7,
          "confidence": 0.9,
          "setup_code": null,
          "tags": [
            "unittest",
            "workflow",
            "integration"
          ],
          "dependencies": [
            "unittest",
            "unittest.mock",
            "skill_seekers.cli.doc_scraper"
          ],
          "ai_analysis": null
        }
      ],
      "steps": [
        {
          "step_number": 1,
          "code": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '",
          "description": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 2,
          "code": "error_urls_with_anchors = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization/index.html.md', 'https://mikro-orm.io/docs/defining-entities#formulas/index.html.md', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums/index.html.md']",
          "description": "Assign error_urls_with_anchors = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 3,
          "code": "input_urls = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization', 'https://mikro-orm.io/docs/propagation', 'https://mikro-orm.io/docs/defining-entities#formulas', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums']",
          "description": "Assign input_urls = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 4,
          "code": "result = self.converter._convert_to_md_urls(input_urls)",
          "description": "Assign result = self.converter._convert_to_md_urls(...)",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 5,
          "code": "correct_urls = ['https://mikro-orm.io/docs/quick-start/index.html.md', 'https://mikro-orm.io/docs/propagation/index.html.md', 'https://mikro-orm.io/docs/defining-entities/index.html.md']",
          "description": "Assign correct_urls = value",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 6,
          "code": "self.assertNotIn(error_url, result, f'Should not generate the 404-causing URL: {error_url}')",
          "description": "Call self.assertNotIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        },
        {
          "step_number": 7,
          "code": "self.assertIn(correct_url, result, f'Should generate the correct URL: {correct_url}')",
          "description": "Call self.assertIn()",
          "expected_result": null,
          "verification": null,
          "setup_required": null,
          "explanation": null,
          "common_pitfall": null,
          "common_variations": []
        }
      ],
      "use_case": "Issue 277 Error Message Urls",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "estimated_time": "15 minutes",
      "source_files": [
        "test_issue_277_real_world.py:213"
      ],
      "common_pitfalls": [],
      "troubleshooting": {},
      "variations": [],
      "related_guides": [],
      "prerequisites_detailed": [],
      "troubleshooting_detailed": [],
      "next_steps_detailed": [],
      "use_cases": []
    }
  ]
}
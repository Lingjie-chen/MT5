{
  "total_examples": 912,
  "examples_by_category": {
    "instantiation": 301,
    "workflow": 361,
    "method_call": 240,
    "config": 10
  },
  "examples_by_language": {
    "Python": 912
  },
  "avg_complexity": 0.48,
  "high_value_count": 912,
  "file_path": null,
  "directory": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers",
  "examples": [
    {
      "example_id": "3118bf83",
      "test_name": "test_get_agent_path_home_expansion",
      "category": "instantiation",
      "code": "path = get_agent_path('claude')",
      "language": "Python",
      "description": "Instantiate get_agent_path: Test that ~ expands to home directory for global agents.",
      "expected_behavior": "assert path.is_absolute()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ce179d1d",
      "test_name": "test_get_agent_path_project_relative",
      "category": "instantiation",
      "code": "path = get_agent_path('cursor')",
      "language": "Python",
      "description": "Instantiate get_agent_path: Test that project-relative paths use current directory.",
      "expected_behavior": "assert path.is_absolute()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 49,
      "line_end": 49,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9afc2724",
      "test_name": "test_get_agent_path_project_relative_with_custom_root",
      "category": "instantiation",
      "code": "custom_root = Path('/tmp/test-project')",
      "language": "Python",
      "description": "Instantiate Path: Test project-relative paths with custom project root.",
      "expected_behavior": "assert path.is_absolute()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 57,
      "line_end": 57,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ea4cfa8d",
      "test_name": "test_get_agent_path_project_relative_with_custom_root",
      "category": "instantiation",
      "code": "path = get_agent_path('cursor', project_root=custom_root)",
      "language": "Python",
      "description": "Instantiate get_agent_path: Test project-relative paths with custom project root.",
      "expected_behavior": "assert path.is_absolute()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 58,
      "line_end": 58,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc772f8f",
      "test_name": "test_agent_path_case_insensitive",
      "category": "instantiation",
      "code": "path_lower = get_agent_path('claude')",
      "language": "Python",
      "description": "Instantiate get_agent_path: Test that agent names are case-insensitive.",
      "expected_behavior": "assert path_lower == path_upper == path_mixed",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 82,
      "line_end": 82,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4012d7c0",
      "test_name": "test_agent_path_case_insensitive",
      "category": "instantiation",
      "code": "path_upper = get_agent_path('CLAUDE')",
      "language": "Python",
      "description": "Instantiate get_agent_path: Test that agent names are case-insensitive.",
      "expected_behavior": "assert path_lower == path_upper == path_mixed",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 83,
      "line_end": 83,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "196955a5",
      "test_name": "test_agent_path_case_insensitive",
      "category": "instantiation",
      "code": "path_mixed = get_agent_path('Claude')",
      "language": "Python",
      "description": "Instantiate get_agent_path: Test that agent names are case-insensitive.",
      "expected_behavior": "assert path_lower == path_upper == path_mixed",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 84,
      "line_end": 84,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "965e9f94",
      "test_name": "test_validate_valid_agent",
      "category": "instantiation",
      "code": "is_valid, error = validate_agent_name('claude')",
      "language": "Python",
      "description": "Instantiate validate_agent_name: Test that valid agent names pass validation.",
      "expected_behavior": "assert is_valid is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 93,
      "line_end": 93,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4af12882",
      "test_name": "test_validate_invalid_agent_suggests_similar",
      "category": "instantiation",
      "code": "is_valid, error = validate_agent_name('courser')",
      "language": "Python",
      "description": "Instantiate validate_agent_name: Test that similar agent names are suggested for typos.",
      "expected_behavior": "assert is_valid is False",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 99,
      "line_end": 99,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6eef9c4e",
      "test_name": "test_validate_special_all",
      "category": "instantiation",
      "code": "is_valid, error = validate_agent_name('all')",
      "language": "Python",
      "description": "Instantiate validate_agent_name: Test that 'all' is a valid special agent name.",
      "expected_behavior": "assert is_valid is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_agent.py",
      "line_start": 105,
      "line_end": 105,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "shutil",
        "sys",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.install_agent"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4021f2d9",
      "test_name": "test_checker_detects_missing_skill_md",
      "category": "instantiation",
      "code": "checker = SkillQualityChecker(skill_dir)",
      "language": "Python",
      "description": "Instantiate SkillQualityChecker: Test that checker detects missing SKILL.md",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 42,
      "line_end": 42,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e2b58d51",
      "test_name": "test_checker_detects_missing_references",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill(tmpdir, skill_md, create_references=False)",
      "language": "Python",
      "description": "Instantiate create_test_skill: Test that checker warns about missing references",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 60,
      "line_end": 60,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4021f2d9",
      "test_name": "test_checker_detects_missing_references",
      "category": "instantiation",
      "code": "checker = SkillQualityChecker(skill_dir)",
      "language": "Python",
      "description": "Instantiate SkillQualityChecker: Test that checker warns about missing references",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 62,
      "line_end": 62,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8aec8f98",
      "test_name": "test_checker_detects_invalid_frontmatter",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill(tmpdir, skill_md)",
      "language": "Python",
      "description": "Instantiate create_test_skill: Test that checker detects invalid YAML frontmatter",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 76,
      "line_end": 76,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4021f2d9",
      "test_name": "test_checker_detects_invalid_frontmatter",
      "category": "instantiation",
      "code": "checker = SkillQualityChecker(skill_dir)",
      "language": "Python",
      "description": "Instantiate SkillQualityChecker: Test that checker detects invalid YAML frontmatter",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 78,
      "line_end": 78,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8aec8f98",
      "test_name": "test_checker_detects_missing_name_field",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill(tmpdir, skill_md)",
      "language": "Python",
      "description": "Instantiate create_test_skill: Test that checker detects missing name field in frontmatter",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 94,
      "line_end": 94,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4021f2d9",
      "test_name": "test_checker_detects_missing_name_field",
      "category": "instantiation",
      "code": "checker = SkillQualityChecker(skill_dir)",
      "language": "Python",
      "description": "Instantiate SkillQualityChecker: Test that checker detects missing name field in frontmatter",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8aec8f98",
      "test_name": "test_checker_detects_code_without_language",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill(tmpdir, skill_md)",
      "language": "Python",
      "description": "Instantiate create_test_skill: Test that checker warns about code blocks without language tags",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 118,
      "line_end": 118,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4021f2d9",
      "test_name": "test_checker_detects_code_without_language",
      "category": "instantiation",
      "code": "checker = SkillQualityChecker(skill_dir)",
      "language": "Python",
      "description": "Instantiate SkillQualityChecker: Test that checker warns about code blocks without language tags",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 120,
      "line_end": 120,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8aec8f98",
      "test_name": "test_checker_approves_good_skill",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill(tmpdir, skill_md)",
      "language": "Python",
      "description": "Instantiate create_test_skill: Test that checker gives high score to well-formed skill",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_checker.py",
      "line_start": 164,
      "line_end": 164,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.quality_checker",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ae8eb210",
      "test_name": "test_chain_dependencies",
      "category": "workflow",
      "code": "'Test chain of dependencies.'\nself.analyzer.analyze_file('main.py', 'import utils', 'Python')\nself.analyzer.analyze_file('utils.py', 'import helpers', 'Python')\nself.analyzer.analyze_file('helpers.py', '', 'Python')\ngraph = self.analyzer.build_graph()\nself.assertEqual(graph.number_of_nodes(), 3)",
      "language": "Python",
      "description": "Workflow: Test chain of dependencies.",
      "expected_behavior": "self.assertEqual(graph.number_of_nodes(), 3)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 208,
      "line_end": 217,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ae8eb210",
      "test_name": "test_chain_dependencies",
      "category": "workflow",
      "code": "'Test chain of dependencies.'\nself.analyzer.analyze_file('main.py', 'import utils', 'Python')\nself.analyzer.analyze_file('utils.py', 'import helpers', 'Python')\nself.analyzer.analyze_file('helpers.py', '', 'Python')\ngraph = self.analyzer.build_graph()\nself.assertEqual(graph.number_of_nodes(), 3)",
      "language": "Python",
      "description": "Workflow: Test chain of dependencies.",
      "expected_behavior": "self.assertEqual(graph.number_of_nodes(), 3)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 208,
      "line_end": 217,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "72452671",
      "test_name": "test_simple_import",
      "category": "method_call",
      "code": "self.assertEqual(len(deps), 2)\nself.assertEqual(deps[0].imported_module, 'os')",
      "language": "Python",
      "description": "Test simple import statement.",
      "expected_behavior": "self.assertEqual(deps[0].imported_module, 'os')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 39,
      "line_end": 40,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a11bf3e7",
      "test_name": "test_simple_import",
      "category": "method_call",
      "code": "self.assertEqual(deps[0].imported_module, 'os')\nself.assertEqual(deps[0].import_type, 'import')",
      "language": "Python",
      "description": "Test simple import statement.",
      "expected_behavior": "self.assertEqual(deps[0].import_type, 'import')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 40,
      "line_end": 41,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b88a00f5",
      "test_name": "test_simple_import",
      "category": "method_call",
      "code": "self.assertEqual(deps[0].import_type, 'import')\nself.assertFalse(deps[0].is_relative)",
      "language": "Python",
      "description": "Test simple import statement.",
      "expected_behavior": "self.assertFalse(deps[0].is_relative)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 41,
      "line_end": 42,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "77ef0762",
      "test_name": "test_from_import",
      "category": "method_call",
      "code": "self.assertEqual(len(deps), 2)\nself.assertEqual(deps[0].imported_module, 'pathlib')",
      "language": "Python",
      "description": "Test from...import statement.",
      "expected_behavior": "self.assertEqual(deps[0].imported_module, 'pathlib')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 49,
      "line_end": 50,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ca1ffbf4",
      "test_name": "test_from_import",
      "category": "method_call",
      "code": "self.assertEqual(deps[0].imported_module, 'pathlib')\nself.assertEqual(deps[0].import_type, 'from')",
      "language": "Python",
      "description": "Test from...import statement.",
      "expected_behavior": "self.assertEqual(deps[0].import_type, 'from')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 50,
      "line_end": 51,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "47ede9d0",
      "test_name": "test_relative_import",
      "category": "method_call",
      "code": "self.assertEqual(len(deps), 2)\nself.assertTrue(deps[0].is_relative)",
      "language": "Python",
      "description": "Test relative import.",
      "expected_behavior": "self.assertTrue(deps[0].is_relative)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 58,
      "line_end": 59,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "59016957",
      "test_name": "test_relative_import",
      "category": "method_call",
      "code": "self.assertTrue(deps[0].is_relative)\nself.assertEqual(deps[0].imported_module, '.')",
      "language": "Python",
      "description": "Test relative import.",
      "expected_behavior": "self.assertEqual(deps[0].imported_module, '.')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 59,
      "line_end": 60,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d0e45ba5",
      "test_name": "test_relative_import",
      "category": "method_call",
      "code": "self.assertEqual(deps[0].imported_module, '.')\nself.assertTrue(deps[1].is_relative)",
      "language": "Python",
      "description": "Test relative import.",
      "expected_behavior": "self.assertTrue(deps[1].is_relative)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_dependency_analyzer.py",
      "line_start": 60,
      "line_end": 61,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not ANALYZER_AVAILABLE:\n    self.skipTest('dependency_analyzer not available')\nself.analyzer = DependencyAnalyzer()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.dependency_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e01a676e",
      "test_name": "test_scrape_parser_creates_subparser",
      "category": "workflow",
      "code": "'Test that ScrapeParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\nscrape_parser = ScrapeParser()\nsubparser = scrape_parser.create_parser(subparsers)\nassert subparser is not None\nassert scrape_parser.name == 'scrape'\nassert scrape_parser.help == 'Scrape documentation website'",
      "language": "Python",
      "description": "Workflow: Test that ScrapeParser creates valid subparser.",
      "expected_behavior": "assert scrape_parser.help == 'Scrape documentation website'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 72,
      "line_end": 82,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "04c400c9",
      "test_name": "test_github_parser_creates_subparser",
      "category": "workflow",
      "code": "'Test that GitHubParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\ngithub_parser = GitHubParser()\nsubparser = github_parser.create_parser(subparsers)\nassert subparser is not None\nassert github_parser.name == 'github'",
      "language": "Python",
      "description": "Workflow: Test that GitHubParser creates valid subparser.",
      "expected_behavior": "assert github_parser.name == 'github'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 84,
      "line_end": 93,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4a3afacf",
      "test_name": "test_package_parser_creates_subparser",
      "category": "workflow",
      "code": "'Test that PackageParser creates valid subparser.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers()\npackage_parser = PackageParser()\nsubparser = package_parser.create_parser(subparsers)\nassert subparser is not None\nassert package_parser.name == 'package'",
      "language": "Python",
      "description": "Workflow: Test that PackageParser creates valid subparser.",
      "expected_behavior": "assert package_parser.name == 'package'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 95,
      "line_end": 104,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1d07962e",
      "test_name": "test_register_parsers_creates_all_subcommands",
      "category": "workflow",
      "code": "'Test that register_parsers creates all 19 subcommands.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nregister_parsers(subparsers)\ntest_commands = ['config --show', 'scrape --config test.json', 'github --repo owner/repo', 'package output/test/', 'upload test.zip', 'analyze --directory .', 'enhance output/test/', 'estimate test.json']\nfor cmd in test_commands:\n    args = main_parser.parse_args(cmd.split())\n    assert args.command is not None",
      "language": "Python",
      "description": "Workflow: Test that register_parsers creates all 19 subcommands.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 106,
      "line_end": 128,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9ab8ad64",
      "test_name": "test_scrape_parser_arguments",
      "category": "workflow",
      "code": "'Test ScrapeParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nscrape_parser = ScrapeParser()\nscrape_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['scrape', '--config', 'test.json'])\nassert args.command == 'scrape'\nassert args.config == 'test.json'\nargs = main_parser.parse_args(['scrape', '--config', 'test.json', '--max-pages', '100'])\nassert args.max_pages == 100\nargs = main_parser.parse_args(['scrape', '--enhance'])\nassert args.enhance is True",
      "language": "Python",
      "description": "Workflow: Test ScrapeParser has correct arguments.",
      "expected_behavior": "assert args.enhance is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 134,
      "line_end": 151,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ee30eed2",
      "test_name": "test_github_parser_arguments",
      "category": "workflow",
      "code": "'Test GitHubParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\ngithub_parser = GitHubParser()\ngithub_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['github', '--repo', 'owner/repo'])\nassert args.command == 'github'\nassert args.repo == 'owner/repo'\nargs = main_parser.parse_args(['github', '--repo', 'owner/repo', '--non-interactive'])\nassert args.non_interactive is True",
      "language": "Python",
      "description": "Workflow: Test GitHubParser has correct arguments.",
      "expected_behavior": "assert args.non_interactive is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 153,
      "line_end": 166,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "485bdd9c",
      "test_name": "test_package_parser_arguments",
      "category": "workflow",
      "code": "'Test PackageParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\npackage_parser = PackageParser()\npackage_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['package', 'output/test/'])\nassert args.command == 'package'\nassert args.skill_directory == 'output/test/'\nargs = main_parser.parse_args(['package', 'output/test/', '--target', 'gemini'])\nassert args.target == 'gemini'\nargs = main_parser.parse_args(['package', 'output/test/', '--no-open'])\nassert args.no_open is True",
      "language": "Python",
      "description": "Workflow: Test PackageParser has correct arguments.",
      "expected_behavior": "assert args.no_open is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 168,
      "line_end": 184,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c475f8f2",
      "test_name": "test_analyze_parser_arguments",
      "category": "workflow",
      "code": "'Test AnalyzeParser has correct arguments.'\nmain_parser = argparse.ArgumentParser()\nsubparsers = main_parser.add_subparsers(dest='command')\nfrom skill_seekers.cli.parsers.analyze_parser import AnalyzeParser\nanalyze_parser = AnalyzeParser()\nanalyze_parser.create_parser(subparsers)\nargs = main_parser.parse_args(['analyze', '--directory', '.'])\nassert args.command == 'analyze'\nassert args.directory == '.'\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--quick'])\nassert args.quick is True\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nassert args.comprehensive is True\nargs = main_parser.parse_args(['analyze', '--directory', '.', '--skip-patterns'])\nassert args.skip_patterns is True",
      "language": "Python",
      "description": "Workflow: Test AnalyzeParser has correct arguments.",
      "expected_behavior": "assert args.skip_patterns is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 186,
      "line_end": 207,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1bc4e4a3",
      "test_name": "test_scrape_parser_creates_subparser",
      "category": "instantiation",
      "code": "subparser = scrape_parser.create_parser(subparsers)",
      "language": "Python",
      "description": "Instantiate create_parser: Test that ScrapeParser creates valid subparser.",
      "expected_behavior": "assert subparser is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 78,
      "line_end": 78,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e4f4c803",
      "test_name": "test_github_parser_creates_subparser",
      "category": "instantiation",
      "code": "subparser = github_parser.create_parser(subparsers)",
      "language": "Python",
      "description": "Instantiate create_parser: Test that GitHubParser creates valid subparser.",
      "expected_behavior": "assert subparser is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_parsers.py",
      "line_start": 90,
      "line_end": 90,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "argparse",
        "pytest",
        "skill_seekers.cli.parsers",
        "skill_seekers.cli.parsers.scrape_parser",
        "skill_seekers.cli.parsers.github_parser",
        "skill_seekers.cli.parsers.package_parser",
        "skill_seekers.cli.parsers.analyze_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "68a4f4b3",
      "test_name": "test_config_file",
      "category": "config",
      "code": "config = {'name': 'test-e2e', 'description': 'Test skill for E2E testing', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article', 'title': 'title', 'code_blocks': 'pre'}, 'url_patterns': {'include': ['/docs/'], 'exclude': ['/search', '/404']}, 'categories': {'getting_started': ['intro', 'start'], 'api': ['api', 'reference']}, 'rate_limit': 0.1, 'max_pages': 5}",
      "language": "Python",
      "description": "Configuration example: Create a minimal test config file",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 67,
      "line_end": 76,
      "complexity_score": 0.85,
      "confidence": 0.75,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "54ac855d",
      "test_name": "test_config_file",
      "category": "config",
      "code": "config = {'name': 'test-cli-e2e', 'description': 'Test skill for CLI E2E testing', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article', 'title': 'title', 'code_blocks': 'pre'}, 'url_patterns': {'include': ['/docs/'], 'exclude': []}, 'categories': {}, 'rate_limit': 0.1, 'max_pages': 3}",
      "language": "Python",
      "description": "Configuration example: Create a minimal test config file",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 317,
      "line_end": 326,
      "complexity_score": 0.65,
      "confidence": 0.75,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d60f96f2",
      "test_name": "test_cli_validation_error_no_config",
      "category": "instantiation",
      "code": "result = subprocess.run([sys.executable, '-m', 'skill_seekers.cli.install_skill'], capture_output=True, text=True)",
      "language": "Python",
      "description": "Instantiate run: E2E test: CLI validation error (no config provided)",
      "expected_behavior": "assert result.returncode != 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 355,
      "line_end": 359,
      "complexity_score": 0.35,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0ccecbd3",
      "test_name": "test_cli_help",
      "category": "instantiation",
      "code": "result = subprocess.run([sys.executable, '-m', 'skill_seekers.cli.install_skill', '--help'], capture_output=True, text=True)",
      "language": "Python",
      "description": "Instantiate run: E2E test: CLI help command",
      "expected_behavior": "assert result.returncode == 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 370,
      "line_end": 374,
      "complexity_score": 0.4,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6c1b0b2b",
      "test_name": "test_cli_via_unified_command",
      "category": "instantiation",
      "code": "result = subprocess.run(['skill-seekers', 'install', '--config', test_config_file, '--dry-run'], capture_output=True, text=True, timeout=30)",
      "language": "Python",
      "description": "Instantiate run: E2E test: Using 'skill-seekers install' unified CLI\n\nNote: Skipped because subprocess execution has asyncio.run() issues.\nThe functionality is already tested in test_cli_full_workflow_mocked\nvia direct function calls.",
      "expected_behavior": "assert result.returncode == 0 or 'DRY RUN' in result.stdout, f'Unified CLI failed:\\nSTDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 438,
      "line_end": 443,
      "complexity_score": 0.5,
      "confidence": 0.8,
      "setup_code": "# Fixtures: test_config_file",
      "tags": [
        "mock",
        "async",
        "pytest"
      ],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "69b5c54b",
      "test_name": "real_test_config",
      "category": "instantiation",
      "code": "test_config_path = Path('configs/test-manual.json')",
      "language": "Python",
      "description": "Instantiate Path: Create a real minimal config that can be scraped",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 459,
      "line_end": 459,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fe7d17cd",
      "test_name": "real_test_config",
      "category": "config",
      "code": "config = {'name': 'test-real-e2e', 'description': 'Real E2E test', 'base_url': 'https://httpbin.org/html', 'selectors': {'main_content': 'body', 'title': 'title', 'code_blocks': 'code'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 1}",
      "language": "Python",
      "description": "Configuration example: Create a real minimal config that can be scraped",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_skill_e2e.py",
      "line_start": 464,
      "line_end": 473,
      "complexity_score": 0.65,
      "confidence": 0.75,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "json",
        "subprocess",
        "sys",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.mcp.tools.packaging_tools",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a8c7065c",
      "test_name": "test_init_loads_data",
      "category": "workflow",
      "code": "'Test that converter loads data file on initialization'\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter.__init__') as mock_init:\n    mock_init.return_value = None\n    converter = self.GitHubToSkillConverter(config)\n    converter.data_file = str(self.data_file)\n    converter.data = converter._load_data()\n    self.assertIn('repo_info', converter.data)\n    self.assertEqual(converter.data['repo_info']['name'], 'react')",
      "language": "Python",
      "description": "Workflow: Test that converter loads data file on initialization",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 596,
      "line_end": 608,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "if not PYGITHUB_AVAILABLE:\n    self.skipTest('PyGithub not installed')\nfrom skill_seekers.cli.github_scraper import GitHubToSkillConverter\nself.GitHubToSkillConverter = GitHubToSkillConverter\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir)\nself.data_file = self.output_dir / 'test_github_data.json'\nself.mock_data = {'repo_info': {'name': 'react', 'full_name': 'facebook/react', 'description': 'A JavaScript library', 'stars': 200000, 'language': 'JavaScript'}, 'readme': '# React\\n\\nA JavaScript library for building user interfaces.', 'languages': {'JavaScript': {'bytes': 8000, 'percentage': 80.0}, 'TypeScript': {'bytes': 2000, 'percentage': 20.0}}, 'issues': [{'number': 123, 'title': 'Bug in useState', 'state': 'open', 'labels': ['bug'], 'milestone': 'v18.0', 'created_at': '2023-01-01T10:00:00', 'updated_at': '2023-01-02T10:00:00', 'closed_at': None, 'url': 'https://github.com/facebook/react/issues/123', 'body': 'Issue description'}], 'changelog': '# Changelog\\n\\n## v18.0.0\\n- New features', 'releases': [{'tag_name': 'v18.0.0', 'name': 'React 18.0.0', 'body': 'Release notes', 'published_at': '2023-03-01T10:00:00', 'prerelease': False, 'draft': False, 'url': 'https://github.com/facebook/react/releases/tag/v18.0.0'}]}\nwith open(self.data_file, 'w') as f:\n    json.dump(self.mock_data, f)",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bf61f1d8",
      "test_name": "test_build_skill_creates_directory_structure",
      "category": "workflow",
      "code": "'Test that build_skill creates proper directory structure'\ndata_file_path = self.output_dir / 'test_github_data.json'\nwith open(data_file_path, 'w') as f:\n    json.dump(self.mock_data, f)\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter._load_data') as mock_load:\n    mock_load.return_value = self.mock_data\n    converter = self.GitHubToSkillConverter(config)\n    converter.skill_dir = str(self.output_dir / 'test_skill')\n    converter.data = self.mock_data\n    converter.build_skill()\n    skill_dir = Path(converter.skill_dir)\n    self.assertTrue(skill_dir.exists())\n    self.assertTrue((skill_dir / 'SKILL.md').exists())\n    self.assertTrue((skill_dir / 'references').exists())",
      "language": "Python",
      "description": "Workflow: Test that build_skill creates proper directory structure",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 610,
      "line_end": 633,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "if not PYGITHUB_AVAILABLE:\n    self.skipTest('PyGithub not installed')\nfrom skill_seekers.cli.github_scraper import GitHubToSkillConverter\nself.GitHubToSkillConverter = GitHubToSkillConverter\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir)\nself.data_file = self.output_dir / 'test_github_data.json'\nself.mock_data = {'repo_info': {'name': 'react', 'full_name': 'facebook/react', 'description': 'A JavaScript library', 'stars': 200000, 'language': 'JavaScript'}, 'readme': '# React\\n\\nA JavaScript library for building user interfaces.', 'languages': {'JavaScript': {'bytes': 8000, 'percentage': 80.0}, 'TypeScript': {'bytes': 2000, 'percentage': 20.0}}, 'issues': [{'number': 123, 'title': 'Bug in useState', 'state': 'open', 'labels': ['bug'], 'milestone': 'v18.0', 'created_at': '2023-01-01T10:00:00', 'updated_at': '2023-01-02T10:00:00', 'closed_at': None, 'url': 'https://github.com/facebook/react/issues/123', 'body': 'Issue description'}], 'changelog': '# Changelog\\n\\n## v18.0.0\\n- New features', 'releases': [{'tag_name': 'v18.0.0', 'name': 'React 18.0.0', 'body': 'Release notes', 'published_at': '2023-03-01T10:00:00', 'prerelease': False, 'draft': False, 'url': 'https://github.com/facebook/react/releases/tag/v18.0.0'}]}\nwith open(self.data_file, 'w') as f:\n    json.dump(self.mock_data, f)",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5528a4b0",
      "test_name": "test_invalid_repo_name",
      "category": "workflow",
      "code": "'Test handling of invalid repository name'\nconfig = {'repo': 'invalid_repo_format', 'name': 'test', 'github_token': None}\nwith patch('skill_seekers.cli.github_scraper.Github'):\n    scraper = self.GitHubScraper(config)\n    scraper.repo = None\n    scraper.github.get_repo = Mock(side_effect=GithubException(404, 'Not found'))\n    with self.assertRaises(ValueError) as context:\n        scraper._fetch_repository()\n    self.assertIn('Repository not found', str(context.exception))",
      "language": "Python",
      "description": "Workflow: Test handling of invalid repository name",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 980,
      "line_end": 993,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "if not PYGITHUB_AVAILABLE:\n    self.skipTest('PyGithub not installed')\nfrom skill_seekers.cli.github_scraper import GitHubScraper\nself.GitHubScraper = GitHubScraper",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a8c7065c",
      "test_name": "test_init_loads_data",
      "category": "workflow",
      "code": "'Test that converter loads data file on initialization'\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter.__init__') as mock_init:\n    mock_init.return_value = None\n    converter = self.GitHubToSkillConverter(config)\n    converter.data_file = str(self.data_file)\n    converter.data = converter._load_data()\n    self.assertIn('repo_info', converter.data)\n    self.assertEqual(converter.data['repo_info']['name'], 'react')",
      "language": "Python",
      "description": "Workflow: Test that converter loads data file on initialization",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 596,
      "line_end": 608,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bf61f1d8",
      "test_name": "test_build_skill_creates_directory_structure",
      "category": "workflow",
      "code": "'Test that build_skill creates proper directory structure'\ndata_file_path = self.output_dir / 'test_github_data.json'\nwith open(data_file_path, 'w') as f:\n    json.dump(self.mock_data, f)\nconfig = {'repo': 'facebook/react', 'name': 'test', 'description': 'Test skill'}\nwith patch('skill_seekers.cli.github_scraper.GitHubToSkillConverter._load_data') as mock_load:\n    mock_load.return_value = self.mock_data\n    converter = self.GitHubToSkillConverter(config)\n    converter.skill_dir = str(self.output_dir / 'test_skill')\n    converter.data = self.mock_data\n    converter.build_skill()\n    skill_dir = Path(converter.skill_dir)\n    self.assertTrue(skill_dir.exists())\n    self.assertTrue((skill_dir / 'SKILL.md').exists())\n    self.assertTrue((skill_dir / 'references').exists())",
      "language": "Python",
      "description": "Workflow: Test that build_skill creates proper directory structure",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 610,
      "line_end": 633,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5528a4b0",
      "test_name": "test_invalid_repo_name",
      "category": "workflow",
      "code": "'Test handling of invalid repository name'\nconfig = {'repo': 'invalid_repo_format', 'name': 'test', 'github_token': None}\nwith patch('skill_seekers.cli.github_scraper.Github'):\n    scraper = self.GitHubScraper(config)\n    scraper.repo = None\n    scraper.github.get_repo = Mock(side_effect=GithubException(404, 'Not found'))\n    with self.assertRaises(ValueError) as context:\n        scraper._fetch_repository()\n    self.assertIn('Repository not found', str(context.exception))",
      "language": "Python",
      "description": "Workflow: Test handling of invalid repository name",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 980,
      "line_end": 993,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f733d604",
      "test_name": "test_init_with_repo_name",
      "category": "method_call",
      "code": "self.assertEqual(scraper.repo_name, 'facebook/react')\nself.assertEqual(scraper.name, 'react')",
      "language": "Python",
      "description": "Test initialization with repository name",
      "expected_behavior": "self.assertEqual(scraper.name, 'react')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 59,
      "line_end": 60,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "if not PYGITHUB_AVAILABLE:\n    self.skipTest('PyGithub not installed')\nfrom skill_seekers.cli.github_scraper import GitHubScraper\nself.GitHubScraper = GitHubScraper\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "03b7a51b",
      "test_name": "test_init_with_repo_name",
      "category": "method_call",
      "code": "self.assertEqual(scraper.name, 'react')\nself.assertIsNotNone(scraper.github)",
      "language": "Python",
      "description": "Test initialization with repository name",
      "expected_behavior": "self.assertIsNotNone(scraper.github)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 60,
      "line_end": 61,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not PYGITHUB_AVAILABLE:\n    self.skipTest('PyGithub not installed')\nfrom skill_seekers.cli.github_scraper import GitHubScraper\nself.GitHubScraper = GitHubScraper\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f733d604",
      "test_name": "test_init_with_repo_name",
      "category": "method_call",
      "code": "self.assertEqual(scraper.repo_name, 'facebook/react')\nself.assertEqual(scraper.name, 'react')",
      "language": "Python",
      "description": "Test initialization with repository name",
      "expected_behavior": "self.assertEqual(scraper.name, 'react')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 59,
      "line_end": 60,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "03b7a51b",
      "test_name": "test_init_with_repo_name",
      "category": "method_call",
      "code": "self.assertEqual(scraper.name, 'react')\nself.assertIsNotNone(scraper.github)",
      "language": "Python",
      "description": "Test initialization with repository name",
      "expected_behavior": "self.assertIsNotNone(scraper.github)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_scraper.py",
      "line_start": 60,
      "line_end": 61,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "datetime",
        "pathlib",
        "unittest.mock",
        "github",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5bbe62dc",
      "test_name": "test_github_workflows_reference_correct_paths",
      "category": "workflow",
      "code": "'Test that GitHub workflows reference correct MCP paths'\nworkflow_file = Path('.github/workflows/tests.yml')\nif workflow_file.exists():\n    with open(workflow_file) as f:\n        content = f.read()\n    assert 'mcp/requirements.txt' not in content or 'skill_seeker_mcp/requirements.txt' in content, 'GitHub workflow should use correct MCP paths'",
      "language": "Python",
      "description": "Workflow: Test that GitHub workflows reference correct MCP paths",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 200,
      "line_end": 210,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b83b2567",
      "test_name": "test_mcp_directory_structure",
      "category": "instantiation",
      "code": "mcp_dir = Path('src/skill_seekers/mcp')",
      "language": "Python",
      "description": "Instantiate Path: Test that MCP directory structure is correct (new src/ layout)",
      "expected_behavior": "assert mcp_dir.exists(), 'src/skill_seekers/mcp/ directory should exist'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 242,
      "line_end": 242,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f1be6bc0",
      "test_name": "test_mcp_directory_structure",
      "category": "instantiation",
      "code": "old_mcp = Path('mcp')",
      "language": "Python",
      "description": "Instantiate Path: Test that MCP directory structure is correct (new src/ layout)",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 249,
      "line_end": 249,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2c0e697c",
      "test_name": "test_mcp_directory_structure",
      "category": "instantiation",
      "code": "old_skill_seeker_mcp = Path('skill_seeker_mcp')",
      "language": "Python",
      "description": "Instantiate Path: Test that MCP directory structure is correct (new src/ layout)",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 250,
      "line_end": 250,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f792a75b",
      "test_name": "test_bash_syntax_valid",
      "category": "instantiation",
      "code": "result = subprocess.run(['bash', '-n', str(script_path)], capture_output=True, text=True)",
      "language": "Python",
      "description": "Instantiate run: Test that setup_mcp.sh has valid bash syntax",
      "expected_behavior": "assert result.returncode == 0, f'Bash syntax error: {result.stderr}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 36,
      "line_end": 36,
      "complexity_score": 0.35,
      "confidence": 0.8,
      "setup_code": "# Fixtures: script_path",
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "54b91d04",
      "test_name": "test_references_correct_mcp_directory",
      "category": "instantiation",
      "code": "old_mcp_refs = re.findall('(?:^|[^a-z_])(?<!/)mcp/(?!\\\\.json)', script_content, re.MULTILINE)",
      "language": "Python",
      "description": "Instantiate findall: Test that script references src/skill_seekers/mcp/ (v2.4.0 MCP 2025 upgrade)",
      "expected_behavior": "assert len(old_mcp_refs) == 0, f\"Found {len(old_mcp_refs)} references to old 'mcp/' directory: {old_mcp_refs}\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 42,
      "line_end": 44,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: script_content",
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "46cdb4c2",
      "test_name": "test_references_correct_mcp_directory",
      "category": "instantiation",
      "code": "old_skill_seeker_refs = re.findall('skill_seeker_mcp/', script_content)",
      "language": "Python",
      "description": "Instantiate findall: Test that script references src/skill_seekers/mcp/ (v2.4.0 MCP 2025 upgrade)",
      "expected_behavior": "assert len(old_mcp_refs) == 0, f\"Found {len(old_mcp_refs)} references to old 'mcp/' directory: {old_mcp_refs}\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 45,
      "line_end": 45,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: script_content",
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2cfc5ce3",
      "test_name": "test_references_correct_mcp_directory",
      "category": "instantiation",
      "code": "new_refs = re.findall('skill_seekers\\\\.mcp', script_content)",
      "language": "Python",
      "description": "Instantiate findall: Test that script references src/skill_seekers/mcp/ (v2.4.0 MCP 2025 upgrade)",
      "expected_behavior": "assert len(new_refs) >= 2, f\"Expected at least 2 references to 'skill_seekers.mcp' module, found {len(new_refs)}\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 57,
      "line_end": 57,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: script_content",
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "66fcb1be",
      "test_name": "test_requirements_txt_path",
      "category": "instantiation",
      "code": "old_skill_seeker_refs = re.findall('skill_seeker_mcp/requirements\\\\.txt', script_content)",
      "language": "Python",
      "description": "Instantiate findall: Test that script uses pip install -e . (v2.0.0 modern packaging)",
      "expected_behavior": "assert len(old_skill_seeker_refs) == 0, f\"Should NOT reference 'skill_seeker_mcp/requirements.txt' (found {len(old_skill_seeker_refs)})\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 77,
      "line_end": 77,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: script_content",
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6c5c09fd",
      "test_name": "test_requirements_txt_path",
      "category": "instantiation",
      "code": "old_mcp_refs = re.findall('(?<!skill_seeker_)mcp/requirements\\\\.txt', script_content)",
      "language": "Python",
      "description": "Instantiate findall: Test that script uses pip install -e . (v2.0.0 modern packaging)",
      "expected_behavior": "assert len(old_skill_seeker_refs) == 0, f\"Should NOT reference 'skill_seeker_mcp/requirements.txt' (found {len(old_skill_seeker_refs)})\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_setup_scripts.py",
      "line_start": 78,
      "line_end": 78,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: script_content",
      "tags": [],
      "dependencies": [
        "re",
        "subprocess",
        "pathlib",
        "pytest",
        "re",
        "re",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3627d120",
      "test_name": "test_flask_framework_detection_from_imports",
      "category": "workflow",
      "code": "'Test that Flask is detected from import statements (Issue #239).'\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / '__init__.py').write_text('from flask import Flask\\napp = Flask(__name__)')\n(app_dir / 'routes.py').write_text(\"from flask import render_template\\nfrom app import app\\n\\n@app.route('/')\\ndef index():\\n    return render_template('index.html')\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none', '--skip-patterns', '--skip-test-examples', '--skip-how-to-guides', '--skip-config-patterns', '--skip-docs']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nself.assertTrue(arch_file.exists(), 'Architecture file should be created')\nwith open(arch_file) as f:\n    arch_data = json.load(f)\nself.assertIn('frameworks_detected', arch_data)\nself.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
      "language": "Python",
      "description": "Workflow: Test that Flask is detected from import statements (Issue #239).",
      "expected_behavior": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 31,
      "line_end": 85,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "94b9c455",
      "test_name": "test_files_with_imports_are_included",
      "category": "workflow",
      "code": "'Test that files with only imports are included in analysis (Issue #239).'\n(self.test_project / 'imports_only.py').write_text('import django\\nfrom flask import Flask\\nimport requests')\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\ncode_analysis = self.output_dir / 'code_analysis.json'\nself.assertTrue(code_analysis.exists(), 'Code analysis file should exist')\nwith open(code_analysis) as f:\n    analysis_data = json.load(f)\nself.assertGreater(len(analysis_data['files']), 0, 'Files with imports should be included')\nimport_file = next((f for f in analysis_data['files'] if 'imports_only.py' in f['file']), None)\nself.assertIsNotNone(import_file, 'Import-only file should be in analysis')\nself.assertIn('imports', import_file, 'Imports should be extracted')\nself.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')\nself.assertIn('django', import_file['imports'], 'Django import should be captured')\nself.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
      "language": "Python",
      "description": "Workflow: Test that files with only imports are included in analysis (Issue #239).",
      "expected_behavior": "self.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 87,
      "line_end": 135,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e8ebe64b",
      "test_name": "test_no_false_positive_frameworks",
      "category": "workflow",
      "code": "\"Test that framework detection doesn't produce false positives (Issue #239).\"\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / 'utils.py').write_text(\"def my_function():\\n    return 'hello'\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nif arch_file.exists():\n    with open(arch_file) as f:\n        arch_data = json.load(f)\n    frameworks = arch_data.get('frameworks_detected', [])\n    self.assertNotIn('Flask', frameworks, 'Should not detect Flask without imports')\n    for fw in ['ASP.NET', 'Rails', 'Laravel']:\n        self.assertNotIn(fw, frameworks, f'Should not detect {fw} without real evidence')",
      "language": "Python",
      "description": "Workflow: Test that framework detection doesn't produce false positives (Issue #239).",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 137,
      "line_end": 179,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3627d120",
      "test_name": "test_flask_framework_detection_from_imports",
      "category": "workflow",
      "code": "'Test that Flask is detected from import statements (Issue #239).'\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / '__init__.py').write_text('from flask import Flask\\napp = Flask(__name__)')\n(app_dir / 'routes.py').write_text(\"from flask import render_template\\nfrom app import app\\n\\n@app.route('/')\\ndef index():\\n    return render_template('index.html')\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none', '--skip-patterns', '--skip-test-examples', '--skip-how-to-guides', '--skip-config-patterns', '--skip-docs']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nself.assertTrue(arch_file.exists(), 'Architecture file should be created')\nwith open(arch_file) as f:\n    arch_data = json.load(f)\nself.assertIn('frameworks_detected', arch_data)\nself.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
      "language": "Python",
      "description": "Workflow: Test that Flask is detected from import statements (Issue #239).",
      "expected_behavior": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 31,
      "line_end": 85,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "94b9c455",
      "test_name": "test_files_with_imports_are_included",
      "category": "workflow",
      "code": "'Test that files with only imports are included in analysis (Issue #239).'\n(self.test_project / 'imports_only.py').write_text('import django\\nfrom flask import Flask\\nimport requests')\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\ncode_analysis = self.output_dir / 'code_analysis.json'\nself.assertTrue(code_analysis.exists(), 'Code analysis file should exist')\nwith open(code_analysis) as f:\n    analysis_data = json.load(f)\nself.assertGreater(len(analysis_data['files']), 0, 'Files with imports should be included')\nimport_file = next((f for f in analysis_data['files'] if 'imports_only.py' in f['file']), None)\nself.assertIsNotNone(import_file, 'Import-only file should be in analysis')\nself.assertIn('imports', import_file, 'Imports should be extracted')\nself.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')\nself.assertIn('django', import_file['imports'], 'Django import should be captured')\nself.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
      "language": "Python",
      "description": "Workflow: Test that files with only imports are included in analysis (Issue #239).",
      "expected_behavior": "self.assertIn('flask', import_file['imports'], 'Flask import should be captured')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 87,
      "line_end": 135,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e8ebe64b",
      "test_name": "test_no_false_positive_frameworks",
      "category": "workflow",
      "code": "\"Test that framework detection doesn't produce false positives (Issue #239).\"\napp_dir = self.test_project / 'app'\napp_dir.mkdir()\n(app_dir / 'utils.py').write_text(\"def my_function():\\n    return 'hello'\\n\")\nfrom skill_seekers.cli.codebase_scraper import main as scraper_main\nimport sys\nold_argv = sys.argv\ntry:\n    sys.argv = ['skill-seekers-codebase', '--directory', str(self.test_project), '--output', str(self.output_dir), '--depth', 'deep', '--ai-mode', 'none']\n    scraper_main()\nfinally:\n    sys.argv = old_argv\narch_file = self.output_dir / 'references' / 'architecture' / 'architectural_patterns.json'\nif arch_file.exists():\n    with open(arch_file) as f:\n        arch_data = json.load(f)\n    frameworks = arch_data.get('frameworks_detected', [])\n    self.assertNotIn('Flask', frameworks, 'Should not detect Flask without imports')\n    for fw in ['ASP.NET', 'Rails', 'Laravel']:\n        self.assertNotIn(fw, frameworks, f'Should not detect {fw} without real evidence')",
      "language": "Python",
      "description": "Workflow: Test that framework detection doesn't produce false positives (Issue #239).",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 137,
      "line_end": 179,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "61b1f8be",
      "test_name": "test_flask_framework_detection_from_imports",
      "category": "method_call",
      "code": "self.assertIn('frameworks_detected', arch_data)\nself.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
      "language": "Python",
      "description": "Test that Flask is detected from import statements (Issue #239).",
      "expected_behavior": "self.assertIn('Flask', arch_data['frameworks_detected'], 'Flask should be detected from imports')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 82,
      "line_end": 85,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b6b4dcdf",
      "test_name": "test_files_with_imports_are_included",
      "category": "method_call",
      "code": "self.assertIsNotNone(import_file, 'Import-only file should be in analysis')\nself.assertIn('imports', import_file, 'Imports should be extracted')",
      "language": "Python",
      "description": "Test that files with only imports are included in analysis (Issue #239).",
      "expected_behavior": "self.assertIn('imports', import_file, 'Imports should be extracted')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 129,
      "line_end": 132,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "986b47f2",
      "test_name": "test_files_with_imports_are_included",
      "category": "method_call",
      "code": "self.assertIn('imports', import_file, 'Imports should be extracted')\nself.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')",
      "language": "Python",
      "description": "Test that files with only imports are included in analysis (Issue #239).",
      "expected_behavior": "self.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 132,
      "line_end": 133,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "67db387c",
      "test_name": "test_files_with_imports_are_included",
      "category": "method_call",
      "code": "self.assertGreater(len(import_file['imports']), 0, 'Should have captured imports')\nself.assertIn('django', import_file['imports'], 'Django import should be captured')",
      "language": "Python",
      "description": "Test that files with only imports are included in analysis (Issue #239).",
      "expected_behavior": "self.assertIn('django', import_file['imports'], 'Django import should be captured')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_framework_detection.py",
      "line_start": 133,
      "line_end": 134,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.test_project = Path(self.temp_dir) / 'test_project'\nself.test_project.mkdir()\nself.output_dir = Path(self.temp_dir) / 'output'",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys",
        "skill_seekers.cli.codebase_scraper",
        "sys"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e893a84b",
      "test_name": "test_detect_unified_format",
      "category": "workflow",
      "code": "'Test unified format detection and legacy rejection'\nimport json\nimport tempfile\nunified_config = {'name': 'test', 'description': 'Test skill', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nlegacy_config = {'name': 'test', 'description': 'Test skill', 'base_url': 'https://example.com'}\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    json.dump(unified_config, f)\n    config_path = f.name\ntry:\n    validator = ConfigValidator(config_path)\n    assert validator.is_unified\n    validator.validate()\nfinally:\n    os.unlink(config_path)\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:\n    json.dump(legacy_config, f)\n    config_path = f.name\ntry:\n    validator = ConfigValidator(config_path)\n    assert validator.is_unified\n    with pytest.raises(ValueError, match='LEGACY CONFIG FORMAT DETECTED'):\n        validator.validate()\nfinally:\n    os.unlink(config_path)",
      "language": "Python",
      "description": "Workflow: Test unified format detection and legacy rejection",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 29,
      "line_end": 66,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1f45a493",
      "test_name": "test_needs_api_merge",
      "category": "workflow",
      "code": "'Test API merge detection'\nconfig_needs_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com', 'extract_api': True}, {'type': 'github', 'repo': 'user/repo', 'include_code': True}]}\nvalidator = ConfigValidator(config_needs_merge)\nassert validator.needs_api_merge()\nconfig_no_merge = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nvalidator = ConfigValidator(config_no_merge)\nassert not validator.needs_api_merge()",
      "language": "Python",
      "description": "Workflow: Test API merge detection",
      "expected_behavior": "assert not validator.needs_api_merge()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 99,
      "line_end": 122,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a5be4d48",
      "test_name": "test_detect_missing_in_docs",
      "category": "workflow",
      "code": "'Test detection of APIs missing in documentation'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'documented_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'undocumented_func', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_missing_in_docs()\nassert len(conflicts) > 0\nassert any((c.type == 'missing_in_docs' for c in conflicts))\nassert any((c.api_name == 'undocumented_func' for c in conflicts))",
      "language": "Python",
      "description": "Workflow: Test detection of APIs missing in documentation",
      "expected_behavior": "assert any((c.api_name == 'undocumented_func' for c in conflicts))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 152,
      "line_end": 190,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f213a2d1",
      "test_name": "test_detect_missing_in_code",
      "category": "workflow",
      "code": "'Test detection of APIs missing in code'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'obsolete_func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': []}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_missing_in_code()\nassert len(conflicts) > 0\nassert any((c.type == 'missing_in_code' for c in conflicts))\nassert any((c.api_name == 'obsolete_func' for c in conflicts))",
      "language": "Python",
      "description": "Workflow: Test detection of APIs missing in code",
      "expected_behavior": "assert any((c.api_name == 'obsolete_func' for c in conflicts))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 193,
      "line_end": 217,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fd49d2de",
      "test_name": "test_detect_signature_mismatch",
      "category": "workflow",
      "code": "'Test detection of signature mismatches'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'func', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'func', 'parameters': [{'name': 'x', 'type_hint': 'int'}, {'name': 'y', 'type_hint': 'bool', 'default': 'False'}], 'return_type': 'str'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector._find_signature_mismatches()\nassert len(conflicts) > 0\nassert any((c.type == 'signature_mismatch' for c in conflicts))\nassert any((c.api_name == 'func' for c in conflicts))",
      "language": "Python",
      "description": "Workflow: Test detection of signature mismatches",
      "expected_behavior": "assert any((c.api_name == 'func' for c in conflicts))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 220,
      "line_end": 261,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5e0faf15",
      "test_name": "test_rule_based_merge_docs_only",
      "category": "workflow",
      "code": "'Test rule-based merge for docs-only APIs'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'docs_only_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': []}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'docs_only_api' in merged['apis']\nassert merged['apis']['docs_only_api']['status'] == 'docs_only'",
      "language": "Python",
      "description": "Workflow: Test rule-based merge for docs-only APIs",
      "expected_behavior": "assert merged['apis']['docs_only_api']['status'] == 'docs_only'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 294,
      "line_end": 321,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ee3da183",
      "test_name": "test_rule_based_merge_code_only",
      "category": "workflow",
      "code": "'Test rule-based merge for code-only APIs'\ndocs_data = {'pages': []}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'code_only_api', 'parameters': [{'name': 'y', 'type_hint': 'float'}], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'code_only_api' in merged['apis']\nassert merged['apis']['code_only_api']['status'] == 'code_only'",
      "language": "Python",
      "description": "Workflow: Test rule-based merge for code-only APIs",
      "expected_behavior": "assert merged['apis']['code_only_api']['status'] == 'code_only'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 324,
      "line_end": 352,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "42fb31d7",
      "test_name": "test_rule_based_merge_matched",
      "category": "workflow",
      "code": "'Test rule-based merge for matched APIs'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type': 'int'}], 'return_type': 'str'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'matched_api', 'parameters': [{'name': 'x', 'type_hint': 'int'}], 'return_type': 'str'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'apis' in merged\nassert 'matched_api' in merged['apis']\nassert merged['apis']['matched_api']['status'] == 'matched'",
      "language": "Python",
      "description": "Workflow: Test rule-based merge for matched APIs",
      "expected_behavior": "assert merged['apis']['matched_api']['status'] == 'matched'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 355,
      "line_end": 396,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "20f90863",
      "test_name": "test_merge_summary",
      "category": "workflow",
      "code": "'Test merge summary statistics'\ndocs_data = {'pages': [{'url': 'https://example.com/api', 'apis': [{'name': 'api1', 'parameters': [], 'return_type': 'str'}, {'name': 'api2', 'parameters': [], 'return_type': 'int'}]}]}\ngithub_data = {'code_analysis': {'analyzed_files': [{'functions': [{'name': 'api3', 'parameters': [], 'return_type': 'bool'}]}]}}\ndetector = ConflictDetector(docs_data, github_data)\nconflicts = detector.detect_all_conflicts()\nmerger = RuleBasedMerger(docs_data, github_data, conflicts)\nmerged = merger.merge_all()\nassert 'summary' in merged\nassert merged['summary']['total_apis'] == 3\nassert merged['summary']['docs_only'] == 2\nassert merged['summary']['code_only'] == 1",
      "language": "Python",
      "description": "Workflow: Test merge summary statistics",
      "expected_behavior": "assert merged['summary']['code_only'] == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 399,
      "line_end": 430,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "819b98bf",
      "test_name": "test_skill_builder_basic",
      "category": "workflow",
      "code": "'Test basic skill building'\nconfig = {'name': 'test_skill', 'description': 'Test skill description', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}]}\nscraped_data = {'documentation': {'pages': [], 'data_file': '/tmp/test.json'}}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    builder = UnifiedSkillBuilder(config, scraped_data)\n    builder.skill_dir = tmpdir\n    builder._generate_skill_md()\n    skill_md = Path(tmpdir) / 'SKILL.md'\n    assert skill_md.exists()\n    content = skill_md.read_text()\n    assert 'test_skill' in content.lower()\n    assert 'Test skill description' in content",
      "language": "Python",
      "description": "Workflow: Test basic skill building",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified.py",
      "line_start": 438,
      "line_end": 461,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "tempfile",
        "pathlib",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_skill_builder",
        "json",
        "tempfile"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "43250466",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as LangChain Documents.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for LangChain format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert len(documents) == 3\nfor doc in documents:\n    assert 'page_content' in doc\n    assert 'metadata' in doc\n    assert doc['metadata']['source'] == 'test_skill'\n    assert doc['metadata']['version'] == '1.0.0'\n    assert 'category' in doc['metadata']\n    assert 'file' in doc['metadata']\n    assert 'type' in doc['metadata']\ncategories = {doc['metadata']['category'] for doc in documents}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as LangChain Documents.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 23,
      "line_end": 63,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e33d6b80",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('langchain')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'langchain' in output_path.name\nwith open(output_path) as f:\n    documents = json.load(f)\nassert isinstance(documents, list)\nassert len(documents) > 0\nassert 'page_content' in documents[0]\nassert 'metadata' in documents[0]",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert 'metadata' in documents[0]",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 65,
      "line_end": 88,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9b3b52e2",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('langchain')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-langchain.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'langchain' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'langchain' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 90,
      "line_end": 105,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a6f4c1f4",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert documents == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert documents == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 146,
      "line_end": 158,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bbc1f278",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert len(documents) == 1\nassert documents[0]['metadata']['category'] == 'test'\nassert documents[0]['metadata']['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert documents[0]['metadata']['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 160,
      "line_end": 177,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "75232c11",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('langchain')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that LangChain adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'langchain'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "75232c11",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('langchain')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as LangChain Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as LangChain Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ff9f3248",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "documents_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as LangChain Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d9612045",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "documents = json.loads(documents_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as LangChain Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_langchain_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7428f5fa",
      "test_name": "temp_git_repo",
      "category": "workflow",
      "code": "'Create a temporary git repository with sample configs.'\nrepo_dir = tempfile.mkdtemp(prefix='ss_repo_')\nrepo = git.Repo.init(repo_dir)\nconfigs = {'react.json': {'name': 'react', 'description': 'React framework for UIs', 'base_url': 'https://react.dev/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {'getting_started': ['learn', 'start'], 'api': ['reference', 'api']}, 'rate_limit': 0.5, 'max_pages': 100}, 'vue.json': {'name': 'vue', 'description': 'Vue.js progressive framework', 'base_url': 'https://vuejs.org/', 'selectors': {'main_content': 'main', 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 50}, 'django.json': {'name': 'django', 'description': 'Django web framework', 'base_url': 'https://docs.djangoproject.com/', 'selectors': {'main_content': \"div[role='main']\", 'title': 'h1'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 200}}\nfor filename, config_data in configs.items():\n    config_path = Path(repo_dir) / filename\n    with open(config_path, 'w') as f:\n        json.dump(config_data, f, indent=2)\nrepo.index.add(['*.json'])\nrepo.index.commit('Initial commit with sample configs')\nyield (repo_dir, repo)\nshutil.rmtree(repo_dir, ignore_errors=True)",
      "language": "Python",
      "description": "Workflow: Create a temporary git repository with sample configs.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 51,
      "line_end": 105,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b0071f7e",
      "test_name": "test_e2e_workflow_direct_git_url",
      "category": "workflow",
      "code": "'\\n        E2E Test 1: Direct git URL workflow (no source registration)\\n\\n        Steps:\\n        1. Clone repository via direct git URL\\n        2. List available configs\\n        3. Fetch specific config\\n        4. Verify config content\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-direct', git_url=git_url, branch='master')\nassert repo_path.exists()\nassert (repo_path / '.git').exists()\nconfigs = git_repo.find_configs(repo_path)\nassert len(configs) == 3\nconfig_names = [c.stem for c in configs]\nassert set(config_names) == {'react', 'vue', 'django'}\nconfig = git_repo.get_config(repo_path, 'react')\nassert config['name'] == 'react'\nassert config['description'] == 'React framework for UIs'\nassert config['base_url'] == 'https://react.dev/'\nassert 'selectors' in config\nassert 'categories' in config\nassert config['max_pages'] == 100",
      "language": "Python",
      "description": "Workflow: E2E Test 1: Direct git URL workflow (no source registration)\n\nSteps:\n1. Clone repository via direct git URL\n2. List available configs\n3. Fetch specific config\n4. Verify config content",
      "expected_behavior": "assert config['max_pages'] == 100",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 107,
      "line_end": 148,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "98f1ba4a",
      "test_name": "test_e2e_workflow_with_source_registration",
      "category": "workflow",
      "code": "'\\n        E2E Test 2: Complete workflow with source registration\\n\\n        Steps:\\n        1. Add source to registry\\n        2. List sources\\n        3. Get source details\\n        4. Clone via source name\\n        5. Fetch config\\n        6. Update source (re-add with different priority)\\n        7. Remove source\\n        8. Verify removal\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nsource_manager = SourceManager(config_dir=config_dir)\nsource = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=10)\nassert source['name'] == 'team-configs'\nassert source['git_url'] == git_url\nassert source['type'] == 'custom'\nassert source['branch'] == 'master'\nassert source['priority'] == 10\nassert source['enabled'] is True\nsources = source_manager.list_sources()\nassert len(sources) == 1\nassert sources[0]['name'] == 'team-configs'\nretrieved_source = source_manager.get_source('team-configs')\nassert retrieved_source['git_url'] == git_url\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name=source['name'], git_url=source['git_url'], branch=source['branch'])\nassert repo_path.exists()\nconfig = git_repo.get_config(repo_path, 'vue')\nassert config['name'] == 'vue'\nassert config['base_url'] == 'https://vuejs.org/'\nupdated_source = source_manager.add_source(name='team-configs', git_url=git_url, source_type='custom', branch='master', priority=5)\nassert updated_source['priority'] == 5\nremoved = source_manager.remove_source('team-configs')\nassert removed is True\nsources = source_manager.list_sources()\nassert len(sources) == 0\nwith pytest.raises(KeyError, match=\"Source 'team-configs' not found\"):\n    source_manager.get_source('team-configs')",
      "language": "Python",
      "description": "Workflow: E2E Test 2: Complete workflow with source registration\n\nSteps:\n1. Add source to registry\n2. List sources\n3. Get source details\n4. Clone via source name\n5. Fetch config\n6. Update source (re-add with different priority)\n7. Remove source\n8. Verify removal",
      "expected_behavior": "assert len(sources) == 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 150,
      "line_end": 223,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c77e4d8d",
      "test_name": "test_e2e_multiple_sources_priority_resolution",
      "category": "workflow",
      "code": "'\\n        E2E Test 3: Multiple sources with priority resolution\\n\\n        Steps:\\n        1. Add multiple sources with different priorities\\n        2. Verify sources are sorted by priority\\n        3. Enable/disable sources\\n        4. List enabled sources only\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nsource_manager = SourceManager(config_dir=config_dir)\nsource_manager.add_source(name='low-priority', git_url=git_url, priority=100)\nsource_manager.add_source(name='high-priority', git_url=git_url, priority=1)\nsource_manager.add_source(name='medium-priority', git_url=git_url, priority=50)\nsources = source_manager.list_sources()\nassert len(sources) == 3\nassert sources[0]['name'] == 'high-priority'\nassert sources[1]['name'] == 'medium-priority'\nassert sources[2]['name'] == 'low-priority'\nsource_manager.add_source(name='high-priority', git_url=git_url, priority=1, enabled=False)\nenabled_sources = source_manager.list_sources(enabled_only=True)\nassert len(enabled_sources) == 2\nassert all((s['enabled'] for s in enabled_sources))\nassert 'high-priority' not in [s['name'] for s in enabled_sources]",
      "language": "Python",
      "description": "Workflow: E2E Test 3: Multiple sources with priority resolution\n\nSteps:\n1. Add multiple sources with different priorities\n2. Verify sources are sorted by priority\n3. Enable/disable sources\n4. List enabled sources only",
      "expected_behavior": "assert 'high-priority' not in [s['name'] for s in enabled_sources]",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 225,
      "line_end": 260,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9313eeac",
      "test_name": "test_e2e_pull_existing_repository",
      "category": "workflow",
      "code": "'\\n        E2E Test 4: Pull updates from existing repository\\n\\n        Steps:\\n        1. Clone repository\\n        2. Add new commit to original repo\\n        3. Pull updates\\n        4. Verify new config is available\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master')\ninitial_configs = git_repo.find_configs(repo_path)\nassert len(initial_configs) == 3\nnew_config = {'name': 'fastapi', 'description': 'FastAPI framework', 'base_url': 'https://fastapi.tiangolo.com/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}, 'rate_limit': 0.5, 'max_pages': 150}\nnew_config_path = Path(repo_dir) / 'fastapi.json'\nwith open(new_config_path, 'w') as f:\n    json.dump(new_config, f, indent=2)\nrepo.index.add(['fastapi.json'])\nrepo.index.commit('Add FastAPI config')\nupdated_repo_path = git_repo.clone_or_pull(source_name='test-pull', git_url=git_url, branch='master', force_refresh=False)\nupdated_configs = git_repo.find_configs(updated_repo_path)\nassert len(updated_configs) == 4\nfastapi_config = git_repo.get_config(updated_repo_path, 'fastapi')\nassert fastapi_config['name'] == 'fastapi'\nassert fastapi_config['max_pages'] == 150",
      "language": "Python",
      "description": "Workflow: E2E Test 4: Pull updates from existing repository\n\nSteps:\n1. Clone repository\n2. Add new commit to original repo\n3. Pull updates\n4. Verify new config is available",
      "expected_behavior": "assert fastapi_config['max_pages'] == 150",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 262,
      "line_end": 319,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "704093e0",
      "test_name": "test_e2e_force_refresh",
      "category": "workflow",
      "code": "'\\n        E2E Test 5: Force refresh (delete and re-clone)\\n\\n        Steps:\\n        1. Clone repository\\n        2. Modify local cache manually\\n        3. Force refresh\\n        4. Verify cache was reset\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master')\ncorrupt_file = repo_path / 'CORRUPTED.txt'\nwith open(corrupt_file, 'w') as f:\n    f.write('This file should not exist after refresh')\nassert corrupt_file.exists()\nrefreshed_repo_path = git_repo.clone_or_pull(source_name='test-refresh', git_url=git_url, branch='master', force_refresh=True)\nassert not corrupt_file.exists()\nconfigs = git_repo.find_configs(refreshed_repo_path)\nassert len(configs) == 3",
      "language": "Python",
      "description": "Workflow: E2E Test 5: Force refresh (delete and re-clone)\n\nSteps:\n1. Clone repository\n2. Modify local cache manually\n3. Force refresh\n4. Verify cache was reset",
      "expected_behavior": "assert len(configs) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 321,
      "line_end": 360,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "879de16a",
      "test_name": "test_e2e_config_not_found",
      "category": "workflow",
      "code": "'\\n        E2E Test 6: Error handling - config not found\\n\\n        Steps:\\n        1. Clone repository\\n        2. Try to fetch non-existent config\\n        3. Verify helpful error message with suggestions\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\nrepo_path = git_repo.clone_or_pull(source_name='test-not-found', git_url=git_url, branch='master')\nwith pytest.raises(FileNotFoundError) as exc_info:\n    git_repo.get_config(repo_path, 'nonexistent')\nerror_msg = str(exc_info.value)\nassert 'nonexistent.json' in error_msg\nassert 'not found' in error_msg\nassert 'react' in error_msg\nassert 'vue' in error_msg\nassert 'django' in error_msg",
      "language": "Python",
      "description": "Workflow: E2E Test 6: Error handling - config not found\n\nSteps:\n1. Clone repository\n2. Try to fetch non-existent config\n3. Verify helpful error message with suggestions",
      "expected_behavior": "assert 'django' in error_msg",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 362,
      "line_end": 392,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7a766988",
      "test_name": "test_e2e_invalid_git_url",
      "category": "workflow",
      "code": "'\\n        E2E Test 7: Error handling - invalid git URL\\n\\n        Steps:\\n        1. Try to clone with invalid URL\\n        2. Verify validation error\\n        '\ncache_dir, config_dir = temp_dirs\ngit_repo = GitConfigRepo(cache_dir=cache_dir)\ninvalid_urls = ['', 'not-a-url', 'ftp://invalid.com/repo.git', \"javascript:alert('xss')\"]\nfor invalid_url in invalid_urls:\n    with pytest.raises(ValueError, match='Invalid git URL'):\n        git_repo.clone_or_pull(source_name='test-invalid', git_url=invalid_url, branch='master')",
      "language": "Python",
      "description": "Workflow: E2E Test 7: Error handling - invalid git URL\n\nSteps:\n1. Try to clone with invalid URL\n2. Verify validation error",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 394,
      "line_end": 412,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dc3326f6",
      "test_name": "test_e2e_source_name_validation",
      "category": "workflow",
      "code": "'\\n        E2E Test 8: Error handling - invalid source names\\n\\n        Steps:\\n        1. Try to add sources with invalid names\\n        2. Verify validation errors\\n        '\ncache_dir, config_dir = temp_dirs\nsource_manager = SourceManager(config_dir=config_dir)\ninvalid_names = ['', 'name with spaces', 'name/with/slashes', 'name@with@symbols', 'name.with.dots', '123-only-numbers-start-is-ok', 'name!exclamation']\nvalid_git_url = 'https://github.com/test/repo.git'\nfor invalid_name in invalid_names[:-2]:\n    if invalid_name == '123-only-numbers-start-is-ok':\n        continue\n    with pytest.raises(ValueError, match='Invalid source name'):\n        source_manager.add_source(name=invalid_name, git_url=valid_git_url)",
      "language": "Python",
      "description": "Workflow: E2E Test 8: Error handling - invalid source names\n\nSteps:\n1. Try to add sources with invalid names\n2. Verify validation errors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 414,
      "line_end": 442,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4b861a9f",
      "test_name": "test_e2e_registry_persistence",
      "category": "workflow",
      "code": "'\\n        E2E Test 9: Registry persistence across instances\\n\\n        Steps:\\n        1. Add source with one SourceManager instance\\n        2. Create new SourceManager instance\\n        3. Verify source persists\\n        4. Modify source with new instance\\n        5. Verify changes persist\\n        '\ncache_dir, config_dir = temp_dirs\nrepo_dir, repo = temp_git_repo\ngit_url = f'file://{repo_dir}'\nmanager1 = SourceManager(config_dir=config_dir)\nmanager1.add_source(name='persistent-source', git_url=git_url, priority=25)\nmanager2 = SourceManager(config_dir=config_dir)\nsources = manager2.list_sources()\nassert len(sources) == 1\nassert sources[0]['name'] == 'persistent-source'\nassert sources[0]['priority'] == 25\nmanager2.add_source(name='persistent-source', git_url=git_url, priority=50)\nmanager3 = SourceManager(config_dir=config_dir)\nsource = manager3.get_source('persistent-source')\nassert source['priority'] == 50",
      "language": "Python",
      "description": "Workflow: E2E Test 9: Registry persistence across instances\n\nSteps:\n1. Add source with one SourceManager instance\n2. Create new SourceManager instance\n3. Verify source persists\n4. Modify source with new instance\n5. Verify changes persist",
      "expected_behavior": "assert source['priority'] == 50",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_sources_e2e.py",
      "line_start": 444,
      "line_end": 483,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_dirs, temp_git_repo",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "pathlib",
        "git",
        "pytest",
        "skill_seekers.mcp.git_repo",
        "skill_seekers.mcp.source_manager",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c2beb8b6",
      "test_name": "test_with_configs_prefix",
      "category": "workflow",
      "code": "'Test resolution with configs/ prefix.'\nconfigs_dir = tmp_path / 'configs'\nconfigs_dir.mkdir()\nconfig_file = configs_dir / 'test.json'\nconfig_file.write_text('{\"name\": \"test\"}')\nimport os\noriginal_cwd = os.getcwd()\ntry:\n    os.chdir(tmp_path)\n    result = resolve_config_path('test.json', auto_fetch=False)\n    assert result is not None\n    assert result.exists()\n    assert result.name == 'test.json'\nfinally:\n    os.chdir(original_cwd)",
      "language": "Python",
      "description": "Workflow: Test resolution with configs/ prefix.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 239,
      "line_end": 258,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "347d551e",
      "test_name": "test_config_name_normalization",
      "category": "workflow",
      "code": "'Test various config name formats.'\nconfigs_dir = tmp_path / 'configs'\nconfigs_dir.mkdir()\nconfig_file = configs_dir / 'react.json'\nconfig_file.write_text('{\"name\": \"react\"}')\nimport os\noriginal_cwd = os.getcwd()\ntry:\n    os.chdir(tmp_path)\n    test_cases = ['react.json', 'configs/react.json']\n    for config_name in test_cases:\n        result = resolve_config_path(config_name, auto_fetch=False)\n        assert result is not None, f'Failed for {config_name}'\n        assert result.exists()\n        assert result.name == 'react.json'\nfinally:\n    os.chdir(original_cwd)",
      "language": "Python",
      "description": "Workflow: Test various config name formats.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 290,
      "line_end": 312,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ee606b0e",
      "test_name": "test_auto_fetch_enabled",
      "category": "method_call",
      "code": "mock_fetch.assert_called_once_with('react', destination='configs')\nassert result is not None",
      "language": "Python",
      "description": "Test that auto-fetch runs when enabled.",
      "expected_behavior": "assert result is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 277,
      "line_end": 278,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: mock_fetch, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "59596273",
      "test_name": "test_successful_fetch",
      "category": "instantiation",
      "code": "destination = str(tmp_path)",
      "language": "Python",
      "description": "Instantiate str: Test successful config download from API.",
      "expected_behavior": "assert result is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 55,
      "line_end": 55,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "af4f92ff",
      "test_name": "test_successful_fetch",
      "category": "instantiation",
      "code": "result = fetch_config_from_api('react', destination=destination)",
      "language": "Python",
      "description": "Instantiate fetch_config_from_api: Test successful config download from API.",
      "expected_behavior": "assert result is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 56,
      "line_end": 56,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cde3e1df",
      "test_name": "test_successful_fetch",
      "category": "instantiation",
      "code": "config = json.load(f)",
      "language": "Python",
      "description": "Instantiate load: Test successful config download from API.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 65,
      "line_end": 65,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "865acf2f",
      "test_name": "test_config_not_found",
      "category": "instantiation",
      "code": "result = fetch_config_from_api('nonexistent')",
      "language": "Python",
      "description": "Instantiate fetch_config_from_api: Test handling of 404 response.",
      "expected_behavior": "assert result is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 80,
      "line_end": 80,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ef72ccb",
      "test_name": "test_no_download_url",
      "category": "instantiation",
      "code": "result = fetch_config_from_api('test')",
      "language": "Python",
      "description": "Instantiate fetch_config_from_api: Test handling of missing download_url.",
      "expected_behavior": "assert result is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f518d9d7",
      "test_name": "test_http_error",
      "category": "instantiation",
      "code": "mock_client.get.side_effect = httpx.HTTPError('Connection failed')",
      "language": "Python",
      "description": "Instantiate HTTPError: Test handling of HTTP errors.",
      "expected_behavior": "assert result is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 106,
      "line_end": 106,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5e6f716c",
      "test_name": "test_http_error",
      "category": "instantiation",
      "code": "result = fetch_config_from_api('react')",
      "language": "Python",
      "description": "Instantiate fetch_config_from_api: Test handling of HTTP errors.",
      "expected_behavior": "assert result is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_fetcher.py",
      "line_start": 108,
      "line_end": 108,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_client_class",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "httpx",
        "pytest",
        "skill_seekers.cli.config_fetcher",
        "os",
        "os"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ba11b0dc",
      "test_name": "mock_git_repo",
      "category": "config",
      "code": "react_config = {'name': 'react', 'description': 'React framework', 'base_url': 'https://react.dev/'}",
      "language": "Python",
      "description": "Configuration example: Create a mock git repository with config files.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_git_sources.py",
      "line_start": 45,
      "line_end": 49,
      "complexity_score": 0.25,
      "confidence": 0.75,
      "setup_code": "# Fixtures: temp_dirs",
      "tags": [
        "mock",
        "pytest"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9c5e1e0e",
      "test_name": "mock_git_repo",
      "category": "config",
      "code": "vue_config = {'name': 'vue', 'description': 'Vue framework', 'base_url': 'https://vuejs.org/'}",
      "language": "Python",
      "description": "Configuration example: Create a mock git repository with config files.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_git_sources.py",
      "line_start": 52,
      "line_end": 52,
      "complexity_score": 0.25,
      "confidence": 0.75,
      "setup_code": "# Fixtures: temp_dirs",
      "tags": [
        "mock",
        "pytest"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "mcp",
        "mcp.types",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server",
        "skill_seekers.mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c3fda686",
      "test_name": "test_classify_files",
      "category": "workflow",
      "code": "'Test classify_files separates code and docs correctly.'\n(tmp_path / 'src').mkdir()\n(tmp_path / 'src' / 'main.py').write_text(\"print('hello')\")\n(tmp_path / 'src' / 'utils.js').write_text('function(){}')\n(tmp_path / 'docs').mkdir()\n(tmp_path / 'README.md').write_text('# README')\n(tmp_path / 'docs' / 'guide.md').write_text('# Guide')\n(tmp_path / 'docs' / 'api.rst').write_text('API')\n(tmp_path / 'node_modules').mkdir()\n(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')\nfetcher = GitHubThreeStreamFetcher('https://github.com/test/repo')\ncode_files, doc_files = fetcher.classify_files(tmp_path)\ncode_paths = [f.name for f in code_files]\nassert 'main.py' in code_paths\nassert 'utils.js' in code_paths\nassert 'lib.js' not in code_paths\ndoc_paths = [f.name for f in doc_files]\nassert 'README.md' in doc_paths\nassert 'guide.md' in doc_paths\nassert 'api.rst' in doc_paths",
      "language": "Python",
      "description": "Workflow: Test classify_files separates code and docs correctly.",
      "expected_behavior": "assert 'api.rst' in doc_paths",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 105,
      "line_end": 133,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7a0e9da2",
      "test_name": "test_classify_files",
      "category": "method_call",
      "code": "(tmp_path / 'node_modules').mkdir()\n(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')",
      "language": "Python",
      "description": "Test classify_files separates code and docs correctly.",
      "expected_behavior": "(tmp_path / 'node_modules' / 'lib.js').write_text('// should be excluded')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 117,
      "line_end": 118,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "27b3d6c5",
      "test_name": "test_code_stream",
      "category": "instantiation",
      "code": "code_stream = CodeStream(directory=Path('/tmp/repo'), files=[Path('/tmp/repo/src/main.py')])",
      "language": "Python",
      "description": "Instantiate CodeStream: Test CodeStream data class.",
      "expected_behavior": "assert code_stream.directory == Path('/tmp/repo')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 29,
      "line_end": 29,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b1b5605e",
      "test_name": "test_docs_stream",
      "category": "instantiation",
      "code": "docs_stream = DocsStream(readme='# README', contributing='# Contributing', docs_files=[{'path': 'docs/guide.md', 'content': '# Guide'}])",
      "language": "Python",
      "description": "Instantiate DocsStream: Test DocsStream data class.",
      "expected_behavior": "assert docs_stream.readme == '# README'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 35,
      "line_end": 39,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cfedc321",
      "test_name": "test_insights_stream",
      "category": "instantiation",
      "code": "insights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56}, common_problems=[{'title': 'Bug', 'number': 42}], known_solutions=[{'title': 'Fix', 'number': 35}], top_labels=[{'label': 'bug', 'count': 10}])",
      "language": "Python",
      "description": "Instantiate InsightsStream: Test InsightsStream data class.",
      "expected_behavior": "assert insights_stream.metadata['stars'] == 1234",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 46,
      "line_end": 51,
      "complexity_score": 0.5,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7ee7e422",
      "test_name": "test_three_stream_data",
      "category": "instantiation",
      "code": "three_streams = ThreeStreamData(code_stream=CodeStream(Path('/tmp'), []), docs_stream=DocsStream(None, None, []), insights_stream=InsightsStream({}, [], [], []))",
      "language": "Python",
      "description": "Instantiate ThreeStreamData: Test ThreeStreamData combination.",
      "expected_behavior": "assert isinstance(three_streams.code_stream, CodeStream)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 59,
      "line_end": 63,
      "complexity_score": 0.55,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8f62b2ca",
      "test_name": "test_parse_https_url",
      "category": "instantiation",
      "code": "fetcher = GitHubThreeStreamFetcher('https://github.com/facebook/react')",
      "language": "Python",
      "description": "Instantiate GitHubThreeStreamFetcher: Test parsing HTTPS GitHub URLs.",
      "expected_behavior": "assert fetcher.owner == 'facebook'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 74,
      "line_end": 74,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dd164f66",
      "test_name": "test_parse_https_url_with_git",
      "category": "instantiation",
      "code": "fetcher = GitHubThreeStreamFetcher('https://github.com/facebook/react.git')",
      "language": "Python",
      "description": "Instantiate GitHubThreeStreamFetcher: Test parsing HTTPS URLs with .git suffix.",
      "expected_behavior": "assert fetcher.owner == 'facebook'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 80,
      "line_end": 80,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b168d28d",
      "test_name": "test_parse_git_url",
      "category": "instantiation",
      "code": "fetcher = GitHubThreeStreamFetcher('git@github.com:facebook/react.git')",
      "language": "Python",
      "description": "Instantiate GitHubThreeStreamFetcher: Test parsing git@ URLs.",
      "expected_behavior": "assert fetcher.owner == 'facebook'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 86,
      "line_end": 86,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8f62b2ca",
      "test_name": "test_github_token_from_env",
      "category": "instantiation",
      "code": "fetcher = GitHubThreeStreamFetcher('https://github.com/facebook/react')",
      "language": "Python",
      "description": "Instantiate GitHubThreeStreamFetcher: Test GitHub token loaded from environment.",
      "expected_behavior": "assert fetcher.github_token == 'test_token'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_github_fetcher.py",
      "line_start": 98,
      "line_end": 98,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_single_worker_default",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test default is single-worker mode",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 35,
      "line_end": 35,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_multiple_workers_creates_lock",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test multiple workers creates thread lock",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 51,
      "line_end": 51,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_workers_from_config",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test workers parameter is read from config",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 66,
      "line_end": 66,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_unlimited_with_none",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test max_pages: None enables unlimited mode",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 92,
      "line_end": 92,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_unlimited_with_minus_one",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test max_pages: -1 enables unlimited mode",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 106,
      "line_end": 106,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_limited_mode_default",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test default max_pages is limited",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 119,
      "line_end": 119,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a59cc91e",
      "test_name": "test_limited_mode_default",
      "category": "instantiation",
      "code": "max_pages = converter.config.get('max_pages', 500)",
      "language": "Python",
      "description": "Instantiate get: Test default max_pages is limited",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 120,
      "line_end": 120,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_rate_limit_from_config",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test rate_limit is read from config",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 147,
      "line_end": 147,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_rate_limit_default",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test default rate_limit is 0.5",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 160,
      "line_end": 160,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_zero_rate_limit_disables",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test rate_limit: 0 disables rate limiting",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_parallel_scraping.py",
      "line_start": 174,
      "line_end": 174,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "threading"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5932c544",
      "test_name": "test_detect_python_with_confidence",
      "category": "workflow",
      "code": "'Test Python detection returns language and confidence'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"def hello():\\n    print('world')\\n    return True\"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'python')\nself.assertGreater(confidence, 0.4)\nself.assertLessEqual(confidence, 1.0)",
      "language": "Python",
      "description": "Workflow: Test Python detection returns language and confidence",
      "expected_behavior": "self.assertLessEqual(confidence, 1.0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 40,
      "line_end": 54,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5942f5df",
      "test_name": "test_detect_javascript_with_confidence",
      "category": "workflow",
      "code": "'Test JavaScript detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"const handleClick = () => {\\n  console.log('clicked');\\n};\"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'javascript')\nself.assertGreater(confidence, 0.5)",
      "language": "Python",
      "description": "Workflow: Test JavaScript detection",
      "expected_behavior": "self.assertGreater(confidence, 0.5)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 56,
      "line_end": 69,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b50ed04d",
      "test_name": "test_detect_cpp_with_confidence",
      "category": "workflow",
      "code": "'Test C++ detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '#include <iostream>\\nint main() {\\n  std::cout << \"Hello\";\\n}'\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'cpp')\nself.assertGreater(confidence, 0.5)",
      "language": "Python",
      "description": "Workflow: Test C++ detection",
      "expected_behavior": "self.assertGreater(confidence, 0.5)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 71,
      "line_end": 84,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "705db234",
      "test_name": "test_detect_unknown_low_confidence",
      "category": "workflow",
      "code": "'Test unknown language returns low confidence'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = 'this is not code at all just plain text'\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'unknown')\nself.assertLess(confidence, 0.3)",
      "language": "Python",
      "description": "Workflow: Test unknown language returns low confidence",
      "expected_behavior": "self.assertLess(confidence, 0.3)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 86,
      "line_end": 99,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "956a066a",
      "test_name": "test_detect_scss_with_confidence",
      "category": "workflow",
      "code": "'Test SCSS detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        $primary-color: #3498db;\\n\\n        @mixin border-radius($radius) {\\n          border-radius: $radius;\\n        }\\n\\n        .button {\\n          color: $primary-color;\\n          @include border-radius(5px);\\n\\n          &:hover {\\n            background: darken($primary-color, 10%);\\n          }\\n        }\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'scss')\nself.assertGreater(confidence, 0.8)",
      "language": "Python",
      "description": "Workflow: Test SCSS detection",
      "expected_behavior": "self.assertGreater(confidence, 0.8)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 122,
      "line_end": 148,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bb83a4b1",
      "test_name": "test_detect_dart_with_confidence",
      "category": "workflow",
      "code": "'Test Dart detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = \"\\n        import 'package:flutter/material.dart';\\n\\n        class MyApp extends StatelessWidget {\\n          @override\\n          Widget build(BuildContext context) {\\n            return MaterialApp(\\n              home: Text('Hello'),\\n            );\\n          }\\n        }\\n        \"\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'dart')\nself.assertGreater(confidence, 0.6)",
      "language": "Python",
      "description": "Workflow: Test Dart detection",
      "expected_behavior": "self.assertGreater(confidence, 0.6)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 150,
      "line_end": 172,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f88a839c",
      "test_name": "test_detect_scala_with_confidence",
      "category": "workflow",
      "code": "'Test Scala detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        case class Person(name: String, age: Int)\\n\\n        object Main extends App {\\n          val person = Person(\"Alice\", 30)\\n          person match {\\n            case Person(n, a) if a >= 18 => println(s\"Adult: $n\")\\n            case _ => println(\"Minor\")\\n          }\\n        }\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'scala')\nself.assertGreater(confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test Scala detection",
      "expected_behavior": "self.assertGreater(confidence, 0.7)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 174,
      "line_end": 195,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "981c2491",
      "test_name": "test_detect_sass_with_confidence",
      "category": "workflow",
      "code": "'Test SASS detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        $primary-color: #3498db\\n\\n        =border-radius($radius)\\n          border-radius: $radius\\n\\n        .button\\n          color: $primary-color\\n          +border-radius(5px)\\n\\n          &:hover\\n            background: darken($primary-color, 10%)\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'sass')\nself.assertGreater(confidence, 0.8)",
      "language": "Python",
      "description": "Workflow: Test SASS detection",
      "expected_behavior": "self.assertGreater(confidence, 0.8)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 197,
      "line_end": 220,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b0934b21",
      "test_name": "test_detect_elixir_with_confidence",
      "category": "workflow",
      "code": "'Test Elixir detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        defmodule MyApp.User do\\n          def greet(name) do\\n            \"Hello, #{name}\"\\n          end\\n\\n          defp calculate_age(birth_year) do\\n            2024 - birth_year\\n          end\\n\\n          def process(data) do\\n            data\\n            |> String.trim()\\n            |> String.downcase()\\n            |> String.split(\",\")\\n          end\\n        end\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'elixir')\nself.assertGreater(confidence, 0.8)",
      "language": "Python",
      "description": "Workflow: Test Elixir detection",
      "expected_behavior": "self.assertGreater(confidence, 0.8)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 222,
      "line_end": 250,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cfaed997",
      "test_name": "test_detect_lua_with_confidence",
      "category": "workflow",
      "code": "'Test Lua detection'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nfrom skill_seekers.cli.language_detector import LanguageDetector\nextractor.language_detector = LanguageDetector(min_confidence=0.15)\ncode = '\\n        local function calculate_sum(numbers)\\n          local total = 0\\n          for i = 1, #numbers do\\n            total = total + numbers[i]\\n          end\\n          return total\\n        end\\n\\n        local items = {1, 2, 3, 4, 5}\\n        local result = calculate_sum(items)\\n        print(\"Sum: \" .. result)\\n        '\nlanguage, confidence = extractor.detect_language_from_code(code)\nself.assertEqual(language, 'lua')\nself.assertGreater(confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test Lua detection",
      "expected_behavior": "self.assertGreater(confidence, 0.7)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_extractor.py",
      "line_start": 252,
      "line_end": 275,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "skill_seekers.cli.pdf_extractor_poc",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz",
        "unittest.mock",
        "fitz"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "84956d78",
      "test_name": "test_router_generator_init",
      "category": "workflow",
      "code": "'Test router generator initialization.'\nconfig1 = {'name': 'test-oauth', 'description': 'OAuth authentication', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth']}}\nconfig2 = {'name': 'test-async', 'description': 'Async operations', 'base_url': 'https://example.com', 'categories': {'async': ['async', 'await']}}\nconfig_path1 = tmp_path / 'config1.json'\nconfig_path2 = tmp_path / 'config2.json'\nwith open(config_path1, 'w') as f:\n    json.dump(config1, f)\nwith open(config_path2, 'w') as f:\n    json.dump(config2, f)\ngenerator = RouterGenerator([str(config_path1), str(config_path2)])\nassert generator.router_name == 'test'\nassert len(generator.configs) == 2\nassert generator.github_streams is None",
      "language": "Python",
      "description": "Workflow: Test router generator initialization.",
      "expected_behavior": "assert generator.github_streams is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 20,
      "line_end": 49,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f7ccecdf",
      "test_name": "test_infer_router_name",
      "category": "workflow",
      "code": "'Test router name inference from sub-skill names.'\nconfig1 = {'name': 'fastmcp-oauth', 'base_url': 'https://example.com'}\nconfig2 = {'name': 'fastmcp-async', 'base_url': 'https://example.com'}\nconfig_path1 = tmp_path / 'config1.json'\nconfig_path2 = tmp_path / 'config2.json'\nwith open(config_path1, 'w') as f:\n    json.dump(config1, f)\nwith open(config_path2, 'w') as f:\n    json.dump(config2, f)\ngenerator = RouterGenerator([str(config_path1), str(config_path2)])\nassert generator.router_name == 'fastmcp'",
      "language": "Python",
      "description": "Workflow: Test router name inference from sub-skill names.",
      "expected_behavior": "assert generator.router_name == 'fastmcp'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 51,
      "line_end": 66,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "997a58df",
      "test_name": "test_extract_routing_keywords_basic",
      "category": "workflow",
      "code": "'Test basic keyword extraction without GitHub.'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'authentication': ['auth', 'oauth'], 'tokens': ['token', 'jwt']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nrouting = generator.extract_routing_keywords()\nassert 'test-oauth' in routing\nkeywords = routing['test-oauth']\nassert 'authentication' in keywords\nassert 'tokens' in keywords\nassert 'oauth' in keywords",
      "language": "Python",
      "description": "Workflow: Test basic keyword extraction without GitHub.",
      "expected_behavior": "assert 'oauth' in keywords",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 68,
      "line_end": 87,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dc5ba794",
      "test_name": "test_router_with_github_metadata",
      "category": "workflow",
      "code": "'Test router generator with GitHub metadata.'\nconfig = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://github.com/test/repo', 'categories': {'oauth': ['oauth', 'auth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test Project\\n\\nA test OAuth library.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'OAuth helper'}, common_problems=[{'title': 'OAuth fails on redirect', 'number': 42, 'state': 'open', 'comments': 15, 'labels': ['bug', 'oauth']}], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 20}, {'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nassert generator.github_metadata is not None\nassert generator.github_metadata['stars'] == 1234\nassert generator.github_docs is not None\nassert generator.github_docs['readme'].startswith('# Test Project')\nassert generator.github_issues is not None",
      "language": "Python",
      "description": "Workflow: Test router generator with GitHub metadata.",
      "expected_behavior": "assert generator.github_issues is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 93,
      "line_end": 139,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "23b763ea",
      "test_name": "test_extract_keywords_with_github_labels",
      "category": "workflow",
      "code": "'Test keyword extraction with GitHub issue labels (2x weight).'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth', 'auth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[], known_solutions=[], top_labels=[{'label': 'oauth', 'count': 50}, {'label': 'authentication', 'count': 30}, {'label': 'bug', 'count': 20}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nrouting = generator.extract_routing_keywords()\nkeywords = routing['test-oauth']\noauth_count = keywords.count('oauth')\nassert oauth_count >= 4",
      "language": "Python",
      "description": "Workflow: Test keyword extraction with GitHub issue labels (2x weight).",
      "expected_behavior": "assert oauth_count >= 4",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 141,
      "line_end": 174,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "31845373",
      "test_name": "test_generate_skill_md_with_github",
      "category": "workflow",
      "code": "'Test SKILL.md generation with GitHub metadata.'\nconfig = {'name': 'test-oauth', 'description': 'OAuth authentication skill', 'base_url': 'https://github.com/test/oauth', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# OAuth Library\\n\\nQuick start: Install with pip install oauth', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 5000, 'forks': 200, 'language': 'Python', 'description': 'OAuth 2.0 library'}, common_problems=[{'title': 'Redirect URI mismatch', 'number': 100, 'state': 'open', 'comments': 25, 'labels': ['bug', 'oauth']}, {'title': 'Token refresh fails', 'number': 95, 'state': 'open', 'comments': 18, 'labels': ['oauth']}], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nskill_md = generator.generate_skill_md()\nassert '\u2b50 5,000' in skill_md\nassert 'Python' in skill_md\nassert 'OAuth 2.0 library' in skill_md\nassert '## Quick Start' in skill_md\nassert 'OAuth Library' in skill_md\nassert '## Common Issues' in skill_md or '## Examples' in skill_md\nassert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
      "language": "Python",
      "description": "Workflow: Test SKILL.md generation with GitHub metadata.",
      "expected_behavior": "assert 'how do i handle redirect uri mismatch' in skill_md.lower() or 'how do i fix redirect uri mismatch' in skill_md.lower()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 176,
      "line_end": 241,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2f9ec2e1",
      "test_name": "test_generate_skill_md_without_github",
      "category": "workflow",
      "code": "'Test SKILL.md generation without GitHub (backward compat).'\nconfig = {'name': 'test-oauth', 'description': 'OAuth skill', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nskill_md = generator.generate_skill_md()\nassert '\u2b50' not in skill_md\nassert 'Repository Info' not in skill_md\nassert 'Quick Start (from README)' not in skill_md\nassert 'Common Issues (from GitHub)' not in skill_md\nassert 'When to Use This Skill' in skill_md\nassert 'How It Works' in skill_md",
      "language": "Python",
      "description": "Workflow: Test SKILL.md generation without GitHub (backward compat).",
      "expected_behavior": "assert 'How It Works' in skill_md",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 244,
      "line_end": 269,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2b19ef0b",
      "test_name": "test_generate_subskill_issues_section",
      "category": "workflow",
      "code": "'Test generation of issues section for sub-skills.'\nconfig = {'name': 'test-oauth', 'base_url': 'https://example.com', 'categories': {'oauth': ['oauth']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth redirect fails', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token expiration issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth']}], known_solutions=[{'title': 'Fixed OAuth flow', 'number': 40, 'state': 'closed', 'comments': 10, 'labels': ['oauth']}], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nissues_section = generator.generate_subskill_issues_section('test-oauth', ['oauth'])\nassert 'Common Issues (from GitHub)' in issues_section\nassert 'OAuth redirect fails' in issues_section\nassert 'Issue #50' in issues_section\nassert '20 comments' in issues_section\nassert '\ud83d\udd34' in issues_section\nassert '\u2705' in issues_section",
      "language": "Python",
      "description": "Workflow: Test generation of issues section for sub-skills.",
      "expected_behavior": "assert '\u2705' in issues_section",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 275,
      "line_end": 332,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "11694666",
      "test_name": "test_generate_subskill_issues_no_matches",
      "category": "workflow",
      "code": "'Test issues section when no issues match the topic.'\nconfig = {'name': 'test-async', 'base_url': 'https://example.com', 'categories': {'async': ['async']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme=None, contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={}, common_problems=[{'title': 'OAuth fails', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['oauth']}], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator = RouterGenerator([str(config_path)], github_streams=github_streams)\nissues_section = generator.generate_subskill_issues_section('test-async', ['async'])\nassert 'Common Issues (from GitHub)' in issues_section\nassert 'Other' in issues_section\nassert 'OAuth fails' in issues_section",
      "language": "Python",
      "description": "Workflow: Test issues section when no issues match the topic.",
      "expected_behavior": "assert 'OAuth fails' in issues_section",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 334,
      "line_end": 373,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2b789e57",
      "test_name": "test_router_generator_init",
      "category": "instantiation",
      "code": "generator = RouterGenerator([str(config_path1), str(config_path2)])",
      "language": "Python",
      "description": "Instantiate RouterGenerator: Test router generator initialization.",
      "expected_behavior": "assert generator.router_name == 'test'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_generate_router_github.py",
      "line_start": 45,
      "line_end": 45,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5295fab3",
      "test_name": "test_creates_subdirectory_per_source",
      "category": "workflow",
      "code": "'Test that each doc source gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_docs_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'source_a', 'base_url': 'https://a.com', 'total_pages': 5, 'refs_dir': refs_dir1}, {'source_id': 'source_b', 'base_url': 'https://b.com', 'total_pages': 3, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\ndocs_dir = os.path.join(builder.skill_dir, 'references', 'documentation')\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_a')))\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
      "language": "Python",
      "description": "Workflow: Test that each doc source gets its own subdirectory.",
      "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 103,
      "line_end": 139,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "457c3874",
      "test_name": "test_creates_index_per_source",
      "category": "workflow",
      "code": "'Test that each source subdirectory has its own index.md.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir = os.path.join(self.temp_dir, 'refs')\nos.makedirs(refs_dir)\nconfig = {'name': 'test_source_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'my_source', 'base_url': 'https://example.com', 'total_pages': 10, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nsource_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'my_source', 'index.md')\nself.assertTrue(os.path.exists(source_index))\nwith open(source_index) as f:\n    content = f.read()\n    self.assertIn('my_source', content)\n    self.assertIn('https://example.com', content)",
      "language": "Python",
      "description": "Workflow: Test that each source subdirectory has its own index.md.",
      "expected_behavior": "self.assertTrue(os.path.exists(source_index))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 141,
      "line_end": 174,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "514fd982",
      "test_name": "test_creates_main_index_listing_all_sources",
      "category": "workflow",
      "code": "'Test that main index.md lists all documentation sources.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_main_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'docs_one', 'base_url': 'https://one.com', 'total_pages': 10, 'refs_dir': refs_dir1}, {'source_id': 'docs_two', 'base_url': 'https://two.com', 'total_pages': 20, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nmain_index = os.path.join(builder.skill_dir, 'references', 'documentation', 'index.md')\nself.assertTrue(os.path.exists(main_index))\nwith open(main_index) as f:\n    content = f.read()\n    self.assertIn('docs_one', content)\n    self.assertIn('docs_two', content)\n    self.assertIn('2 documentation sources', content)",
      "language": "Python",
      "description": "Workflow: Test that main index.md lists all documentation sources.",
      "expected_behavior": "self.assertTrue(os.path.exists(main_index))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 176,
      "line_end": 216,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "15a9374c",
      "test_name": "test_copies_reference_files_to_source_dir",
      "category": "workflow",
      "code": "'Test that reference files are copied to source subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir = os.path.join(self.temp_dir, 'refs')\nos.makedirs(refs_dir)\nwith open(os.path.join(refs_dir, 'api.md'), 'w') as f:\n    f.write('# API Reference')\nwith open(os.path.join(refs_dir, 'guide.md'), 'w') as f:\n    f.write('# User Guide')\nconfig = {'name': 'test_copy_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'test_source', 'base_url': 'https://test.com', 'total_pages': 5, 'refs_dir': refs_dir}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\nsource_dir = os.path.join(builder.skill_dir, 'references', 'documentation', 'test_source')\nself.assertTrue(os.path.exists(os.path.join(source_dir, 'api.md')))\nself.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
      "language": "Python",
      "description": "Workflow: Test that reference files are copied to source subdirectory.",
      "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(source_dir, 'guide.md')))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 218,
      "line_end": 251,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5f9cac6a",
      "test_name": "test_creates_subdirectory_per_repo",
      "category": "workflow",
      "code": "'Test that each GitHub repo gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_github_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'org/repo1', 'repo_id': 'org_repo1', 'data': {'readme': '# Repo 1', 'issues': [], 'releases': [], 'repo_info': {}}}, {'repo': 'org/repo2', 'repo_id': 'org_repo2', 'data': {'readme': '# Repo 2', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\ngithub_dir = os.path.join(builder.skill_dir, 'references', 'github')\nself.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo1')))\nself.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
      "language": "Python",
      "description": "Workflow: Test that each GitHub repo gets its own subdirectory.",
      "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(github_dir, 'org_repo2')))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 269,
      "line_end": 297,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "80ec31f0",
      "test_name": "test_creates_readme_per_repo",
      "category": "workflow",
      "code": "'Test that README.md is created for each repo.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_readme', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'test/myrepo', 'repo_id': 'test_myrepo', 'data': {'readme': '# My Repository\\n\\nDescription here.', 'issues': [], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nreadme_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_myrepo', 'README.md')\nself.assertTrue(os.path.exists(readme_path))\nwith open(readme_path) as f:\n    content = f.read()\n    self.assertIn('test/myrepo', content)",
      "language": "Python",
      "description": "Workflow: Test that README.md is created for each repo.",
      "expected_behavior": "self.assertTrue(os.path.exists(readme_path))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 299,
      "line_end": 332,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "665633ca",
      "test_name": "test_creates_issues_file_when_issues_exist",
      "category": "workflow",
      "code": "'Test that issues.md is created when repo has issues.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_issues', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'data': {'readme': '# Repo', 'issues': [{'number': 1, 'title': 'Bug report', 'state': 'open', 'labels': ['bug'], 'url': 'https://github.com/test/repo/issues/1'}, {'number': 2, 'title': 'Feature request', 'state': 'closed', 'labels': ['enhancement'], 'url': 'https://github.com/test/repo/issues/2'}], 'releases': [], 'repo_info': {}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nissues_path = os.path.join(builder.skill_dir, 'references', 'github', 'test_repo', 'issues.md')\nself.assertTrue(os.path.exists(issues_path))\nwith open(issues_path) as f:\n    content = f.read()\n    self.assertIn('Bug report', content)\n    self.assertIn('Feature request', content)",
      "language": "Python",
      "description": "Workflow: Test that issues.md is created when repo has issues.",
      "expected_behavior": "self.assertTrue(os.path.exists(issues_path))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 334,
      "line_end": 383,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "262c48dd",
      "test_name": "test_creates_main_index_listing_all_repos",
      "category": "workflow",
      "code": "'Test that main index.md lists all GitHub repositories.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_github_index', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [{'repo': 'org/first', 'repo_id': 'org_first', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 100}}}, {'repo': 'org/second', 'repo_id': 'org_second', 'data': {'readme': '#', 'issues': [], 'releases': [], 'repo_info': {'stars': 50}}}], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_github_references(scraped_data['github'])\nmain_index = os.path.join(builder.skill_dir, 'references', 'github', 'index.md')\nself.assertTrue(os.path.exists(main_index))\nwith open(main_index) as f:\n    content = f.read()\n    self.assertIn('org/first', content)\n    self.assertIn('org/second', content)\n    self.assertIn('2 GitHub repositories', content)",
      "language": "Python",
      "description": "Workflow: Test that main index.md lists all GitHub repositories.",
      "expected_behavior": "self.assertTrue(os.path.exists(main_index))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 385,
      "line_end": 428,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "faf6c58e",
      "test_name": "test_creates_pdf_index_with_count",
      "category": "workflow",
      "code": "'Test that PDF index shows correct document count.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nconfig = {'name': 'test_pdf', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [], 'github': [], 'pdf': [{'path': '/path/to/doc1.pdf'}, {'path': '/path/to/doc2.pdf'}, {'path': '/path/to/doc3.pdf'}]}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_pdf_references(scraped_data['pdf'])\npdf_index = os.path.join(builder.skill_dir, 'references', 'pdf', 'index.md')\nself.assertTrue(os.path.exists(pdf_index))\nwith open(pdf_index) as f:\n    content = f.read()\n    self.assertIn('3 PDF document', content)",
      "language": "Python",
      "description": "Workflow: Test that PDF index shows correct document count.",
      "expected_behavior": "self.assertTrue(os.path.exists(pdf_index))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 446,
      "line_end": 470,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures.'\nself.temp_dir = tempfile.mkdtemp()\nself.original_dir = os.getcwd()\nos.chdir(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5295fab3",
      "test_name": "test_creates_subdirectory_per_source",
      "category": "workflow",
      "code": "'Test that each doc source gets its own subdirectory.'\nfrom skill_seekers.cli.unified_skill_builder import UnifiedSkillBuilder\nrefs_dir1 = os.path.join(self.temp_dir, 'refs1')\nrefs_dir2 = os.path.join(self.temp_dir, 'refs2')\nos.makedirs(refs_dir1)\nos.makedirs(refs_dir2)\nconfig = {'name': 'test_docs_refs', 'description': 'Test', 'sources': []}\nscraped_data = {'documentation': [{'source_id': 'source_a', 'base_url': 'https://a.com', 'total_pages': 5, 'refs_dir': refs_dir1}, {'source_id': 'source_b', 'base_url': 'https://b.com', 'total_pages': 3, 'refs_dir': refs_dir2}], 'github': [], 'pdf': []}\nbuilder = UnifiedSkillBuilder(config, scraped_data)\nbuilder._generate_docs_references(scraped_data['documentation'])\ndocs_dir = os.path.join(builder.skill_dir, 'references', 'documentation')\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_a')))\nself.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
      "language": "Python",
      "description": "Workflow: Test that each doc source gets its own subdirectory.",
      "expected_behavior": "self.assertTrue(os.path.exists(os.path.join(docs_dir, 'source_b')))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multi_source.py",
      "line_start": 103,
      "line_end": 139,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "tempfile",
        "unittest",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "094c18e5",
      "test_name": "test_upload_with_nonexistent_file",
      "category": "method_call",
      "code": "self.assertFalse(success)\nself.assertIn('not found', message.lower())",
      "language": "Python",
      "description": "Test upload with nonexistent file",
      "expected_behavior": "self.assertIn('not found', message.lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 60,
      "line_end": 61,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "094c18e5",
      "test_name": "test_upload_with_nonexistent_file",
      "category": "method_call",
      "code": "self.assertFalse(success)\nself.assertIn('not found', message.lower())",
      "language": "Python",
      "description": "Test upload with nonexistent file",
      "expected_behavior": "self.assertIn('not found', message.lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 60,
      "line_end": 61,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "468cab8c",
      "test_name": "test_upload_without_api_key",
      "category": "instantiation",
      "code": "zip_path = self.create_test_zip(tmpdir)",
      "language": "Python",
      "description": "Instantiate create_test_zip: Test that upload fails gracefully without API key",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d1d1179f",
      "test_name": "test_upload_without_api_key",
      "category": "instantiation",
      "code": "success, message = upload_skill_api(zip_path)",
      "language": "Python",
      "description": "Instantiate upload_skill_api: Test that upload fails gracefully without API key",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 48,
      "line_end": 48,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f0919ba3",
      "test_name": "test_upload_with_nonexistent_file",
      "category": "instantiation",
      "code": "success, message = upload_skill_api('/nonexistent/file.zip')",
      "language": "Python",
      "description": "Instantiate upload_skill_api: Test upload with nonexistent file",
      "expected_behavior": "self.assertFalse(success)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 58,
      "line_end": 58,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "045d7e30",
      "test_name": "test_upload_with_invalid_zip",
      "category": "instantiation",
      "code": "success, message = upload_skill_api(tmpfile.name)",
      "language": "Python",
      "description": "Instantiate upload_skill_api: Test upload with invalid zip file (not a zip)",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 72,
      "line_end": 72,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "468cab8c",
      "test_name": "test_upload_accepts_path_object",
      "category": "instantiation",
      "code": "zip_path = self.create_test_zip(tmpdir)",
      "language": "Python",
      "description": "Instantiate create_test_zip: Test that upload_skill_api accepts Path objects",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 84,
      "line_end": 84,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "925ec955",
      "test_name": "test_upload_accepts_path_object",
      "category": "instantiation",
      "code": "success, message = upload_skill_api(Path(zip_path))",
      "language": "Python",
      "description": "Instantiate upload_skill_api: Test that upload_skill_api accepts Path objects",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 88,
      "line_end": 88,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Store original API key state'\nself.original_api_key = os.environ.get('ANTHROPIC_API_KEY')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a72ea3a7",
      "test_name": "test_cli_help_output",
      "category": "instantiation",
      "code": "result = subprocess.run(['skill-seekers', 'upload', '--help'], capture_output=True, text=True, timeout=5)",
      "language": "Python",
      "description": "Instantiate run: Test that skill-seekers upload --help works",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 101,
      "line_end": 103,
      "complexity_score": 0.4,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "72eb7f75",
      "test_name": "test_cli_executes_without_errors",
      "category": "instantiation",
      "code": "result = subprocess.run(['skill-seekers-upload', '--help'], capture_output=True, text=True, timeout=5)",
      "language": "Python",
      "description": "Instantiate run: Test that skill-seekers-upload entry point works",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_skill.py",
      "line_start": 117,
      "line_end": 119,
      "complexity_score": 0.35,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.upload_skill",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0fb85393",
      "test_name": "test_bootstrap_script_runs",
      "category": "instantiation",
      "code": "result = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=600)",
      "language": "Python",
      "description": "Instantiate run: Test that bootstrap script runs successfully.\n\nNote: This test is slow as it runs full codebase analysis.\nRun with: pytest -m slow",
      "expected_behavior": "assert result.returncode == 0, f'Script failed: {result.stderr}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill.py",
      "line_start": 63,
      "line_end": 69,
      "complexity_score": 0.4,
      "confidence": 0.8,
      "setup_code": "# Fixtures: project_root",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "subprocess",
        "pathlib",
        "pytest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7e0f2c67",
      "test_name": "test_bootstrap_script_runs",
      "category": "workflow",
      "code": "'Test that bootstrap script runs successfully.\\n\\n        Note: This test is slow as it runs full codebase analysis.\\n        Run with: pytest -m slow\\n        '\nscript = project_root / 'scripts' / 'bootstrap_skill.sh'\nresult = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=600)\nassert result.returncode == 0, f'Script failed: {result.stderr}'\noutput_dir = project_root / 'output' / 'skill-seekers'\nassert output_dir.exists(), 'Output directory should be created'\nskill_md = output_dir / 'SKILL.md'\nassert skill_md.exists(), 'SKILL.md should be created'\ncontent = skill_md.read_text()\nassert '## Prerequisites' in content, 'SKILL.md should have header prepended'\nassert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
      "language": "Python",
      "description": "Workflow: Test that bootstrap script runs successfully.\n\nNote: This test is slow as it runs full codebase analysis.\nRun with: pytest -m slow",
      "expected_behavior": "assert 'pip install skill-seekers' in content, 'SKILL.md should have install instructions'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill.py",
      "line_start": 54,
      "line_end": 84,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: project_root",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "subprocess",
        "pathlib",
        "pytest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c75ec58f",
      "test_name": "test_deduplicate_urls",
      "category": "workflow",
      "code": "'Test that duplicate URLs are removed.'\nfrom skill_seekers.cli.llms_txt_parser import LlmsTxtParser\ncontent = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'\nparser = LlmsTxtParser(content)\nurls = parser.extract_urls()\ncount = sum((1 for u in urls if u == 'https://example.com/doc.md'))\nself.assertEqual(count, 1)",
      "language": "Python",
      "description": "Workflow: Test that duplicate URLs are removed.",
      "expected_behavior": "self.assertEqual(count, 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 273,
      "line_end": 287,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c75ec58f",
      "test_name": "test_deduplicate_urls",
      "category": "workflow",
      "code": "'Test that duplicate URLs are removed.'\nfrom skill_seekers.cli.llms_txt_parser import LlmsTxtParser\ncontent = '\\n- [Doc 1](https://example.com/doc.md)\\n- [Doc 2](https://example.com/doc.md)\\nhttps://example.com/doc.md\\n'\nparser = LlmsTxtParser(content)\nurls = parser.extract_urls()\ncount = sum((1 for u in urls if u == 'https://example.com/doc.md'))\nself.assertEqual(count, 1)",
      "language": "Python",
      "description": "Workflow: Test that duplicate URLs are removed.",
      "expected_behavior": "self.assertEqual(count, 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 273,
      "line_end": 287,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d3bbaf46",
      "test_name": "test_extract_headings_h2_to_h6",
      "category": "method_call",
      "code": "self.assertEqual(len(result['headings']), 5)\nself.assertEqual(result['headings'][0]['level'], 'h2')",
      "language": "Python",
      "description": "Test extracting h2-h6 headings (not h1).",
      "expected_behavior": "self.assertEqual(result['headings'][0]['level'], 'h2')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 58,
      "line_end": 59,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test fixtures.'\nfrom skill_seekers.cli.doc_scraper import DocToSkillConverter\nself.config = {'name': 'test_md_parsing', 'base_url': 'https://example.com', 'selectors': {}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}}\nself.converter = DocToSkillConverter(self.config)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2795f9ec",
      "test_name": "test_extract_headings_h2_to_h6",
      "category": "method_call",
      "code": "self.assertEqual(result['headings'][0]['level'], 'h2')\nself.assertEqual(result['headings'][0]['text'], 'Section One')",
      "language": "Python",
      "description": "Test extracting h2-h6 headings (not h1).",
      "expected_behavior": "self.assertEqual(result['headings'][0]['text'], 'Section One')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 59,
      "line_end": 60,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test fixtures.'\nfrom skill_seekers.cli.doc_scraper import DocToSkillConverter\nself.config = {'name': 'test_md_parsing', 'base_url': 'https://example.com', 'selectors': {}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}}\nself.converter = DocToSkillConverter(self.config)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "41a76a9d",
      "test_name": "test_extract_code_blocks_with_language",
      "category": "method_call",
      "code": "self.assertEqual(len(result['code_samples']), 3)\nself.assertEqual(result['code_samples'][0]['language'], 'python')",
      "language": "Python",
      "description": "Test extracting code blocks with language tags.",
      "expected_behavior": "self.assertEqual(result['code_samples'][0]['language'], 'python')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 82,
      "line_end": 83,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test fixtures.'\nfrom skill_seekers.cli.doc_scraper import DocToSkillConverter\nself.config = {'name': 'test_md_parsing', 'base_url': 'https://example.com', 'selectors': {}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}}\nself.converter = DocToSkillConverter(self.config)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "29c2922b",
      "test_name": "test_extract_code_blocks_with_language",
      "category": "method_call",
      "code": "self.assertEqual(result['code_samples'][0]['language'], 'python')\nself.assertEqual(result['code_samples'][1]['language'], 'javascript')",
      "language": "Python",
      "description": "Test extracting code blocks with language tags.",
      "expected_behavior": "self.assertEqual(result['code_samples'][1]['language'], 'javascript')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 83,
      "line_end": 84,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test fixtures.'\nfrom skill_seekers.cli.doc_scraper import DocToSkillConverter\nself.config = {'name': 'test_md_parsing', 'base_url': 'https://example.com', 'selectors': {}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}}\nself.converter = DocToSkillConverter(self.config)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d8136b5c",
      "test_name": "test_extract_code_blocks_with_language",
      "category": "method_call",
      "code": "self.assertEqual(result['code_samples'][1]['language'], 'javascript')\nself.assertEqual(result['code_samples'][2]['language'], 'unknown')",
      "language": "Python",
      "description": "Test extracting code blocks with language tags.",
      "expected_behavior": "self.assertEqual(result['code_samples'][2]['language'], 'unknown')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 84,
      "line_end": 85,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test fixtures.'\nfrom skill_seekers.cli.doc_scraper import DocToSkillConverter\nself.config = {'name': 'test_md_parsing', 'base_url': 'https://example.com', 'selectors': {}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}}\nself.converter = DocToSkillConverter(self.config)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6cc3dc83",
      "test_name": "test_extract_content_paragraphs",
      "category": "method_call",
      "code": "self.assertIn('paragraph with enough content', result['content'])\nself.assertNotIn('Short.', result['content'])",
      "language": "Python",
      "description": "Test extracting paragraph content.",
      "expected_behavior": "self.assertNotIn('Short.', result['content'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 114,
      "line_end": 115,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test fixtures.'\nfrom skill_seekers.cli.doc_scraper import DocToSkillConverter\nself.config = {'name': 'test_md_parsing', 'base_url': 'https://example.com', 'selectors': {}, 'url_patterns': {'include': [], 'exclude': []}, 'categories': {}}\nself.converter = DocToSkillConverter(self.config)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1ef0485f",
      "test_name": "test_extract_markdown_style_links",
      "category": "method_call",
      "code": "self.assertIn('https://docs.example.com/start.md', urls)\nself.assertIn('https://docs.example.com/api/index.md', urls)",
      "language": "Python",
      "description": "Test extracting [text](url) style links.",
      "expected_behavior": "self.assertIn('https://docs.example.com/api/index.md', urls)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 212,
      "line_end": 213,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7ba1fb5c",
      "test_name": "test_extract_markdown_style_links",
      "category": "method_call",
      "code": "self.assertIn('https://docs.example.com/api/index.md', urls)\nself.assertIn('https://docs.example.com/advanced.md', urls)",
      "language": "Python",
      "description": "Test extracting [text](url) style links.",
      "expected_behavior": "self.assertIn('https://docs.example.com/advanced.md', urls)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_markdown_parsing.py",
      "line_start": 213,
      "line_end": 214,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "unittest",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.llms_txt_parser",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7308fb05",
      "test_name": "test_estimate_pages_with_minimal_config",
      "category": "method_call",
      "code": "self.assertIsInstance(result, dict)\nself.assertIn('discovered', result)",
      "language": "Python",
      "description": "Test estimation with minimal configuration",
      "expected_behavior": "self.assertIn('discovered', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c602da34",
      "test_name": "test_estimate_pages_with_minimal_config",
      "category": "method_call",
      "code": "self.assertIn('discovered', result)\nself.assertIn('estimated_total', result)",
      "language": "Python",
      "description": "Test estimation with minimal configuration",
      "expected_behavior": "self.assertIn('estimated_total', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 26,
      "line_end": 27,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "33c53524",
      "test_name": "test_estimate_pages_with_minimal_config",
      "category": "method_call",
      "code": "self.assertIn('estimated_total', result)\nself.assertIn('elapsed_seconds', result)",
      "language": "Python",
      "description": "Test estimation with minimal configuration",
      "expected_behavior": "self.assertIn('elapsed_seconds', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 27,
      "line_end": 29,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0c1a245c",
      "test_name": "test_estimate_pages_returns_discovered_count",
      "category": "method_call",
      "code": "self.assertGreaterEqual(result['discovered'], 0)\nself.assertIsInstance(result['discovered'], int)",
      "language": "Python",
      "description": "Test that result contains discovered page count",
      "expected_behavior": "self.assertIsInstance(result['discovered'], int)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 37,
      "line_end": 38,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7308fb05",
      "test_name": "test_estimate_pages_with_start_urls",
      "category": "method_call",
      "code": "self.assertIsInstance(result, dict)\nself.assertIn('discovered', result)",
      "language": "Python",
      "description": "Test estimation with custom start_urls",
      "expected_behavior": "self.assertIn('discovered', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 60,
      "line_end": 61,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7308fb05",
      "test_name": "test_estimate_with_real_config_file",
      "category": "method_call",
      "code": "self.assertIsInstance(result, dict)\nself.assertIn('discovered', result)",
      "language": "Python",
      "description": "Test estimation using a real config file (if exists)",
      "expected_behavior": "self.assertIn('discovered', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 181,
      "line_end": 182,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "df90596b",
      "test_name": "test_estimate_with_real_config_file",
      "category": "method_call",
      "code": "self.assertIn('discovered', result)\nself.assertGreater(result['discovered'], 0)",
      "language": "Python",
      "description": "Test estimation using a real config file (if exists)",
      "expected_behavior": "self.assertGreater(result['discovered'], 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 182,
      "line_end": 183,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7308fb05",
      "test_name": "test_estimate_pages_with_minimal_config",
      "category": "method_call",
      "code": "self.assertIsInstance(result, dict)\nself.assertIn('discovered', result)",
      "language": "Python",
      "description": "Test estimation with minimal configuration",
      "expected_behavior": "self.assertIn('discovered', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c602da34",
      "test_name": "test_estimate_pages_with_minimal_config",
      "category": "method_call",
      "code": "self.assertIn('discovered', result)\nself.assertIn('estimated_total', result)",
      "language": "Python",
      "description": "Test estimation with minimal configuration",
      "expected_behavior": "self.assertIn('estimated_total', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 26,
      "line_end": 27,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "33c53524",
      "test_name": "test_estimate_pages_with_minimal_config",
      "category": "method_call",
      "code": "self.assertIn('estimated_total', result)\nself.assertIn('elapsed_seconds', result)",
      "language": "Python",
      "description": "Test estimation with minimal configuration",
      "expected_behavior": "self.assertIn('elapsed_seconds', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_estimate_pages.py",
      "line_start": 27,
      "line_end": 29,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "unittest",
        "pathlib",
        "skill_seekers.cli.estimate_pages",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0d478cf7",
      "test_name": "test_cache_set_and_get",
      "category": "workflow",
      "code": "'Test setting and getting cached values'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ntest_data = {'page': 1, 'text': 'cached content'}\nextractor.set_cached('page_1', test_data)\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached, test_data)",
      "language": "Python",
      "description": "Workflow: Test setting and getting cached values",
      "expected_behavior": "self.assertEqual(cached, test_data)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 339,
      "line_end": 352,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "79af8725",
      "test_name": "test_cache_miss",
      "category": "workflow",
      "code": "'Test cache miss returns None'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ncached = extractor.get_cached('nonexistent_key')\nself.assertIsNone(cached)",
      "language": "Python",
      "description": "Workflow: Test cache miss returns None",
      "expected_behavior": "self.assertIsNone(cached)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 354,
      "line_end": 362,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4908a829",
      "test_name": "test_cache_disabled",
      "category": "workflow",
      "code": "'Test caching can be disabled'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = False\nextractor.set_cached('page_1', {'data': 'test'})\nself.assertEqual(len(extractor._cache), 0)\ncached = extractor.get_cached('page_1')\nself.assertIsNone(cached)",
      "language": "Python",
      "description": "Workflow: Test caching can be disabled",
      "expected_behavior": "self.assertIsNone(cached)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 364,
      "line_end": 378,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "33222edf",
      "test_name": "test_cache_overwrite",
      "category": "workflow",
      "code": "'Test cache can be overwritten'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\nextractor.set_cached('page_1', {'version': 1})\nextractor.set_cached('page_1', {'version': 2})\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached['version'], 2)",
      "language": "Python",
      "description": "Workflow: Test cache can be overwritten",
      "expected_behavior": "self.assertEqual(cached['version'], 2)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 380,
      "line_end": 395,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0d478cf7",
      "test_name": "test_cache_set_and_get",
      "category": "workflow",
      "code": "'Test setting and getting cached values'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ntest_data = {'page': 1, 'text': 'cached content'}\nextractor.set_cached('page_1', test_data)\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached, test_data)",
      "language": "Python",
      "description": "Workflow: Test setting and getting cached values",
      "expected_behavior": "self.assertEqual(cached, test_data)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 339,
      "line_end": 352,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "79af8725",
      "test_name": "test_cache_miss",
      "category": "workflow",
      "code": "'Test cache miss returns None'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\ncached = extractor.get_cached('nonexistent_key')\nself.assertIsNone(cached)",
      "language": "Python",
      "description": "Workflow: Test cache miss returns None",
      "expected_behavior": "self.assertIsNone(cached)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 354,
      "line_end": 362,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4908a829",
      "test_name": "test_cache_disabled",
      "category": "workflow",
      "code": "'Test caching can be disabled'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = False\nextractor.set_cached('page_1', {'data': 'test'})\nself.assertEqual(len(extractor._cache), 0)\ncached = extractor.get_cached('page_1')\nself.assertIsNone(cached)",
      "language": "Python",
      "description": "Workflow: Test caching can be disabled",
      "expected_behavior": "self.assertIsNone(cached)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 364,
      "line_end": 378,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "33222edf",
      "test_name": "test_cache_overwrite",
      "category": "workflow",
      "code": "'Test cache can be overwritten'\nextractor = self.PDFExtractor.__new__(self.PDFExtractor)\nextractor._cache = {}\nextractor.use_cache = True\nextractor.set_cached('page_1', {'version': 1})\nextractor.set_cached('page_1', {'version': 2})\ncached = extractor.get_cached('page_1')\nself.assertEqual(cached['version'], 2)",
      "language": "Python",
      "description": "Workflow: Test cache can be overwritten",
      "expected_behavior": "self.assertEqual(cached['version'], 2)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 380,
      "line_end": 395,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "66e78abd",
      "test_name": "test_extract_text_with_ocr_disabled",
      "category": "method_call",
      "code": "self.assertEqual(text, 'This is regular text')\nmock_page.get_text.assert_called_once_with('text')",
      "language": "Python",
      "description": "Test that OCR can be disabled",
      "expected_behavior": "mock_page.get_text.assert_called_once_with('text')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 73,
      "line_end": 74,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0d2817a5",
      "test_name": "test_extract_text_with_ocr_sufficient_text",
      "category": "method_call",
      "code": "self.assertEqual(len(text), 53)\nmock_page.get_pixmap.assert_not_called()",
      "language": "Python",
      "description": "Test OCR not triggered when sufficient text exists",
      "expected_behavior": "mock_page.get_pixmap.assert_not_called()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_advanced_features.py",
      "line_start": 88,
      "line_end": 90,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom pdf_extractor_poc import PDFExtractor\nself.PDFExtractor = PDFExtractor\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "io",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "fitz",
        "pytesseract",
        "PIL",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "pdf_extractor_poc",
        "os",
        "pdf_extractor_poc"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "faf1b3e8",
      "test_name": "test_exponential_backoff",
      "category": "method_call",
      "code": "mock_sleep.assert_any_call(1)\nmock_sleep.assert_any_call(2)",
      "language": "Python",
      "description": "Test that exponential backoff delays are correct",
      "expected_behavior": "mock_sleep.assert_any_call(2)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 102,
      "line_end": 103,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bcf9d9cf",
      "test_name": "test_successful_download",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test successful download with valid markdown content",
      "expected_behavior": "assert content is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 10,
      "line_end": 10,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "707fe9c6",
      "test_name": "test_timeout_with_retry",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt', max_retries=2)",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test timeout scenario with retry logic",
      "expected_behavior": "assert content is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 31,
      "line_end": 31,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bcf9d9cf",
      "test_name": "test_empty_content_rejection",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test rejection of content shorter than 100 chars",
      "expected_behavior": "assert content is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bcf9d9cf",
      "test_name": "test_non_markdown_rejection",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test rejection of content that doesn't look like markdown",
      "expected_behavior": "assert content is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 60,
      "line_end": 60,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "707fe9c6",
      "test_name": "test_http_error_handling",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt', max_retries=2)",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test handling of HTTP errors (404, 500, etc.)",
      "expected_behavior": "assert content is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 74,
      "line_end": 74,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5dc256ac",
      "test_name": "test_http_error_handling",
      "category": "instantiation",
      "code": "mock_response.raise_for_status.side_effect = requests.HTTPError('404 Not Found')",
      "language": "Python",
      "description": "Instantiate HTTPError: Test handling of HTTP errors (404, 500, etc.)",
      "expected_behavior": "assert content is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 77,
      "line_end": 77,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b4a1a3f7",
      "test_name": "test_exponential_backoff",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt', max_retries=3)",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test that exponential backoff delays are correct",
      "expected_behavior": "assert content is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 91,
      "line_end": 91,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bcf9d9cf",
      "test_name": "test_markdown_validation",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test markdown pattern detection",
      "expected_behavior": "assert downloader._is_markdown('# Header')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 108,
      "line_end": 108,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b2f00074",
      "test_name": "test_custom_timeout",
      "category": "instantiation",
      "code": "downloader = LlmsTxtDownloader('https://example.com/llms.txt', timeout=10)",
      "language": "Python",
      "description": "Instantiate LlmsTxtDownloader: Test custom timeout parameter",
      "expected_behavior": "assert content is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_downloader.py",
      "line_start": 124,
      "line_end": 124,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "requests",
        "skill_seekers.cli.llms_txt_downloader"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a27e4b70",
      "test_name": "test_github_command_has_enhancement_flags",
      "category": "method_call",
      "code": "self.assertEqual(result.returncode, 0, 'github --help should succeed')\nself.assertIn('--enhance', result.stdout, 'Missing --enhance flag')",
      "language": "Python",
      "description": "E2E: Verify --enhance-local flag exists in github command help",
      "expected_behavior": "self.assertIn('--enhance', result.stdout, 'Missing --enhance flag')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 129,
      "line_end": 132,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cc6f18cf",
      "test_name": "test_github_command_has_enhancement_flags",
      "category": "method_call",
      "code": "self.assertIn('--enhance', result.stdout, 'Missing --enhance flag')\nself.assertIn('--enhance-local', result.stdout, 'Missing --enhance-local flag')",
      "language": "Python",
      "description": "E2E: Verify --enhance-local flag exists in github command help",
      "expected_behavior": "self.assertIn('--enhance-local', result.stdout, 'Missing --enhance-local flag')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 132,
      "line_end": 133,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1faedc0d",
      "test_name": "test_github_command_has_enhancement_flags",
      "category": "method_call",
      "code": "self.assertIn('--enhance-local', result.stdout, 'Missing --enhance-local flag')\nself.assertIn('--api-key', result.stdout, 'Missing --api-key flag')",
      "language": "Python",
      "description": "E2E: Verify --enhance-local flag exists in github command help",
      "expected_behavior": "self.assertIn('--api-key', result.stdout, 'Missing --api-key flag')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 133,
      "line_end": 134,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "94a31db2",
      "test_name": "test_all_fixes_work_together",
      "category": "method_call",
      "code": "self.assertIn('--enhance', result.stdout)\nself.assertIn('--enhance-local', result.stdout)",
      "language": "Python",
      "description": "E2E: Verify all 3 fixes work in combination",
      "expected_behavior": "self.assertIn('--enhance-local', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 351,
      "line_end": 352,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5eaff4b0",
      "test_name": "test_all_fixes_work_together",
      "category": "method_call",
      "code": "self.assertIn('--enhance-local', result.stdout)\nself.assertIn('--api-key', result.stdout)",
      "language": "Python",
      "description": "E2E: Verify all 3 fixes work in combination",
      "expected_behavior": "self.assertIn('--api-key', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 352,
      "line_end": 353,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a27e4b70",
      "test_name": "test_github_command_has_enhancement_flags",
      "category": "method_call",
      "code": "self.assertEqual(result.returncode, 0, 'github --help should succeed')\nself.assertIn('--enhance', result.stdout, 'Missing --enhance flag')",
      "language": "Python",
      "description": "E2E: Verify --enhance-local flag exists in github command help",
      "expected_behavior": "self.assertIn('--enhance', result.stdout, 'Missing --enhance flag')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 129,
      "line_end": 132,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cc6f18cf",
      "test_name": "test_github_command_has_enhancement_flags",
      "category": "method_call",
      "code": "self.assertIn('--enhance', result.stdout, 'Missing --enhance flag')\nself.assertIn('--enhance-local', result.stdout, 'Missing --enhance-local flag')",
      "language": "Python",
      "description": "E2E: Verify --enhance-local flag exists in github command help",
      "expected_behavior": "self.assertIn('--enhance-local', result.stdout, 'Missing --enhance-local flag')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 132,
      "line_end": 133,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1faedc0d",
      "test_name": "test_github_command_has_enhancement_flags",
      "category": "method_call",
      "code": "self.assertIn('--enhance-local', result.stdout, 'Missing --enhance-local flag')\nself.assertIn('--api-key', result.stdout, 'Missing --api-key flag')",
      "language": "Python",
      "description": "E2E: Verify --enhance-local flag exists in github command help",
      "expected_behavior": "self.assertIn('--api-key', result.stdout, 'Missing --api-key flag')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 133,
      "line_end": 134,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "94a31db2",
      "test_name": "test_all_fixes_work_together",
      "category": "method_call",
      "code": "self.assertIn('--enhance', result.stdout)\nself.assertIn('--enhance-local', result.stdout)",
      "language": "Python",
      "description": "E2E: Verify all 3 fixes work in combination",
      "expected_behavior": "self.assertIn('--enhance-local', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 351,
      "line_end": 352,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5eaff4b0",
      "test_name": "test_all_fixes_work_together",
      "category": "method_call",
      "code": "self.assertIn('--enhance-local', result.stdout)\nself.assertIn('--api-key', result.stdout)",
      "language": "Python",
      "description": "E2E: Verify all 3 fixes work in combination",
      "expected_behavior": "self.assertIn('--api-key', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_219_e2e.py",
      "line_start": 352,
      "line_end": 353,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "contextlib",
        "os",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "types",
        "unittest.mock",
        "anthropic",
        "skill_seekers.cli.github_scraper",
        "argparse",
        "skill_seekers.cli",
        "github",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli",
        "skill_seekers.cli.enhance_skill",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a5d53b04",
      "test_name": "test_dry_run_no_directories_created",
      "category": "method_call",
      "code": "self.assertFalse(data_dir.exists(), 'Dry-run should not create data directory')\nself.assertFalse(skill_dir.exists(), 'Dry-run should not create skill directory')",
      "language": "Python",
      "description": "Test that dry-run mode doesn't create directories",
      "expected_behavior": "self.assertFalse(skill_dir.exists(), 'Dry-run should not create skill directory')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 44,
      "line_end": 45,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test configuration'\nself.config = {'name': 'test-dry-run', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'rate_limit': 0.1, 'max_pages': 10}",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3410dfae",
      "test_name": "test_normal_mode_creates_directories",
      "category": "method_call",
      "code": "self.assertTrue(data_dir.exists(), 'Normal mode should create data directory')\nself.assertTrue(skill_dir.exists(), 'Normal mode should create skill directory')",
      "language": "Python",
      "description": "Test that normal mode creates directories",
      "expected_behavior": "self.assertTrue(skill_dir.exists(), 'Normal mode should create skill directory')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 67,
      "line_end": 68,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test configuration'\nself.config = {'name': 'test-dry-run', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'url_patterns': {'include': [], 'exclude': []}, 'rate_limit': 0.1, 'max_pages': 10}",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eaa6a74d",
      "test_name": "test_load_valid_config",
      "category": "method_call",
      "code": "self.assertEqual(loaded_config['name'], 'test-config')\nself.assertEqual(len(loaded_config['sources']), 1)",
      "language": "Python",
      "description": "Test loading a valid configuration file (unified format)",
      "expected_behavior": "self.assertEqual(len(loaded_config['sources']), 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 111,
      "line_end": 112,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up temporary directory for test configs'\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4f67f64d",
      "test_name": "test_load_valid_config",
      "category": "method_call",
      "code": "self.assertEqual(len(loaded_config['sources']), 1)\nself.assertEqual(loaded_config['sources'][0]['base_url'], 'https://example.com/')",
      "language": "Python",
      "description": "Test loading a valid configuration file (unified format)",
      "expected_behavior": "self.assertEqual(loaded_config['sources'][0]['base_url'], 'https://example.com/')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 112,
      "line_end": 113,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up temporary directory for test configs'\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "74f651f7",
      "test_name": "test_start_urls_fallback",
      "category": "method_call",
      "code": "self.assertEqual(len(converter.pending_urls), 1)\nself.assertEqual(converter.pending_urls[0], 'https://example.com/')",
      "language": "Python",
      "description": "Test that start_urls defaults to base_url",
      "expected_behavior": "self.assertEqual(converter.pending_urls[0], 'https://example.com/')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 239,
      "line_end": 240,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "da87e972",
      "test_name": "test_scraper_has_llms_txt_attributes",
      "category": "method_call",
      "code": "self.assertFalse(scraper.llms_txt_detected)\nself.assertIsNone(scraper.llms_txt_variant)",
      "language": "Python",
      "description": "Test that scraper has llms.txt detection attributes",
      "expected_behavior": "self.assertIsNone(scraper.llms_txt_variant)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 277,
      "line_end": 278,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "13301b8a",
      "test_name": "test_scraper_has_try_llms_txt_method",
      "category": "method_call",
      "code": "self.assertTrue(hasattr(scraper, '_try_llms_txt'))\nself.assertTrue(callable(scraper._try_llms_txt))",
      "language": "Python",
      "description": "Test that scraper has _try_llms_txt method",
      "expected_behavior": "self.assertTrue(callable(scraper._try_llms_txt))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 292,
      "line_end": 293,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "28a90e2e",
      "test_name": "test_extract_empty_content",
      "category": "method_call",
      "code": "self.assertEqual(page['url'], 'https://example.com/test')\nself.assertEqual(page['title'], '')",
      "language": "Python",
      "description": "Test extracting from empty HTML",
      "expected_behavior": "self.assertEqual(page['title'], '')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 319,
      "line_end": 320,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "012cdaa8",
      "test_name": "test_extract_empty_content",
      "category": "method_call",
      "code": "self.assertEqual(page['title'], '')\nself.assertEqual(page['content'], '')",
      "language": "Python",
      "description": "Test extracting from empty HTML",
      "expected_behavior": "self.assertEqual(page['content'], '')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 320,
      "line_end": 321,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cbf9deb5",
      "test_name": "test_extract_empty_content",
      "category": "method_call",
      "code": "self.assertEqual(page['content'], '')\nself.assertEqual(len(page['code_samples']), 0)",
      "language": "Python",
      "description": "Test extracting from empty HTML",
      "expected_behavior": "self.assertEqual(len(page['code_samples']), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration.py",
      "line_start": 321,
      "line_end": 322,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre code'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.doc_scraper",
        "skill_seekers.cli.doc_scraper",
        "bs4",
        "bs4",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "addec59a",
      "test_name": "test_no_config_no_logging",
      "category": "workflow",
      "code": "\"Test that default mode doesn't log exclude_dirs messages.\"\nconfig = {'repo': 'owner/repo'}\n_scraper = GitHubScraper(config)\ninfo_calls = [str(call) for call in mock_logger.info.call_args_list]\nwarning_calls = [str(call) for call in mock_logger.warning.call_args_list]\nexclude_info = [c for c in info_calls if 'directory exclusion' in c]\nexclude_warnings = [c for c in warning_calls if 'directory exclusion' in c]\nself.assertEqual(len(exclude_info), 0)\nself.assertEqual(len(exclude_warnings), 0)",
      "language": "Python",
      "description": "Workflow: Test that default mode doesn't log exclude_dirs messages.",
      "expected_behavior": "self.assertEqual(len(exclude_warnings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 299,
      "line_end": 314,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "addec59a",
      "test_name": "test_no_config_no_logging",
      "category": "workflow",
      "code": "\"Test that default mode doesn't log exclude_dirs messages.\"\nconfig = {'repo': 'owner/repo'}\n_scraper = GitHubScraper(config)\ninfo_calls = [str(call) for call in mock_logger.info.call_args_list]\nwarning_calls = [str(call) for call in mock_logger.warning.call_args_list]\nexclude_info = [c for c in info_calls if 'directory exclusion' in c]\nexclude_warnings = [c for c in warning_calls if 'directory exclusion' in c]\nself.assertEqual(len(exclude_info), 0)\nself.assertEqual(len(exclude_warnings), 0)",
      "language": "Python",
      "description": "Workflow: Test that default mode doesn't log exclude_dirs messages.",
      "expected_behavior": "self.assertEqual(len(exclude_warnings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 299,
      "line_end": 314,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_logger, _mock_github",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9acf2106",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertTrue(scraper.should_exclude_dir('venv'))\nself.assertTrue(scraper.should_exclude_dir('node_modules'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertTrue(scraper.should_exclude_dir('node_modules'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 33,
      "line_end": 34,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "51451656",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertTrue(scraper.should_exclude_dir('node_modules'))\nself.assertTrue(scraper.should_exclude_dir('__pycache__'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertTrue(scraper.should_exclude_dir('__pycache__'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 34,
      "line_end": 35,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1bccbb9b",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertTrue(scraper.should_exclude_dir('__pycache__'))\nself.assertTrue(scraper.should_exclude_dir('.git'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertTrue(scraper.should_exclude_dir('.git'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 35,
      "line_end": 36,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "451fc8c8",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertTrue(scraper.should_exclude_dir('.git'))\nself.assertTrue(scraper.should_exclude_dir('build'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertTrue(scraper.should_exclude_dir('build'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 36,
      "line_end": 37,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e4de5042",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertTrue(scraper.should_exclude_dir('build'))\nself.assertFalse(scraper.should_exclude_dir('src'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertFalse(scraper.should_exclude_dir('src'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 37,
      "line_end": 40,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4765c931",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertFalse(scraper.should_exclude_dir('src'))\nself.assertFalse(scraper.should_exclude_dir('tests'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertFalse(scraper.should_exclude_dir('tests'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 40,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eacd5118",
      "test_name": "test_defaults_exclude_common_dirs",
      "category": "method_call",
      "code": "self.assertFalse(scraper.should_exclude_dir('tests'))\nself.assertFalse(scraper.should_exclude_dir('docs'))",
      "language": "Python",
      "description": "Test that default exclusions work correctly.",
      "expected_behavior": "self.assertFalse(scraper.should_exclude_dir('docs'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 41,
      "line_end": 42,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "be9118fd",
      "test_name": "test_dot_directories_always_excluded",
      "category": "method_call",
      "code": "self.assertTrue(scraper.should_exclude_dir('.hidden'))\nself.assertTrue(scraper.should_exclude_dir('.cache'))",
      "language": "Python",
      "description": "Test that directories starting with '.' are always excluded.",
      "expected_behavior": "self.assertTrue(scraper.should_exclude_dir('.cache'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_excluded_dirs_config.py",
      "line_start": 52,
      "line_end": 53,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.github_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6834496c",
      "test_name": "test_cli_accepts_target_flag",
      "category": "instantiation",
      "code": "args = parser.parse_args(['--config', 'test'])",
      "language": "Python",
      "description": "Instantiate parse_args: Test that CLI accepts --target flag",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_multiplatform.py",
      "line_start": 36,
      "line_end": 36,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "pathlib",
        "unittest.mock",
        "argparse",
        "sys",
        "argparse",
        "skill_seekers.mcp.tools.packaging_tools",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8a597edc",
      "test_name": "test_cli_accepts_target_flag",
      "category": "instantiation",
      "code": "args = parser.parse_args(['--config', 'test', '--target', platform])",
      "language": "Python",
      "description": "Instantiate parse_args: Test that CLI accepts --target flag",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_multiplatform.py",
      "line_start": 32,
      "line_end": 32,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "pathlib",
        "unittest.mock",
        "argparse",
        "sys",
        "argparse",
        "skill_seekers.mcp.tools.packaging_tools",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6834496c",
      "test_name": "test_cli_accepts_target_flag",
      "category": "instantiation",
      "code": "args = parser.parse_args(['--config', 'test'])",
      "language": "Python",
      "description": "Instantiate parse_args: Test that CLI accepts --target flag",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_multiplatform.py",
      "line_start": 36,
      "line_end": 36,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "pathlib",
        "unittest.mock",
        "argparse",
        "sys",
        "argparse",
        "skill_seekers.mcp.tools.packaging_tools",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8a597edc",
      "test_name": "test_cli_accepts_target_flag",
      "category": "instantiation",
      "code": "args = parser.parse_args(['--config', 'test', '--target', platform])",
      "language": "Python",
      "description": "Instantiate parse_args: Test that CLI accepts --target flag",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_install_multiplatform.py",
      "line_start": 32,
      "line_end": 32,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "pathlib",
        "unittest.mock",
        "argparse",
        "sys",
        "argparse",
        "skill_seekers.mcp.tools.packaging_tools",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "267f2b59",
      "test_name": "test_detect_llms_txt_variants",
      "category": "instantiation",
      "code": "detector = LlmsTxtDetector('https://hono.dev/docs')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDetector: Test detection of llms.txt file variants",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_detector.py",
      "line_start": 8,
      "line_end": 8,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "skill_seekers.cli.llms_txt_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "78bfecf4",
      "test_name": "test_detect_no_llms_txt",
      "category": "instantiation",
      "code": "detector = LlmsTxtDetector('https://example.com/docs')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDetector: Test detection when no llms.txt file exists",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_detector.py",
      "line_start": 25,
      "line_end": 25,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "skill_seekers.cli.llms_txt_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dc3f5b29",
      "test_name": "test_url_parsing_with_complex_paths",
      "category": "instantiation",
      "code": "detector = LlmsTxtDetector('https://example.com/docs/v2/guide')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDetector: Test URL parsing handles non-standard paths correctly",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_detector.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "skill_seekers.cli.llms_txt_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "267f2b59",
      "test_name": "test_detect_all_variants",
      "category": "instantiation",
      "code": "detector = LlmsTxtDetector('https://hono.dev/docs')",
      "language": "Python",
      "description": "Instantiate LlmsTxtDetector: Test detecting all llms.txt variants",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_detector.py",
      "line_start": 58,
      "line_end": 58,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "unittest.mock",
        "skill_seekers.cli.llms_txt_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1df940df",
      "test_name": "test_01_three_streams_present",
      "category": "method_call",
      "code": "print('\\n\ud83d\udcca STREAM 1: Code Analysis')\nassert result.code_analysis is not None, 'Code analysis missing'",
      "language": "Python",
      "description": "Test that all 3 streams are present and populated.",
      "expected_behavior": "assert result.code_analysis is not None, 'Code analysis missing'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 126,
      "line_end": 127,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f43fc7eb",
      "test_name": "test_01_three_streams_present",
      "category": "method_call",
      "code": "print(f'   \u2705 Files analyzed: {len(files)}')\nassert len(files) > 0, 'No files found in code analysis'",
      "language": "Python",
      "description": "Test that all 3 streams are present and populated.",
      "expected_behavior": "assert len(files) > 0, 'No files found in code analysis'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 130,
      "line_end": 131,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "07a88375",
      "test_name": "test_01_three_streams_present",
      "category": "method_call",
      "code": "print('\\n\ud83d\udcc4 STREAM 2: GitHub Documentation')\nassert result.github_docs is not None, 'GitHub docs missing'",
      "language": "Python",
      "description": "Test that all 3 streams are present and populated.",
      "expected_behavior": "assert result.github_docs is not None, 'GitHub docs missing'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 134,
      "line_end": 135,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "755ce02d",
      "test_name": "test_01_three_streams_present",
      "category": "method_call",
      "code": "print(f'   \u2705 README length: {len(readme)} chars')\nassert len(readme) > 100, 'README too short (< 100 chars)'",
      "language": "Python",
      "description": "Test that all 3 streams are present and populated.",
      "expected_behavior": "assert len(readme) > 100, 'README too short (< 100 chars)'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 139,
      "line_end": 140,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7ec8759a",
      "test_name": "test_01_three_streams_present",
      "category": "method_call",
      "code": "print('\\n\ud83d\udc1b STREAM 3: GitHub Insights')\nassert result.github_insights is not None, 'GitHub insights missing'",
      "language": "Python",
      "description": "Test that all 3 streams are present and populated.",
      "expected_behavior": "assert result.github_insights is not None, 'GitHub insights missing'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 153,
      "line_end": 154,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "99c78214",
      "test_name": "test_01_three_streams_present",
      "category": "method_call",
      "code": "print(f'   \u2705 Description: {description}')\nassert stars >= 0, 'Stars count invalid'",
      "language": "Python",
      "description": "Test that all 3 streams are present and populated.",
      "expected_behavior": "assert stars >= 0, 'Stars count invalid'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 165,
      "line_end": 167,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0109eed6",
      "test_name": "test_02_c3x_components_populated",
      "category": "method_call",
      "code": "print(f'\\n\ud83d\udcca Total C3.x items: {total_c3x_items}')\nassert total_c3x_items > 0, '\u274c CRITICAL: No C3.x data found! This suggests placeholders are being used instead of actual analysis.'",
      "language": "Python",
      "description": "Test that C3.x components have ACTUAL data (not placeholders).",
      "expected_behavior": "assert total_c3x_items > 0, '\u274c CRITICAL: No C3.x data found! This suggests placeholders are being used instead of actual analysis.'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 253,
      "line_end": 257,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e062f961",
      "test_name": "test_03_router_generation",
      "category": "method_call",
      "code": "print('\\n\ud83d\udcdd Router Content Analysis:')\nassert 'fastmcp' in skill_md.lower(), \"Router doesn't mention FastMCP\"",
      "language": "Python",
      "description": "Test router generation with GitHub integration.",
      "expected_behavior": "assert 'fastmcp' in skill_md.lower(), \"Router doesn't mention FastMCP\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 332,
      "line_end": 335,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis, output_dir",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a40e69fd",
      "test_name": "test_04_quality_metrics",
      "category": "method_call",
      "code": "print(f'   Code files: {code_files}')\nassert code_files > 0, 'No code files found'",
      "language": "Python",
      "description": "Test that quality metrics meet architecture targets.",
      "expected_behavior": "assert code_files > 0, 'No code files found'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 406,
      "line_end": 407,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis, output_dir",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "985ccd8b",
      "test_name": "test_04_quality_metrics",
      "category": "method_call",
      "code": "print(f'   README length: {readme_len} chars')\nassert readme_len > 100, 'README too short'",
      "language": "Python",
      "description": "Test that quality metrics meet architecture targets.",
      "expected_behavior": "assert readme_len > 100, 'README too short'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_real_world_fastmcp.py",
      "line_start": 411,
      "line_end": 412,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: fastmcp_analysis, output_dir",
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "datetime",
        "pathlib",
        "pytest",
        "skill_seekers.cli.unified_codebase_analyzer",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2110f28e",
      "test_name": "test_full_metadata",
      "category": "workflow",
      "code": "'Test metadata with all fields'\nmetadata = SkillMetadata(name='react', description='React documentation', version='2.5.0', author='Test Author', tags=['react', 'javascript', 'web'])\nself.assertEqual(metadata.name, 'react')\nself.assertEqual(metadata.description, 'React documentation')\nself.assertEqual(metadata.version, '2.5.0')\nself.assertEqual(metadata.author, 'Test Author')\nself.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
      "language": "Python",
      "description": "Workflow: Test metadata with all fields",
      "expected_behavior": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 30,
      "line_end": 44,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2110f28e",
      "test_name": "test_full_metadata",
      "category": "workflow",
      "code": "'Test metadata with all fields'\nmetadata = SkillMetadata(name='react', description='React documentation', version='2.5.0', author='Test Author', tags=['react', 'javascript', 'web'])\nself.assertEqual(metadata.name, 'react')\nself.assertEqual(metadata.description, 'React documentation')\nself.assertEqual(metadata.version, '2.5.0')\nself.assertEqual(metadata.author, 'Test Author')\nself.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
      "language": "Python",
      "description": "Workflow: Test metadata with all fields",
      "expected_behavior": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 30,
      "line_end": 44,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cca18939",
      "test_name": "test_basic_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.name, 'test-skill')\nself.assertEqual(metadata.description, 'Test skill description')",
      "language": "Python",
      "description": "Test basic metadata creation",
      "expected_behavior": "self.assertEqual(metadata.description, 'Test skill description')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e4f87eed",
      "test_name": "test_basic_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.description, 'Test skill description')\nself.assertEqual(metadata.version, '1.0.0')",
      "language": "Python",
      "description": "Test basic metadata creation",
      "expected_behavior": "self.assertEqual(metadata.version, '1.0.0')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5956cfdf",
      "test_name": "test_basic_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.version, '1.0.0')\nself.assertIsNone(metadata.author)",
      "language": "Python",
      "description": "Test basic metadata creation",
      "expected_behavior": "self.assertIsNone(metadata.author)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 26,
      "line_end": 27,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "08f44b0a",
      "test_name": "test_basic_metadata",
      "category": "method_call",
      "code": "self.assertIsNone(metadata.author)\nself.assertEqual(metadata.tags, [])",
      "language": "Python",
      "description": "Test basic metadata creation",
      "expected_behavior": "self.assertEqual(metadata.tags, [])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 27,
      "line_end": 28,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2e8e5e50",
      "test_name": "test_full_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.name, 'react')\nself.assertEqual(metadata.description, 'React documentation')",
      "language": "Python",
      "description": "Test metadata with all fields",
      "expected_behavior": "self.assertEqual(metadata.description, 'React documentation')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 40,
      "line_end": 41,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cefe7816",
      "test_name": "test_full_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.description, 'React documentation')\nself.assertEqual(metadata.version, '2.5.0')",
      "language": "Python",
      "description": "Test metadata with all fields",
      "expected_behavior": "self.assertEqual(metadata.version, '2.5.0')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 41,
      "line_end": 42,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8a58a7f3",
      "test_name": "test_full_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.version, '2.5.0')\nself.assertEqual(metadata.author, 'Test Author')",
      "language": "Python",
      "description": "Test metadata with all fields",
      "expected_behavior": "self.assertEqual(metadata.author, 'Test Author')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 42,
      "line_end": 43,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5a666cd7",
      "test_name": "test_full_metadata",
      "category": "method_call",
      "code": "self.assertEqual(metadata.author, 'Test Author')\nself.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
      "language": "Python",
      "description": "Test metadata with all fields",
      "expected_behavior": "self.assertEqual(metadata.tags, ['react', 'javascript', 'web'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_base.py",
      "line_start": 43,
      "line_end": 44,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "75ea9c0c",
      "test_name": "test_detect_from_html_swift_class",
      "category": "workflow",
      "code": "'Test HTML element with Swift CSS class'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-swift\">let x = 5</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'let x = 5')\nassert lang == 'swift'\nassert confidence == 1.0",
      "language": "Python",
      "description": "Workflow: Test HTML element with Swift CSS class",
      "expected_behavior": "assert confidence == 1.0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 44,
      "line_end": 53,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "601881a3",
      "test_name": "test_viewcontroller_lifecycle",
      "category": "workflow",
      "code": "'Test UIViewController lifecycle methods'\ndetector = LanguageDetector()\ncode = '\\n        import UIKit\\n\\n        class HomeViewController: UIViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear(_ animated: Bool) {\\n                super.viewWillAppear(animated)\\n            }\\n\\n            override func viewDidAppear(_ animated: Bool) {\\n                super.viewDidAppear(animated)\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.9",
      "language": "Python",
      "description": "Workflow: Test UIViewController lifecycle methods",
      "expected_behavior": "assert confidence >= 0.9",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 342,
      "line_end": 365,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5942a2f1",
      "test_name": "test_nsviewcontroller_lifecycle",
      "category": "workflow",
      "code": "'Test NSViewController lifecycle methods'\ndetector = LanguageDetector()\ncode = '\\n        import AppKit\\n\\n        class MainViewController: NSViewController {\\n            override func viewDidLoad() {\\n                super.viewDidLoad()\\n                setupUI()\\n            }\\n\\n            override func viewWillAppear() {\\n                super.viewWillAppear()\\n            }\\n\\n            override func viewDidAppear() {\\n                super.viewDidAppear()\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.9",
      "language": "Python",
      "description": "Workflow: Test NSViewController lifecycle methods",
      "expected_behavior": "assert confidence >= 0.9",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 468,
      "line_end": 491,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "16e54dc7",
      "test_name": "test_high_confidence_full_app",
      "category": "workflow",
      "code": "'Test complete SwiftUI app (high confidence expected)'\ndetector = LanguageDetector()\ncode = '\\n        import SwiftUI\\n\\n        @main\\n        struct MyApp: App {\\n            @StateObject private var viewModel = AppViewModel()\\n\\n            var body: some Scene {\\n                WindowGroup {\\n                    ContentView()\\n                        .environmentObject(viewModel)\\n                }\\n            }\\n        }\\n\\n        struct ContentView: View {\\n            @EnvironmentObject var viewModel: AppViewModel\\n            @State private var searchText = \"\"\\n\\n            var body: some View {\\n                NavigationStack {\\n                    List {\\n                        ForEach(viewModel.filteredItems) { item in\\n                            NavigationLink(destination: DetailView(item: item)) {\\n                                ItemRow(item: item)\\n                            }\\n                        }\\n                    }\\n                    .navigationTitle(\"Items\")\\n                    .searchable(text: $searchText)\\n                    .refreshable {\\n                        await viewModel.refresh()\\n                    }\\n                }\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'swift'\nassert confidence >= 0.95",
      "language": "Python",
      "description": "Workflow: Test complete SwiftUI app (high confidence expected)",
      "expected_behavior": "assert confidence >= 0.95",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 960,
      "line_end": 1002,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "89e4c403",
      "test_name": "test_swift_vs_similar_languages",
      "category": "workflow",
      "code": "\"\\n        Test Swift doesn't false-positive for similar syntax in other languages.\\n\\n        Critical for avoiding misclassification of:\\n        - Go: 'func', ':=' short declaration\\n        - Rust: 'fn', 'let mut', struct\\n        - TypeScript: 'let', 'const', type annotations with ':'\\n\\n        These languages share keywords or syntax patterns with Swift,\\n        so detection must use unique Swift patterns (guard let, @State, etc.)\\n        \"\ndetector = LanguageDetector()\ngo_code = '\\n        package main\\n\\n        func main() {\\n            message := \"Hello\"\\n            fmt.Println(message)\\n        }\\n        '\nlang, _ = detector.detect_from_code(go_code)\nassert lang == 'go', f\"Expected 'go', got '{lang}'\"\nrust_code = '\\n        fn main() {\\n            let mut x = 5;\\n            println!(\"Value: {}\", x);\\n        }\\n        '\nlang, _ = detector.detect_from_code(rust_code)\nassert lang == 'rust', f\"Expected 'rust', got '{lang}'\"\nts_code = \"\\n        interface User {\\n            name: string;\\n            age: number;\\n        }\\n\\n        const greet = (user: User): string => {\\n            return `Hello, ${user.name}`;\\n        }\\n\\n        export type Status = 'active' | 'inactive';\\n        \"\nlang, _ = detector.detect_from_code(ts_code)\nassert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
      "language": "Python",
      "description": "Workflow: Test Swift doesn't false-positive for similar syntax in other languages.\n\nCritical for avoiding misclassification of:\n- Go: 'func', ':=' short declaration\n- Rust: 'fn', 'let mut', struct\n- TypeScript: 'let', 'const', type annotations with ':'\n\nThese languages share keywords or syntax patterns with Swift,\nso detection must use unique Swift patterns (guard let, @State, etc.)",
      "expected_behavior": "assert lang == 'typescript', f\"Expected 'typescript', got '{lang}'\"",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 1004,
      "line_end": 1054,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7b4ca31c",
      "test_name": "test_malformed_regex_patterns_are_skipped",
      "category": "workflow",
      "code": "'Test that invalid regex patterns are logged and skipped without crashing'\nfrom unittest.mock import patch\nfrom skill_seekers.cli.language_detector import LanguageDetector\nwith patch('skill_seekers.cli.language_detector.logger') as mock_logger:\n    import skill_seekers.cli.language_detector as ld_module\n    original_patterns = ld_module.LANGUAGE_PATTERNS.copy()\n    try:\n        ld_module.LANGUAGE_PATTERNS['test_malformed'] = [('(?P<invalid)', 5), ('valid_pattern', 3)]\n        _detector = LanguageDetector()\n        assert any(('Invalid regex pattern' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for malformed pattern'\n    finally:\n        ld_module.LANGUAGE_PATTERNS = original_patterns",
      "language": "Python",
      "description": "Workflow: Test that invalid regex patterns are logged and skipped without crashing",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 1289,
      "line_end": 1321,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "45643623",
      "test_name": "test_empty_swift_patterns_handled_gracefully",
      "category": "workflow",
      "code": "\"Test that empty SWIFT_PATTERNS dict doesn't crash detection\"\nimport sys\nfrom unittest.mock import patch\nfor mod in list(sys.modules.keys()):\n    if 'skill_seekers.cli' in mod:\n        del sys.modules[mod]\nwith patch.dict('sys.modules', {'skill_seekers.cli.swift_patterns': type('MockModule', (), {'SWIFT_PATTERNS': {}})}):\n    from skill_seekers.cli.language_detector import LanguageDetector\n    detector = LanguageDetector()\n    code = 'import SwiftUI\\nstruct MyView: View { }'\n    lang, confidence = detector.detect_from_code(code)\n    assert isinstance(lang, str)\n    assert isinstance(confidence, (int, float))",
      "language": "Python",
      "description": "Workflow: Test that empty SWIFT_PATTERNS dict doesn't crash detection",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 1323,
      "line_end": 1349,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "298d3cb7",
      "test_name": "test_non_string_pattern_handled_during_compilation",
      "category": "workflow",
      "code": "'Test that non-string patterns are caught during compilation'\nfrom unittest.mock import patch\nfrom skill_seekers.cli.language_detector import LanguageDetector\nwith patch('skill_seekers.cli.language_detector.logger') as mock_logger:\n    import skill_seekers.cli.language_detector as ld_module\n    original = ld_module.LANGUAGE_PATTERNS.copy()\n    try:\n        ld_module.LANGUAGE_PATTERNS['test_nonstring'] = [(None, 5)]\n        _detector = LanguageDetector()\n        assert any(('not a string' in str(call) for call in mock_logger.error.call_args_list)), 'Expected error log for non-string pattern'\n    finally:\n        ld_module.LANGUAGE_PATTERNS = original",
      "language": "Python",
      "description": "Workflow: Test that non-string patterns are caught during compilation",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 1351,
      "line_end": 1378,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "498967ee",
      "test_name": "test_detect_from_html_swift_class",
      "category": "instantiation",
      "code": "soup = BeautifulSoup(html, 'html.parser')",
      "language": "Python",
      "description": "Instantiate BeautifulSoup: Test HTML element with Swift CSS class",
      "expected_behavior": "assert lang == 'swift'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 48,
      "line_end": 48,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cb0f0729",
      "test_name": "test_detect_from_html_swift_class",
      "category": "instantiation",
      "code": "elem = soup.find('code')",
      "language": "Python",
      "description": "Instantiate find: Test HTML element with Swift CSS class",
      "expected_behavior": "assert lang == 'swift'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_swift_detection.py",
      "line_start": 49,
      "line_end": 49,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "skill_seekers.cli.swift_patterns",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "sys",
        "unittest.mock",
        "unittest.mock",
        "skill_seekers.cli.language_detector",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f007db47",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as Weaviate objects.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for Weaviate format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('weaviate')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\nobjects_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(objects_json)\nassert 'schema' in result\nassert 'objects' in result\nassert 'class_name' in result\nassert len(result['objects']) == 3\nfor obj in result['objects']:\n    assert 'id' in obj\n    assert 'properties' in obj\n    props = obj['properties']\n    assert 'content' in props\n    assert 'source' in props\n    assert props['source'] == 'test_skill'\n    assert props['version'] == '1.0.0'\n    assert 'category' in props\n    assert 'file' in props\n    assert 'type' in props\ncategories = {obj['properties']['category'] for obj in result['objects']}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as Weaviate objects.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 23,
      "line_end": 69,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "24d52270",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('weaviate')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'weaviate' in output_path.name\nwith open(output_path) as f:\n    result = json.load(f)\nassert isinstance(result, dict)\nassert 'objects' in result\nassert len(result['objects']) > 0\nassert 'id' in result['objects'][0]\nassert 'properties' in result['objects'][0]",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert 'properties' in result['objects'][0]",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 71,
      "line_end": 95,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6adc2d4b",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('weaviate')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-weaviate.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'weaviate' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'weaviate' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 97,
      "line_end": 112,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e3b2e44d",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('weaviate')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\nobjects_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(objects_json)\nassert 'objects' in result\nassert result['objects'] == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert result['objects'] == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 157,
      "line_end": 170,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d69e68cc",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('weaviate')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\nobjects_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(objects_json)\nassert len(result['objects']) == 1\nassert result['objects'][0]['properties']['category'] == 'test'\nassert result['objects'][0]['properties']['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert result['objects'][0]['properties']['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 172,
      "line_end": 189,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1da217a2",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('weaviate')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that Weaviate adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'weaviate'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1da217a2",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('weaviate')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as Weaviate objects.",
      "expected_behavior": "assert 'schema' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as Weaviate objects.",
      "expected_behavior": "assert 'schema' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7a1f2d9e",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "objects_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as Weaviate objects.",
      "expected_behavior": "assert 'schema' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9ef07d02",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "result = json.loads(objects_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as Weaviate objects.",
      "expected_behavior": "assert 'schema' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_weaviate_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "589e4bdf",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'claude')\nself.assertIn('Claude', self.adaptor.PLATFORM_NAME)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIn('Claude', self.adaptor.PLATFORM_NAME)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "30c15917",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertIn('Claude', self.adaptor.PLATFORM_NAME)\nself.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 26,
      "line_end": 27,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8128c913",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)\nself.assertIn('anthropic.com', self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIn('anthropic.com', self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 27,
      "line_end": 28,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "43fe7cf0",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('sk-ant-abc123'))\nself.assertTrue(self.adaptor.validate_api_key('sk-ant-api03-test'))",
      "language": "Python",
      "description": "Test valid Claude API keys",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('sk-ant-api03-test'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 32,
      "line_end": 33,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "37117f20",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('sk-ant-api03-test'))\nself.assertTrue(self.adaptor.validate_api_key('  sk-ant-test  '))",
      "language": "Python",
      "description": "Test valid Claude API keys",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('  sk-ant-test  '))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 33,
      "line_end": 34,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a290c28c",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))\nself.assertFalse(self.adaptor.validate_api_key('sk-proj-123'))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('sk-proj-123'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 38,
      "line_end": 39,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "329fa10f",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('sk-proj-123'))\nself.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 39,
      "line_end": 40,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1efcb246",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('invalid'))\nself.assertFalse(self.adaptor.validate_api_key(''))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key(''))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 40,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5caec91e",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key(''))\nself.assertFalse(self.adaptor.validate_api_key('sk-test'))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('sk-test'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 41,
      "line_end": 42,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "95804c2a",
      "test_name": "test_upload_invalid_file",
      "category": "method_call",
      "code": "self.assertFalse(result['success'])\nself.assertIn('not found', result['message'].lower())",
      "language": "Python",
      "description": "Test upload with invalid file",
      "expected_behavior": "self.assertIn('not found', result['message'].lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_claude_adaptor.py",
      "line_start": 195,
      "line_end": 196,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('claude')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "301275b9",
      "test_name": "test_async_dry_run_completes",
      "category": "workflow",
      "code": "'Test async dry run completes without errors'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'async_mode': True, 'max_pages': 5}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=True)\n        with patch.object(converter, '_try_llms_txt', return_value=False):\n            converter.scrape_all()\n            self.assertTrue(converter.dry_run)\n    finally:\n        os.chdir(self.original_cwd)",
      "language": "Python",
      "description": "Workflow: Test async dry run completes without errors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 205,
      "line_end": 227,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "'Set up test fixtures'\nself.original_cwd = os.getcwd()",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "301275b9",
      "test_name": "test_async_dry_run_completes",
      "category": "workflow",
      "code": "'Test async dry run completes without errors'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'async_mode': True, 'max_pages': 5}\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=True)\n        with patch.object(converter, '_try_llms_txt', return_value=False):\n            converter.scrape_all()\n            self.assertTrue(converter.dry_run)\n    finally:\n        os.chdir(self.original_cwd)",
      "language": "Python",
      "description": "Workflow: Test async dry run completes without errors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 205,
      "line_end": 227,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_async_mode_default_false",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test async mode is disabled by default",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_async_mode_enabled_from_config",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test async mode can be enabled via config",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 58,
      "line_end": 58,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_async_mode_with_workers",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test async mode works with multiple workers",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 76,
      "line_end": 76,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Save original working directory'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_scrape_page_async_exists",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test scrape_page_async method exists",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 105,
      "line_end": 105,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Set up test fixtures'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_scrape_all_async_exists",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test scrape_all_async method exists",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 122,
      "line_end": 122,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Set up test fixtures'\nself.original_cwd = os.getcwd()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_scrape_all_routes_to_async_when_enabled",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test scrape_all calls async version when async_mode=True",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 153,
      "line_end": 153,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Set up test fixtures'\nself.original_cwd = os.getcwd()",
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_scrape_all_uses_sync_when_async_disabled",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test scrape_all uses sync version when async_mode=False",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 178,
      "line_end": 178,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Set up test fixtures'\nself.original_cwd = os.getcwd()",
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_async_dry_run_completes",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test async dry run completes without errors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_async_scraping.py",
      "line_start": 218,
      "line_end": 218,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "'Set up test fixtures'\nself.original_cwd = os.getcwd()",
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "asyncio",
        "inspect",
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper",
        "httpx"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "38f99d71",
      "test_name": "test_format_bytes_below_1kb",
      "category": "method_call",
      "code": "self.assertEqual(format_file_size(500), '500 bytes')\nself.assertEqual(format_file_size(1023), '1023 bytes')",
      "language": "Python",
      "description": "Test formatting bytes below 1 KB",
      "expected_behavior": "self.assertEqual(format_file_size(1023), '1023 bytes')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 96,
      "line_end": 97,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8c5929ce",
      "test_name": "test_format_kilobytes",
      "category": "method_call",
      "code": "self.assertEqual(format_file_size(1024), '1.0 KB')\nself.assertEqual(format_file_size(1536), '1.5 KB')",
      "language": "Python",
      "description": "Test formatting KB sizes",
      "expected_behavior": "self.assertEqual(format_file_size(1536), '1.5 KB')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 101,
      "line_end": 102,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "99f99764",
      "test_name": "test_format_kilobytes",
      "category": "method_call",
      "code": "self.assertEqual(format_file_size(1536), '1.5 KB')\nself.assertEqual(format_file_size(10240), '10.0 KB')",
      "language": "Python",
      "description": "Test formatting KB sizes",
      "expected_behavior": "self.assertEqual(format_file_size(10240), '10.0 KB')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 102,
      "line_end": 103,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7838d72c",
      "test_name": "test_format_megabytes",
      "category": "method_call",
      "code": "self.assertEqual(format_file_size(1048576), '1.0 MB')\nself.assertEqual(format_file_size(1572864), '1.5 MB')",
      "language": "Python",
      "description": "Test formatting MB sizes",
      "expected_behavior": "self.assertEqual(format_file_size(1572864), '1.5 MB')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 107,
      "line_end": 108,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b5f05558",
      "test_name": "test_format_megabytes",
      "category": "method_call",
      "code": "self.assertEqual(format_file_size(1572864), '1.5 MB')\nself.assertEqual(format_file_size(10485760), '10.0 MB')",
      "language": "Python",
      "description": "Test formatting MB sizes",
      "expected_behavior": "self.assertEqual(format_file_size(10485760), '10.0 MB')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 108,
      "line_end": 109,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "89dad967",
      "test_name": "test_format_large_files",
      "category": "method_call",
      "code": "self.assertEqual(format_file_size(104857600), '100.0 MB')\nself.assertEqual(format_file_size(1073741824), '1024.0 MB')",
      "language": "Python",
      "description": "Test formatting large file sizes",
      "expected_behavior": "self.assertEqual(format_file_size(1073741824), '1024.0 MB')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 118,
      "line_end": 120,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "689a0dff",
      "test_name": "test_nonexistent_directory",
      "category": "method_call",
      "code": "self.assertFalse(is_valid)\nself.assertIn('not found', error.lower())",
      "language": "Python",
      "description": "Test validation of nonexistent directory",
      "expected_behavior": "self.assertIn('not found', error.lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 140,
      "line_end": 141,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "689a0dff",
      "test_name": "test_nonexistent_file",
      "category": "method_call",
      "code": "self.assertFalse(is_valid)\nself.assertIn('not found', error.lower())",
      "language": "Python",
      "description": "Test validation of nonexistent file",
      "expected_behavior": "self.assertIn('not found', error.lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 177,
      "line_end": 178,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "67874163",
      "test_name": "test_successful_operation_first_try",
      "category": "method_call",
      "code": "self.assertEqual(result, 'success')\nself.assertEqual(call_count, 1)",
      "language": "Python",
      "description": "Test operation that succeeds on first try",
      "expected_behavior": "self.assertEqual(call_count, 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 235,
      "line_end": 236,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "83251d5a",
      "test_name": "test_successful_operation_after_retry",
      "category": "method_call",
      "code": "self.assertEqual(result, 'success')\nself.assertEqual(call_count, 2)",
      "language": "Python",
      "description": "Test operation that fails once then succeeds",
      "expected_behavior": "self.assertEqual(call_count, 2)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_utilities.py",
      "line_start": 250,
      "line_end": 251,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.utils",
        "time",
        "asyncio",
        "asyncio",
        "asyncio"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b67909da",
      "test_name": "test_enhance_guide_error_fallback",
      "category": "workflow",
      "code": "'Test graceful fallback on enhancement error'\nenhancer = GuideEnhancer(mode='none')\nwith patch.object(enhancer, 'enhance_guide', side_effect=Exception('API error')):\n    guide_data = {'title': 'Test', 'steps': [], 'language': 'python', 'prerequisites': [], 'description': 'Test'}\n    try:\n        enhancer = GuideEnhancer(mode='none')\n        result = enhancer.enhance_guide(guide_data)\n        assert result['title'] == guide_data['title']\n    except Exception:\n        pytest.fail('Should handle errors gracefully')",
      "language": "Python",
      "description": "Workflow: Test graceful fallback on enhancement error",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 444,
      "line_end": 464,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "df128142",
      "test_name": "test_call_claude_local_success",
      "category": "workflow",
      "code": "'Test successful LOCAL mode call'\nmock_run.return_value = MagicMock(returncode=0, stdout=json.dumps({'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}))\nenhancer = GuideEnhancer(mode='local')\nif enhancer.mode == 'local':\n    prompt = 'Test prompt'\n    result = enhancer._call_claude_local(prompt)\n    assert result is not None\n    assert mock_run.called",
      "language": "Python",
      "description": "Workflow: Test successful LOCAL mode call",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 471,
      "line_end": 492,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_run",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4d3e542e",
      "test_name": "test_call_claude_local_timeout",
      "category": "workflow",
      "code": "'Test LOCAL mode timeout handling'\nfrom subprocess import TimeoutExpired\nmock_run.side_effect = TimeoutExpired('claude', 300)\nenhancer = GuideEnhancer(mode='local')\nif enhancer.mode == 'local':\n    prompt = 'Test prompt'\n    result = enhancer._call_claude_local(prompt)\n    assert result is None",
      "language": "Python",
      "description": "Workflow: Test LOCAL mode timeout handling",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 495,
      "line_end": 506,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_run",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c9fbf074",
      "test_name": "test_parse_enhancement_response_valid_json",
      "category": "workflow",
      "code": "'Test parsing valid JSON response'\nenhancer = GuideEnhancer(mode='none')\nresponse = json.dumps({'step_descriptions': [{'step_index': 0, 'explanation': 'Test', 'variations': []}], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []})\nguide_data = {'title': 'Test', 'steps': [{'description': 'Test', 'code': 'test'}], 'language': 'python'}\nresult = enhancer._parse_enhancement_response(response, guide_data)\nassert 'step_enhancements' in result\nassert len(result['step_enhancements']) == 1",
      "language": "Python",
      "description": "Workflow: Test parsing valid JSON response",
      "expected_behavior": "assert len(result['step_enhancements']) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 560,
      "line_end": 583,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b07ea653",
      "test_name": "test_parse_enhancement_response_with_extra_text",
      "category": "workflow",
      "code": "'Test parsing JSON embedded in text'\nenhancer = GuideEnhancer(mode='none')\njson_data = {'step_descriptions': [], 'troubleshooting': [], 'prerequisites_detailed': [], 'next_steps': [], 'use_cases': []}\nresponse = f\"Here's the result:\\n{json.dumps(json_data)}\\nDone!\"\nguide_data = {'title': 'Test', 'steps': [], 'language': 'python'}\nresult = enhancer._parse_enhancement_response(response, guide_data)\nassert 'title' in result",
      "language": "Python",
      "description": "Workflow: Test parsing JSON embedded in text",
      "expected_behavior": "assert 'title' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 585,
      "line_end": 603,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "76b3d4cf",
      "test_name": "test_auto_mode_with_api_key",
      "category": "instantiation",
      "code": "enhancer = GuideEnhancer(mode='auto')",
      "language": "Python",
      "description": "Instantiate GuideEnhancer: Test auto mode detects API when key present and library available",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 37,
      "line_end": 37,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "76b3d4cf",
      "test_name": "test_auto_mode_without_api_key",
      "category": "instantiation",
      "code": "enhancer = GuideEnhancer(mode='auto')",
      "language": "Python",
      "description": "Instantiate GuideEnhancer: Test auto mode falls back to LOCAL when no API key",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 47,
      "line_end": 47,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9081854c",
      "test_name": "test_explicit_api_mode",
      "category": "instantiation",
      "code": "enhancer = GuideEnhancer(mode='api')",
      "language": "Python",
      "description": "Instantiate GuideEnhancer: Test explicit API mode",
      "expected_behavior": "assert enhancer.mode in ['api', 'none']",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 52,
      "line_end": 52,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2f5a1d48",
      "test_name": "test_explicit_local_mode",
      "category": "instantiation",
      "code": "enhancer = GuideEnhancer(mode='local')",
      "language": "Python",
      "description": "Instantiate GuideEnhancer: Test explicit LOCAL mode",
      "expected_behavior": "assert enhancer.mode in ['local', 'none']",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 57,
      "line_end": 57,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "acfdc20a",
      "test_name": "test_explicit_none_mode",
      "category": "instantiation",
      "code": "enhancer = GuideEnhancer(mode='none')",
      "language": "Python",
      "description": "Instantiate GuideEnhancer: Test explicit none mode",
      "expected_behavior": "assert enhancer.mode == 'none'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_guide_enhancer.py",
      "line_start": 62,
      "line_end": 62,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.guide_enhancer",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "41186b80",
      "test_name": "test_compare_benchmarks",
      "category": "workflow",
      "code": "'Test comparing benchmarks.'\nrunner = BenchmarkRunner(output_dir=tmp_path)\n\ndef baseline_bench(bench):\n    with bench.timer('operation'):\n        time.sleep(0.1)\nrunner.run('baseline', baseline_bench, save=True)\nbaseline_path = list(tmp_path.glob('baseline_*.json'))[0]\n\ndef improved_bench(bench):\n    with bench.timer('operation'):\n        time.sleep(0.05)\nrunner.run('improved', improved_bench, save=True)\nimproved_path = list(tmp_path.glob('improved_*.json'))[0]\nfrom skill_seekers.benchmark.models import ComparisonReport\ncomparison = runner.compare(baseline_path, improved_path)\nassert isinstance(comparison, ComparisonReport)\nassert comparison.speedup_factor > 1.0\nassert len(comparison.improvements) > 0",
      "language": "Python",
      "description": "Workflow: Test comparing benchmarks.",
      "expected_behavior": "assert len(comparison.improvements) > 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 368,
      "line_end": 395,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ce3bc3cc",
      "test_name": "test_cleanup_old",
      "category": "workflow",
      "code": "'Test cleaning up old benchmarks.'\nimport os\nrunner = BenchmarkRunner(output_dir=tmp_path)\nbase_time = time.time()\nfor i in range(10):\n    filename = f'test_{i:08d}.json'\n    file_path = tmp_path / filename\n    report_data = {'name': 'test', 'started_at': datetime.utcnow().isoformat(), 'finished_at': datetime.utcnow().isoformat(), 'total_duration': 1.0, 'timings': [], 'memory': [], 'metrics': [], 'system_info': {}, 'recommendations': []}\n    with open(file_path, 'w') as f:\n        json.dump(report_data, f)\n    mtime = base_time - (10 - i) * 60\n    os.utime(file_path, (mtime, mtime))\nassert len(list(tmp_path.glob('test_*.json'))) == 10\nrunner.cleanup_old(keep_latest=3)\nremaining = list(tmp_path.glob('test_*.json'))\nassert len(remaining) == 3\nremaining_names = {f.stem for f in remaining}\nassert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
      "language": "Python",
      "description": "Workflow: Test cleaning up old benchmarks.",
      "expected_behavior": "assert 'test_00000007' in remaining_names or 'test_00000008' in remaining_names",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 441,
      "line_end": 484,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d6c0efdf",
      "test_name": "test_comparison_report_overall_improvement",
      "category": "workflow",
      "code": "'Test ComparisonReport overall_improvement property.'\nfrom skill_seekers.benchmark.models import ComparisonReport\nbaseline = BenchmarkReport(name='baseline', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=10.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])\ncurrent = BenchmarkReport(name='current', started_at=datetime.utcnow(), finished_at=datetime.utcnow(), total_duration=5.0, timings=[], memory=[], metrics=[], system_info={}, recommendations=[])\ncomparison = ComparisonReport(name='test', baseline=baseline, current=current, improvements=[], regressions=[], speedup_factor=2.0, memory_change_mb=0.0)\nimprovement = comparison.overall_improvement\nassert '100.0% faster' in improvement\nassert '\u2705' in improvement",
      "language": "Python",
      "description": "Workflow: Test ComparisonReport overall_improvement property.",
      "expected_behavior": "assert '\u2705' in improvement",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 586,
      "line_end": 627,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e6e7b03a",
      "test_name": "test_add_timing",
      "category": "method_call",
      "code": "result.add_timing(timing)\nassert len(result.timings) == 1",
      "language": "Python",
      "description": "Test adding timing result.",
      "expected_behavior": "assert len(result.timings) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 45,
      "line_end": 47,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1c146d6c",
      "test_name": "test_add_memory",
      "category": "method_call",
      "code": "result.add_memory(usage)\nassert len(result.memory) == 1",
      "language": "Python",
      "description": "Test adding memory usage.",
      "expected_behavior": "assert len(result.memory) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 59,
      "line_end": 61,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3ded11b2",
      "test_name": "test_add_metric",
      "category": "method_call",
      "code": "result.add_metric(metric)\nassert len(result.metrics) == 1",
      "language": "Python",
      "description": "Test adding custom metric.",
      "expected_behavior": "assert len(result.metrics) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 71,
      "line_end": 73,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "34b8f91d",
      "test_name": "test_add_recommendation",
      "category": "method_call",
      "code": "result.add_recommendation('Consider caching')\nassert len(result.recommendations) == 1",
      "language": "Python",
      "description": "Test adding recommendation.",
      "expected_behavior": "assert len(result.recommendations) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 81,
      "line_end": 83,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e39eb7a5",
      "test_name": "test_set_system_info",
      "category": "method_call",
      "code": "result.set_system_info()\nassert 'cpu_count' in result.system_info",
      "language": "Python",
      "description": "Test collecting system info.",
      "expected_behavior": "assert 'cpu_count' in result.system_info",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 90,
      "line_end": 92,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "befa4b5e",
      "test_name": "test_measure_with_memory_tracking",
      "category": "method_call",
      "code": "benchmark.measure(allocate_memory, operation='allocate', track_memory=True)\nassert len(benchmark.result.timings) == 1",
      "language": "Python",
      "description": "Test measure with memory tracking.",
      "expected_behavior": "assert len(benchmark.result.timings) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 177,
      "line_end": 179,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5d193161",
      "test_name": "test_timed_decorator_with_memory",
      "category": "method_call",
      "code": "allocate()\nassert len(benchmark.result.timings) == 1",
      "language": "Python",
      "description": "Test timed decorator with memory tracking.",
      "expected_behavior": "assert len(benchmark.result.timings) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_benchmark.py",
      "line_start": 205,
      "line_end": 207,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "time",
        "json",
        "datetime",
        "skill_seekers.benchmark",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models",
        "os",
        "skill_seekers.benchmark.models",
        "skill_seekers.benchmark.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f6dc7925",
      "test_name": "test_init_preserves_existing_registry",
      "category": "workflow",
      "code": "\"Test that initialization doesn't overwrite existing registry.\"\nregistry_file = temp_config_dir / 'sources.json'\nexisting_data = {'version': '1.0', 'sources': [{'name': 'test', 'git_url': 'https://example.com/repo.git'}]}\nwith open(registry_file, 'w') as f:\n    json.dump(existing_data, f)\n_manager = SourceManager(config_dir=str(temp_config_dir))\nwith open(registry_file) as f:\n    data = json.load(f)\n    assert len(data['sources']) == 1",
      "language": "Python",
      "description": "Workflow: Test that initialization doesn't overwrite existing registry.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 51,
      "line_end": 69,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_config_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "efdb7dce",
      "test_name": "test_add_source_full_parameters",
      "category": "workflow",
      "code": "'Test adding source with all parameters.'\nsource = source_manager.add_source(name='company', git_url='https://gitlab.company.com/platform/configs.git', source_type='gitlab', token_env='CUSTOM_TOKEN', branch='develop', priority=1, enabled=False)\nassert source['name'] == 'company'\nassert source['type'] == 'gitlab'\nassert source['token_env'] == 'CUSTOM_TOKEN'\nassert source['branch'] == 'develop'\nassert source['priority'] == 1\nassert source['enabled'] is False",
      "language": "Python",
      "description": "Workflow: Test adding source with all parameters.",
      "expected_behavior": "assert source['enabled'] is False",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 98,
      "line_end": 115,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: source_manager",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fb24d3f1",
      "test_name": "test_init_creates_config_dir",
      "category": "instantiation",
      "code": "manager = SourceManager(config_dir=str(config_dir))",
      "language": "Python",
      "description": "Instantiate SourceManager: Test that initialization creates config directory.",
      "expected_behavior": "assert config_dir.exists()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 34,
      "line_end": 34,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c7f69131",
      "test_name": "test_init_creates_registry_file",
      "category": "instantiation",
      "code": "_manager = SourceManager(config_dir=str(temp_config_dir))",
      "language": "Python",
      "description": "Instantiate SourceManager: Test that initialization creates registry file.",
      "expected_behavior": "assert registry_file.exists()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: temp_config_dir",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c7f69131",
      "test_name": "test_init_preserves_existing_registry",
      "category": "instantiation",
      "code": "_manager = SourceManager(config_dir=str(temp_config_dir))",
      "language": "Python",
      "description": "Instantiate SourceManager: Test that initialization doesn't overwrite existing registry.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 64,
      "line_end": 64,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: temp_config_dir",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2540510b",
      "test_name": "test_add_source_minimal",
      "category": "instantiation",
      "code": "source = source_manager.add_source(name='team', git_url='https://github.com/myorg/configs.git')",
      "language": "Python",
      "description": "Instantiate add_source: Test adding source with minimal parameters.",
      "expected_behavior": "assert source['name'] == 'team'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 84,
      "line_end": 86,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: source_manager",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dc321188",
      "test_name": "test_add_source_full_parameters",
      "category": "instantiation",
      "code": "source = source_manager.add_source(name='company', git_url='https://gitlab.company.com/platform/configs.git', source_type='gitlab', token_env='CUSTOM_TOKEN', branch='develop', priority=1, enabled=False)",
      "language": "Python",
      "description": "Instantiate add_source: Test adding source with all parameters.",
      "expected_behavior": "assert source['name'] == 'company'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 100,
      "line_end": 108,
      "complexity_score": 0.45,
      "confidence": 0.8,
      "setup_code": "# Fixtures: source_manager",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1ef899de",
      "test_name": "test_add_source_normalizes_name",
      "category": "instantiation",
      "code": "source = source_manager.add_source(name='MyTeam', git_url='https://github.com/org/repo.git')",
      "language": "Python",
      "description": "Instantiate add_source: Test that source names are normalized to lowercase.",
      "expected_behavior": "assert source['name'] == 'myteam'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 119,
      "line_end": 119,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: source_manager",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "aa87d06b",
      "test_name": "test_add_source_valid_name_with_hyphens",
      "category": "instantiation",
      "code": "source = source_manager.add_source(name='team-alpha', git_url='https://github.com/org/repo.git')",
      "language": "Python",
      "description": "Instantiate add_source: Test that source names with hyphens are allowed.",
      "expected_behavior": "assert source['name'] == 'team-alpha'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 137,
      "line_end": 139,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: source_manager",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "20d61150",
      "test_name": "test_add_source_valid_name_with_underscores",
      "category": "instantiation",
      "code": "source = source_manager.add_source(name='team_alpha', git_url='https://github.com/org/repo.git')",
      "language": "Python",
      "description": "Instantiate add_source: Test that source names with underscores are allowed.",
      "expected_behavior": "assert source['name'] == 'team_alpha'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_source_manager.py",
      "line_start": 145,
      "line_end": 147,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: source_manager",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "pytest",
        "skill_seekers.mcp.source_manager"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cf3d2039",
      "test_name": "sample_skill_dir",
      "category": "workflow",
      "code": "'Create a sample skill for integration testing.'\nskill_dir = tmp_path / 'test_integration_skill'\nskill_dir.mkdir()\nskill_md = '# Integration Test Skill\\n\\nThis is a test skill for integration testing with vector databases.\\n\\n## Core Concepts\\n\\n- Concept 1: Understanding vector embeddings\\n- Concept 2: Similarity search algorithms\\n- Concept 3: Metadata filtering\\n\\n## Quick Start\\n\\nGet started with vector databases in 3 steps:\\n1. Initialize your database\\n2. Upload your documents\\n3. Query with semantic search\\n'\n(skill_dir / 'SKILL.md').write_text(skill_md)\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\nreferences = {'api_reference.md': '# API Reference\\n\\n## Core Functions\\n\\n### add_documents(documents, metadata)\\nAdd documents to the vector database.\\n\\n### query(text, limit=10)\\nQuery the database with semantic search.\\n\\n### delete_collection(name)\\nDelete a collection from the database.\\n', 'getting_started.md': '# Getting Started\\n\\n## Installation\\n\\n```bash\\npip install vector-db-client\\n```\\n\\n## Basic Usage\\n\\n```python\\nfrom vector_db import Client\\n\\nclient = Client(\"http://localhost:8080\")\\nclient.add_documents([\"doc1\", \"doc2\"])\\nresults = client.query(\"search query\")\\n```\\n', 'advanced_features.md': '# Advanced Features\\n\\n## Hybrid Search\\n\\nCombine keyword and vector search for better results.\\n\\n## Metadata Filtering\\n\\nFilter results based on metadata attributes.\\n\\n## Multi-modal Search\\n\\nSearch across text, images, and audio.\\n'}\nfor filename, content in references.items():\n    (refs_dir / filename).write_text(content)\nreturn skill_dir",
      "language": "Python",
      "description": "Workflow: Create a sample skill for integration testing.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 29,
      "line_end": 109,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a2f1403c",
      "test_name": "test_chroma_query_filtering",
      "category": "workflow",
      "code": "'Test metadata filtering in ChromaDB queries.'\ntry:\n    import chromadb\nexcept ImportError:\n    pytest.skip('chromadb not installed')\nif not check_service_available('http://localhost:8000/api/v1/heartbeat'):\n    pytest.skip('ChromaDB not running')\ntry:\n    client = chromadb.HttpClient(host='localhost', port=8000)\n    client.heartbeat()\nexcept Exception as e:\n    pytest.skip(f'Cannot connect to ChromaDB: {e}')\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='chroma_filter_test', description='Test filtering capabilities')\npackage_path = adaptor.package(sample_skill_dir, tmp_path)\nwith open(package_path) as f:\n    data = json.load(f)\ncollection_name = data['collection_name']\ntry:\n    collection = client.get_or_create_collection(name=collection_name)\n    collection.add(documents=data['documents'], metadatas=data['metadatas'], ids=data['ids'])\n    time.sleep(1)\n    results = collection.get(where={'category': 'getting started'})\n    assert len(results['documents']) > 0, 'No documents matched filter'\n    for metadata in results['metadatas']:\n        assert metadata['category'] == 'getting started', 'Filter returned wrong category'\nfinally:\n    with contextlib.suppress(Exception):\n        client.delete_collection(name=collection_name)",
      "language": "Python",
      "description": "Workflow: Test metadata filtering in ChromaDB queries.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 357,
      "line_end": 403,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1da217a2",
      "test_name": "test_complete_workflow_with_weaviate",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('weaviate')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test: package \u2192 upload to Weaviate \u2192 query \u2192 verify.",
      "expected_behavior": "assert package_path.exists(), 'Package not created'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 149,
      "line_end": 149,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e322baa5",
      "test_name": "test_complete_workflow_with_weaviate",
      "category": "instantiation",
      "code": "package_path = adaptor.package(sample_skill_dir, tmp_path)",
      "language": "Python",
      "description": "Instantiate package: Test: package \u2192 upload to Weaviate \u2192 query \u2192 verify.",
      "expected_behavior": "assert package_path.exists(), 'Package not created'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 151,
      "line_end": 151,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "88545473",
      "test_name": "test_complete_workflow_with_weaviate",
      "category": "instantiation",
      "code": "client = weaviate.Client('http://localhost:8080')",
      "language": "Python",
      "description": "Instantiate Client: Test: package \u2192 upload to Weaviate \u2192 query \u2192 verify.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 143,
      "line_end": 143,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1da217a2",
      "test_name": "test_weaviate_metadata_preservation",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('weaviate')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that metadata is correctly stored and retrieved.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 229,
      "line_end": 229,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e322baa5",
      "test_name": "test_weaviate_metadata_preservation",
      "category": "instantiation",
      "code": "package_path = adaptor.package(sample_skill_dir, tmp_path)",
      "language": "Python",
      "description": "Instantiate package: Test that metadata is correctly stored and retrieved.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 237,
      "line_end": 237,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "88545473",
      "test_name": "test_weaviate_metadata_preservation",
      "category": "instantiation",
      "code": "client = weaviate.Client('http://localhost:8080')",
      "language": "Python",
      "description": "Instantiate Client: Test that metadata is correctly stored and retrieved.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 223,
      "line_end": 223,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ac42b59",
      "test_name": "test_complete_workflow_with_chroma",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('chroma')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test: package \u2192 upload to Chroma \u2192 query \u2192 verify.",
      "expected_behavior": "assert package_path.exists(), 'Package not created'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 299,
      "line_end": 299,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e322baa5",
      "test_name": "test_complete_workflow_with_chroma",
      "category": "instantiation",
      "code": "package_path = adaptor.package(sample_skill_dir, tmp_path)",
      "language": "Python",
      "description": "Instantiate package: Test: package \u2192 upload to Chroma \u2192 query \u2192 verify.",
      "expected_behavior": "assert package_path.exists(), 'Package not created'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_integration_adaptors.py",
      "line_start": 303,
      "line_end": 303,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "time",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "contextlib",
        "sys",
        "requests",
        "weaviate",
        "weaviate",
        "chromadb",
        "chromadb",
        "qdrant_client",
        "qdrant_client.models",
        "qdrant_client",
        "qdrant_client.models"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "620cefa1",
      "test_name": "test_factory_method_detection",
      "category": "workflow",
      "code": "'Test detection of create/make methods'\ncode = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Factory']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertIn('create', ' '.join(pattern.evidence).lower())",
      "language": "Python",
      "description": "Workflow: Test detection of create/make methods",
      "expected_behavior": "self.assertIn('create', ' '.join(pattern.evidence).lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 135,
      "line_end": 153,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "self.detector = FactoryDetector(depth='deep')\nself.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0f757575",
      "test_name": "test_observer_triplet_detection",
      "category": "workflow",
      "code": "'Test classic attach/detach/notify triplet'\ncode = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Observer']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertGreaterEqual(pattern.confidence, 0.8)\nevidence_str = ' '.join(pattern.evidence).lower()\nself.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
      "language": "Python",
      "description": "Workflow: Test classic attach/detach/notify triplet",
      "expected_behavior": "self.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 199,
      "line_end": 225,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.detector = ObserverDetector(depth='deep')\nself.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "db79e8d6",
      "test_name": "test_pattern_report_summary",
      "category": "workflow",
      "code": "'Test PatternReport.get_summary() method'\ncode = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'\nreport = self.recognizer.analyze_file('logging.py', code, 'Python')\nsummary = report.get_summary()\nself.assertIsInstance(summary, dict)\nif summary:\n    total_count = sum(summary.values())\n    self.assertGreater(total_count, 0)",
      "language": "Python",
      "description": "Workflow: Test PatternReport.get_summary() method",
      "expected_behavior": "self.assertIsInstance(summary, dict)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 329,
      "line_end": 350,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "self.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "620cefa1",
      "test_name": "test_factory_method_detection",
      "category": "workflow",
      "code": "'Test detection of create/make methods'\ncode = \"\\nclass VehicleFactory:\\n    def create(self, vehicle_type):\\n        if vehicle_type == 'car':\\n            return Car()\\n        elif vehicle_type == 'truck':\\n            return Truck()\\n\\n    def make_vehicle(self, specs):\\n        return Vehicle(specs)\\n\"\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Factory']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertIn('create', ' '.join(pattern.evidence).lower())",
      "language": "Python",
      "description": "Workflow: Test detection of create/make methods",
      "expected_behavior": "self.assertIn('create', ' '.join(pattern.evidence).lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 135,
      "line_end": 153,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0f757575",
      "test_name": "test_observer_triplet_detection",
      "category": "workflow",
      "code": "'Test classic attach/detach/notify triplet'\ncode = '\\nclass Subject:\\n    def __init__(self):\\n        self.observers = []\\n\\n    def attach(self, observer):\\n        self.observers.append(observer)\\n\\n    def detach(self, observer):\\n        self.observers.remove(observer)\\n\\n    def notify(self):\\n        for observer in self.observers:\\n            observer.update()\\n'\nreport = self.recognizer.analyze_file('test.py', code, 'Python')\npatterns = [p for p in report.patterns if p.pattern_type == 'Observer']\nself.assertGreater(len(patterns), 0)\npattern = patterns[0]\nself.assertGreaterEqual(pattern.confidence, 0.8)\nevidence_str = ' '.join(pattern.evidence).lower()\nself.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
      "language": "Python",
      "description": "Workflow: Test classic attach/detach/notify triplet",
      "expected_behavior": "self.assertTrue('attach' in evidence_str and 'detach' in evidence_str and ('notify' in evidence_str))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 199,
      "line_end": 225,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "db79e8d6",
      "test_name": "test_pattern_report_summary",
      "category": "workflow",
      "code": "'Test PatternReport.get_summary() method'\ncode = '\\nclass LoggerSingleton:\\n    _instance = None\\n\\n    def getInstance(self):\\n        return self._instance\\n\\nclass LoggerFactory:\\n    def create_logger(self, type):\\n        return Logger(type)\\n'\nreport = self.recognizer.analyze_file('logging.py', code, 'Python')\nsummary = report.get_summary()\nself.assertIsInstance(summary, dict)\nif summary:\n    total_count = sum(summary.values())\n    self.assertGreater(total_count, 0)",
      "language": "Python",
      "description": "Workflow: Test PatternReport.get_summary() method",
      "expected_behavior": "self.assertIsInstance(summary, dict)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 329,
      "line_end": 350,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "26d729f7",
      "test_name": "test_surface_detection_by_name",
      "category": "method_call",
      "code": "self.assertEqual(pattern.pattern_type, 'Singleton')\nself.assertGreaterEqual(pattern.confidence, 0.5)",
      "language": "Python",
      "description": "Test surface detection using class name",
      "expected_behavior": "self.assertGreaterEqual(pattern.confidence, 0.5)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 48,
      "line_end": 51,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "self.detector = SingletonDetector(depth='deep')\nself.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9f054739",
      "test_name": "test_surface_detection_by_name",
      "category": "method_call",
      "code": "self.assertGreaterEqual(pattern.confidence, 0.5)\nself.assertIn('Singleton', pattern.class_name)",
      "language": "Python",
      "description": "Test surface detection using class name",
      "expected_behavior": "self.assertIn('Singleton', pattern.class_name)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 51,
      "line_end": 52,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "self.detector = SingletonDetector(depth='deep')\nself.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5cf5a7a2",
      "test_name": "test_deep_detection_with_instance_method",
      "category": "method_call",
      "code": "self.assertIsNotNone(report)\nself.assertEqual(report.language, 'Python')",
      "language": "Python",
      "description": "Test deep detection with getInstance() method",
      "expected_behavior": "self.assertEqual(report.language, 'Python')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 68,
      "line_end": 69,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "self.detector = SingletonDetector(depth='deep')\nself.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "863be73b",
      "test_name": "test_python_singleton_with_new",
      "category": "method_call",
      "code": "self.assertIsNotNone(report)\nself.assertGreaterEqual(report.total_classes, 1)",
      "language": "Python",
      "description": "Test Python-specific __new__ singleton pattern",
      "expected_behavior": "self.assertGreaterEqual(report.total_classes, 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pattern_recognizer.py",
      "line_start": 86,
      "line_end": 87,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "self.detector = SingletonDetector(depth='deep')\nself.recognizer = PatternRecognizer(depth='deep')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.pattern_recognizer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5eccf782",
      "test_name": "test_generator_compute_hash",
      "category": "workflow",
      "code": "'Test hash computation.'\nhash1 = EmbeddingGenerator.compute_hash('text1', 'model1')\nhash2 = EmbeddingGenerator.compute_hash('text1', 'model1')\nhash3 = EmbeddingGenerator.compute_hash('text2', 'model1')\nhash4 = EmbeddingGenerator.compute_hash('text1', 'model2')\nassert hash1 == hash2\nassert hash1 != hash3\nassert hash1 != hash4",
      "language": "Python",
      "description": "Workflow: Test hash computation.",
      "expected_behavior": "assert hash1 != hash4",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 165,
      "line_end": 179,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7c8131cf",
      "test_name": "test_cache_persistence",
      "category": "workflow",
      "code": "'Test cache persistence to file.'\nwith tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp:\n    tmp_path = tmp.name\ntry:\n    cache1 = EmbeddingCache(tmp_path)\n    cache1.set('hash1', [0.1, 0.2, 0.3], 'model1')\n    cache1.close()\n    cache2 = EmbeddingCache(tmp_path)\n    retrieved = cache2.get('hash1')\n    assert retrieved == [0.1, 0.2, 0.3]\n    cache2.close()\nfinally:\n    Path(tmp_path).unlink(missing_ok=True)",
      "language": "Python",
      "description": "Workflow: Test cache persistence to file.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 349,
      "line_end": 367,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "884f0bfe",
      "test_name": "test_cache_has",
      "category": "method_call",
      "code": "cache.set('hash123', embedding, 'test-model')\nassert cache.has('hash123') is True",
      "language": "Python",
      "description": "Test cache has method.",
      "expected_behavior": "assert cache.has('hash123') is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 52,
      "line_end": 54,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "884f0bfe",
      "test_name": "test_cache_delete",
      "category": "method_call",
      "code": "cache.set('hash123', embedding, 'test-model')\nassert cache.has('hash123') is True",
      "language": "Python",
      "description": "Test cache deletion.",
      "expected_behavior": "assert cache.has('hash123') is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 63,
      "line_end": 65,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8ed915df",
      "test_name": "test_cache_delete",
      "category": "method_call",
      "code": "cache.delete('hash123')\nassert cache.has('hash123') is False",
      "language": "Python",
      "description": "Test cache deletion.",
      "expected_behavior": "assert cache.has('hash123') is False",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 67,
      "line_end": 69,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8c18eb71",
      "test_name": "test_cache_clear",
      "category": "method_call",
      "code": "cache.set('hash3', [0.3], 'model1')\nassert cache.size() == 3",
      "language": "Python",
      "description": "Test cache clearing.",
      "expected_behavior": "assert cache.size() == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 78,
      "line_end": 80,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e47e6d95",
      "test_name": "test_cache_init",
      "category": "instantiation",
      "code": "cache = EmbeddingCache(':memory:')",
      "language": "Python",
      "description": "Instantiate EmbeddingCache: Test cache initialization.",
      "expected_behavior": "assert cache.size() == 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 32,
      "line_end": 32,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e47e6d95",
      "test_name": "test_cache_set_get",
      "category": "instantiation",
      "code": "cache = EmbeddingCache(':memory:')",
      "language": "Python",
      "description": "Instantiate EmbeddingCache: Test cache set and get.",
      "expected_behavior": "assert retrieved == embedding",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 38,
      "line_end": 38,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "34b752d6",
      "test_name": "test_cache_set_get",
      "category": "instantiation",
      "code": "retrieved = cache.get('hash123')",
      "language": "Python",
      "description": "Instantiate get: Test cache set and get.",
      "expected_behavior": "assert retrieved == embedding",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e47e6d95",
      "test_name": "test_cache_has",
      "category": "instantiation",
      "code": "cache = EmbeddingCache(':memory:')",
      "language": "Python",
      "description": "Instantiate EmbeddingCache: Test cache has method.",
      "expected_behavior": "assert cache.has('hash123') is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding.py",
      "line_start": 49,
      "line_end": 49,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.embedding.models",
        "skill_seekers.embedding.generator",
        "skill_seekers.embedding.cache",
        "numpy"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d534fd8c",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'openai')\nself.assertEqual(self.adaptor.PLATFORM_NAME, 'OpenAI ChatGPT')",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'OpenAI ChatGPT')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1fb742e0",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'OpenAI ChatGPT')\nself.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c2d0a439",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('sk-proj-abc123'))\nself.assertTrue(self.adaptor.validate_api_key('sk-abc123'))",
      "language": "Python",
      "description": "Test valid OpenAI API keys",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('sk-abc123'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 30,
      "line_end": 31,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "44d440f6",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('sk-abc123'))\nself.assertTrue(self.adaptor.validate_api_key('  sk-test  '))",
      "language": "Python",
      "description": "Test valid OpenAI API keys",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('  sk-test  '))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 31,
      "line_end": 32,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc71d5e0",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))\nself.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 36,
      "line_end": 38,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1efcb246",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('invalid'))\nself.assertFalse(self.adaptor.validate_api_key(''))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key(''))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 38,
      "line_end": 39,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "95804c2a",
      "test_name": "test_upload_invalid_file",
      "category": "method_call",
      "code": "self.assertFalse(result['success'])\nself.assertIn('not found', result['message'].lower())",
      "language": "Python",
      "description": "Test upload with invalid file",
      "expected_behavior": "self.assertIn('not found', result['message'].lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 113,
      "line_end": 114,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('openai')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d534fd8c",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'openai')\nself.assertEqual(self.adaptor.PLATFORM_NAME, 'OpenAI ChatGPT')",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'OpenAI ChatGPT')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1fb742e0",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'OpenAI ChatGPT')\nself.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c2d0a439",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('sk-proj-abc123'))\nself.assertTrue(self.adaptor.validate_api_key('sk-abc123'))",
      "language": "Python",
      "description": "Test valid OpenAI API keys",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('sk-abc123'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_openai_adaptor.py",
      "line_start": 30,
      "line_end": 31,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4b5beb85",
      "test_name": "test_validate_existing_unified_configs",
      "category": "instantiation",
      "code": "validator = validate_config(str(config_path))",
      "language": "Python",
      "description": "Instantiate validate_config: Test that all existing unified configs are valid",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 35,
      "line_end": 35,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4b5beb85",
      "test_name": "test_backward_compatibility",
      "category": "instantiation",
      "code": "validator = validate_config(str(config_path))",
      "language": "Python",
      "description": "Instantiate validate_config: Test that legacy configs still work",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 52,
      "line_end": 52,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "080c7a51",
      "test_name": "test_create_temp_unified_config",
      "category": "instantiation",
      "code": "validator = validate_config(config_path)",
      "language": "Python",
      "description": "Instantiate validate_config: Test creating a unified config from scratch",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 85,
      "line_end": 85,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1ca1501c",
      "test_name": "test_create_temp_unified_config",
      "category": "config",
      "code": "config = {'name': 'test_unified', 'description': 'Test unified config', 'merge_mode': 'rule-based', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com/docs', 'extract_api': True, 'max_pages': 50}, {'type': 'github', 'repo': 'test/repo', 'include_code': True, 'code_analysis_depth': 'surface'}]}",
      "language": "Python",
      "description": "Configuration example: Test creating a unified config from scratch",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 59,
      "line_end": 77,
      "complexity_score": 0.65,
      "confidence": 0.75,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "080c7a51",
      "test_name": "test_mixed_source_types",
      "category": "instantiation",
      "code": "validator = validate_config(config_path)",
      "language": "Python",
      "description": "Instantiate validate_config: Test config with documentation, GitHub, and PDF sources",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 114,
      "line_end": 114,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a10d21d5",
      "test_name": "test_mixed_source_types",
      "category": "config",
      "code": "config = {'name': 'test_mixed', 'description': 'Test mixed sources', 'merge_mode': 'rule-based', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com'}, {'type': 'github', 'repo': 'test/repo'}, {'type': 'pdf', 'path': '/path/to/manual.pdf'}]}",
      "language": "Python",
      "description": "Configuration example: Test config with documentation, GitHub, and PDF sources",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 97,
      "line_end": 106,
      "complexity_score": 0.55,
      "confidence": 0.75,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "228969bc",
      "test_name": "test_config_validation_errors",
      "category": "instantiation",
      "code": "_validator = validate_config(config_path)",
      "language": "Python",
      "description": "Instantiate validate_config: Test that invalid configs are rejected",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 145,
      "line_end": 145,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f71cbfac",
      "test_name": "test_config_validation_errors",
      "category": "config",
      "code": "config = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'invalid_type', 'url': 'https://example.com'}]}",
      "language": "Python",
      "description": "Configuration example: Test that invalid configs are rejected",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\src\\skill_seekers\\cli\\test_unified_simple.py",
      "line_start": 131,
      "line_end": 135,
      "complexity_score": 0.3,
      "confidence": 0.75,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "pathlib",
        "config_validator",
        "traceback"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d5c87b7c",
      "test_name": "test_vector_databases",
      "category": "instantiation",
      "code": "adaptor = get_adaptor(target)",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test all 4 vector database adaptors.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 31,
      "line_end": 31,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "45ecab0f",
      "test_name": "test_vector_databases",
      "category": "instantiation",
      "code": "package_path = adaptor.package(skill_dir, Path(tmpdir))",
      "language": "Python",
      "description": "Instantiate package: Test all 4 vector database adaptors.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 32,
      "line_end": 32,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a0151bc6",
      "test_name": "test_streaming",
      "category": "instantiation",
      "code": "ingester = StreamingIngester(chunk_size=1000, chunk_overlap=100)",
      "language": "Python",
      "description": "Instantiate StreamingIngester: Test streaming ingestion.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 50,
      "line_end": 50,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "530f7a8e",
      "test_name": "test_streaming",
      "category": "instantiation",
      "code": "chunks = list(ingester.chunk_document(large_content, {'source': 'test'}))",
      "language": "Python",
      "description": "Instantiate list: Test streaming ingestion.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 52,
      "line_end": 55,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "73750624",
      "test_name": "test_incremental",
      "category": "instantiation",
      "code": "updater = IncrementalUpdater(skill_dir)",
      "language": "Python",
      "description": "Instantiate IncrementalUpdater: Test incremental updates.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 87,
      "line_end": 87,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f088fda6",
      "test_name": "test_incremental",
      "category": "instantiation",
      "code": "updater2 = IncrementalUpdater(skill_dir)",
      "language": "Python",
      "description": "Instantiate IncrementalUpdater: Test incremental updates.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 99,
      "line_end": 99,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3085b732",
      "test_name": "test_multilang",
      "category": "instantiation",
      "code": "en_detected = detector.detect(en_text)",
      "language": "Python",
      "description": "Instantiate detect: Test multi-language support.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 130,
      "line_end": 130,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d4bdcbab",
      "test_name": "test_multilang",
      "category": "instantiation",
      "code": "es_detected = detector.detect(es_text)",
      "language": "Python",
      "description": "Instantiate detect: Test multi-language support.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 131,
      "line_end": 131,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "008a1604",
      "test_name": "test_embeddings",
      "category": "instantiation",
      "code": "config = EmbeddingConfig(provider='local', model='test-model', dimension=64, batch_size=10, cache_dir=Path(tmpdir))",
      "language": "Python",
      "description": "Instantiate EmbeddingConfig: Test embedding pipeline.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 166,
      "line_end": 172,
      "complexity_score": 0.35,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "206c2c79",
      "test_name": "test_embeddings",
      "category": "instantiation",
      "code": "pipeline = EmbeddingPipeline(config)",
      "language": "Python",
      "description": "Instantiate EmbeddingPipeline: Test embedding pipeline.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\test_week2_features.py",
      "line_start": 174,
      "line_end": 174,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pathlib",
        "tempfile",
        "shutil",
        "skill_seekers.cli.adaptors",
        "json",
        "skill_seekers.cli.streaming_ingest",
        "skill_seekers.cli.incremental_updater",
        "time",
        "skill_seekers.cli.multilang_support",
        "skill_seekers.cli.embedding_pipeline",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1bcc7bef",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as Haystack Documents.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for Haystack format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('haystack')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert len(documents) == 3\nfor doc in documents:\n    assert 'content' in doc\n    assert 'meta' in doc\n    assert doc['meta']['source'] == 'test_skill'\n    assert doc['meta']['version'] == '1.0.0'\n    assert 'category' in doc['meta']\n    assert 'file' in doc['meta']\n    assert 'type' in doc['meta']\ncategories = {doc['meta']['category'] for doc in documents}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as Haystack Documents.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 23,
      "line_end": 63,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "debccbb5",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('haystack')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'haystack' in output_path.name\nwith open(output_path) as f:\n    documents = json.load(f)\nassert isinstance(documents, list)\nassert len(documents) > 0\nassert 'content' in documents[0]\nassert 'meta' in documents[0]",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert 'meta' in documents[0]",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 65,
      "line_end": 88,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "10b47c9f",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('haystack')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-haystack.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'haystack' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'haystack' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 90,
      "line_end": 105,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1f9c661f",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('haystack')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert documents == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert documents == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 147,
      "line_end": 159,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f03e7f0d",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('haystack')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert len(documents) == 1\nassert documents[0]['meta']['category'] == 'test'\nassert documents[0]['meta']['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert documents[0]['meta']['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 161,
      "line_end": 178,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "598af4a3",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('haystack')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that Haystack adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'haystack'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "598af4a3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('haystack')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as Haystack Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as Haystack Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ff9f3248",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "documents_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as Haystack Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d9612045",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "documents = json.loads(documents_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as Haystack Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_haystack_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "00c9a61d",
      "test_name": "test_walk_with_subdirectories",
      "category": "workflow",
      "code": "'Test walking nested directory structure.'\nsrc_dir = self.root / 'src'\nsrc_dir.mkdir()\n(src_dir / 'module.py').write_text('test')\ntests_dir = self.root / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_module.py').write_text('test')\nfiles = walk_directory(self.root)\nself.assertEqual(len(files), 2)\nfilenames = [f.name for f in files]\nself.assertIn('module.py', filenames)\nself.assertIn('test_module.py', filenames)",
      "language": "Python",
      "description": "Workflow: Test walking nested directory structure.",
      "expected_behavior": "self.assertIn('test_module.py', filenames)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 159,
      "line_end": 176,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.root = Path(self.temp_dir)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3c7c2450",
      "test_name": "test_no_duplicate_directories_created",
      "category": "workflow",
      "code": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'\ntest_dirs = ['documentation', 'api_reference', 'patterns']\nfor dir_name in test_dirs:\n    dir_path = self.output_dir / dir_name\n    dir_path.mkdir()\n    (dir_path / 'test.txt').write_text(f'Test content for {dir_name}')\n_generate_references(self.output_dir)\nreferences_dir = self.output_dir / 'references'\nself.assertTrue(references_dir.exists(), 'references/ should exist')\nfor dir_name in test_dirs:\n    ref_path = references_dir / dir_name\n    self.assertTrue(ref_path.exists(), f'references/{dir_name} should exist')\n    self.assertTrue((ref_path / 'test.txt').exists(), f'references/{dir_name}/test.txt should exist')\nfor dir_name in test_dirs:\n    source_path = self.output_dir / dir_name\n    self.assertFalse(source_path.exists(), f'Source directory {dir_name}/ should be cleaned up to avoid duplication')",
      "language": "Python",
      "description": "Workflow: Test that source directories are cleaned up after copying to references/ (Issue #279).",
      "expected_behavior": "self.assertTrue(references_dir.exists(), 'references/ should exist')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 411,
      "line_end": 443,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6c4cfcff",
      "test_name": "test_no_disk_space_wasted",
      "category": "workflow",
      "code": "'Test that disk space is not wasted by duplicate directories.'\ndoc_dir = self.output_dir / 'documentation'\ndoc_dir.mkdir()\ntest_content = 'x' * 1000\n(doc_dir / 'large_file.txt').write_text(test_content)\n_generate_references(self.output_dir)\nref_doc_dir = self.output_dir / 'references' / 'documentation'\nsource_doc_dir = self.output_dir / 'documentation'\nself.assertTrue(ref_doc_dir.exists(), 'references/documentation/ should exist')\nself.assertFalse(source_doc_dir.exists(), 'Source documentation/ should not exist (cleaned up)')\nself.assertTrue((ref_doc_dir / 'large_file.txt').exists(), 'File should exist in references/')\nself.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
      "language": "Python",
      "description": "Workflow: Test that disk space is not wasted by duplicate directories.",
      "expected_behavior": "self.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 445,
      "line_end": 473,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Create temporary directory for testing.'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "00c9a61d",
      "test_name": "test_walk_with_subdirectories",
      "category": "workflow",
      "code": "'Test walking nested directory structure.'\nsrc_dir = self.root / 'src'\nsrc_dir.mkdir()\n(src_dir / 'module.py').write_text('test')\ntests_dir = self.root / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_module.py').write_text('test')\nfiles = walk_directory(self.root)\nself.assertEqual(len(files), 2)\nfilenames = [f.name for f in files]\nself.assertIn('module.py', filenames)\nself.assertIn('test_module.py', filenames)",
      "language": "Python",
      "description": "Workflow: Test walking nested directory structure.",
      "expected_behavior": "self.assertIn('test_module.py', filenames)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 159,
      "line_end": 176,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3c7c2450",
      "test_name": "test_no_duplicate_directories_created",
      "category": "workflow",
      "code": "'Test that source directories are cleaned up after copying to references/ (Issue #279).'\ntest_dirs = ['documentation', 'api_reference', 'patterns']\nfor dir_name in test_dirs:\n    dir_path = self.output_dir / dir_name\n    dir_path.mkdir()\n    (dir_path / 'test.txt').write_text(f'Test content for {dir_name}')\n_generate_references(self.output_dir)\nreferences_dir = self.output_dir / 'references'\nself.assertTrue(references_dir.exists(), 'references/ should exist')\nfor dir_name in test_dirs:\n    ref_path = references_dir / dir_name\n    self.assertTrue(ref_path.exists(), f'references/{dir_name} should exist')\n    self.assertTrue((ref_path / 'test.txt').exists(), f'references/{dir_name}/test.txt should exist')\nfor dir_name in test_dirs:\n    source_path = self.output_dir / dir_name\n    self.assertFalse(source_path.exists(), f'Source directory {dir_name}/ should be cleaned up to avoid duplication')",
      "language": "Python",
      "description": "Workflow: Test that source directories are cleaned up after copying to references/ (Issue #279).",
      "expected_behavior": "self.assertTrue(references_dir.exists(), 'references/ should exist')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 411,
      "line_end": 443,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6c4cfcff",
      "test_name": "test_no_disk_space_wasted",
      "category": "workflow",
      "code": "'Test that disk space is not wasted by duplicate directories.'\ndoc_dir = self.output_dir / 'documentation'\ndoc_dir.mkdir()\ntest_content = 'x' * 1000\n(doc_dir / 'large_file.txt').write_text(test_content)\n_generate_references(self.output_dir)\nref_doc_dir = self.output_dir / 'references' / 'documentation'\nsource_doc_dir = self.output_dir / 'documentation'\nself.assertTrue(ref_doc_dir.exists(), 'references/documentation/ should exist')\nself.assertFalse(source_doc_dir.exists(), 'Source documentation/ should not exist (cleaned up)')\nself.assertTrue((ref_doc_dir / 'large_file.txt').exists(), 'File should exist in references/')\nself.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
      "language": "Python",
      "description": "Workflow: Test that disk space is not wasted by duplicate directories.",
      "expected_behavior": "self.assertEqual((ref_doc_dir / 'large_file.txt').read_text(), test_content, 'File content should be preserved')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 445,
      "line_end": 473,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "136efcc9",
      "test_name": "test_javascript_detection",
      "category": "method_call",
      "code": "self.assertEqual(detect_language(Path('test.js')), 'JavaScript')\nself.assertEqual(detect_language(Path('test.jsx')), 'JavaScript')",
      "language": "Python",
      "description": "Test JavaScript file detection.",
      "expected_behavior": "self.assertEqual(detect_language(Path('test.jsx')), 'JavaScript')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 48,
      "line_end": 49,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "624d2102",
      "test_name": "test_typescript_detection",
      "category": "method_call",
      "code": "self.assertEqual(detect_language(Path('test.ts')), 'TypeScript')\nself.assertEqual(detect_language(Path('test.tsx')), 'TypeScript')",
      "language": "Python",
      "description": "Test TypeScript file detection.",
      "expected_behavior": "self.assertEqual(detect_language(Path('test.tsx')), 'TypeScript')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 53,
      "line_end": 54,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "056f9603",
      "test_name": "test_cpp_detection",
      "category": "method_call",
      "code": "self.assertEqual(detect_language(Path('test.cpp')), 'C++')\nself.assertEqual(detect_language(Path('test.h')), 'C++')",
      "language": "Python",
      "description": "Test C++ file detection.",
      "expected_behavior": "self.assertEqual(detect_language(Path('test.h')), 'C++')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 58,
      "line_end": 59,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ac8eaf6f",
      "test_name": "test_cpp_detection",
      "category": "method_call",
      "code": "self.assertEqual(detect_language(Path('test.h')), 'C++')\nself.assertEqual(detect_language(Path('test.hpp')), 'C++')",
      "language": "Python",
      "description": "Test C++ file detection.",
      "expected_behavior": "self.assertEqual(detect_language(Path('test.hpp')), 'C++')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_codebase_scraper.py",
      "line_start": 59,
      "line_end": 60,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.codebase_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7d2e56e4",
      "test_name": "test_parse_markdown_sections",
      "category": "instantiation",
      "code": "parser = LlmsTxtParser(sample_content)",
      "language": "Python",
      "description": "Instantiate LlmsTxtParser: Test parsing markdown into page sections",
      "expected_behavior": "assert len(pages) >= 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_llms_txt_parser.py",
      "line_start": 27,
      "line_end": 27,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "skill_seekers.cli.llms_txt_parser"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "136845d4",
      "test_name": "test_server_initialization",
      "category": "instantiation",
      "code": "app = mcp.server.Server('test-skill-seeker')",
      "language": "Python",
      "description": "Instantiate Server: Test server initializes correctly",
      "expected_behavior": "self.assertEqual(app.name, 'test-skill-seeker')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_server.py",
      "line_start": 61,
      "line_end": 61,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "mcp.server",
        "mcp.types",
        "skill_seekers.mcp",
        "mcp",
        "mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "136845d4",
      "test_name": "test_server_initialization",
      "category": "instantiation",
      "code": "app = mcp.server.Server('test-skill-seeker')",
      "language": "Python",
      "description": "Instantiate Server: Test server initializes correctly",
      "expected_behavior": "self.assertEqual(app.name, 'test-skill-seeker')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_server.py",
      "line_start": 61,
      "line_end": 61,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "unittest.mock",
        "mcp.server",
        "mcp.types",
        "skill_seekers.mcp",
        "mcp",
        "mcp.server"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7757584e",
      "test_name": "test_build_agent_command_claude",
      "category": "workflow",
      "code": "'Test Claude Code command building.'\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='claude')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, True)\nassert cmd_parts[0] == 'claude'\nassert '--dangerously-skip-permissions' in cmd_parts\nassert prompt_file in cmd_parts\nassert uses_file is True",
      "language": "Python",
      "description": "Workflow: Test Claude Code command building.",
      "expected_behavior": "assert uses_file is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 32,
      "line_end": 43,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7a9d3a78",
      "test_name": "test_build_agent_command_codex",
      "category": "workflow",
      "code": "'Test Codex CLI command building.'\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='codex')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)\nassert cmd_parts[0] == 'codex'\nassert 'exec' in cmd_parts\nassert '--full-auto' in cmd_parts\nassert '--skip-git-repo-check' in cmd_parts\nassert uses_file is False",
      "language": "Python",
      "description": "Workflow: Test Codex CLI command building.",
      "expected_behavior": "assert uses_file is False",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 45,
      "line_end": 57,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "75f0193a",
      "test_name": "test_build_agent_command_custom_with_placeholder",
      "category": "workflow",
      "code": "'Test custom command with {prompt_file} placeholder.'\n_allow_executable(monkeypatch, name='my-agent')\nskill_dir = _make_skill_dir(tmp_path)\nenhancer = LocalSkillEnhancer(skill_dir, agent='custom', agent_cmd='my-agent --input {prompt_file}')\nprompt_file = str(tmp_path / 'prompt.txt')\ncmd_parts, uses_file = enhancer._build_agent_command(prompt_file, False)\nassert cmd_parts[0] == 'my-agent'\nassert '--input' in cmd_parts\nassert prompt_file in cmd_parts\nassert uses_file is True",
      "language": "Python",
      "description": "Workflow: Test custom command with {prompt_file} placeholder.",
      "expected_behavior": "assert uses_file is True",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 59,
      "line_end": 75,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path, monkeypatch",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cccfe296",
      "test_name": "test_build_agent_command_claude",
      "category": "instantiation",
      "code": "skill_dir = _make_skill_dir(tmp_path)",
      "language": "Python",
      "description": "Instantiate _make_skill_dir: Test Claude Code command building.",
      "expected_behavior": "assert cmd_parts[0] == 'claude'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 34,
      "line_end": 34,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "05f3535c",
      "test_name": "test_build_agent_command_claude",
      "category": "instantiation",
      "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='claude')",
      "language": "Python",
      "description": "Instantiate LocalSkillEnhancer: Test Claude Code command building.",
      "expected_behavior": "assert cmd_parts[0] == 'claude'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 35,
      "line_end": 35,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "684185d3",
      "test_name": "test_build_agent_command_claude",
      "category": "instantiation",
      "code": "prompt_file = str(tmp_path / 'prompt.txt')",
      "language": "Python",
      "description": "Instantiate str: Test Claude Code command building.",
      "expected_behavior": "assert cmd_parts[0] == 'claude'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 36,
      "line_end": 36,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9addb4f6",
      "test_name": "test_build_agent_command_claude",
      "category": "instantiation",
      "code": "cmd_parts, uses_file = enhancer._build_agent_command(prompt_file, True)",
      "language": "Python",
      "description": "Instantiate _build_agent_command: Test Claude Code command building.",
      "expected_behavior": "assert cmd_parts[0] == 'claude'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 38,
      "line_end": 38,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cccfe296",
      "test_name": "test_build_agent_command_codex",
      "category": "instantiation",
      "code": "skill_dir = _make_skill_dir(tmp_path)",
      "language": "Python",
      "description": "Instantiate _make_skill_dir: Test Codex CLI command building.",
      "expected_behavior": "assert cmd_parts[0] == 'codex'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 47,
      "line_end": 47,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8949106f",
      "test_name": "test_build_agent_command_codex",
      "category": "instantiation",
      "code": "enhancer = LocalSkillEnhancer(skill_dir, agent='codex')",
      "language": "Python",
      "description": "Instantiate LocalSkillEnhancer: Test Codex CLI command building.",
      "expected_behavior": "assert cmd_parts[0] == 'codex'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 48,
      "line_end": 48,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "684185d3",
      "test_name": "test_build_agent_command_codex",
      "category": "instantiation",
      "code": "prompt_file = str(tmp_path / 'prompt.txt')",
      "language": "Python",
      "description": "Instantiate str: Test Codex CLI command building.",
      "expected_behavior": "assert cmd_parts[0] == 'codex'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_enhance_skill_local.py",
      "line_start": 49,
      "line_end": 49,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "77e4d66e",
      "test_name": "test_langchain_no_chunking_default",
      "category": "workflow",
      "code": "\"Test that LangChain doesn't chunk by default.\"\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) == 2, f'Expected 2 docs, got {len(data)}'\nfor doc in data:\n    assert 'is_chunked' not in doc['metadata']\n    assert 'chunk_index' not in doc['metadata']",
      "language": "Python",
      "description": "Workflow: Test that LangChain doesn't chunk by default.",
      "expected_behavior": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 59,
      "line_end": 75,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3e61e5d4",
      "test_name": "test_langchain_chunking_enabled",
      "category": "workflow",
      "code": "'Test that LangChain chunks large documents when enabled.'\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) > 2, f'Large doc should be chunked, got {len(data)} docs'\nchunked_docs = [doc for doc in data if doc['metadata'].get('is_chunked')]\nassert len(chunked_docs) > 0, 'Should have chunked documents'\nfor doc in chunked_docs:\n    assert 'chunk_index' in doc['metadata']\n    assert 'total_chunks' in doc['metadata']\n    assert 'chunk_id' in doc['metadata']",
      "language": "Python",
      "description": "Workflow: Test that LangChain chunks large documents when enabled.",
      "expected_behavior": "assert len(chunked_docs) > 0, 'Should have chunked documents'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 81,
      "line_end": 104,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5305693f",
      "test_name": "test_chunking_preserves_small_docs",
      "category": "workflow",
      "code": "'Test that small documents are not chunked.'\nskill_dir = create_test_skill(tmp_path, large_doc=False)\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=512)\nwith open(package_path) as f:\n    data = json.load(f)\nassert len(data) == 2, 'Small docs should not be chunked'\nfor doc in data:\n    assert 'is_chunked' not in doc['metadata']",
      "language": "Python",
      "description": "Workflow: Test that small documents are not chunked.",
      "expected_behavior": "assert len(data) == 2, 'Small docs should not be chunked'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 106,
      "line_end": 122,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "65dc39cd",
      "test_name": "test_preserve_code_blocks",
      "category": "workflow",
      "code": "'Test that code blocks are not split during chunking.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\ncontent = '# Test\\n\\nSome intro text that needs to be here for context.\\n\\n```python\\ndef example_function():\\n    # This code block should not be split\\n    x = 1\\n    y = 2\\n    z = 3\\n    return x + y + z\\n```\\n\\nMore content after code block.\\n' + 'Lorem ipsum dolor sit amet. ' * 1000\n(skill_dir / 'SKILL.md').write_text(content)\n(skill_dir / 'references').mkdir()\nadaptor = get_adaptor('langchain')\npackage_path = adaptor.package(skill_dir, tmp_path, enable_chunking=True, chunk_max_tokens=200, preserve_code_blocks=True)\nwith open(package_path) as f:\n    data = json.load(f)\ncode_chunks = [doc for doc in data if '```python' in doc['page_content']]\nassert len(code_chunks) >= 1, 'Code block should be preserved'\nfor chunk in code_chunks:\n    content = chunk['page_content']\n    if '```python' in content:\n        assert content.count('```') >= 2, 'Code block should be complete'",
      "language": "Python",
      "description": "Workflow: Test that code blocks are not split during chunking.",
      "expected_behavior": "assert len(code_chunks) >= 1, 'Code block should be preserved'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 128,
      "line_end": 178,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e7e0e0d9",
      "test_name": "test_maybe_chunk_content_disabled",
      "category": "workflow",
      "code": "'Test that _maybe_chunk_content returns single chunk when disabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Test content ' * 1000\nmetadata = {'source': 'test'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=False)\nassert len(chunks) == 1\nassert chunks[0][0] == content\nassert chunks[0][1] == metadata",
      "language": "Python",
      "description": "Workflow: Test that _maybe_chunk_content returns single chunk when disabled.",
      "expected_behavior": "assert chunks[0][1] == metadata",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 225,
      "line_end": 239,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f61d3115",
      "test_name": "test_maybe_chunk_content_small_doc",
      "category": "workflow",
      "code": "'Test that small docs are not chunked even when enabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Small test content'\nmetadata = {'source': 'test'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512)\nassert len(chunks) == 1",
      "language": "Python",
      "description": "Workflow: Test that small docs are not chunked even when enabled.",
      "expected_behavior": "assert len(chunks) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 241,
      "line_end": 255,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "daf42b67",
      "test_name": "test_maybe_chunk_content_large_doc",
      "category": "workflow",
      "code": "'Test that large docs are chunked when enabled.'\nfrom skill_seekers.cli.adaptors.langchain import LangChainAdaptor\nadaptor = LangChainAdaptor()\ncontent = 'Lorem ipsum dolor sit amet. ' * 2000\nmetadata = {'source': 'test', 'file': 'test.md'}\nchunks = adaptor._maybe_chunk_content(content, metadata, enable_chunking=True, chunk_max_tokens=512, preserve_code_blocks=True, source_file='test.md')\nassert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'\nfor chunk_text, chunk_meta in chunks:\n    assert isinstance(chunk_text, str)\n    assert isinstance(chunk_meta, dict)\n    assert chunk_meta['is_chunked']\n    assert 'chunk_index' in chunk_meta\n    assert 'chunk_id' in chunk_meta\n    assert chunk_meta['source'] == 'test'\n    assert chunk_meta['file'] == 'test.md'",
      "language": "Python",
      "description": "Workflow: Test that large docs are chunked when enabled.",
      "expected_behavior": "assert len(chunks) > 1, f'Large doc should be chunked, got {len(chunks)} chunks'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 257,
      "line_end": 287,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "94b738fe",
      "test_name": "test_chunk_tokens_parameter",
      "category": "workflow",
      "code": "'Test --chunk-tokens parameter controls chunk size.'\nfrom skill_seekers.cli.package_skill import package_skill\nskill_dir = create_test_skill(tmp_path, large_doc=True)\nsuccess, package_path = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=256, preserve_code_blocks=True)\nassert success\nwith open(package_path) as f:\n    data_small = json.load(f)\nsuccess, package_path2 = package_skill(skill_dir=skill_dir, open_folder_after=False, skip_quality_check=True, target='langchain', enable_chunking=True, chunk_max_tokens=1024, preserve_code_blocks=True)\nassert success\nwith open(package_path2) as f:\n    data_large = json.load(f)\nassert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
      "language": "Python",
      "description": "Workflow: Test --chunk-tokens parameter controls chunk size.",
      "expected_behavior": "assert len(data_small) > len(data_large), f'Small chunks ({len(data_small)}) should be more than large chunks ({len(data_large)})'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 318,
      "line_end": 359,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0f04d335",
      "test_name": "test_langchain_no_chunking_default",
      "category": "instantiation",
      "code": "skill_dir = create_test_skill(tmp_path, large_doc=True)",
      "language": "Python",
      "description": "Instantiate create_test_skill: Test that LangChain doesn't chunk by default.",
      "expected_behavior": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 61,
      "line_end": 61,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "75232c11",
      "test_name": "test_langchain_no_chunking_default",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('langchain')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that LangChain doesn't chunk by default.",
      "expected_behavior": "assert len(data) == 2, f'Expected 2 docs, got {len(data)}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_chunking_integration.py",
      "line_start": 63,
      "line_end": 63,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "json",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.adaptors.langchain",
        "skill_seekers.cli.package_skill",
        "skill_seekers.cli.package_skill"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "13d01943",
      "test_name": "test_terminal_launch_error_handling",
      "category": "workflow",
      "code": "'Test error handling when terminal launch fails.'\nif sys.platform != 'darwin':\n    self.skipTest('This test only runs on macOS')\nmock_popen.side_effect = Exception('Terminal not found')\nimport tempfile\nwith tempfile.TemporaryDirectory() as tmpdir:\n    skill_dir = Path(tmpdir) / 'test_skill'\n    skill_dir.mkdir()\n    (skill_dir / 'references').mkdir()\n    (skill_dir / 'references' / 'test.md').write_text('# Test')\n    (skill_dir / 'SKILL.md').write_text('---\\nname: test\\n---\\n# Test')\n    enhancer = LocalSkillEnhancer(skill_dir)\n    from io import StringIO\n    captured_output = StringIO()\n    old_stdout = sys.stdout\n    sys.stdout = captured_output\n    result = enhancer.run(headless=False)\n    sys.stdout = old_stdout\n    self.assertFalse(result)\n    output = captured_output.getvalue()\n    self.assertIn('Error launching', output)",
      "language": "Python",
      "description": "Workflow: Test error handling when terminal launch fails.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 218,
      "line_end": 256,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "13d01943",
      "test_name": "test_terminal_launch_error_handling",
      "category": "workflow",
      "code": "'Test error handling when terminal launch fails.'\nif sys.platform != 'darwin':\n    self.skipTest('This test only runs on macOS')\nmock_popen.side_effect = Exception('Terminal not found')\nimport tempfile\nwith tempfile.TemporaryDirectory() as tmpdir:\n    skill_dir = Path(tmpdir) / 'test_skill'\n    skill_dir.mkdir()\n    (skill_dir / 'references').mkdir()\n    (skill_dir / 'references' / 'test.md').write_text('# Test')\n    (skill_dir / 'SKILL.md').write_text('---\\nname: test\\n---\\n# Test')\n    enhancer = LocalSkillEnhancer(skill_dir)\n    from io import StringIO\n    captured_output = StringIO()\n    old_stdout = sys.stdout\n    sys.stdout = captured_output\n    result = enhancer.run(headless=False)\n    sys.stdout = old_stdout\n    self.assertFalse(result)\n    output = captured_output.getvalue()\n    self.assertIn('Error launching', output)",
      "language": "Python",
      "description": "Workflow: Test error handling when terminal launch fails.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 218,
      "line_end": 256,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_popen",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b3154873",
      "test_name": "test_detect_terminal_with_skill_seeker_env",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'Ghostty')\nself.assertEqual(detection_method, 'SKILL_SEEKER_TERMINAL')",
      "language": "Python",
      "description": "Test that SKILL_SEEKER_TERMINAL env var takes highest priority.",
      "expected_behavior": "self.assertEqual(detection_method, 'SKILL_SEEKER_TERMINAL')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 53,
      "line_end": 54,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d796b000",
      "test_name": "test_detect_terminal_with_term_program_known",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'iTerm')\nself.assertEqual(detection_method, 'TERM_PROGRAM')",
      "language": "Python",
      "description": "Test detection from TERM_PROGRAM with known terminal (iTerm).",
      "expected_behavior": "self.assertEqual(detection_method, 'TERM_PROGRAM')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 66,
      "line_end": 67,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3b3db04b",
      "test_name": "test_detect_terminal_with_term_program_ghostty",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'Ghostty')\nself.assertEqual(detection_method, 'TERM_PROGRAM')",
      "language": "Python",
      "description": "Test detection from TERM_PROGRAM with Ghostty terminal.",
      "expected_behavior": "self.assertEqual(detection_method, 'TERM_PROGRAM')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 78,
      "line_end": 79,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "36f68e14",
      "test_name": "test_detect_terminal_with_term_program_apple_terminal",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'Terminal')\nself.assertEqual(detection_method, 'TERM_PROGRAM')",
      "language": "Python",
      "description": "Test detection from TERM_PROGRAM with Apple Terminal.",
      "expected_behavior": "self.assertEqual(detection_method, 'TERM_PROGRAM')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 90,
      "line_end": 91,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7df017ea",
      "test_name": "test_detect_terminal_with_term_program_wezterm",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'WezTerm')\nself.assertEqual(detection_method, 'TERM_PROGRAM')",
      "language": "Python",
      "description": "Test detection from TERM_PROGRAM with WezTerm.",
      "expected_behavior": "self.assertEqual(detection_method, 'TERM_PROGRAM')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 102,
      "line_end": 103,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7e0e841f",
      "test_name": "test_detect_terminal_with_term_program_unknown",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'Terminal')\nself.assertEqual(detection_method, 'unknown TERM_PROGRAM (zed)')",
      "language": "Python",
      "description": "Test fallback behavior when TERM_PROGRAM is unknown (e.g., IDE terminals).",
      "expected_behavior": "self.assertEqual(detection_method, 'unknown TERM_PROGRAM (zed)')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 114,
      "line_end": 115,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "33528278",
      "test_name": "test_detect_terminal_default_fallback",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'Terminal')\nself.assertEqual(detection_method, 'default')",
      "language": "Python",
      "description": "Test default fallback when no environment variables are set.",
      "expected_behavior": "self.assertEqual(detection_method, 'default')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 127,
      "line_end": 128,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b3154873",
      "test_name": "test_detect_terminal_priority_order",
      "category": "method_call",
      "code": "self.assertEqual(terminal_app, 'Ghostty')\nself.assertEqual(detection_method, 'SKILL_SEEKER_TERMINAL')",
      "language": "Python",
      "description": "Test that SKILL_SEEKER_TERMINAL takes priority over TERM_PROGRAM.",
      "expected_behavior": "self.assertEqual(detection_method, 'SKILL_SEEKER_TERMINAL')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_terminal_detection.py",
      "line_start": 138,
      "line_end": 139,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Save original environment variables.'\nself.original_skill_seeker = os.environ.get('SKILL_SEEKER_TERMINAL')\nself.original_term_program = os.environ.get('TERM_PROGRAM')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.enhance_skill_local",
        "tempfile",
        "tempfile",
        "tempfile",
        "skill_seekers.cli.enhance_skill_local",
        "io",
        "io"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5449a4a8",
      "test_name": "test_analysis_result_basic",
      "category": "instantiation",
      "code": "result = AnalysisResult(code_analysis={'files': []}, source_type='local', analysis_depth='basic')",
      "language": "Python",
      "description": "Instantiate AnalysisResult: Test basic AnalysisResult creation.",
      "expected_behavior": "assert result.code_analysis == {'files': []}",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 33,
      "line_end": 35,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6e14703b",
      "test_name": "test_analysis_result_with_github",
      "category": "instantiation",
      "code": "result = AnalysisResult(code_analysis={'files': []}, github_docs={'readme': '# README'}, github_insights={'metadata': {'stars': 1234}}, source_type='github', analysis_depth='c3x')",
      "language": "Python",
      "description": "Instantiate AnalysisResult: Test AnalysisResult with GitHub data.",
      "expected_behavior": "assert result.github_docs is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 44,
      "line_end": 50,
      "complexity_score": 0.35,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fa0934ef",
      "test_name": "test_basic_analysis_local",
      "category": "instantiation",
      "code": "result = analyzer.analyze(source=str(tmp_path), depth='basic')",
      "language": "Python",
      "description": "Instantiate analyze: Test basic analysis on local directory.",
      "expected_behavior": "assert result.source_type == 'local'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 92,
      "line_end": 92,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "223c9f7b",
      "test_name": "test_list_files",
      "category": "instantiation",
      "code": "files = analyzer.list_files(tmp_path)",
      "language": "Python",
      "description": "Instantiate list_files: Test file listing.",
      "expected_behavior": "assert len(files) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 107,
      "line_end": 107,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ca390f27",
      "test_name": "test_get_directory_structure",
      "category": "instantiation",
      "code": "structure = analyzer.get_directory_structure(tmp_path)",
      "language": "Python",
      "description": "Instantiate get_directory_structure: Test directory structure extraction.",
      "expected_behavior": "assert structure['type'] == 'directory'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 123,
      "line_end": 123,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "09ca8b49",
      "test_name": "test_extract_imports_python",
      "category": "instantiation",
      "code": "imports = analyzer.extract_imports(tmp_path)",
      "language": "Python",
      "description": "Instantiate extract_imports: Test Python import extraction.",
      "expected_behavior": "assert '.py' in imports",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 146,
      "line_end": 146,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "09ca8b49",
      "test_name": "test_extract_imports_javascript",
      "category": "instantiation",
      "code": "imports = analyzer.extract_imports(tmp_path)",
      "language": "Python",
      "description": "Instantiate extract_imports: Test JavaScript import extraction.",
      "expected_behavior": "assert '.js' in imports",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 164,
      "line_end": 164,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0c91e80a",
      "test_name": "test_find_entry_points",
      "category": "instantiation",
      "code": "entry_points = analyzer.find_entry_points(tmp_path)",
      "language": "Python",
      "description": "Instantiate find_entry_points: Test entry point detection.",
      "expected_behavior": "assert 'main.py' in entry_points",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 177,
      "line_end": 177,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9c90d8e5",
      "test_name": "test_compute_statistics",
      "category": "instantiation",
      "code": "stats = analyzer.compute_statistics(tmp_path)",
      "language": "Python",
      "description": "Instantiate compute_statistics: Test statistics computation.",
      "expected_behavior": "assert stats['total_files'] == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 190,
      "line_end": 190,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3352668e",
      "test_name": "test_c3x_analysis_local",
      "category": "instantiation",
      "code": "result = analyzer.analyze(source=str(tmp_path), depth='c3x')",
      "language": "Python",
      "description": "Instantiate analyze: Test C3.x analysis on local directory with actual components.",
      "expected_behavior": "assert result.source_type == 'local'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_unified_analyzer.py",
      "line_start": 209,
      "line_end": 209,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "os",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "64b471d9",
      "test_name": "test_strips_anchor_fragments",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 3)\nself.assertEqual(result[0], 'https://example.com/docs/quick-start/index.html.md')",
      "language": "Python",
      "description": "Test that anchor fragments (#anchor) are properly stripped from URLs",
      "expected_behavior": "self.assertEqual(result[0], 'https://example.com/docs/quick-start/index.html.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 35,
      "line_end": 36,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "71512167",
      "test_name": "test_strips_anchor_fragments",
      "category": "method_call",
      "code": "self.assertEqual(result[0], 'https://example.com/docs/quick-start/index.html.md')\nself.assertEqual(result[1], 'https://example.com/docs/api/index.html.md')",
      "language": "Python",
      "description": "Test that anchor fragments (#anchor) are properly stripped from URLs",
      "expected_behavior": "self.assertEqual(result[1], 'https://example.com/docs/api/index.html.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 36,
      "line_end": 37,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "003b3968",
      "test_name": "test_strips_anchor_fragments",
      "category": "method_call",
      "code": "self.assertEqual(result[1], 'https://example.com/docs/api/index.html.md')\nself.assertEqual(result[2], 'https://example.com/docs/guide/index.html.md')",
      "language": "Python",
      "description": "Test that anchor fragments (#anchor) are properly stripped from URLs",
      "expected_behavior": "self.assertEqual(result[2], 'https://example.com/docs/guide/index.html.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 37,
      "line_end": 38,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b0ee5f3c",
      "test_name": "test_deduplicates_multiple_anchors_same_url",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 1)\nself.assertEqual(result[0], 'https://example.com/docs/api/index.html.md')",
      "language": "Python",
      "description": "Test that multiple anchors on the same URL are deduplicated",
      "expected_behavior": "self.assertEqual(result[0], 'https://example.com/docs/api/index.html.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 52,
      "line_end": 53,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4c8278a4",
      "test_name": "test_preserves_md_extension_urls",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 3)\nself.assertEqual(result[0], 'https://example.com/docs/guide.md')",
      "language": "Python",
      "description": "Test that URLs already ending with .md are preserved",
      "expected_behavior": "self.assertEqual(result[0], 'https://example.com/docs/guide.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 66,
      "line_end": 67,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50de8bcf",
      "test_name": "test_preserves_md_extension_urls",
      "category": "method_call",
      "code": "self.assertEqual(result[0], 'https://example.com/docs/guide.md')\nself.assertEqual(result[1], 'https://example.com/docs/readme.md')",
      "language": "Python",
      "description": "Test that URLs already ending with .md are preserved",
      "expected_behavior": "self.assertEqual(result[1], 'https://example.com/docs/readme.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 67,
      "line_end": 68,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ba9e8de7",
      "test_name": "test_preserves_md_extension_urls",
      "category": "method_call",
      "code": "self.assertEqual(result[1], 'https://example.com/docs/readme.md')\nself.assertEqual(result[2], 'https://example.com/docs/api-reference.md')",
      "language": "Python",
      "description": "Test that URLs already ending with .md are preserved",
      "expected_behavior": "self.assertEqual(result[2], 'https://example.com/docs/api-reference.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 68,
      "line_end": 69,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b8bad008",
      "test_name": "test_md_extension_with_anchor_fragments",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 2)\nself.assertIn('https://example.com/docs/guide.md', result)",
      "language": "Python",
      "description": "Test that .md URLs with anchors are handled correctly",
      "expected_behavior": "self.assertIn('https://example.com/docs/guide.md', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 82,
      "line_end": 83,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7f6d8cbf",
      "test_name": "test_md_extension_with_anchor_fragments",
      "category": "method_call",
      "code": "self.assertIn('https://example.com/docs/guide.md', result)\nself.assertIn('https://example.com/docs/api.md', result)",
      "language": "Python",
      "description": "Test that .md URLs with anchors are handled correctly",
      "expected_behavior": "self.assertIn('https://example.com/docs/api.md', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 83,
      "line_end": 84,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a6801567",
      "test_name": "test_does_not_match_md_in_path",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 3)\nself.assertEqual(result[0], 'https://example.com/cmd-line/index.html.md')",
      "language": "Python",
      "description": "Test that URLs containing 'md' in path (but not ending with .md) are converted",
      "expected_behavior": "self.assertEqual(result[0], 'https://example.com/cmd-line/index.html.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_url_conversion.py",
      "line_start": 97,
      "line_end": 98,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter instance'\nconfig = {'name': 'test', 'description': 'Test', 'base_url': 'https://example.com/docs/', 'selectors': {'main_content': 'article'}}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a326d5e1",
      "test_name": "test_detect_from_html_with_css_class",
      "category": "workflow",
      "code": "'Test HTML element with CSS class'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-python\">print(\"hello\")</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'print(\"hello\")')\nassert lang == 'python'\nassert confidence == 1.0",
      "language": "Python",
      "description": "Workflow: Test HTML element with CSS class",
      "expected_behavior": "assert confidence == 1.0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 77,
      "line_end": 88,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4f01d261",
      "test_name": "test_detect_from_html_with_parent_class",
      "category": "workflow",
      "code": "'Test parent <pre> element with CSS class'\ndetector = LanguageDetector()\nhtml = '<pre class=\"language-java\"><code>System.out.println(\"hello\");</code></pre>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\nlang, confidence = detector.detect_from_html(elem, 'System.out.println(\"hello\");')\nassert lang == 'java'\nassert confidence == 1.0",
      "language": "Python",
      "description": "Workflow: Test parent <pre> element with CSS class",
      "expected_behavior": "assert confidence == 1.0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 90,
      "line_end": 101,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0a9a9ea2",
      "test_name": "test_unity_lifecycle_methods",
      "category": "workflow",
      "code": "'Test Unity lifecycle method detection'\ndetector = LanguageDetector()\ncode = '\\n        void Awake() { }\\n        void Start() { }\\n        void Update() { }\\n        void FixedUpdate() { }\\n        void LateUpdate() { }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5",
      "language": "Python",
      "description": "Workflow: Test Unity lifecycle method detection",
      "expected_behavior": "assert confidence >= 0.5",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 128,
      "line_end": 142,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fea31fb0",
      "test_name": "test_unity_namespace",
      "category": "workflow",
      "code": "'Test Unity namespace detection'\ndetector = LanguageDetector()\ncode = 'using UnityEngine;'\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5\ncode = '\\n        using UnityEngine;\\n        using System.Collections;\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.5",
      "language": "Python",
      "description": "Workflow: Test Unity namespace detection",
      "expected_behavior": "assert confidence >= 0.5",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 190,
      "line_end": 209,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "aa0288ef",
      "test_name": "test_unity_full_script",
      "category": "workflow",
      "code": "'Test complete Unity script (high confidence expected)'\ndetector = LanguageDetector()\ncode = '\\n        using UnityEngine;\\n        using System.Collections;\\n\\n        public class PlayerController : MonoBehaviour\\n        {\\n            [SerializeField]\\n            private float speed = 5.0f;\\n\\n            [SerializeField]\\n            private Rigidbody rb;\\n\\n            void Awake()\\n            {\\n                rb = GetComponent<Rigidbody>();\\n            }\\n\\n            void Update()\\n            {\\n                float moveH = Input.GetAxis(\"Horizontal\");\\n                float moveV = Input.GetAxis(\"Vertical\");\\n\\n                Vector3 movement = new Vector3(moveH, 0, moveV);\\n                rb.AddForce(movement * speed);\\n            }\\n\\n            IEnumerator DashCoroutine()\\n            {\\n                speed *= 2;\\n                yield return new WaitForSeconds(0.5f);\\n                speed /= 2;\\n            }\\n        }\\n        '\nlang, confidence = detector.detect_from_code(code)\nassert lang == 'csharp'\nassert confidence >= 0.9",
      "language": "Python",
      "description": "Workflow: Test complete Unity script (high confidence expected)",
      "expected_behavior": "assert confidence >= 0.9",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 256,
      "line_end": 297,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1bede1e3",
      "test_name": "test_backward_compatibility_with_doc_scraper",
      "category": "workflow",
      "code": "'Test that detector can be used as drop-in replacement'\ndetector = LanguageDetector()\nhtml = '<code class=\"language-python\">import os\\nprint(\"hello\")</code>'\nsoup = BeautifulSoup(html, 'html.parser')\nelem = soup.find('code')\ncode = elem.get_text()\nlang, confidence = detector.detect_from_html(elem, code)\nassert isinstance(lang, str)\nassert isinstance(confidence, float)\nassert lang == 'python'\nassert 0.0 <= confidence <= 1.0",
      "language": "Python",
      "description": "Workflow: Test that detector can be used as drop-in replacement",
      "expected_behavior": "assert 0.0 <= confidence <= 1.0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 688,
      "line_end": 705,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "498967ee",
      "test_name": "test_detect_from_html_with_css_class",
      "category": "instantiation",
      "code": "soup = BeautifulSoup(html, 'html.parser')",
      "language": "Python",
      "description": "Instantiate BeautifulSoup: Test HTML element with CSS class",
      "expected_behavior": "assert lang == 'python'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 83,
      "line_end": 83,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cb0f0729",
      "test_name": "test_detect_from_html_with_css_class",
      "category": "instantiation",
      "code": "elem = soup.find('code')",
      "language": "Python",
      "description": "Instantiate find: Test HTML element with CSS class",
      "expected_behavior": "assert lang == 'python'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 84,
      "line_end": 84,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7f5030f8",
      "test_name": "test_detect_from_html_with_css_class",
      "category": "instantiation",
      "code": "lang, confidence = detector.detect_from_html(elem, 'print(\"hello\")')",
      "language": "Python",
      "description": "Instantiate detect_from_html: Test HTML element with CSS class",
      "expected_behavior": "assert lang == 'python'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 86,
      "line_end": 86,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "498967ee",
      "test_name": "test_detect_from_html_with_parent_class",
      "category": "instantiation",
      "code": "soup = BeautifulSoup(html, 'html.parser')",
      "language": "Python",
      "description": "Instantiate BeautifulSoup: Test parent <pre> element with CSS class",
      "expected_behavior": "assert lang == 'java'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_language_detector.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "bs4",
        "skill_seekers.cli.language_detector"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c0424b8d",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as FAISS index data.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for FAISS format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('faiss')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\nindex_json = adaptor.format_skill_md(skill_dir, metadata)\nindex_data = json.loads(index_json)\nassert 'documents' in index_data\nassert 'metadatas' in index_data\nassert 'ids' in index_data\nassert 'config' in index_data\nassert len(index_data['documents']) == 3\nassert len(index_data['metadatas']) == 3\nassert len(index_data['ids']) == 3\nfor meta in index_data['metadatas']:\n    assert meta['source'] == 'test_skill'\n    assert meta['version'] == '1.0.0'\n    assert 'category' in meta\n    assert 'file' in meta\n    assert 'type' in meta\ncategories = {meta['category'] for meta in index_data['metadatas']}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as FAISS index data.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 23,
      "line_end": 68,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "24fcdd0a",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('faiss')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'faiss' in output_path.name\nwith open(output_path) as f:\n    index_data = json.load(f)\nassert 'documents' in index_data\nassert 'metadatas' in index_data\nassert 'ids' in index_data\nassert len(index_data['documents']) > 0",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert len(index_data['documents']) > 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 70,
      "line_end": 93,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "76064f19",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('faiss')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-faiss.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'faiss' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'faiss' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 95,
      "line_end": 110,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bfff328c",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('faiss')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\nindex_json = adaptor.format_skill_md(skill_dir, metadata)\nindex_data = json.loads(index_json)\nassert index_data['documents'] == []\nassert index_data['metadatas'] == []\nassert index_data['ids'] == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert index_data['ids'] == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 151,
      "line_end": 165,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e0c42bdb",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('faiss')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\nindex_json = adaptor.format_skill_md(skill_dir, metadata)\nindex_data = json.loads(index_json)\nassert len(index_data['documents']) == 1\nassert index_data['metadatas'][0]['category'] == 'test'\nassert index_data['metadatas'][0]['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert index_data['metadatas'][0]['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 167,
      "line_end": 184,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f1ab398b",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('faiss')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that FAISS adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'faiss'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f1ab398b",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('faiss')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as FAISS index data.",
      "expected_behavior": "assert 'documents' in index_data",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as FAISS index data.",
      "expected_behavior": "assert 'documents' in index_data",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0c9b56ad",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "index_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as FAISS index data.",
      "expected_behavior": "assert 'documents' in index_data",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ca7f1f93",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "index_data = json.loads(index_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as FAISS index data.",
      "expected_behavior": "assert 'documents' in index_data",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_faiss_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2f6a8729",
      "test_name": "test_local_provider_deterministic",
      "category": "workflow",
      "code": "'Test local provider generates deterministic embeddings.'\nprovider = LocalEmbeddingProvider(dimension=64)\ntext = 'same text'\nemb1 = provider.generate_embeddings([text])[0]\nemb2 = provider.generate_embeddings([text])[0]\nassert emb1 == emb2",
      "language": "Python",
      "description": "Workflow: Test local provider generates deterministic embeddings.",
      "expected_behavior": "assert emb1 == emb2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 45,
      "line_end": 54,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a1116f14",
      "test_name": "test_cache_memory",
      "category": "workflow",
      "code": "'Test memory cache functionality.'\ncache = EmbeddingCache()\ntext = 'test text'\nmodel = 'test-model'\nembedding = [0.1, 0.2, 0.3]\ncache.set(text, model, embedding)\nretrieved = cache.get(text, model)\nassert retrieved == embedding",
      "language": "Python",
      "description": "Workflow: Test memory cache functionality.",
      "expected_behavior": "assert retrieved == embedding",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 65,
      "line_end": 77,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "25a65715",
      "test_name": "test_pipeline_initialization",
      "category": "workflow",
      "code": "'Test pipeline initialization.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128, batch_size=10)\npipeline = EmbeddingPipeline(config)\nassert pipeline.config == config\nassert pipeline.provider is not None\nassert pipeline.cache is not None",
      "language": "Python",
      "description": "Workflow: Test pipeline initialization.",
      "expected_behavior": "assert pipeline.cache is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 125,
      "line_end": 133,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c4af93c8",
      "test_name": "test_pipeline_generate_batch",
      "category": "workflow",
      "code": "'Test batch embedding generation.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=64, batch_size=2)\npipeline = EmbeddingPipeline(config)\ntexts = ['doc 1', 'doc 2', 'doc 3']\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert len(result.embeddings) == 3\nassert len(result.embeddings[0]) == 64\nassert result.generated_count == 3\nassert result.cached_count == 0",
      "language": "Python",
      "description": "Workflow: Test batch embedding generation.",
      "expected_behavior": "assert result.cached_count == 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 136,
      "line_end": 148,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "407de5a9",
      "test_name": "test_pipeline_batch_processing",
      "category": "workflow",
      "code": "'Test large batch is processed in chunks.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=16, batch_size=3)\npipeline = EmbeddingPipeline(config)\ntexts = [f'doc {i}' for i in range(10)]\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert len(result.embeddings) == 10",
      "language": "Python",
      "description": "Workflow: Test large batch is processed in chunks.",
      "expected_behavior": "assert len(result.embeddings) == 10",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 177,
      "line_end": 192,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a837031b",
      "test_name": "test_validate_dimensions_valid",
      "category": "workflow",
      "code": "'Test dimension validation with valid embeddings.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128)\npipeline = EmbeddingPipeline(config)\nembeddings = [[0.1] * 128, [0.2] * 128]\nis_valid = pipeline.validate_dimensions(embeddings)\nassert is_valid",
      "language": "Python",
      "description": "Workflow: Test dimension validation with valid embeddings.",
      "expected_behavior": "assert is_valid",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 195,
      "line_end": 204,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d25ca695",
      "test_name": "test_validate_dimensions_invalid",
      "category": "workflow",
      "code": "'Test dimension validation with invalid embeddings.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=128)\npipeline = EmbeddingPipeline(config)\nembeddings = [[0.1] * 64, [0.2] * 128]\nis_valid = pipeline.validate_dimensions(embeddings)\nassert not is_valid",
      "language": "Python",
      "description": "Workflow: Test dimension validation with invalid embeddings.",
      "expected_behavior": "assert not is_valid",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 207,
      "line_end": 217,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "93a3469f",
      "test_name": "test_embedding_result_metadata",
      "category": "workflow",
      "code": "'Test embedding result includes metadata.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=256)\npipeline = EmbeddingPipeline(config)\ntexts = ['test']\nresult = pipeline.generate_batch(texts, show_progress=False)\nassert 'provider' in result.metadata\nassert 'model' in result.metadata\nassert 'dimension' in result.metadata\nassert result.metadata['dimension'] == 256",
      "language": "Python",
      "description": "Workflow: Test embedding result includes metadata.",
      "expected_behavior": "assert result.metadata['dimension'] == 256",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 220,
      "line_end": 232,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "98b546c7",
      "test_name": "test_cost_stats",
      "category": "workflow",
      "code": "'Test cost statistics tracking.'\nconfig = EmbeddingConfig(provider='local', model='test-model', dimension=64)\npipeline = EmbeddingPipeline(config)\ntexts = ['doc 1', 'doc 2']\npipeline.generate_batch(texts, show_progress=False)\nstats = pipeline.get_cost_stats()\nassert 'total_requests' in stats\nassert 'cache_hits' in stats\nassert 'estimated_cost' in stats",
      "language": "Python",
      "description": "Workflow: Test cost statistics tracking.",
      "expected_behavior": "assert 'estimated_cost' in stats",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 235,
      "line_end": 248,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d17adc09",
      "test_name": "test_local_provider_generation",
      "category": "instantiation",
      "code": "provider = LocalEmbeddingProvider(dimension=128)",
      "language": "Python",
      "description": "Instantiate LocalEmbeddingProvider: Test local embedding provider.",
      "expected_behavior": "assert len(embeddings) == 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_embedding_pipeline.py",
      "line_start": 35,
      "line_end": 35,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.embedding_pipeline"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ad900c24",
      "test_name": "test_categorize_issues_basic",
      "category": "workflow",
      "code": "'Test basic issue categorization.'\nproblems = [{'title': 'OAuth setup fails', 'labels': ['bug', 'oauth'], 'number': 1, 'state': 'open', 'comments': 10}, {'title': 'Testing framework issue', 'labels': ['testing'], 'number': 2, 'state': 'open', 'comments': 5}]\nsolutions = [{'title': 'Fixed OAuth redirect', 'labels': ['oauth'], 'number': 3, 'state': 'closed', 'comments': 3}]\ntopics = ['oauth', 'testing', 'async']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized\nassert len(categorized['oauth']) == 2\nassert 'testing' in categorized\nassert len(categorized['testing']) == 1",
      "language": "Python",
      "description": "Workflow: Test basic issue categorization.",
      "expected_behavior": "assert len(categorized['testing']) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 24,
      "line_end": 59,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "90f3d018",
      "test_name": "test_generate_hybrid_content_basic",
      "category": "workflow",
      "code": "'Test basic hybrid content generation.'\napi_data = {'apis': {'oauth_login': {'name': 'oauth_login', 'status': 'matched'}}, 'summary': {'total_apis': 1}}\ngithub_docs = {'readme': '# Project README', 'contributing': None, 'docs_files': [{'path': 'docs/oauth.md', 'content': 'OAuth guide'}]}\ngithub_insights = {'metadata': {'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'Test project'}, 'common_problems': [{'title': 'OAuth fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug']}], 'known_solutions': [{'title': 'Fixed OAuth', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], 'top_labels': [{'label': 'bug', 'count': 10}, {'label': 'enhancement', 'count': 5}]}\nconflicts = []\nhybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)\nassert 'api_reference' in hybrid\nassert 'github_context' in hybrid\nassert 'conflict_summary' in hybrid\nassert 'issue_links' in hybrid\nassert hybrid['github_context']['docs']['readme'] == '# Project README'\nassert hybrid['github_context']['docs']['docs_files_count'] == 1\nassert hybrid['github_context']['metadata']['stars'] == 1234\nassert hybrid['github_context']['metadata']['language'] == 'Python'\nassert hybrid['github_context']['issues']['common_problems_count'] == 1\nassert hybrid['github_context']['issues']['known_solutions_count'] == 1\nassert len(hybrid['github_context']['issues']['top_problems']) == 1\nassert len(hybrid['github_context']['top_labels']) == 2",
      "language": "Python",
      "description": "Workflow: Test basic hybrid content generation.",
      "expected_behavior": "assert len(hybrid['github_context']['top_labels']) == 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 133,
      "line_end": 194,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "06f6dd43",
      "test_name": "test_generate_hybrid_content_with_conflicts",
      "category": "workflow",
      "code": "'Test hybrid content with conflicts.'\napi_data = {'apis': {}, 'summary': {}}\ngithub_docs = None\ngithub_insights = None\nconflicts = [Conflict(api_name='test_api', type='signature_mismatch', severity='medium', difference='Parameter count differs', docs_info={'parameters': ['a', 'b']}, code_info={'parameters': ['a', 'b', 'c']}), Conflict(api_name='test_api_2', type='missing_in_docs', severity='low', difference='API not documented', docs_info=None, code_info={'name': 'test_api_2'})]\nhybrid = generate_hybrid_content(api_data, github_docs, github_insights, conflicts)\nassert hybrid['conflict_summary']['total_conflicts'] == 2\nassert hybrid['conflict_summary']['by_type']['signature_mismatch'] == 1\nassert hybrid['conflict_summary']['by_type']['missing_in_docs'] == 1\nassert hybrid['conflict_summary']['by_severity']['medium'] == 1\nassert hybrid['conflict_summary']['by_severity']['low'] == 1",
      "language": "Python",
      "description": "Workflow: Test hybrid content with conflicts.",
      "expected_behavior": "assert hybrid['conflict_summary']['by_severity']['low'] == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 196,
      "line_end": 228,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4a327bf9",
      "test_name": "test_match_issues_to_apis_basic",
      "category": "workflow",
      "code": "'Test basic issue to API matching.'\napis = {'oauth_login': {'name': 'oauth_login'}, 'async_fetch': {'name': 'async_fetch'}}\nproblems = [{'title': 'OAuth login fails', 'number': 42, 'state': 'open', 'comments': 10, 'labels': ['bug', 'oauth']}]\nsolutions = [{'title': 'Fixed async fetch timeout', 'number': 35, 'state': 'closed', 'comments': 5, 'labels': ['async']}]\nissue_links = _match_issues_to_apis(apis, problems, solutions)\nassert 'oauth_login' in issue_links\nassert len(issue_links['oauth_login']) == 1\nassert issue_links['oauth_login'][0]['number'] == 42\nassert 'async_fetch' in issue_links\nassert len(issue_links['async_fetch']) == 1\nassert issue_links['async_fetch'][0]['number'] == 35",
      "language": "Python",
      "description": "Workflow: Test basic issue to API matching.",
      "expected_behavior": "assert issue_links['async_fetch'][0]['number'] == 35",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 246,
      "line_end": 280,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ca735931",
      "test_name": "test_merger_with_github_streams",
      "category": "workflow",
      "code": "'Test merger with three-stream GitHub data.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\nconflicts = []\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# README', contributing='# Contributing', docs_files=[{'path': 'docs/guide.md', 'content': 'Guide content'}])\ninsights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python'}, common_problems=[{'title': 'Bug 1', 'number': 1, 'state': 'open', 'comments': 10, 'labels': ['bug']}], known_solutions=[{'title': 'Fix 1', 'number': 2, 'state': 'closed', 'comments': 5, 'labels': ['bug']}], top_labels=[{'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)\nassert merger.github_streams is not None\nassert merger.github_docs is not None\nassert merger.github_insights is not None\nassert merger.github_docs['readme'] == '# README'\nassert merger.github_insights['metadata']['stars'] == 1234",
      "language": "Python",
      "description": "Workflow: Test merger with three-stream GitHub data.",
      "expected_behavior": "assert merger.github_insights['metadata']['stars'] == 1234",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 325,
      "line_end": 357,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e819cbda",
      "test_name": "test_merger_merge_all_with_streams",
      "category": "workflow",
      "code": "'Test merge_all() with GitHub streams.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\nconflicts = []\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# README', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 500}, common_problems=[], known_solutions=[], top_labels=[])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, conflicts, github_streams)\nresult = merger.merge_all()\nassert 'github_context' in result\nassert 'conflict_summary' in result\nassert 'issue_links' in result\nassert result['github_context']['metadata']['stars'] == 500",
      "language": "Python",
      "description": "Workflow: Test merge_all() with GitHub streams.",
      "expected_behavior": "assert result['github_context']['metadata']['stars'] == 500",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 359,
      "line_end": 381,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "01f0d76f",
      "test_name": "test_full_pipeline_with_streams",
      "category": "workflow",
      "code": "'Test complete pipeline with three-stream data.'\ndocs_data = {'pages': []}\ngithub_data = {'apis': {}}\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test Project\\n\\nA test project.', contributing='# Contributing\\n\\nPull requests welcome.', docs_files=[{'path': 'docs/quickstart.md', 'content': '# Quick Start'}, {'path': 'docs/api.md', 'content': '# API Reference'}])\ninsights_stream = InsightsStream(metadata={'stars': 2500, 'forks': 123, 'language': 'Python', 'description': 'Test framework'}, common_problems=[{'title': 'Installation fails on Windows', 'number': 150, 'state': 'open', 'comments': 25, 'labels': ['bug', 'windows']}, {'title': 'Memory leak in async mode', 'number': 142, 'state': 'open', 'comments': 18, 'labels': ['bug', 'async']}], known_solutions=[{'title': 'Fixed config loading', 'number': 130, 'state': 'closed', 'comments': 8, 'labels': ['bug']}, {'title': 'Resolved OAuth timeout', 'number': 125, 'state': 'closed', 'comments': 12, 'labels': ['oauth']}], top_labels=[{'label': 'bug', 'count': 45}, {'label': 'enhancement', 'count': 20}, {'label': 'question', 'count': 15}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nmerger = RuleBasedMerger(docs_data, github_data, [], github_streams)\nresult = merger.merge_all()\nassert 'apis' in result\nassert 'github_context' in result\ngh_context = result['github_context']\nassert gh_context['docs']['readme'] == '# Test Project\\n\\nA test project.'\nassert gh_context['docs']['contributing'] == '# Contributing\\n\\nPull requests welcome.'\nassert gh_context['docs']['docs_files_count'] == 2\nassert gh_context['metadata']['stars'] == 2500\nassert gh_context['metadata']['language'] == 'Python'\nassert gh_context['issues']['common_problems_count'] == 2\nassert gh_context['issues']['known_solutions_count'] == 2\nassert len(gh_context['issues']['top_problems']) == 2\nassert len(gh_context['issues']['top_solutions']) == 2\nassert len(gh_context['top_labels']) == 3\nassert 'conflict_summary' in result\nassert result['conflict_summary']['total_conflicts'] == 0",
      "language": "Python",
      "description": "Workflow: Test complete pipeline with three-stream data.",
      "expected_behavior": "assert result['conflict_summary']['total_conflicts'] == 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 407,
      "line_end": 495,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d13f61a0",
      "test_name": "test_categorize_issues_basic",
      "category": "instantiation",
      "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
      "language": "Python",
      "description": "Instantiate categorize_issues_by_topic: Test basic issue categorization.",
      "expected_behavior": "assert 'oauth' in categorized",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 54,
      "line_end": 54,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d13f61a0",
      "test_name": "test_categorize_issues_keyword_matching",
      "category": "instantiation",
      "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
      "language": "Python",
      "description": "Instantiate categorize_issues_by_topic: Test keyword matching in titles and labels.",
      "expected_behavior": "assert 'database' in categorized or 'other' in categorized",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 76,
      "line_end": 76,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d13f61a0",
      "test_name": "test_categorize_issues_multi_keyword_topic",
      "category": "instantiation",
      "code": "categorized = categorize_issues_by_topic(problems, solutions, topics)",
      "language": "Python",
      "description": "Instantiate categorize_issues_by_topic: Test topics with multiple keywords.",
      "expected_behavior": "assert 'async api' in categorized",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_merge_sources_github.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "skill_seekers.cli.conflict_detector",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "03aa860a",
      "test_name": "test_benchmark_format_skill_md_all_adaptors",
      "category": "workflow",
      "code": "'Benchmark format_skill_md across all adaptors'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: format_skill_md() - All Adaptors')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nmetadata = SkillMetadata(name='benchmark', description='Benchmark test')\nplatforms = ['claude', 'gemini', 'openai', 'markdown', 'langchain', 'llama-index', 'haystack', 'weaviate', 'chroma', 'faiss', 'qdrant']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    adaptor.format_skill_md(skill_dir, metadata)\n    times = []\n    for _ in range(5):\n        start = time.perf_counter()\n        formatted = adaptor.format_skill_md(skill_dir, metadata)\n        end = time.perf_counter()\n        times.append(end - start)\n        self.assertIsInstance(formatted, str)\n        self.assertGreater(len(formatted), 0)\n    avg_time = sum(times) / len(times)\n    min_time = min(times)\n    max_time = max(times)\n    results[platform] = {'avg': avg_time, 'min': min_time, 'max': max_time}\n    print(f'{platform:15} - Avg: {avg_time * 1000:6.2f}ms | Min: {min_time * 1000:6.2f}ms | Max: {max_time * 1000:6.2f}ms')\nfor platform, metrics in results.items():\n    self.assertLess(metrics['avg'], 0.5, f\"{platform} format_skill_md too slow: {metrics['avg'] * 1000:.2f}ms\")",
      "language": "Python",
      "description": "Workflow: Benchmark format_skill_md across all adaptors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 76,
      "line_end": 139,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2af4f94a",
      "test_name": "test_benchmark_package_operations",
      "category": "workflow",
      "code": "'Benchmark complete package operation'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: package() - Complete Operation')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nplatforms = ['claude', 'langchain', 'chroma', 'weaviate', 'faiss']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    start = time.perf_counter()\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    end = time.perf_counter()\n    elapsed = end - start\n    file_size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'time': elapsed, 'size_kb': file_size_kb}\n    print(f'{platform:15} - Time: {elapsed * 1000:7.2f}ms | Size: {file_size_kb:7.1f} KB')\n    self.assertTrue(package_path.exists())\nfor platform, metrics in results.items():\n    self.assertLess(metrics['time'], 1.0, f\"{platform} packaging too slow: {metrics['time'] * 1000:.2f}ms\")\n    self.assertLess(metrics['size_kb'], 1000, f\"{platform} package too large: {metrics['size_kb']:.1f}KB\")",
      "language": "Python",
      "description": "Workflow: Benchmark complete package operation",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 141,
      "line_end": 186,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "779840e9",
      "test_name": "test_benchmark_scaling_with_reference_count",
      "category": "workflow",
      "code": "'Test how performance scales with reference count'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Scaling with Reference Count')\nprint('=' * 80)\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='scaling_test', description='Scaling benchmark test')\nreference_counts = [1, 5, 10, 25, 50]\nresults = []\nprint(f\"\\n{'Refs':>4} | {'Time (ms)':>10} | {'Time/Ref':>10} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor ref_count in reference_counts:\n    skill_dir = self._create_skill_with_n_references(ref_count)\n    start = time.perf_counter()\n    formatted = adaptor.format_skill_md(skill_dir, metadata)\n    end = time.perf_counter()\n    elapsed = end - start\n    time_per_ref = elapsed / ref_count\n    json.loads(formatted)\n    size_kb = len(formatted) / 1024\n    results.append({'count': ref_count, 'time': elapsed, 'time_per_ref': time_per_ref, 'size_kb': size_kb})\n    print(f'{ref_count:4} | {elapsed * 1000:10.2f} | {time_per_ref * 1000:10.3f} | {size_kb:10.1f}')\nfirst_per_ref = results[0]['time_per_ref']\nlast_per_ref = results[-1]['time_per_ref']\nscaling_factor = last_per_ref / first_per_ref\nprint(f'\\nScaling Factor: {scaling_factor:.2f}x')\nprint(f'(Time per ref at 50 refs / Time per ref at 1 ref)')\nself.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
      "language": "Python",
      "description": "Workflow: Test how performance scales with reference count",
      "expected_behavior": "self.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 188,
      "line_end": 243,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ac4a4955",
      "test_name": "test_benchmark_json_vs_zip_size_comparison",
      "category": "workflow",
      "code": "'Compare output sizes: JSON vs ZIP/tar.gz'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Output Size Comparison')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nformats = {'claude': ('ZIP', '.zip'), 'gemini': ('tar.gz', '.tar.gz'), 'langchain': ('JSON', '.json'), 'weaviate': ('JSON', '.json')}\nresults = {}\nprint(f\"\\n{'Platform':15} | {'Format':8} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor platform, (format_name, ext) in formats.items():\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'format': format_name, 'size_kb': size_kb}\n    print(f'{platform:15} | {format_name:8} | {size_kb:10.1f}')\njson_sizes = [v['size_kb'] for k, v in results.items() if v['format'] == 'JSON']\ncompressed_sizes = [v['size_kb'] for k, v in results.items() if v['format'] in ['ZIP', 'tar.gz']]\nif json_sizes and compressed_sizes:\n    avg_json = sum(json_sizes) / len(json_sizes)\n    avg_compressed = sum(compressed_sizes) / len(compressed_sizes)\n    print(f'\\nAverage JSON size: {avg_json:.1f} KB')\n    print(f'Average compressed size: {avg_compressed:.1f} KB')\n    print(f'Compression ratio: {avg_json / avg_compressed:.2f}x')",
      "language": "Python",
      "description": "Workflow: Compare output sizes: JSON vs ZIP/tar.gz",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 245,
      "line_end": 289,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eed3ef32",
      "test_name": "test_benchmark_metadata_overhead",
      "category": "workflow",
      "code": "'Measure metadata processing overhead'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Metadata Processing Overhead')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nminimal_meta = SkillMetadata(name='test', description='Test')\nrich_meta = SkillMetadata(name='test', description='A comprehensive test skill for benchmarking purposes', version='2.5.0', author='Benchmark Suite', tags=['test', 'benchmark', 'performance', 'validation', 'quality'])\nadaptor = get_adaptor('langchain')\ntimes_minimal = []\nfor _ in range(5):\n    start = time.perf_counter()\n    adaptor.format_skill_md(skill_dir, minimal_meta)\n    end = time.perf_counter()\n    times_minimal.append(end - start)\ntimes_rich = []\nfor _ in range(5):\n    start = time.perf_counter()\n    adaptor.format_skill_md(skill_dir, rich_meta)\n    end = time.perf_counter()\n    times_rich.append(end - start)\navg_minimal = sum(times_minimal) / len(times_minimal)\navg_rich = sum(times_rich) / len(times_rich)\noverhead = avg_rich - avg_minimal\noverhead_pct = overhead / avg_minimal * 100\nprint(f'\\nMinimal metadata: {avg_minimal * 1000:.2f}ms')\nprint(f'Rich metadata:    {avg_rich * 1000:.2f}ms')\nprint(f'Overhead:         {overhead * 1000:.2f}ms ({overhead_pct:.1f}%)')\nself.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
      "language": "Python",
      "description": "Workflow: Measure metadata processing overhead",
      "expected_behavior": "self.assertLess(overhead_pct, 10.0, f'Metadata overhead too high: {overhead_pct:.1f}%')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 291,
      "line_end": 340,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "68aea8f2",
      "test_name": "test_benchmark_empty_vs_full_skill",
      "category": "workflow",
      "code": "'Compare performance: empty skill vs full skill'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Empty vs Full Skill')\nprint('=' * 80)\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='test', description='Test benchmark')\nempty_dir = Path(self.temp_dir.name) / 'empty'\nempty_dir.mkdir()\nstart = time.perf_counter()\nadaptor.format_skill_md(empty_dir, metadata)\nempty_time = time.perf_counter() - start\nfull_dir = self._create_skill_with_n_references(50)\nstart = time.perf_counter()\nadaptor.format_skill_md(full_dir, metadata)\nfull_time = time.perf_counter() - start\nprint(f'\\nEmpty skill: {empty_time * 1000:.2f}ms')\nprint(f'Full skill (50 refs): {full_time * 1000:.2f}ms')\nprint(f'Ratio: {full_time / empty_time:.1f}x')\nself.assertLess(empty_time, 0.01, 'Empty skill processing too slow')\nself.assertLess(full_time, 0.5, 'Full skill processing too slow')",
      "language": "Python",
      "description": "Workflow: Compare performance: empty skill vs full skill",
      "expected_behavior": "self.assertLess(full_time, 0.5, 'Full skill processing too slow')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 342,
      "line_end": 374,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "03aa860a",
      "test_name": "test_benchmark_format_skill_md_all_adaptors",
      "category": "workflow",
      "code": "'Benchmark format_skill_md across all adaptors'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: format_skill_md() - All Adaptors')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nmetadata = SkillMetadata(name='benchmark', description='Benchmark test')\nplatforms = ['claude', 'gemini', 'openai', 'markdown', 'langchain', 'llama-index', 'haystack', 'weaviate', 'chroma', 'faiss', 'qdrant']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    adaptor.format_skill_md(skill_dir, metadata)\n    times = []\n    for _ in range(5):\n        start = time.perf_counter()\n        formatted = adaptor.format_skill_md(skill_dir, metadata)\n        end = time.perf_counter()\n        times.append(end - start)\n        self.assertIsInstance(formatted, str)\n        self.assertGreater(len(formatted), 0)\n    avg_time = sum(times) / len(times)\n    min_time = min(times)\n    max_time = max(times)\n    results[platform] = {'avg': avg_time, 'min': min_time, 'max': max_time}\n    print(f'{platform:15} - Avg: {avg_time * 1000:6.2f}ms | Min: {min_time * 1000:6.2f}ms | Max: {max_time * 1000:6.2f}ms')\nfor platform, metrics in results.items():\n    self.assertLess(metrics['avg'], 0.5, f\"{platform} format_skill_md too slow: {metrics['avg'] * 1000:.2f}ms\")",
      "language": "Python",
      "description": "Workflow: Benchmark format_skill_md across all adaptors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 76,
      "line_end": 139,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2af4f94a",
      "test_name": "test_benchmark_package_operations",
      "category": "workflow",
      "code": "'Benchmark complete package operation'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: package() - Complete Operation')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nplatforms = ['claude', 'langchain', 'chroma', 'weaviate', 'faiss']\nresults = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    start = time.perf_counter()\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    end = time.perf_counter()\n    elapsed = end - start\n    file_size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'time': elapsed, 'size_kb': file_size_kb}\n    print(f'{platform:15} - Time: {elapsed * 1000:7.2f}ms | Size: {file_size_kb:7.1f} KB')\n    self.assertTrue(package_path.exists())\nfor platform, metrics in results.items():\n    self.assertLess(metrics['time'], 1.0, f\"{platform} packaging too slow: {metrics['time'] * 1000:.2f}ms\")\n    self.assertLess(metrics['size_kb'], 1000, f\"{platform} package too large: {metrics['size_kb']:.1f}KB\")",
      "language": "Python",
      "description": "Workflow: Benchmark complete package operation",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 141,
      "line_end": 186,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "779840e9",
      "test_name": "test_benchmark_scaling_with_reference_count",
      "category": "workflow",
      "code": "'Test how performance scales with reference count'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Scaling with Reference Count')\nprint('=' * 80)\nadaptor = get_adaptor('langchain')\nmetadata = SkillMetadata(name='scaling_test', description='Scaling benchmark test')\nreference_counts = [1, 5, 10, 25, 50]\nresults = []\nprint(f\"\\n{'Refs':>4} | {'Time (ms)':>10} | {'Time/Ref':>10} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor ref_count in reference_counts:\n    skill_dir = self._create_skill_with_n_references(ref_count)\n    start = time.perf_counter()\n    formatted = adaptor.format_skill_md(skill_dir, metadata)\n    end = time.perf_counter()\n    elapsed = end - start\n    time_per_ref = elapsed / ref_count\n    json.loads(formatted)\n    size_kb = len(formatted) / 1024\n    results.append({'count': ref_count, 'time': elapsed, 'time_per_ref': time_per_ref, 'size_kb': size_kb})\n    print(f'{ref_count:4} | {elapsed * 1000:10.2f} | {time_per_ref * 1000:10.3f} | {size_kb:10.1f}')\nfirst_per_ref = results[0]['time_per_ref']\nlast_per_ref = results[-1]['time_per_ref']\nscaling_factor = last_per_ref / first_per_ref\nprint(f'\\nScaling Factor: {scaling_factor:.2f}x')\nprint(f'(Time per ref at 50 refs / Time per ref at 1 ref)')\nself.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
      "language": "Python",
      "description": "Workflow: Test how performance scales with reference count",
      "expected_behavior": "self.assertLess(scaling_factor, 3.0, f'Non-linear scaling detected: {scaling_factor:.2f}x')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 188,
      "line_end": 243,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ac4a4955",
      "test_name": "test_benchmark_json_vs_zip_size_comparison",
      "category": "workflow",
      "code": "'Compare output sizes: JSON vs ZIP/tar.gz'\nprint('\\n' + '=' * 80)\nprint('BENCHMARK: Output Size Comparison')\nprint('=' * 80)\nskill_dir = self._create_skill_with_n_references(10)\nformats = {'claude': ('ZIP', '.zip'), 'gemini': ('tar.gz', '.tar.gz'), 'langchain': ('JSON', '.json'), 'weaviate': ('JSON', '.json')}\nresults = {}\nprint(f\"\\n{'Platform':15} | {'Format':8} | {'Size (KB)':>10}\")\nprint('-' * 50)\nfor platform, (format_name, ext) in formats.items():\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(skill_dir, self.output_dir)\n    size_kb = package_path.stat().st_size / 1024\n    results[platform] = {'format': format_name, 'size_kb': size_kb}\n    print(f'{platform:15} | {format_name:8} | {size_kb:10.1f}')\njson_sizes = [v['size_kb'] for k, v in results.items() if v['format'] == 'JSON']\ncompressed_sizes = [v['size_kb'] for k, v in results.items() if v['format'] in ['ZIP', 'tar.gz']]\nif json_sizes and compressed_sizes:\n    avg_json = sum(json_sizes) / len(json_sizes)\n    avg_compressed = sum(compressed_sizes) / len(compressed_sizes)\n    print(f'\\nAverage JSON size: {avg_json:.1f} KB')\n    print(f'Average compressed size: {avg_compressed:.1f} KB')\n    print(f'Compression ratio: {avg_json / avg_compressed:.2f}x')",
      "language": "Python",
      "description": "Workflow: Compare output sizes: JSON vs ZIP/tar.gz",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptor_benchmarks.py",
      "line_start": 245,
      "line_end": 289,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tempfile",
        "time",
        "unittest",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d446910c",
      "test_name": "test_estimate_tokens",
      "category": "workflow",
      "code": "'Test token estimation.'\nchunker = RAGChunker()\nassert chunker.estimate_tokens('') == 0\ntext = 'Hello world!'\ntokens = chunker.estimate_tokens(text)\nassert tokens == 3\ntext = 'A' * 1000\ntokens = chunker.estimate_tokens(text)\nassert tokens == 250",
      "language": "Python",
      "description": "Workflow: Test token estimation.",
      "expected_behavior": "assert tokens == 250",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 40,
      "line_end": 55,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7e5bbcf1",
      "test_name": "test_chunk_document_simple",
      "category": "workflow",
      "code": "'Test chunking simple document.'\nchunker = RAGChunker(chunk_size=50, chunk_overlap=10)\ntext = 'This is a simple document.\\n\\nIt has two paragraphs.\\n\\nAnd a third one.'\nmetadata = {'source': 'test', 'category': 'simple'}\nchunks = chunker.chunk_document(text, metadata)\nassert len(chunks) > 0\nassert all(('chunk_id' in chunk for chunk in chunks))\nassert all(('page_content' in chunk for chunk in chunks))\nassert all(('metadata' in chunk for chunk in chunks))\nfor i, chunk in enumerate(chunks):\n    assert chunk['metadata']['source'] == 'test'\n    assert chunk['metadata']['category'] == 'simple'\n    assert chunk['metadata']['chunk_index'] == i\n    assert chunk['metadata']['total_chunks'] == len(chunks)",
      "language": "Python",
      "description": "Workflow: Test chunking simple document.",
      "expected_behavior": "assert all(('metadata' in chunk for chunk in chunks))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 64,
      "line_end": 83,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "12c916c2",
      "test_name": "test_preserve_code_blocks",
      "category": "workflow",
      "code": "'Test code block preservation.'\nchunker = RAGChunker(chunk_size=50, preserve_code_blocks=True)\ntext = '\\n        Here is some text.\\n\\n        ```python\\n        def hello():\\n            print(\"Hello, world!\")\\n        ```\\n\\n        More text here.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\nhas_code = any(('```' in chunk['page_content'] for chunk in chunks))\nassert has_code\ncode_chunks = [c for c in chunks if c['metadata']['has_code_block']]\nassert len(code_chunks) > 0",
      "language": "Python",
      "description": "Workflow: Test code block preservation.",
      "expected_behavior": "assert len(code_chunks) > 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 85,
      "line_end": 108,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ee4dd1d6",
      "test_name": "test_code_block_not_split",
      "category": "workflow",
      "code": "'Test that code blocks are not split across chunks.'\nchunker = RAGChunker(chunk_size=20, preserve_code_blocks=True)\ntext = '\\n        Short intro.\\n\\n        ```python\\n        def very_long_function_that_exceeds_chunk_size():\\n            # This function is longer than our chunk size\\n            # But it should not be split\\n            print(\"Line 1\")\\n            print(\"Line 2\")\\n            print(\"Line 3\")\\n            return True\\n        ```\\n\\n        Short outro.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\ncode_chunks = [c for c in chunks if '```python' in c['page_content']]\nif code_chunks:\n    code_chunk = code_chunks[0]\n    assert code_chunk['page_content'].count('```') >= 2",
      "language": "Python",
      "description": "Workflow: Test that code blocks are not split across chunks.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 110,
      "line_end": 138,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d3918756",
      "test_name": "test_semantic_boundaries",
      "category": "workflow",
      "code": "'Test that chunks respect paragraph boundaries.'\nchunker = RAGChunker(chunk_size=50, preserve_paragraphs=True)\ntext = '\\n        First paragraph here.\\n        It has multiple sentences.\\n\\n        Second paragraph here.\\n        Also with multiple sentences.\\n\\n        Third paragraph.\\n        '\nchunks = chunker.chunk_document(text, {'source': 'test'})\nfor chunk in chunks:\n    content = chunk['page_content']\n    if content.strip():\n        assert not content.strip().endswith(',')",
      "language": "Python",
      "description": "Workflow: Test that chunks respect paragraph boundaries.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 140,
      "line_end": 162,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9c1e7df4",
      "test_name": "test_chunk_skill_directory",
      "category": "workflow",
      "code": "'Test chunking entire skill directory.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Main Skill\\n\\nThis is the main skill content.\\n\\nWith multiple paragraphs.')\nreferences_dir = skill_dir / 'references'\nreferences_dir.mkdir()\n(references_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start guide.')\n(references_dir / 'api.md').write_text('# API Reference\\n\\nAPI documentation.')\nchunker = RAGChunker(chunk_size=50)\nchunks = chunker.chunk_skill(skill_dir)\nassert len(chunks) > 0\ncategories = {chunk['metadata']['category'] for chunk in chunks}\nassert 'overview' in categories\nassert 'getting_started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test chunking entire skill directory.",
      "expected_behavior": "assert 'getting_started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 175,
      "line_end": 206,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "31b13860",
      "test_name": "test_save_chunks",
      "category": "workflow",
      "code": "'Test saving chunks to JSON file.'\nchunker = RAGChunker()\nchunks = [{'chunk_id': 'test_0', 'page_content': 'Test content', 'metadata': {'source': 'test', 'chunk_index': 0}}]\noutput_path = tmp_path / 'chunks.json'\nchunker.save_chunks(chunks, output_path)\nassert output_path.exists()\nwith open(output_path) as f:\n    loaded = json.load(f)\nassert len(loaded) == 1\nassert loaded[0]['chunk_id'] == 'test_0'",
      "language": "Python",
      "description": "Workflow: Test saving chunks to JSON file.",
      "expected_behavior": "assert loaded[0]['chunk_id'] == 'test_0'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 208,
      "line_end": 231,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9cfb2366",
      "test_name": "test_real_world_documentation",
      "category": "workflow",
      "code": "'Test with realistic documentation content.'\nchunker = RAGChunker(chunk_size=512, chunk_overlap=50)\ntext = '\\n        # React Hooks\\n\\n        React Hooks are functions that let you \"hook into\" React state and lifecycle features from function components.\\n\\n        ## useState\\n\\n        The `useState` Hook lets you add React state to function components.\\n\\n        ```javascript\\n        import { useState } from \\'react\\';\\n\\n        function Example() {\\n          const [count, setCount] = useState(0);\\n\\n          return (\\n            <div>\\n              <p>You clicked {count} times</p>\\n              <button onClick={() => setCount(count + 1)}>\\n                Click me\\n              </button>\\n            </div>\\n          );\\n        }\\n        ```\\n\\n        ## useEffect\\n\\n        The `useEffect` Hook lets you perform side effects in function components.\\n\\n        ```javascript\\n        import { useEffect } from \\'react\\';\\n\\n        function Example() {\\n          useEffect(() => {\\n            document.title = `You clicked ${count} times`;\\n          });\\n        }\\n        ```\\n\\n        ## Best Practices\\n\\n        - Only call Hooks at the top level\\n        - Only call Hooks from React functions\\n        - Use multiple Hooks to separate concerns\\n        '\nmetadata = {'source': 'react-docs', 'category': 'hooks', 'url': 'https://react.dev/reference/react'}\nchunks = chunker.chunk_document(text, metadata)\nassert len(chunks) > 0\ncode_chunks = [c for c in chunks if c['metadata']['has_code_block']]\nassert len(code_chunks) >= 1\nfor chunk in chunks:\n    assert chunk['metadata']['source'] == 'react-docs'\n    assert chunk['metadata']['category'] == 'hooks'\n    assert chunk['metadata']['estimated_tokens'] > 0",
      "language": "Python",
      "description": "Workflow: Test with realistic documentation content.",
      "expected_behavior": "assert len(code_chunks) >= 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 293,
      "line_end": 363,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "01bb21ce",
      "test_name": "test_chunk_then_load_with_langchain",
      "category": "workflow",
      "code": "'Test that chunks can be loaded by LangChain.'\npytest.importorskip('langchain')\nfrom langchain.schema import Document\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LangChain.')\nchunker = RAGChunker()\nchunks = chunker.chunk_skill(skill_dir)\ndocs = [Document(page_content=chunk['page_content'], metadata=chunk['metadata']) for chunk in chunks]\nassert len(docs) > 0\nassert all((isinstance(doc, Document) for doc in docs))",
      "language": "Python",
      "description": "Workflow: Test that chunks can be loaded by LangChain.",
      "expected_behavior": "assert all((isinstance(doc, Document) for doc in docs))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 369,
      "line_end": 392,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "98c630e0",
      "test_name": "test_chunk_then_load_with_llamaindex",
      "category": "workflow",
      "code": "'Test that chunks can be loaded by LlamaIndex.'\npytest.importorskip('llama_index')\nfrom llama_index.core.schema import TextNode\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content for LlamaIndex.')\nchunker = RAGChunker()\nchunks = chunker.chunk_skill(skill_dir)\nnodes = [TextNode(text=chunk['page_content'], metadata=chunk['metadata'], id_=chunk['chunk_id']) for chunk in chunks]\nassert len(nodes) > 0\nassert all((isinstance(node, TextNode) for node in nodes))",
      "language": "Python",
      "description": "Workflow: Test that chunks can be loaded by LlamaIndex.",
      "expected_behavior": "assert all((isinstance(node, TextNode) for node in nodes))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rag_chunker.py",
      "line_start": 394,
      "line_end": 417,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "json",
        "skill_seekers.cli.rag_chunker",
        "langchain.schema",
        "llama_index.core.schema"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4199eada",
      "test_name": "test_detect_python_from_heuristics",
      "category": "workflow",
      "code": "'Test Python detection from code content'\nhtml = '<code>import os\\nfrom pathlib import Path</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'python')",
      "language": "Python",
      "description": "Workflow: Test Python detection from code content",
      "expected_behavior": "self.assertEqual(lang, 'python')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 111,
      "line_end": 117,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "974d5840",
      "test_name": "test_detect_javascript_from_const",
      "category": "workflow",
      "code": "'Test JavaScript detection from const keyword'\nhtml = '<code>const myVar = 10;</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'javascript')",
      "language": "Python",
      "description": "Workflow: Test JavaScript detection from const keyword",
      "expected_behavior": "self.assertEqual(lang, 'javascript')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 127,
      "line_end": 133,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c65ab030",
      "test_name": "test_detect_javascript_from_arrow",
      "category": "workflow",
      "code": "'Test JavaScript detection from arrow function'\nhtml = '<code>const add = (a, b) => a + b;</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'javascript')",
      "language": "Python",
      "description": "Workflow: Test JavaScript detection from arrow function",
      "expected_behavior": "self.assertEqual(lang, 'javascript')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 135,
      "line_end": 141,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "02a40f20",
      "test_name": "test_detect_gdscript",
      "category": "workflow",
      "code": "'Test GDScript detection'\nhtml = '<code>func _ready():\\n    var x = 5</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'gdscript')",
      "language": "Python",
      "description": "Workflow: Test GDScript detection",
      "expected_behavior": "self.assertEqual(lang, 'gdscript')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 143,
      "line_end": 149,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eba50aa8",
      "test_name": "test_detect_cpp",
      "category": "workflow",
      "code": "'Test C++ detection'\nhtml = '<code>#include <iostream>\\nint main() { return 0; }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'cpp')",
      "language": "Python",
      "description": "Workflow: Test C++ detection",
      "expected_behavior": "self.assertEqual(lang, 'cpp')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 151,
      "line_end": 157,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "aca8c16c",
      "test_name": "test_detect_unknown",
      "category": "workflow",
      "code": "'Test unknown language detection'\nhtml = '<code>some random text without clear indicators</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'unknown')",
      "language": "Python",
      "description": "Workflow: Test unknown language detection",
      "expected_behavior": "self.assertEqual(lang, 'unknown')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 159,
      "line_end": 165,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2a54cc7a",
      "test_name": "test_detect_csharp_from_using_system",
      "category": "workflow",
      "code": "\"Test C# detection from 'using System' keyword\"\nhtml = '<code>using System;\\nnamespace MyApp { }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
      "language": "Python",
      "description": "Workflow: Test C# detection from 'using System' keyword",
      "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from using System')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 188,
      "line_end": 194,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "228736e8",
      "test_name": "test_detect_csharp_from_namespace",
      "category": "workflow",
      "code": "\"Test C# detection from 'namespace' keyword\"\nhtml = '<code>namespace MyNamespace\\n{\\n    public class Test { }\\n}</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
      "language": "Python",
      "description": "Workflow: Test C# detection from 'namespace' keyword",
      "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from namespace')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 196,
      "line_end": 202,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c7a14a7a",
      "test_name": "test_detect_csharp_from_property_syntax",
      "category": "workflow",
      "code": "'Test C# detection from property syntax'\nhtml = '<code>public string Name { get; set; }</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
      "language": "Python",
      "description": "Workflow: Test C# detection from property syntax",
      "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from { get; set; } syntax')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 204,
      "line_end": 210,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b9045a34",
      "test_name": "test_detect_csharp_from_public_class",
      "category": "workflow",
      "code": "\"Test C# detection from 'public class' keyword\"\nhtml = '<code>public class MyClass\\n{\\n    private int value;\\n}</code>'\nelem = BeautifulSoup(html, 'html.parser').find('code')\ncode = elem.get_text()\nlang = self.converter.detect_language(elem, code)\nself.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
      "language": "Python",
      "description": "Workflow: Test C# detection from 'public class' keyword",
      "expected_behavior": "self.assertEqual(lang, 'csharp', 'Should detect C# from public class')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_scraper_features.py",
      "line_start": 212,
      "line_end": 218,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test converter'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'rate_limit': 0.1, 'max_pages': 10}\nself.converter = DocToSkillConverter(config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "bs4",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bde90d3d",
      "test_name": "test_add_and_retrieve_github_profile",
      "category": "workflow",
      "code": "'Test adding and retrieving GitHub profiles.'\nconfig_dir = tmp_path / '.config' / 'skill-seekers'\nmonkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)\nmonkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')\nmonkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', tmp_path / '.local' / 'share' / 'skill-seekers' / 'progress')\nconfig = ConfigManager()\nconfig.add_github_profile(name='test-profile', token='ghp_test123', description='Test profile', rate_limit_strategy='wait', timeout_minutes=45, set_as_default=True)\ntoken = config.get_github_token(profile_name='test-profile')\nassert token == 'ghp_test123'\nprofiles = config.list_github_profiles()\nassert len(profiles) == 1\nassert profiles[0]['is_default'] is True\nassert profiles[0]['name'] == 'test-profile'",
      "language": "Python",
      "description": "Workflow: Test adding and retrieving GitHub profiles.",
      "expected_behavior": "assert profiles[0]['name'] == 'test-profile'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 224,
      "line_end": 255,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path, monkeypatch",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "578bb227",
      "test_name": "test_get_next_profile",
      "category": "workflow",
      "code": "'Test profile switching.'\ntest_dir = tmp_path / 'test_switching'\nconfig_dir = test_dir / '.config' / 'skill-seekers'\nmonkeypatch.setattr(ConfigManager, 'CONFIG_DIR', config_dir)\nmonkeypatch.setattr(ConfigManager, 'CONFIG_FILE', config_dir / 'config.json')\nmonkeypatch.setattr(ConfigManager, 'PROGRESS_DIR', test_dir / '.local' / 'share' / 'skill-seekers' / 'progress')\nmonkeypatch.setattr(ConfigManager, 'WELCOME_FLAG', config_dir / '.welcomed')\nconfig = ConfigManager()\nconfig.config['github']['profiles'] = {}\nconfig.add_github_profile('profile1', 'ghp_token1', set_as_default=True)\nconfig.add_github_profile('profile2', 'ghp_token2', set_as_default=False)\nprofiles = config.list_github_profiles()\nassert len(profiles) == 2\nnext_data = config.get_next_profile('ghp_token1')\nassert next_data is not None\nname, token = next_data\nassert name == 'profile2'\nassert token == 'ghp_token2'\nnext_data = config.get_next_profile('ghp_token2')\nassert next_data is not None\nname, token = next_data\nassert name == 'profile1'\nassert token == 'ghp_token1'",
      "language": "Python",
      "description": "Workflow: Test profile switching.",
      "expected_behavior": "assert token == 'ghp_token1'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 257,
      "line_end": 296,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path, monkeypatch",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2129a74f",
      "test_name": "test_create_headers_no_token",
      "category": "instantiation",
      "code": "headers = create_github_headers(None)",
      "language": "Python",
      "description": "Instantiate create_github_headers: Test header creation without token.",
      "expected_behavior": "assert headers == {}",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 25,
      "line_end": 25,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ab1d55fd",
      "test_name": "test_create_headers_with_token",
      "category": "instantiation",
      "code": "headers = create_github_headers(token)",
      "language": "Python",
      "description": "Instantiate create_github_headers: Test header creation with token.",
      "expected_behavior": "assert headers == {'Authorization': 'token ghp_test123'}",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 31,
      "line_end": 31,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a0c10da5",
      "test_name": "test_init_without_token",
      "category": "instantiation",
      "code": "handler = RateLimitHandler(token=None, interactive=True)",
      "language": "Python",
      "description": "Instantiate RateLimitHandler: Test initialization without token.",
      "expected_behavior": "assert handler.token is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 36,
      "line_end": 36,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f8c443d3",
      "test_name": "test_init_with_token",
      "category": "instantiation",
      "code": "handler = RateLimitHandler(token='ghp_test', interactive=False)",
      "language": "Python",
      "description": "Instantiate RateLimitHandler: Test initialization with token.",
      "expected_behavior": "assert handler.token == 'ghp_test'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0ecdc9c6",
      "test_name": "test_init_with_config_strategy",
      "category": "instantiation",
      "code": "handler = RateLimitHandler(token='ghp_test', interactive=True)",
      "language": "Python",
      "description": "Instantiate RateLimitHandler: Test initialization pulls strategy from config.",
      "expected_behavior": "assert handler.strategy == 'wait'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 62,
      "line_end": 62,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_get_config",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "05f98e9f",
      "test_name": "test_extract_rate_limit_info",
      "category": "instantiation",
      "code": "reset_time = int((datetime.now() + timedelta(minutes=30)).timestamp())",
      "language": "Python",
      "description": "Instantiate int: Test extracting rate limit info from response headers.",
      "expected_behavior": "assert info['limit'] == 5000",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 73,
      "line_end": 73,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "46087e6f",
      "test_name": "test_extract_rate_limit_info",
      "category": "instantiation",
      "code": "info = handler.extract_rate_limit_info(mock_response)",
      "language": "Python",
      "description": "Instantiate extract_rate_limit_info: Test extracting rate limit info from response headers.",
      "expected_behavior": "assert info['limit'] == 5000",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 80,
      "line_end": 80,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a0c10da5",
      "test_name": "test_check_upfront_no_token_declined",
      "category": "instantiation",
      "code": "handler = RateLimitHandler(token=None, interactive=True)",
      "language": "Python",
      "description": "Instantiate RateLimitHandler: Test upfront check with no token, user declines.",
      "expected_behavior": "assert result is False",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_rate_limit_handler.py",
      "line_start": 90,
      "line_end": 90,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_input",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "datetime",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_manager",
        "skill_seekers.cli.rate_limit_handler"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e82c288d",
      "test_name": "test_parse_json_config",
      "category": "workflow",
      "code": "'Test parsing JSON configuration'\njson_content = {'database': {'host': 'localhost', 'port': 5432}, 'api_key': 'secret'}\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'config.json'), relative_path='config.json', config_type='json', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'config.json'\nfile_path.write_text(json.dumps(json_content))\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_settings = [s for s in config_file.settings if 'database' in s.key]\nself.assertGreater(len(db_settings), 0)",
      "language": "Python",
      "description": "Workflow: Test parsing JSON configuration",
      "expected_behavior": "self.assertGreater(len(db_settings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 116,
      "line_end": 135,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.parser = ConfigParser()\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "70942543",
      "test_name": "test_parse_env_file",
      "category": "workflow",
      "code": "'Test parsing .env file'\nenv_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / '.env'), relative_path='.env', config_type='env', purpose='unknown')\nfile_path = Path(self.temp_dir) / '.env'\nfile_path.write_text(env_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_url = [s for s in config_file.settings if s.key == 'DATABASE_URL']\nself.assertEqual(len(db_url), 1)\nself.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
      "language": "Python",
      "description": "Workflow: Test parsing .env file",
      "expected_behavior": "self.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 165,
      "line_end": 191,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "self.parser = ConfigParser()\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "160b409c",
      "test_name": "test_parse_python_config",
      "category": "workflow",
      "code": "'Test parsing Python config module'\npython_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'settings.py'), relative_path='settings.py', config_type='python', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'settings.py'\nfile_path.write_text(python_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_host = [s for s in config_file.settings if s.key == 'DATABASE_HOST']\nself.assertGreaterEqual(len(db_host), 1)",
      "language": "Python",
      "description": "Workflow: Test parsing Python config module",
      "expected_behavior": "self.assertGreaterEqual(len(db_host), 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 217,
      "line_end": 240,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.parser = ConfigParser()\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "61a8dd02",
      "test_name": "test_parse_dockerfile",
      "category": "workflow",
      "code": "'Test parsing Dockerfile for ENV vars'\ndockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'Dockerfile'), relative_path='Dockerfile', config_type='dockerfile', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'Dockerfile'\nfile_path.write_text(dockerfile_content)\nself.parser.parse_config_file(config_file)\nenv_settings = [s for s in config_file.settings if s.env_var]\nself.assertGreater(len(env_settings), 0)",
      "language": "Python",
      "description": "Workflow: Test parsing Dockerfile for ENV vars",
      "expected_behavior": "self.assertGreater(len(env_settings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 242,
      "line_end": 263,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "self.parser = ConfigParser()\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e82c288d",
      "test_name": "test_parse_json_config",
      "category": "workflow",
      "code": "'Test parsing JSON configuration'\njson_content = {'database': {'host': 'localhost', 'port': 5432}, 'api_key': 'secret'}\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'config.json'), relative_path='config.json', config_type='json', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'config.json'\nfile_path.write_text(json.dumps(json_content))\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_settings = [s for s in config_file.settings if 'database' in s.key]\nself.assertGreater(len(db_settings), 0)",
      "language": "Python",
      "description": "Workflow: Test parsing JSON configuration",
      "expected_behavior": "self.assertGreater(len(db_settings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 116,
      "line_end": 135,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "70942543",
      "test_name": "test_parse_env_file",
      "category": "workflow",
      "code": "'Test parsing .env file'\nenv_content = '\\n# Database configuration\\nDATABASE_URL=postgresql://localhost:5432/db\\nAPI_KEY=secret123\\n\\n# Server configuration\\nPORT=8000\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / '.env'), relative_path='.env', config_type='env', purpose='unknown')\nfile_path = Path(self.temp_dir) / '.env'\nfile_path.write_text(env_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_url = [s for s in config_file.settings if s.key == 'DATABASE_URL']\nself.assertEqual(len(db_url), 1)\nself.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
      "language": "Python",
      "description": "Workflow: Test parsing .env file",
      "expected_behavior": "self.assertEqual(db_url[0].value, 'postgresql://localhost:5432/db')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 165,
      "line_end": 191,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "160b409c",
      "test_name": "test_parse_python_config",
      "category": "workflow",
      "code": "'Test parsing Python config module'\npython_content = \"\\nDATABASE_HOST = 'localhost'\\nDATABASE_PORT = 5432\\nDEBUG = True\\nAPI_KEYS = ['key1', 'key2']\\n\"\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'settings.py'), relative_path='settings.py', config_type='python', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'settings.py'\nfile_path.write_text(python_content)\nself.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)\ndb_host = [s for s in config_file.settings if s.key == 'DATABASE_HOST']\nself.assertGreaterEqual(len(db_host), 1)",
      "language": "Python",
      "description": "Workflow: Test parsing Python config module",
      "expected_behavior": "self.assertGreaterEqual(len(db_host), 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 217,
      "line_end": 240,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "61a8dd02",
      "test_name": "test_parse_dockerfile",
      "category": "workflow",
      "code": "'Test parsing Dockerfile for ENV vars'\ndockerfile_content = '\\nFROM python:3.10\\nENV DATABASE_URL=postgresql://localhost:5432/db\\nENV API_KEY=secret\\nWORKDIR /app\\n'\nconfig_file = ConfigFile(file_path=str(Path(self.temp_dir) / 'Dockerfile'), relative_path='Dockerfile', config_type='dockerfile', purpose='unknown')\nfile_path = Path(self.temp_dir) / 'Dockerfile'\nfile_path.write_text(dockerfile_content)\nself.parser.parse_config_file(config_file)\nenv_settings = [s for s in config_file.settings if s.env_var]\nself.assertGreater(len(env_settings), 0)",
      "language": "Python",
      "description": "Workflow: Test parsing Dockerfile for ENV vars",
      "expected_behavior": "self.assertGreater(len(env_settings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 242,
      "line_end": 263,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e43481b7",
      "test_name": "test_detect_json_files",
      "category": "method_call",
      "code": "self.assertTrue(any(('config.json' in f for f in filenames)))\nself.assertTrue(any(('package.json' in f for f in filenames)))",
      "language": "Python",
      "description": "Test detection of JSON config files",
      "expected_behavior": "self.assertTrue(any(('package.json' in f for f in filenames)))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 59,
      "line_end": 60,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "self.detector = ConfigFileDetector()\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f7a4d4b8",
      "test_name": "test_parse_json_config",
      "category": "method_call",
      "code": "self.parser.parse_config_file(config_file)\nself.assertGreater(len(config_file.settings), 0)",
      "language": "Python",
      "description": "Test parsing JSON configuration",
      "expected_behavior": "self.assertGreater(len(config_file.settings), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_extractor.py",
      "line_start": 130,
      "line_end": 132,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "self.parser = ConfigParser()\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "os",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.config_extractor",
        "shutil",
        "shutil",
        "shutil",
        "shutil"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d61033bb",
      "test_name": "test_analyze_python_workflow",
      "category": "workflow",
      "code": "'Test analysis of Python workflow with multiple steps'\nworkflow = {'code': \"\\ndef test_user_creation_workflow():\\n    # Step 1: Create database\\n    db = Database('test.db')\\n\\n    # Step 2: Create user\\n    user = User(name='Alice', email='alice@example.com')\\n    db.save(user)\\n\\n    # Step 3: Verify creation\\n    assert db.get_user('Alice').email == 'alice@example.com'\\n\", 'language': 'python', 'category': 'workflow', 'test_name': 'test_user_creation_workflow', 'file_path': 'tests/test_user.py'}\nsteps, metadata = self.analyzer.analyze_workflow(workflow)\nself.assertGreaterEqual(len(steps), 2)\nself.assertIsInstance(steps[0], WorkflowStep)\nself.assertEqual(steps[0].step_number, 1)\nself.assertIsNotNone(steps[0].description)\nself.assertIn('complexity_level', metadata)\nself.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
      "language": "Python",
      "description": "Workflow: Test analysis of Python workflow with multiple steps",
      "expected_behavior": "self.assertIn(metadata['complexity_level'], ['beginner', 'intermediate', 'advanced'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 42,
      "line_end": 75,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.analyzer = WorkflowAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "123790b8",
      "test_name": "test_calculate_complexity",
      "category": "workflow",
      "code": "'Test complexity level calculation'\nsimple_steps = [WorkflowStep(1, 'x = 1', 'Assign variable'), WorkflowStep(2, 'print(x)', 'Print variable')]\nsimple_workflow = {'code': 'x = 1\\nprint(x)', 'category': 'workflow'}\ncomplexity_simple = self.analyzer._calculate_complexity(simple_steps, simple_workflow)\nself.assertEqual(complexity_simple, 'beginner')\ncomplex_steps = [WorkflowStep(i, f'step{i}', f'Step {i}') for i in range(1, 8)]\ncomplex_workflow = {'code': '\\n'.join([f'async def step{i}(): await complex_operation()' for i in range(7)]), 'category': 'workflow'}\ncomplexity_complex = self.analyzer._calculate_complexity(complex_steps, complex_workflow)\nself.assertIn(complexity_complex, ['intermediate', 'advanced'])",
      "language": "Python",
      "description": "Workflow: Test complexity level calculation",
      "expected_behavior": "self.assertIn(complexity_complex, ['intermediate', 'advanced'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 121,
      "line_end": 141,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.analyzer = WorkflowAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50490a77",
      "test_name": "test_create_complete_example",
      "category": "workflow",
      "code": "'Test complete example generation'\nguide = HowToGuide(guide_id='test-1', title='Test', overview='Test', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Assign'), WorkflowStep(2, 'print(x)', 'Print')], workflows=[{'code': 'x = 1\\nprint(x)', 'language': 'python'}])\nexample_md = self.generator._create_complete_example(guide)\nself.assertIn('## Complete Example', example_md)\nself.assertIn('```python', example_md)",
      "language": "Python",
      "description": "Workflow: Test complete example generation",
      "expected_behavior": "self.assertIn('```python', example_md)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 373,
      "line_end": 387,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "self.generator = GuideGenerator()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "852de058",
      "test_name": "test_extract_workflow_examples",
      "category": "workflow",
      "code": "'Test extraction of workflow examples from mixed examples'\nexamples = [{'category': 'workflow', 'code': 'db = Database()\\nuser = User()\\ndb.save(user)', 'test_name': 'test_user_workflow', 'file_path': 'tests/test_user.py', 'language': 'python'}, {'category': 'instantiation', 'code': 'db = Database()', 'test_name': 'test_db', 'file_path': 'tests/test_db.py', 'language': 'python'}]\nworkflows = self.builder._extract_workflow_examples(examples)\nself.assertEqual(len(workflows), 1)\nself.assertEqual(workflows[0]['category'], 'workflow')",
      "language": "Python",
      "description": "Workflow: Test extraction of workflow examples from mixed examples",
      "expected_behavior": "self.assertEqual(workflows[0]['category'], 'workflow')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 427,
      "line_end": 450,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6af04b0b",
      "test_name": "test_create_guide_from_workflows",
      "category": "workflow",
      "code": "'Test guide creation from grouped workflows'\nworkflows = [{'code': 'user = User(name=\"Alice\")\\ndb.save(user)', 'test_name': 'test_create_user', 'file_path': 'tests/test_user.py', 'language': 'python', 'category': 'workflow'}]\nguide = self.builder._create_guide('User Management', workflows)\nself.assertIsInstance(guide, HowToGuide)\nself.assertEqual(guide.title, 'User Management')\nself.assertGreater(len(guide.steps), 0)\nself.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
      "language": "Python",
      "description": "Workflow: Test guide creation from grouped workflows",
      "expected_behavior": "self.assertIn(guide.complexity_level, ['beginner', 'intermediate', 'advanced'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 452,
      "line_end": 469,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ecc0bb12",
      "test_name": "test_save_guides_to_files",
      "category": "workflow",
      "code": "'Test saving guides to markdown files'\nguides = [HowToGuide(guide_id='test-guide', title='Test Guide', overview='Test overview', complexity_level='beginner', steps=[WorkflowStep(1, 'x = 1', 'Test step')])]\ncollection = GuideCollection(total_guides=1, guides=guides, guides_by_complexity={'beginner': 1}, guides_by_use_case={})\noutput_dir = Path(self.temp_dir)\nself.builder._save_guides_to_files(collection, output_dir)\nself.assertTrue((output_dir / 'index.md').exists())\nindex_content = (output_dir / 'index.md').read_text()\nself.assertIn('Test Guide', index_content)\nmd_files = list(output_dir.glob('*.md'))\nself.assertGreaterEqual(len(md_files), 1)",
      "language": "Python",
      "description": "Workflow: Test saving guides to markdown files",
      "expected_behavior": "self.assertGreaterEqual(len(md_files), 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 490,
      "line_end": 522,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "self.builder = HowToGuideBuilder(enhance_with_ai=False)\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "285f6c98",
      "test_name": "test_build_with_ai_enhancement_disabled",
      "category": "workflow",
      "code": "'Test building guides WITHOUT AI enhancement (backward compatibility)'\nexamples = [{'example_id': 'test_001', 'test_name': 'test_user_registration', 'category': 'workflow', 'code': '\\ndef test_user_registration():\\n    user = User.create(username=\"test\", email=\"test@example.com\")\\n    assert user.id is not None\\n    assert user.is_active is True\\n                ', 'language': 'python', 'file_path': 'tests/test_user.py', 'line_start': 10, 'tags': ['authentication', 'user'], 'ai_analysis': {'tutorial_group': 'User Management', 'best_practices': ['Validate email format'], 'common_mistakes': ['Not checking uniqueness']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides'\ncollection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=False, ai_mode='none')\nself.assertIsInstance(collection, GuideCollection)\nself.assertGreater(collection.total_guides, 0)\nself.assertTrue(output_dir.exists())\nself.assertTrue((output_dir / 'index.md').exists())",
      "language": "Python",
      "description": "Workflow: Test building guides WITHOUT AI enhancement (backward compatibility)",
      "expected_behavior": "self.assertTrue((output_dir / 'index.md').exists())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 653,
      "line_end": 696,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ffc85d58",
      "test_name": "test_build_with_ai_enhancement_api_mode_mocked",
      "category": "workflow",
      "code": "'Test building guides WITH AI enhancement in API mode (mocked)'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_002', 'test_name': 'test_data_scraping', 'category': 'workflow', 'code': '\\ndef test_data_scraping():\\n    scraper = DocumentationScraper()\\n    result = scraper.scrape(\"https://example.com/docs\")\\n    assert result.pages > 0\\n                ', 'language': 'python', 'file_path': 'tests/test_scraper.py', 'line_start': 20, 'tags': ['scraping', 'documentation'], 'ai_analysis': {'tutorial_group': 'Data Collection', 'best_practices': ['Handle rate limiting'], 'common_mistakes': ['Not handling SSL errors']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_enhanced'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'api'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = [StepEnhancement(step_index=0, explanation='Test explanation', variations=[])]\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='api')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='api')",
      "language": "Python",
      "description": "Workflow: Test building guides WITH AI enhancement in API mode (mocked)",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 698,
      "line_end": 762,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "830c1fe1",
      "test_name": "test_build_with_ai_enhancement_local_mode_mocked",
      "category": "workflow",
      "code": "'Test building guides WITH AI enhancement in LOCAL mode (mocked)'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_003', 'test_name': 'test_api_integration', 'category': 'workflow', 'code': '\\ndef test_api_integration():\\n    client = APIClient(base_url=\"https://api.example.com\")\\n    response = client.get(\"/users\")\\n    assert response.status_code == 200\\n                ', 'language': 'python', 'file_path': 'tests/test_api.py', 'line_start': 30, 'tags': ['api', 'integration'], 'ai_analysis': {'tutorial_group': 'API Testing', 'best_practices': ['Use environment variables'], 'common_mistakes': ['Hardcoded credentials']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_local'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'local'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = []\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='local')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='local')",
      "language": "Python",
      "description": "Workflow: Test building guides WITH AI enhancement in LOCAL mode (mocked)",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 764,
      "line_end": 825,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6b4b2d61",
      "test_name": "test_build_with_ai_enhancement_auto_mode",
      "category": "workflow",
      "code": "'Test building guides WITH AI enhancement in AUTO mode'\nfrom unittest.mock import patch\nexamples = [{'example_id': 'test_004', 'test_name': 'test_database_migration', 'category': 'workflow', 'code': '\\ndef test_database_migration():\\n    migrator = DatabaseMigrator()\\n    migrator.run_migrations()\\n    assert migrator.current_version == \"2.0\"\\n                ', 'language': 'python', 'file_path': 'tests/test_db.py', 'line_start': 40, 'tags': ['database', 'migration'], 'ai_analysis': {'tutorial_group': 'Database Operations', 'best_practices': ['Backup before migration'], 'common_mistakes': ['Not testing rollback']}}]\nbuilder = HowToGuideBuilder()\noutput_dir = Path(self.temp_dir) / 'guides_auto'\nwith patch('skill_seekers.cli.guide_enhancer.GuideEnhancer') as MockEnhancer:\n    mock_enhancer = MockEnhancer.return_value\n    mock_enhancer.mode = 'local'\n\n    def mock_enhance_guide(guide_data):\n        enhanced = guide_data.copy()\n        enhanced['step_enhancements'] = []\n        enhanced['troubleshooting_detailed'] = []\n        enhanced['prerequisites_detailed'] = []\n        enhanced['next_steps_detailed'] = []\n        enhanced['use_cases'] = []\n        return enhanced\n    mock_enhancer.enhance_guide = mock_enhance_guide\n    collection = builder.build_guides_from_examples(examples=examples, grouping_strategy='ai-tutorial-group', output_dir=output_dir, enhance_with_ai=True, ai_mode='auto')\n    self.assertIsInstance(collection, GuideCollection)\n    self.assertGreater(collection.total_guides, 0)\n    MockEnhancer.assert_called_once_with(mode='auto')",
      "language": "Python",
      "description": "Workflow: Test building guides WITH AI enhancement in AUTO mode",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_how_to_guide_builder.py",
      "line_start": 827,
      "line_end": 887,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.guide_enhancer",
        "skill_seekers.cli.how_to_guide_builder",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "unittest.mock",
        "ast",
        "ast"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d0764a0d",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'gemini')\nself.assertEqual(self.adaptor.PLATFORM_NAME, 'Google Gemini')",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Google Gemini')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('gemini')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6c155afd",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Google Gemini')\nself.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('gemini')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4fd28840",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('AIzaSyABC123'))\nself.assertTrue(self.adaptor.validate_api_key('  AIzaSyTest  '))",
      "language": "Python",
      "description": "Test valid Google API key",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('  AIzaSyTest  '))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 30,
      "line_end": 31,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('gemini')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "abb554c4",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('sk-ant-123'))\nself.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 35,
      "line_end": 36,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('gemini')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1efcb246",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('invalid'))\nself.assertFalse(self.adaptor.validate_api_key(''))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key(''))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 36,
      "line_end": 37,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('gemini')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "95804c2a",
      "test_name": "test_upload_invalid_file",
      "category": "method_call",
      "code": "self.assertFalse(result['success'])\nself.assertIn('not found', result['message'].lower())",
      "language": "Python",
      "description": "Test upload with invalid file",
      "expected_behavior": "self.assertIn('not found', result['message'].lower())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 115,
      "line_end": 116,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('gemini')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d0764a0d",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'gemini')\nself.assertEqual(self.adaptor.PLATFORM_NAME, 'Google Gemini')",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Google Gemini')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6c155afd",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Google Gemini')\nself.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNotNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4fd28840",
      "test_name": "test_validate_api_key_valid",
      "category": "method_call",
      "code": "self.assertTrue(self.adaptor.validate_api_key('AIzaSyABC123'))\nself.assertTrue(self.adaptor.validate_api_key('  AIzaSyTest  '))",
      "language": "Python",
      "description": "Test valid Google API key",
      "expected_behavior": "self.assertTrue(self.adaptor.validate_api_key('  AIzaSyTest  '))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 30,
      "line_end": 31,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "abb554c4",
      "test_name": "test_validate_api_key_invalid",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('sk-ant-123'))\nself.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "language": "Python",
      "description": "Test invalid API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('invalid'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_gemini_adaptor.py",
      "line_start": 35,
      "line_end": 36,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tarfile",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2e536985",
      "test_name": "test_detect_modified_file",
      "category": "workflow",
      "code": "'Test detection of modified files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\nskill_md = temp_skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nModified content')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.modified) == 1\nassert len(change_set.added) == 0\nassert len(change_set.deleted) == 0\nassert change_set.modified[0].file_path == 'SKILL.md'\nassert change_set.modified[0].version == 2",
      "language": "Python",
      "description": "Workflow: Test detection of modified files.",
      "expected_behavior": "assert change_set.modified[0].version == 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 80,
      "line_end": 101,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "31b88c27",
      "test_name": "test_detect_added_file",
      "category": "workflow",
      "code": "'Test detection of new files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nrefs_dir = temp_skill_dir / 'references'\nnew_ref = refs_dir / 'api_reference.md'\nnew_ref.write_text('# API Reference\\n\\nNew documentation')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.added) == 1\nassert len(change_set.modified) == 0\nassert len(change_set.deleted) == 0\nassert change_set.added[0].file_path == 'references/api_reference.md'",
      "language": "Python",
      "description": "Workflow: Test detection of new files.",
      "expected_behavior": "assert change_set.added[0].file_path == 'references/api_reference.md'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 104,
      "line_end": 124,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "da7dec84",
      "test_name": "test_detect_deleted_file",
      "category": "workflow",
      "code": "'Test detection of deleted files.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nref_file = temp_skill_dir / 'references' / 'getting_started.md'\nref_file.unlink()\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.deleted) == 1\nassert len(change_set.added) == 0\nassert len(change_set.modified) == 0\nassert 'references/getting_started.md' in change_set.deleted",
      "language": "Python",
      "description": "Workflow: Test detection of deleted files.",
      "expected_behavior": "assert 'references/getting_started.md' in change_set.deleted",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 127,
      "line_end": 146,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "06aa74e5",
      "test_name": "test_mixed_changes",
      "category": "workflow",
      "code": "'Test detection of multiple types of changes.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Test Skill\\n\\nModified')\nrefs_dir = temp_skill_dir / 'references'\n(refs_dir / 'new_file.md').write_text('# New File')\n(refs_dir / 'getting_started.md').unlink()\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nassert len(change_set.modified) == 1\nassert len(change_set.added) == 1\nassert len(change_set.deleted) == 1\nassert change_set.total_changes == 3",
      "language": "Python",
      "description": "Workflow: Test detection of multiple types of changes.",
      "expected_behavior": "assert change_set.total_changes == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 149,
      "line_end": 177,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a16387fa",
      "test_name": "test_generate_update_package",
      "category": "workflow",
      "code": "'Test update package generation.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Modified')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    package_path = Path(tmpdir) / 'update.json'\n    result_path = updater2.generate_update_package(change_set, package_path)\n    assert result_path.exists()\n    package_data = json.loads(result_path.read_text())\n    assert 'metadata' in package_data\n    assert 'changes' in package_data\n    assert package_data['metadata']['total_changes'] == 1\n    assert 'SKILL.md' in package_data['changes']\n    assert package_data['changes']['SKILL.md']['action'] == 'modify'",
      "language": "Python",
      "description": "Workflow: Test update package generation.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 180,
      "line_end": 209,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0815fd04",
      "test_name": "test_diff_report_generation",
      "category": "workflow",
      "code": "'Test diff report generation.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('# Modified content')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set = updater2.detect_changes()\nreport = updater2.generate_diff_report(change_set)\nassert 'INCREMENTAL UPDATE REPORT' in report\nassert 'Modified: 1 files' in report\nassert 'SKILL.md' in report",
      "language": "Python",
      "description": "Workflow: Test diff report generation.",
      "expected_behavior": "assert 'SKILL.md' in report",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 212,
      "line_end": 231,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "46c630fc",
      "test_name": "test_version_increment",
      "category": "workflow",
      "code": "'Test version numbers increment correctly.'\nupdater = IncrementalUpdater(temp_skill_dir)\nchange_set1 = updater.detect_changes()\nupdater.save_current_versions()\nfor doc in change_set1.added:\n    assert doc.version == 1\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('Modified once')\nupdater2 = IncrementalUpdater(temp_skill_dir)\nchange_set2 = updater2.detect_changes()\nupdater2.save_current_versions()\nassert change_set2.modified[0].version == 2\ntime.sleep(0.01)\n(temp_skill_dir / 'SKILL.md').write_text('Modified twice')\nupdater3 = IncrementalUpdater(temp_skill_dir)\nchange_set3 = updater3.detect_changes()\nassert change_set3.modified[0].version == 3",
      "language": "Python",
      "description": "Workflow: Test version numbers increment correctly.",
      "expected_behavior": "assert change_set3.modified[0].version == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 234,
      "line_end": 263,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6f4fe178",
      "test_name": "test_apply_update_package",
      "category": "workflow",
      "code": "'Test applying an update package.'\nupdater = IncrementalUpdater(temp_skill_dir)\nupdater.detect_changes()\nupdater.save_current_versions()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    package_path = Path(tmpdir) / 'update.json'\n    update_data = {'metadata': {'timestamp': '2026-02-05T12:00:00', 'skill_name': 'test_skill', 'change_summary': {'modified': 1}, 'total_changes': 1}, 'changes': {'SKILL.md': {'action': 'modify', 'version': 2, 'content': '# Updated Content\\n\\nApplied from package'}}}\n    package_path.write_text(json.dumps(update_data))\n    success = updater.apply_update_package(package_path)\n    assert success\n    assert (temp_skill_dir / 'SKILL.md').read_text() == '# Updated Content\\n\\nApplied from package'",
      "language": "Python",
      "description": "Workflow: Test applying an update package.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 266,
      "line_end": 301,
      "complexity_score": 0.5,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "afda60d8",
      "test_name": "test_content_hash_consistency",
      "category": "workflow",
      "code": "'Test content hash is consistent for same content.'\nupdater = IncrementalUpdater(temp_skill_dir)\nskill_md = temp_skill_dir / 'SKILL.md'\nhash1 = updater._compute_file_hash(skill_md)\ncontent = skill_md.read_text()\nskill_md.write_text(content)\nhash2 = updater._compute_file_hash(skill_md)\nassert hash1 == hash2",
      "language": "Python",
      "description": "Workflow: Test content hash is consistent for same content.",
      "expected_behavior": "assert hash1 == hash2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 304,
      "line_end": 319,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "72dfc3c4",
      "test_name": "test_version_increment",
      "category": "method_call",
      "code": "updater2.save_current_versions()\nassert change_set2.modified[0].version == 2",
      "language": "Python",
      "description": "Test version numbers increment correctly.",
      "expected_behavior": "assert change_set2.modified[0].version == 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_incremental_updates.py",
      "line_start": 252,
      "line_end": 254,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "time",
        "skill_seekers.cli.incremental_updater"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4dbd32f6",
      "test_name": "test_scraping_proceeds_when_llms_txt_skipped",
      "category": "workflow",
      "code": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'skip_llms_txt': True}\noriginal_cwd = os.getcwd()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=False)\n        scrape_called = []\n\n        def mock_scrape(url):\n            scrape_called.append(url)\n            return None\n        with patch.object(converter, 'scrape_page', side_effect=mock_scrape), patch.object(converter, 'save_summary'):\n            converter.scrape_all()\n            self.assertTrue(len(scrape_called) > 0)\n    finally:\n        os.chdir(original_cwd)",
      "language": "Python",
      "description": "Workflow: Test that HTML scraping proceeds normally when llms.txt is skipped.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 295,
      "line_end": 325,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4dbd32f6",
      "test_name": "test_scraping_proceeds_when_llms_txt_skipped",
      "category": "workflow",
      "code": "'Test that HTML scraping proceeds normally when llms.txt is skipped.'\nconfig = {'name': 'test', 'base_url': 'https://example.com/', 'selectors': {'main_content': 'article'}, 'skip_llms_txt': True}\noriginal_cwd = os.getcwd()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    try:\n        os.chdir(tmpdir)\n        converter = DocToSkillConverter(config, dry_run=False)\n        scrape_called = []\n\n        def mock_scrape(url):\n            scrape_called.append(url)\n            return None\n        with patch.object(converter, 'scrape_page', side_effect=mock_scrape), patch.object(converter, 'save_summary'):\n            converter.scrape_all()\n            self.assertTrue(len(scrape_called) > 0)\n    finally:\n        os.chdir(original_cwd)",
      "language": "Python",
      "description": "Workflow: Test that HTML scraping proceeds normally when llms.txt is skipped.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 295,
      "line_end": 325,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4ca5cc09",
      "test_name": "test_telegram_bots_config_pattern",
      "category": "method_call",
      "code": "self.assertTrue(converter.skip_llms_txt)\nself.assertEqual(converter.name, 'telegram-bots')",
      "language": "Python",
      "description": "Test the telegram-bots config pattern which uses skip_llms_txt.",
      "expected_behavior": "self.assertEqual(converter.name, 'telegram-bots')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 213,
      "line_end": 214,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "aabd75db",
      "test_name": "test_skip_llms_txt_with_multiple_start_urls",
      "category": "method_call",
      "code": "self.assertTrue(converter.skip_llms_txt)\nself.assertEqual(len(converter.pending_urls), 3)",
      "language": "Python",
      "description": "Test skip_llms_txt works correctly with multiple start URLs.",
      "expected_behavior": "self.assertEqual(len(converter.pending_urls), 3)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 231,
      "line_end": 233,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4ca5cc09",
      "test_name": "test_telegram_bots_config_pattern",
      "category": "method_call",
      "code": "self.assertTrue(converter.skip_llms_txt)\nself.assertEqual(converter.name, 'telegram-bots')",
      "language": "Python",
      "description": "Test the telegram-bots config pattern which uses skip_llms_txt.",
      "expected_behavior": "self.assertEqual(converter.name, 'telegram-bots')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 213,
      "line_end": 214,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "aabd75db",
      "test_name": "test_skip_llms_txt_with_multiple_start_urls",
      "category": "method_call",
      "code": "self.assertTrue(converter.skip_llms_txt)\nself.assertEqual(len(converter.pending_urls), 3)",
      "language": "Python",
      "description": "Test skip_llms_txt works correctly with multiple start URLs.",
      "expected_behavior": "self.assertEqual(len(converter.pending_urls), 3)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 231,
      "line_end": 233,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_default_skip_llms_txt_is_false",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test that skip_llms_txt defaults to False when not specified.",
      "expected_behavior": "self.assertFalse(converter.skip_llms_txt)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 29,
      "line_end": 29,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_skip_llms_txt_can_be_set_true",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test that skip_llms_txt can be explicitly set to True.",
      "expected_behavior": "self.assertTrue(converter.skip_llms_txt)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3eebd269",
      "test_name": "test_skip_llms_txt_can_be_set_false",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=True)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test that skip_llms_txt can be explicitly set to False.",
      "expected_behavior": "self.assertFalse(converter.skip_llms_txt)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 53,
      "line_end": 53,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b9d78fa2",
      "test_name": "test_llms_txt_tried_when_not_skipped",
      "category": "instantiation",
      "code": "converter = DocToSkillConverter(config, dry_run=False)",
      "language": "Python",
      "description": "Instantiate DocToSkillConverter: Test that _try_llms_txt is called when skip_llms_txt is False.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_skip_llms_txt.py",
      "line_start": 73,
      "line_end": 73,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock",
        "unittest"
      ],
      "dependencies": [
        "os",
        "tempfile",
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0b398609",
      "test_name": "test_issue_categorization_by_topic",
      "category": "workflow",
      "code": "'Test that issues are correctly categorized by topic keywords.'\nproblems = [{'title': 'OAuth fails on redirect', 'number': 50, 'state': 'open', 'comments': 20, 'labels': ['oauth', 'bug']}, {'title': 'Token refresh issue', 'number': 45, 'state': 'open', 'comments': 15, 'labels': ['oauth', 'token']}, {'title': 'Async deadlock', 'number': 40, 'state': 'open', 'comments': 12, 'labels': ['async', 'bug']}, {'title': 'Database connection lost', 'number': 35, 'state': 'open', 'comments': 10, 'labels': ['database']}]\nsolutions = [{'title': 'Fixed OAuth flow', 'number': 30, 'state': 'closed', 'comments': 8, 'labels': ['oauth']}, {'title': 'Resolved async race', 'number': 25, 'state': 'closed', 'comments': 6, 'labels': ['async']}]\ntopics = ['oauth', 'auth', 'authentication']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized or 'auth' in categorized or 'authentication' in categorized\noauth_issues = categorized.get('oauth', []) + categorized.get('auth', []) + categorized.get('authentication', [])\nassert len(oauth_issues) >= 2\noauth_titles = [issue['title'] for issue in oauth_issues]\nassert any(('OAuth' in title for title in oauth_titles))",
      "language": "Python",
      "description": "Workflow: Test that issues are correctly categorized by topic keywords.",
      "expected_behavior": "assert any(('OAuth' in title for title in oauth_titles))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 154,
      "line_end": 222,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e2c9a8d6",
      "test_name": "test_github_overhead_within_limits",
      "category": "workflow",
      "code": "'\\n        Test that GitHub integration adds ~30-50 lines per skill (not more).\\n\\n        Quality metric: GitHub overhead should be minimal.\\n        '\nconfig = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://github.com/test/repo', 'categories': {'api': ['api']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ncode_stream = CodeStream(directory=tmp_path, files=[])\ndocs_stream = DocsStream(readme='# Test\\n\\nA short README.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 100, 'forks': 10, 'language': 'Python', 'description': 'Test'}, common_problems=[{'title': 'Issue 1', 'number': 1, 'state': 'open', 'comments': 5, 'labels': ['bug']}, {'title': 'Issue 2', 'number': 2, 'state': 'open', 'comments': 3, 'labels': ['bug']}], known_solutions=[], top_labels=[{'label': 'bug', 'count': 10}])\ngithub_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\ngenerator_no_github = RouterGenerator([str(config_path)])\nskill_md_no_github = generator_no_github.generate_skill_md()\nlines_no_github = len(skill_md_no_github.split('\\n'))\ngenerator_with_github = RouterGenerator([str(config_path)], github_streams=github_streams)\nskill_md_with_github = generator_with_github.generate_skill_md()\nlines_with_github = len(skill_md_with_github.split('\\n'))\ngithub_overhead = lines_with_github - lines_no_github\nassert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
      "language": "Python",
      "description": "Workflow: Test that GitHub integration adds ~30-50 lines per skill (not more).\n\nQuality metric: GitHub overhead should be minimal.",
      "expected_behavior": "assert 20 <= github_overhead <= 60, f'GitHub overhead is {github_overhead} lines, expected 20-60'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 407,
      "line_end": 469,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a65c1251",
      "test_name": "test_router_size_within_limits",
      "category": "workflow",
      "code": "'\\n        Test that router SKILL.md is ~150 lines (\u00b120).\\n\\n        Quality metric: Router should be concise overview, not exhaustive.\\n        '\nconfigs = []\nfor i in range(4):\n    config = {'name': f'test-skill-{i}', 'description': f'Test skill {i}', 'base_url': 'https://github.com/test/repo', 'categories': {f'topic{i}': [f'topic{i}']}}\n    config_path = tmp_path / f'config{i}.json'\n    with open(config_path, 'w') as f:\n        json.dump(config, f)\n    configs.append(str(config_path))\ngenerator = RouterGenerator(configs)\nskill_md = generator.generate_skill_md()\nlines = len(skill_md.split('\\n'))\nassert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
      "language": "Python",
      "description": "Workflow: Test that router SKILL.md is ~150 lines (\u00b120).\n\nQuality metric: Router should be concise overview, not exhaustive.",
      "expected_behavior": "assert 60 <= lines <= 250, f'Router is {lines} lines, expected 60-250 for 4 sub-skills'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 471,
      "line_end": 498,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "be77a796",
      "test_name": "test_router_without_github_streams",
      "category": "workflow",
      "code": "'Test that router generation works without GitHub streams (backward compat).'\nconfig = {'name': 'test-skill', 'description': 'Test skill', 'base_url': 'https://example.com', 'categories': {'api': ['api']}}\nconfig_path = tmp_path / 'config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f)\ngenerator = RouterGenerator([str(config_path)])\nassert generator.github_metadata is None\nassert generator.github_docs is None\nassert generator.github_issues is None\nskill_md = generator.generate_skill_md()\nassert 'When to Use This Skill' in skill_md\nassert 'How It Works' in skill_md\nassert '\u2b50' not in skill_md\nassert 'Repository Info' not in skill_md\nassert 'Quick Start (from README)' not in skill_md\nassert 'Common Issues (from GitHub)' not in skill_md",
      "language": "Python",
      "description": "Workflow: Test that router generation works without GitHub streams (backward compat).",
      "expected_behavior": "assert 'Common Issues (from GitHub)' not in skill_md",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 504,
      "line_end": 534,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a4166214",
      "test_name": "test_three_stream_produces_compact_output",
      "category": "workflow",
      "code": "'\\n        Test that three-stream architecture produces compact, efficient output.\\n\\n        This is a qualitative test - we verify that output is structured and\\n        not duplicated across streams.\\n        '\n(tmp_path / 'main.py').write_text(\"import os\\nprint('test')\")\ncode_stream = CodeStream(directory=tmp_path, files=[tmp_path / 'main.py'])\ndocs_stream = DocsStream(readme='# Test\\n\\nQuick start guide.', contributing=None, docs_files=[])\ninsights_stream = InsightsStream(metadata={'stars': 100}, common_problems=[], known_solutions=[], top_labels=[])\n_three_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)\nassert code_stream.directory == tmp_path\nassert docs_stream.readme is not None\nassert insights_stream.metadata is not None\nassert 'Quick start guide' not in str(code_stream.files)\nassert str(tmp_path) not in docs_stream.readme",
      "language": "Python",
      "description": "Workflow: Test that three-stream architecture produces compact, efficient output.\n\nThis is a qualitative test - we verify that output is structured and\nnot duplicated across streams.",
      "expected_behavior": "assert str(tmp_path) not in docs_stream.readme",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 567,
      "line_end": 594,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c0bf812f",
      "test_name": "test_github_url_to_basic_analysis",
      "category": "instantiation",
      "code": "code_stream = CodeStream(directory=tmp_path, files=[tmp_path / 'main.py', tmp_path / 'utils.js'])",
      "language": "Python",
      "description": "Instantiate CodeStream: Test complete pipeline: GitHub URL \u2192 Basic analysis \u2192 Merged output\n\nThis tests the fast path (1-2 minutes) without C3.x analysis.",
      "expected_behavior": "assert result.source_type == 'github'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 57,
      "line_end": 59,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_fetcher_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ead4ddd4",
      "test_name": "test_github_url_to_basic_analysis",
      "category": "instantiation",
      "code": "docs_stream = DocsStream(readme='# Test Project\\n\\nA simple test project for demonstrating the three-stream architecture.\\n\\n## Installation\\n\\n```bash\\npip install test-project\\n```\\n\\n## Quick Start\\n\\n```python\\nfrom test_project import hello\\nhello()\\n```\\n', contributing='# Contributing\\n\\nPull requests welcome!', docs_files=[{'path': 'docs/guide.md', 'content': '# User Guide\\n\\nHow to use this project.'}])",
      "language": "Python",
      "description": "Instantiate DocsStream: Test complete pipeline: GitHub URL \u2192 Basic analysis \u2192 Merged output\n\nThis tests the fast path (1-2 minutes) without C3.x analysis.",
      "expected_behavior": "assert result.source_type == 'github'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 60,
      "line_end": 82,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_fetcher_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d8036f04",
      "test_name": "test_github_url_to_basic_analysis",
      "category": "instantiation",
      "code": "insights_stream = InsightsStream(metadata={'stars': 1234, 'forks': 56, 'language': 'Python', 'description': 'A test project'}, common_problems=[{'title': 'Installation fails on Windows', 'number': 42, 'state': 'open', 'comments': 15, 'labels': ['bug', 'windows']}, {'title': 'Import error with Python 3.6', 'number': 38, 'state': 'open', 'comments': 10, 'labels': ['bug', 'python']}], known_solutions=[{'title': 'Fixed: Module not found', 'number': 35, 'state': 'closed', 'comments': 8, 'labels': ['bug']}], top_labels=[{'label': 'bug', 'count': 25}, {'label': 'enhancement', 'count': 15}, {'label': 'documentation', 'count': 10}])",
      "language": "Python",
      "description": "Instantiate InsightsStream: Test complete pipeline: GitHub URL \u2192 Basic analysis \u2192 Merged output\n\nThis tests the fast path (1-2 minutes) without C3.x analysis.",
      "expected_behavior": "assert result.source_type == 'github'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 83,
      "line_end": 120,
      "complexity_score": 1.0,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_fetcher_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d216cefe",
      "test_name": "test_github_url_to_basic_analysis",
      "category": "instantiation",
      "code": "three_streams = ThreeStreamData(code_stream, docs_stream, insights_stream)",
      "language": "Python",
      "description": "Instantiate ThreeStreamData: Test complete pipeline: GitHub URL \u2192 Basic analysis \u2192 Merged output\n\nThis tests the fast path (1-2 minutes) without C3.x analysis.",
      "expected_behavior": "assert result.source_type == 'github'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 121,
      "line_end": 121,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_fetcher_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b19383a9",
      "test_name": "test_github_url_to_basic_analysis",
      "category": "instantiation",
      "code": "result = analyzer.analyze(source='https://github.com/test/project', depth='basic', fetch_github_metadata=True)",
      "language": "Python",
      "description": "Instantiate analyze: Test complete pipeline: GitHub URL \u2192 Basic analysis \u2192 Merged output\n\nThis tests the fast path (1-2 minutes) without C3.x analysis.",
      "expected_behavior": "assert result.source_type == 'github'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_e2e_three_stream_pipeline.py",
      "line_start": 126,
      "line_end": 128,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_fetcher_class, tmp_path",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bd12e11a",
      "test_name": "test_preset_flag_preferred",
      "category": "workflow",
      "code": "'Test that --preset flag is the recommended way.'\nargs = {'preset': 'quick'}\nupdated = PresetManager.apply_preset('quick', args)\nassert updated['depth'] == 'surface'\nargs = {'preset': 'standard'}\nupdated = PresetManager.apply_preset('standard', args)\nassert updated['depth'] == 'deep'\nargs = {'preset': 'comprehensive'}\nupdated = PresetManager.apply_preset('comprehensive', args)\nassert updated['depth'] == 'full'",
      "language": "Python",
      "description": "Workflow: Test that --preset flag is the recommended way.",
      "expected_behavior": "assert updated['depth'] == 'full'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 319,
      "line_end": 334,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b5619dc3",
      "test_name": "test_get_preset",
      "category": "instantiation",
      "code": "quick = PresetManager.get_preset('quick')",
      "language": "Python",
      "description": "Instantiate get_preset: Test PresetManager.get_preset().",
      "expected_behavior": "assert quick is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 84,
      "line_end": 84,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7f5b74ca",
      "test_name": "test_get_preset",
      "category": "instantiation",
      "code": "standard = PresetManager.get_preset('STANDARD')",
      "language": "Python",
      "description": "Instantiate get_preset: Test PresetManager.get_preset().",
      "expected_behavior": "assert standard is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 90,
      "line_end": 90,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f0748b24",
      "test_name": "test_get_preset_invalid",
      "category": "instantiation",
      "code": "invalid = PresetManager.get_preset('nonexistent')",
      "language": "Python",
      "description": "Instantiate get_preset: Test PresetManager.get_preset() with invalid name.",
      "expected_behavior": "assert invalid is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "424f316d",
      "test_name": "test_apply_preset_quick",
      "category": "instantiation",
      "code": "updated = PresetManager.apply_preset('quick', args)",
      "language": "Python",
      "description": "Instantiate apply_preset: Test applying quick preset.",
      "expected_behavior": "assert updated['depth'] == 'surface'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 130,
      "line_end": 130,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "035faf60",
      "test_name": "test_apply_preset_standard",
      "category": "instantiation",
      "code": "updated = PresetManager.apply_preset('standard', args)",
      "language": "Python",
      "description": "Instantiate apply_preset: Test applying standard preset.",
      "expected_behavior": "assert updated['depth'] == 'deep'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 144,
      "line_end": 144,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "83adcf82",
      "test_name": "test_apply_preset_comprehensive",
      "category": "instantiation",
      "code": "updated = PresetManager.apply_preset('comprehensive', args)",
      "language": "Python",
      "description": "Instantiate apply_preset: Test applying comprehensive preset.",
      "expected_behavior": "assert updated['depth'] == 'full'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 158,
      "line_end": 158,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "424f316d",
      "test_name": "test_cli_overrides_preset",
      "category": "instantiation",
      "code": "updated = PresetManager.apply_preset('quick', args)",
      "language": "Python",
      "description": "Instantiate apply_preset: Test that CLI args override preset defaults.",
      "expected_behavior": "assert updated['enhance_level'] == 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 179,
      "line_end": 179,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "035faf60",
      "test_name": "test_apply_preset_preserves_args",
      "category": "instantiation",
      "code": "updated = PresetManager.apply_preset('standard', args)",
      "language": "Python",
      "description": "Instantiate apply_preset: Test that apply_preset preserves existing args.",
      "expected_behavior": "assert updated['directory'] == '/tmp/test'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 195,
      "line_end": 195,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f2e926ec",
      "test_name": "test_check_deprecated_flags_quick",
      "category": "instantiation",
      "code": "args = argparse.Namespace(quick=True, comprehensive=False, depth=None, ai_mode='auto')",
      "language": "Python",
      "description": "Instantiate Namespace: Test deprecation warning for --quick flag.",
      "expected_behavior": "assert 'DEPRECATED' in captured.out",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_preset_system.py",
      "line_start": 218,
      "line_end": 218,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": "# Fixtures: capsys",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.presets",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse",
        "skill_seekers.cli.codebase_scraper",
        "argparse"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d38aed34",
      "test_name": "test_scraping_constants_exist",
      "category": "method_call",
      "code": "self.assertIsNotNone(DEFAULT_RATE_LIMIT)\nself.assertIsNotNone(DEFAULT_MAX_PAGES)",
      "language": "Python",
      "description": "Test that scraping constants are defined.",
      "expected_behavior": "self.assertIsNotNone(DEFAULT_MAX_PAGES)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 37,
      "line_end": 38,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "05a83d43",
      "test_name": "test_scraping_constants_exist",
      "category": "method_call",
      "code": "self.assertIsNotNone(DEFAULT_MAX_PAGES)\nself.assertIsNotNone(DEFAULT_CHECKPOINT_INTERVAL)",
      "language": "Python",
      "description": "Test that scraping constants are defined.",
      "expected_behavior": "self.assertIsNotNone(DEFAULT_CHECKPOINT_INTERVAL)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 38,
      "line_end": 39,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4177d51a",
      "test_name": "test_scraping_constants_types",
      "category": "method_call",
      "code": "self.assertIsInstance(DEFAULT_RATE_LIMIT, (int, float))\nself.assertIsInstance(DEFAULT_MAX_PAGES, int)",
      "language": "Python",
      "description": "Test that scraping constants have correct types.",
      "expected_behavior": "self.assertIsInstance(DEFAULT_MAX_PAGES, int)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 43,
      "line_end": 44,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "765bd06d",
      "test_name": "test_scraping_constants_types",
      "category": "method_call",
      "code": "self.assertIsInstance(DEFAULT_MAX_PAGES, int)\nself.assertIsInstance(DEFAULT_CHECKPOINT_INTERVAL, int)",
      "language": "Python",
      "description": "Test that scraping constants have correct types.",
      "expected_behavior": "self.assertIsInstance(DEFAULT_CHECKPOINT_INTERVAL, int)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 44,
      "line_end": 45,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7513ed8d",
      "test_name": "test_scraping_constants_ranges",
      "category": "method_call",
      "code": "self.assertGreater(DEFAULT_RATE_LIMIT, 0)\nself.assertGreater(DEFAULT_MAX_PAGES, 0)",
      "language": "Python",
      "description": "Test that scraping constants have sensible values.",
      "expected_behavior": "self.assertGreater(DEFAULT_MAX_PAGES, 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 49,
      "line_end": 50,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "237a0ad0",
      "test_name": "test_scraping_constants_ranges",
      "category": "method_call",
      "code": "self.assertGreater(DEFAULT_MAX_PAGES, 0)\nself.assertGreater(DEFAULT_CHECKPOINT_INTERVAL, 0)",
      "language": "Python",
      "description": "Test that scraping constants have sensible values.",
      "expected_behavior": "self.assertGreater(DEFAULT_CHECKPOINT_INTERVAL, 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 50,
      "line_end": 51,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "af03dc27",
      "test_name": "test_scraping_constants_ranges",
      "category": "method_call",
      "code": "self.assertGreater(DEFAULT_CHECKPOINT_INTERVAL, 0)\nself.assertEqual(DEFAULT_RATE_LIMIT, 0.5)",
      "language": "Python",
      "description": "Test that scraping constants have sensible values.",
      "expected_behavior": "self.assertEqual(DEFAULT_RATE_LIMIT, 0.5)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 51,
      "line_end": 52,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "94d31bf0",
      "test_name": "test_scraping_constants_ranges",
      "category": "method_call",
      "code": "self.assertEqual(DEFAULT_RATE_LIMIT, 0.5)\nself.assertEqual(DEFAULT_MAX_PAGES, 500)",
      "language": "Python",
      "description": "Test that scraping constants have sensible values.",
      "expected_behavior": "self.assertEqual(DEFAULT_MAX_PAGES, 500)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 52,
      "line_end": 53,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b03302d5",
      "test_name": "test_scraping_constants_ranges",
      "category": "method_call",
      "code": "self.assertEqual(DEFAULT_MAX_PAGES, 500)\nself.assertEqual(DEFAULT_CHECKPOINT_INTERVAL, 1000)",
      "language": "Python",
      "description": "Test that scraping constants have sensible values.",
      "expected_behavior": "self.assertEqual(DEFAULT_CHECKPOINT_INTERVAL, 1000)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 53,
      "line_end": 54,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c07abce1",
      "test_name": "test_content_analysis_constants",
      "category": "method_call",
      "code": "self.assertEqual(CONTENT_PREVIEW_LENGTH, 500)\nself.assertEqual(MAX_PAGES_WARNING_THRESHOLD, 10000)",
      "language": "Python",
      "description": "Test content analysis constants.",
      "expected_behavior": "self.assertEqual(MAX_PAGES_WARNING_THRESHOLD, 10000)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_constants.py",
      "line_start": 58,
      "line_end": 59,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.constants",
        "skill_seekers.cli",
        "inspect",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli",
        "skill_seekers.cli"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f368a9d1",
      "test_name": "test_completeness_full",
      "category": "workflow",
      "code": "'Test completeness analysis with complete skill.'\nanalyzer = QualityAnalyzer(complete_skill_dir)\nscore = analyzer.analyze_completeness()\nassert score >= 70",
      "language": "Python",
      "description": "Workflow: Test completeness analysis with complete skill.",
      "expected_behavior": "assert score >= 70",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 60,
      "line_end": 65,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": "# Fixtures: complete_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "632eb543",
      "test_name": "test_completeness_minimal",
      "category": "workflow",
      "code": "'Test completeness analysis with minimal skill.'\nanalyzer = QualityAnalyzer(minimal_skill_dir)\nscore = analyzer.analyze_completeness()\nassert score < 80",
      "language": "Python",
      "description": "Workflow: Test completeness analysis with minimal skill.",
      "expected_behavior": "assert score < 80",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 68,
      "line_end": 73,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": "# Fixtures: minimal_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5b0d530e",
      "test_name": "test_completeness_full",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(complete_skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test completeness analysis with complete skill.",
      "expected_behavior": "assert score >= 70",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 62,
      "line_end": 62,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: complete_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "87f35239",
      "test_name": "test_completeness_minimal",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(minimal_skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test completeness analysis with minimal skill.",
      "expected_behavior": "assert score < 80",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 70,
      "line_end": 70,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: minimal_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "de7b1d71",
      "test_name": "test_accuracy_clean",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test accuracy analysis with clean content.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 84,
      "line_end": 84,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "de7b1d71",
      "test_name": "test_accuracy_with_todos",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test accuracy detects TODO markers.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 98,
      "line_end": 98,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "de7b1d71",
      "test_name": "test_accuracy_with_placeholder",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test accuracy detects placeholder text.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 112,
      "line_end": 112,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5b0d530e",
      "test_name": "test_coverage_high",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(complete_skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test coverage analysis with good coverage.",
      "expected_behavior": "assert score >= 60",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 120,
      "line_end": 120,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: complete_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "de7b1d71",
      "test_name": "test_coverage_low",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test coverage analysis with low coverage.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 134,
      "line_end": 134,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "de7b1d71",
      "test_name": "test_health_good",
      "category": "instantiation",
      "code": "analyzer = QualityAnalyzer(skill_dir)",
      "language": "Python",
      "description": "Instantiate QualityAnalyzer: Test health analysis with healthy skill.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_quality_metrics.py",
      "line_start": 151,
      "line_end": 151,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.quality_metrics"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e05661ef",
      "test_name": "mock_github_repo",
      "category": "workflow",
      "code": "'Create mock GitHub repository structure.'\nrepo_dir = tmp_path / 'fastmcp'\nrepo_dir.mkdir()\nsrc_dir = repo_dir / 'src'\nsrc_dir.mkdir()\n(src_dir / 'auth.py').write_text(\"\\n# OAuth authentication\\ndef google_provider(client_id, client_secret):\\n    '''Google OAuth provider'''\\n    return Provider('google', client_id, client_secret)\\n\\ndef azure_provider(tenant_id, client_id):\\n    '''Azure OAuth provider'''\\n    return Provider('azure', tenant_id, client_id)\\n\")\n(src_dir / 'async_tools.py').write_text('\\nimport asyncio\\n\\nasync def async_tool():\\n    \\'\\'\\'Async tool decorator\\'\\'\\'\\n    await asyncio.sleep(1)\\n    return \"result\"\\n')\ntests_dir = repo_dir / 'tests'\ntests_dir.mkdir()\n(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")\n(repo_dir / 'README.md').write_text('\\n# FastMCP\\n\\nFastMCP is a Python framework for building MCP servers.\\n\\n## Quick Start\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Features\\n- OAuth authentication (Google, Azure, GitHub)\\n- Async/await support\\n- Easy testing with pytest\\n')\n(repo_dir / 'CONTRIBUTING.md').write_text('\\n# Contributing\\n\\nPlease follow these guidelines when contributing.\\n')\ndocs_dir = repo_dir / 'docs'\ndocs_dir.mkdir()\n(docs_dir / 'oauth.md').write_text('\\n# OAuth Guide\\n\\nHow to set up OAuth providers.\\n')\n(docs_dir / 'async.md').write_text('\\n# Async Guide\\n\\nHow to use async tools.\\n')\nreturn repo_dir",
      "language": "Python",
      "description": "Workflow: Create mock GitHub repository structure.",
      "expected_behavior": "(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 65,
      "line_end": 157,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "mock",
        "pytest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2013ef2a",
      "test_name": "test_scenario_1_quality_metrics",
      "category": "workflow",
      "code": "'Test quality metrics meet architecture targets.'\nrouter_md = '---\\nname: fastmcp\\ndescription: FastMCP framework overview\\n---\\n\\n# FastMCP - Overview\\n\\n**Repository:** https://github.com/jlowin/fastmcp\\n**Stars:** \u2b50 1,234 | **Language:** Python\\n\\n## Quick Start (from README)\\n\\nInstall with pip:\\n```bash\\npip install fastmcp\\n```\\n\\n## Common Issues (from GitHub)\\n\\n1. **OAuth setup fails** (Issue #42, 15 comments)\\n   - See `fastmcp-oauth` skill\\n\\n2. **Async tools not working** (Issue #38, 8 comments)\\n   - See `fastmcp-async` skill\\n\\n## Choose Your Path\\n\\n**OAuth?** \u2192 Use `fastmcp-oauth` skill\\n**Async?** \u2192 Use `fastmcp-async` skill\\n'\nlines = router_md.strip().split('\\n')\nassert len(lines) <= 200, f'Router too large: {len(lines)} lines (max 200)'\ngithub_lines = 0\nif 'Repository:' in router_md:\n    github_lines += 1\nif 'Stars:' in router_md or '\u2b50' in router_md:\n    github_lines += 1\nif 'Common Issues' in router_md:\n    github_lines += router_md.count('Issue #')\nassert github_lines >= 3, f'GitHub overhead too small: {github_lines} lines'\nassert github_lines <= 60, f'GitHub overhead too large: {github_lines} lines'\nassert 'Issue #42' in router_md, 'Missing issue references'\nassert '\u2b50' in router_md or 'Stars:' in router_md, 'Missing GitHub metadata'\nassert 'Quick Start' in router_md or 'README' in router_md, 'Missing README content'",
      "language": "Python",
      "description": "Workflow: Test quality metrics meet architecture targets.",
      "expected_behavior": "assert 'Quick Start' in router_md or 'README' in router_md, 'Missing README content'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 427,
      "line_end": 482,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "16d35564",
      "test_name": "test_scenario_2_issue_categorization",
      "category": "workflow",
      "code": "'Test categorizing GitHub issues by topic.'\nproblems = [{'number': 42, 'title': 'OAuth setup fails', 'labels': ['oauth', 'bug']}, {'number': 38, 'title': 'Async tools not working', 'labels': ['async', 'question']}, {'number': 35, 'title': 'Testing with pytest', 'labels': ['testing', 'question']}, {'number': 30, 'title': 'Google OAuth redirect', 'labels': ['oauth', 'question']}]\nsolutions = [{'number': 25, 'title': 'Fixed OAuth redirect', 'labels': ['oauth', 'bug']}, {'number': 20, 'title': 'Async timeout solution', 'labels': ['async', 'bug']}]\ntopics = ['oauth', 'async', 'testing']\ncategorized = categorize_issues_by_topic(problems, solutions, topics)\nassert 'oauth' in categorized\nassert 'async' in categorized\nassert 'testing' in categorized\noauth_issues = categorized['oauth']\nassert len(oauth_issues) >= 2\noauth_numbers = [i['number'] for i in oauth_issues]\nassert 42 in oauth_numbers\nasync_issues = categorized['async']\nassert len(async_issues) >= 2\nasync_numbers = [i['number'] for i in async_issues]\nassert 38 in async_numbers\ntesting_issues = categorized['testing']\nassert len(testing_issues) >= 1",
      "language": "Python",
      "description": "Workflow: Test categorizing GitHub issues by topic.",
      "expected_behavior": "assert len(testing_issues) >= 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 519,
      "line_end": 572,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "15777a62",
      "test_name": "test_scenario_2_conflict_detection",
      "category": "workflow",
      "code": "'Test conflict detection between docs and code.'\napi_data = {'GoogleProvider': {'params': ['app_id', 'app_secret'], 'source': 'html_docs'}}\ngithub_docs = {'readme': 'Use client_id and client_secret for Google OAuth'}\nassert 'GoogleProvider' in api_data\nassert 'params' in api_data['GoogleProvider']\nassert github_docs is not None",
      "language": "Python",
      "description": "Workflow: Test conflict detection between docs and code.",
      "expected_behavior": "assert github_docs is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 574,
      "line_end": 595,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "32affc6b",
      "test_name": "test_scenario_2_multi_layer_merge",
      "category": "workflow",
      "code": "'Test multi-layer source merging priority.'\nsource1_data = {'api': [{'name': 'GoogleProvider', 'params': ['app_id', 'app_secret']}]}\nsource2_data = {'api': [{'name': 'GoogleProvider', 'params': ['client_id', 'client_secret']}]}\n_github_streams = ThreeStreamData(code_stream=CodeStream(directory=Path('/tmp'), files=[]), docs_stream=DocsStream(readme='Use client_id and client_secret', contributing=None, docs_files=[]), insights_stream=InsightsStream(metadata={'stars': 1000}, common_problems=[{'number': 42, 'title': 'OAuth parameter confusion', 'labels': ['oauth']}], known_solutions=[], top_labels=[]))\nmerger = RuleBasedMerger(docs_data=source1_data, github_data=source2_data, conflicts=[])\nmerged = merger.merge_all()\nassert merged is not None\nassert isinstance(merged, dict)",
      "language": "Python",
      "description": "Workflow: Test multi-layer source merging priority.",
      "expected_behavior": "assert isinstance(merged, dict)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 597,
      "line_end": 643,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "41b21168",
      "test_name": "test_scenario_3_local_analysis_basic",
      "category": "workflow",
      "code": "'Test basic analysis of local codebase.'\nanalyzer = UnifiedCodebaseAnalyzer()\nresult = analyzer.analyze(source=str(local_codebase), depth='basic', fetch_github_metadata=False)\nassert isinstance(result, AnalysisResult)\nassert result.source_type == 'local'\nassert result.analysis_depth == 'basic'\nassert result.code_analysis is not None\nassert 'files' in result.code_analysis\nassert len(result.code_analysis['files']) >= 2\nassert result.github_docs is None\nassert result.github_insights is None",
      "language": "Python",
      "description": "Workflow: Test basic analysis of local codebase.",
      "expected_behavior": "assert result.github_insights is None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 720,
      "line_end": 740,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: local_codebase",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "393c5e0e",
      "test_name": "test_scenario_3_local_analysis_c3x",
      "category": "workflow",
      "code": "'Test C3.x analysis of local codebase.'\nanalyzer = UnifiedCodebaseAnalyzer()\nwith patch('skill_seekers.cli.unified_codebase_analyzer.UnifiedCodebaseAnalyzer.c3x_analysis') as mock_c3x:\n    mock_c3x.return_value = {'files': ['database.py', 'api.py'], 'analysis_type': 'c3x', 'c3_1_patterns': [{'name': 'Singleton', 'count': 1, 'file': 'database.py'}], 'c3_2_examples': [{'name': 'test_connection', 'file': 'test_database.py'}], 'c3_2_examples_count': 1, 'c3_3_guides': [], 'c3_4_configs': [], 'c3_7_architecture': []}\n    result = analyzer.analyze(source=str(local_codebase), depth='c3x', fetch_github_metadata=False)\n    assert result.source_type == 'local'\n    assert result.analysis_depth == 'c3x'\n    assert result.code_analysis['analysis_type'] == 'c3x'\n    assert 'c3_1_patterns' in result.code_analysis\n    assert 'c3_2_examples' in result.code_analysis\n    assert result.github_docs is None\n    assert result.github_insights is None",
      "language": "Python",
      "description": "Workflow: Test C3.x analysis of local codebase.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 742,
      "line_end": 776,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "# Fixtures: local_codebase",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "634f58a2",
      "test_name": "test_scenario_3_router_without_github",
      "category": "workflow",
      "code": "'Test router generation without GitHub data.'\nconfig1 = tmp_path / 'internal-database.json'\nconfig1.write_text(json.dumps({'name': 'internal-database', 'description': 'Database layer', 'categories': {'database': ['db', 'sql', 'connection']}}))\nconfig2 = tmp_path / 'internal-api.json'\nconfig2.write_text(json.dumps({'name': 'internal-api', 'description': 'API endpoints', 'categories': {'api': ['api', 'endpoint', 'route']}}))\ngenerator = RouterGenerator(config_paths=[str(config1), str(config2)], router_name='internal-tool', github_streams=None)\nskill_md = generator.generate_skill_md()\nassert 'internal-tool' in skill_md.lower()\nassert 'Repository:' not in skill_md\nassert 'Stars:' not in skill_md\nassert '\u2b50' not in skill_md\nassert 'Common Issues' not in skill_md\nassert 'Issue #' not in skill_md\nassert 'internal-database' in skill_md\nassert 'internal-api' in skill_md",
      "language": "Python",
      "description": "Workflow: Test router generation without GitHub data.",
      "expected_behavior": "assert 'internal-api' in skill_md",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 778,
      "line_end": 826,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bab78031",
      "test_name": "test_token_efficiency_calculation",
      "category": "workflow",
      "code": "'Calculate token efficiency with GitHub overhead.'\nmonolithic_size = 666 + 50\nrouter_size = 150 + 50\navg_subskill_size = (250 + 200 + 250 + 400) / 4\navg_subskill_with_github = avg_subskill_size + 30\navg_router_query = router_size + avg_subskill_with_github\nreduction = (monolithic_size - avg_router_query) / monolithic_size\nreduction_percent = reduction * 100\nprint('\\n=== Token Efficiency Calculation ===')\nprint(f'Monolithic: {monolithic_size} lines')\nprint(f'Router: {router_size} lines')\nprint(f'Avg Sub-skill: {avg_subskill_with_github} lines')\nprint(f'Avg Query: {avg_router_query} lines')\nprint(f'Reduction: {reduction_percent:.1f}%')\nprint('Target: 35-40%')\nassert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
      "language": "Python",
      "description": "Workflow: Calculate token efficiency with GitHub overhead.",
      "expected_behavior": "assert reduction_percent >= 29, f'Token reduction {reduction_percent:.1f}% below 29% (conservative target)'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 1025,
      "line_end": 1054,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f39ef138",
      "test_name": "mock_github_repo",
      "category": "method_call",
      "code": "tests_dir.mkdir()\n(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
      "language": "Python",
      "description": "Create mock GitHub repository structure.",
      "expected_behavior": "(tests_dir / 'test_auth.py').write_text(\"\\ndef test_google_provider():\\n    provider = google_provider('id', 'secret')\\n    assert provider.name == 'google'\\n\\ndef test_azure_provider():\\n    provider = azure_provider('tenant', 'id')\\n    assert provider.name == 'azure'\\n\")",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_architecture_scenarios.py",
      "line_start": 98,
      "line_end": 109,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "mock",
        "pytest"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.generate_router",
        "skill_seekers.cli.github_fetcher",
        "skill_seekers.cli.merge_sources",
        "skill_seekers.cli.unified_codebase_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "86bddd5c",
      "test_name": "run_bootstrap",
      "category": "instantiation",
      "code": "result = subprocess.run(['bash', str(script)], cwd=project_root, capture_output=True, text=True, timeout=timeout)",
      "language": "Python",
      "description": "Instantiate run: Execute bootstrap script and return result",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 45,
      "line_end": 47,
      "complexity_score": 0.4,
      "confidence": 0.8,
      "setup_code": "# Fixtures: project_root",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a4e98024",
      "test_name": "test_bootstrap_validates_yaml_frontmatter",
      "category": "instantiation",
      "code": "lines = content.split('\\n')",
      "language": "Python",
      "description": "Instantiate split: Verify generated SKILL.md has valid YAML frontmatter",
      "expected_behavior": "assert closing_found, 'Missing frontmatter closing delimiter'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir",
      "tags": [],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "82685bf1",
      "test_name": "test_bootstrap_validates_yaml_frontmatter",
      "category": "workflow",
      "code": "'Verify generated SKILL.md has valid YAML frontmatter'\nresult = run_bootstrap()\nassert result.returncode == 0\ncontent = (output_skill_dir / 'SKILL.md').read_text()\nassert content.startswith('---'), 'Missing frontmatter start'\nlines = content.split('\\n')\nclosing_found = False\nfor _i, line in enumerate(lines[1:], 1):\n    if line.strip() == '---':\n        closing_found = True\n        break\nassert closing_found, 'Missing frontmatter closing delimiter'\nassert 'name:' in content[:500], 'Missing name field'\nassert 'description:' in content[:500], 'Missing description field'",
      "language": "Python",
      "description": "Workflow: Verify generated SKILL.md has valid YAML frontmatter",
      "expected_behavior": "assert 'description:' in content[:500], 'Missing description field'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 85,
      "line_end": 107,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "743c7875",
      "test_name": "test_bootstrap_output_line_count",
      "category": "instantiation",
      "code": "line_count = len((output_skill_dir / 'SKILL.md').read_text().splitlines())",
      "language": "Python",
      "description": "Instantiate len: Verify output SKILL.md has reasonable line count",
      "expected_behavior": "assert line_count > 100, f'SKILL.md too short: {line_count} lines'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 114,
      "line_end": 114,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir",
      "tags": [],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "82446b9f",
      "test_name": "test_skill_installable_in_venv",
      "category": "instantiation",
      "code": "result = subprocess.run([str(pip_path), 'install', '-e', '.'], cwd=output_skill_dir.parent.parent, capture_output=True, text=True, timeout=120)",
      "language": "Python",
      "description": "Instantiate run: Test skill is installable in clean virtual environment",
      "expected_behavior": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 134,
      "line_end": 140,
      "complexity_score": 0.5,
      "confidence": 0.8,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir, tmp_path",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0aae0187",
      "test_name": "test_skill_installable_in_venv",
      "category": "workflow",
      "code": "'Test skill is installable in clean virtual environment'\nresult = run_bootstrap()\nassert result.returncode == 0\nvenv_path = tmp_path / 'test_venv'\nsubprocess.run([sys.executable, '-m', 'venv', str(venv_path)], check=True, timeout=60)\npip_path = venv_path / 'bin' / 'pip'\nresult = subprocess.run([str(pip_path), 'install', '-e', '.'], cwd=output_skill_dir.parent.parent, capture_output=True, text=True, timeout=120)\nassert result.returncode == 0, f'Install failed: {result.stderr}'",
      "language": "Python",
      "description": "Workflow: Test skill is installable in clean virtual environment",
      "expected_behavior": "assert result.returncode == 0, f'Install failed: {result.stderr}'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 122,
      "line_end": 143,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir, tmp_path",
      "tags": [
        "pytest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a5350115",
      "test_name": "test_skill_packageable_with_adaptors",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('claude')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Verify bootstrap output works with all platform adaptors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 153,
      "line_end": 153,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "59ebaae8",
      "test_name": "test_skill_packageable_with_adaptors",
      "category": "instantiation",
      "code": "package_path = adaptor.package(skill_dir=output_skill_dir, output_path=tmp_path)",
      "language": "Python",
      "description": "Instantiate package: Verify bootstrap output works with all platform adaptors",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_bootstrap_skill_e2e.py",
      "line_start": 157,
      "line_end": 160,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: run_bootstrap, output_skill_dir, tmp_path",
      "tags": [],
      "dependencies": [
        "subprocess",
        "sys",
        "pathlib",
        "pytest",
        "skill_seekers.cli.adaptors"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cfcda9be",
      "test_name": "test_doc_scraper_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers scrape', content)\nself.assertNotIn('python3 cli/doc_scraper.py', content)",
      "language": "Python",
      "description": "Test doc_scraper.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/doc_scraper.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 30,
      "line_end": 33,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6b9ece97",
      "test_name": "test_enhance_skill_local_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers', content)\nself.assertNotIn('python3 cli/enhance_skill_local.py', content)",
      "language": "Python",
      "description": "Test enhance_skill_local.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/enhance_skill_local.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 49,
      "line_end": 52,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "329006f5",
      "test_name": "test_estimate_pages_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers estimate', content)\nself.assertNotIn('python3 cli/estimate_pages.py', content)",
      "language": "Python",
      "description": "Test estimate_pages.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/estimate_pages.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 64,
      "line_end": 67,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ee96f84a",
      "test_name": "test_package_skill_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers package', content)\nself.assertNotIn('python3 cli/package_skill.py', content)",
      "language": "Python",
      "description": "Test package_skill.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/package_skill.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 79,
      "line_end": 82,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f805e26e",
      "test_name": "test_github_scraper_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers', content)\nself.assertNotIn('python3 cli/github_scraper.py', content)",
      "language": "Python",
      "description": "Test github_scraper.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/github_scraper.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 94,
      "line_end": 97,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cfcda9be",
      "test_name": "test_doc_scraper_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers scrape', content)\nself.assertNotIn('python3 cli/doc_scraper.py', content)",
      "language": "Python",
      "description": "Test doc_scraper.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/doc_scraper.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 30,
      "line_end": 33,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6b9ece97",
      "test_name": "test_enhance_skill_local_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers', content)\nself.assertNotIn('python3 cli/enhance_skill_local.py', content)",
      "language": "Python",
      "description": "Test enhance_skill_local.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/enhance_skill_local.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 49,
      "line_end": 52,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "329006f5",
      "test_name": "test_estimate_pages_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers estimate', content)\nself.assertNotIn('python3 cli/estimate_pages.py', content)",
      "language": "Python",
      "description": "Test estimate_pages.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/estimate_pages.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 64,
      "line_end": 67,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ee96f84a",
      "test_name": "test_package_skill_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers package', content)\nself.assertNotIn('python3 cli/package_skill.py', content)",
      "language": "Python",
      "description": "Test package_skill.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/package_skill.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 79,
      "line_end": 82,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f805e26e",
      "test_name": "test_github_scraper_uses_modern_commands",
      "category": "method_call",
      "code": "self.assertIn('skill-seekers', content)\nself.assertNotIn('python3 cli/github_scraper.py', content)",
      "language": "Python",
      "description": "Test github_scraper.py uses skill-seekers commands",
      "expected_behavior": "self.assertNotIn('python3 cli/github_scraper.py', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cli_paths.py",
      "line_start": 94,
      "line_end": 97,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "subprocess",
        "sys",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "982887d9",
      "test_name": "sample_config",
      "category": "config",
      "code": "config_data = {'name': 'test-framework', 'description': 'Test framework for testing', 'base_url': 'https://test-framework.dev/', 'selectors': {'main_content': 'article', 'title': 'h1', 'code_blocks': 'pre'}, 'url_patterns': {'include': ['/docs/'], 'exclude': ['/blog/', '/search/']}, 'categories': {'getting_started': ['introduction', 'getting-started'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 100}",
      "language": "Python",
      "description": "Configuration example: Create a sample config file.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_fastmcp.py",
      "line_start": 64,
      "line_end": 76,
      "complexity_score": 0.85,
      "confidence": 0.75,
      "setup_code": "# Fixtures: temp_dirs",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "mcp.server",
        "mcp.types",
        "skill_seekers.mcp"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2410da95",
      "test_name": "unified_config",
      "category": "config",
      "code": "config_data = {'name': 'test-unified', 'description': 'Test unified scraping', 'merge_mode': 'rule-based', 'sources': [{'type': 'documentation', 'base_url': 'https://example.com/docs/', 'extract_api': True, 'max_pages': 10}, {'type': 'github', 'repo': 'test/repo', 'extract_readme': True}]}",
      "language": "Python",
      "description": "Configuration example: Create a sample unified config file.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_fastmcp.py",
      "line_start": 86,
      "line_end": 99,
      "complexity_score": 0.6,
      "confidence": 0.75,
      "setup_code": "# Fixtures: temp_dirs",
      "tags": [
        "pytest"
      ],
      "dependencies": [
        "json",
        "os",
        "unittest.mock",
        "pytest",
        "mcp.server",
        "mcp.types",
        "skill_seekers.mcp"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b3823f05",
      "test_name": "test_analyze_quick_preset",
      "category": "workflow",
      "code": "'Test quick analysis preset (real execution).'\noutput_dir = self.test_dir / 'output_quick'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Quick analysis failed:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}')\nself.assertTrue(output_dir.exists(), 'Output directory not created')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not generated')\nskill_content = skill_file.read_text()\nself.assertGreater(len(skill_content), 100, 'SKILL.md is too short')\nself.assertIn('Codebase', skill_content, 'Missing codebase header')\nself.assertIn('Analysis', skill_content, 'Missing analysis section')\nself.assertTrue(skill_content.startswith('---'), 'Missing YAML frontmatter')\nself.assertIn('name:', skill_content, 'Missing name in frontmatter')",
      "language": "Python",
      "description": "Workflow: Test quick analysis preset (real execution).",
      "expected_behavior": "self.assertIn('name:', skill_content, 'Missing name in frontmatter')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 106,
      "line_end": 138,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4db84019",
      "test_name": "test_analyze_output_structure",
      "category": "workflow",
      "code": "'Test that output has expected structure.'\noutput_dir = self.test_dir / 'output_structure'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nself.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')\nanalysis_file = output_dir / 'code_analysis.json'\nif analysis_file.exists():\n    with open(analysis_file) as f:\n        data = json.load(f)\n        self.assertIsInstance(data, (dict, list), 'code_analysis.json is not valid JSON')",
      "language": "Python",
      "description": "Workflow: Test that output has expected structure.",
      "expected_behavior": "self.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 228,
      "line_end": 247,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c431e62b",
      "test_name": "test_analyze_then_check_output",
      "category": "workflow",
      "code": "'Test analyzing and verifying output can be read.'\noutput_dir = self.test_dir / 'output'\nresult = subprocess.run(['skill-seekers', 'analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick'], capture_output=True, text=True, timeout=120)\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not created')\ncontent = skill_file.read_text()\nself.assertGreater(len(content), 50, 'Output too short')\nself.assertIn('Codebase', content, 'Missing codebase header')\nself.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
      "language": "Python",
      "description": "Workflow: Test analyzing and verifying output can be read.",
      "expected_behavior": "self.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 283,
      "line_end": 314,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test directory.'\nself.test_dir = Path(tempfile.mkdtemp(prefix='analyze_int_'))\n(self.test_dir / 'main.py').write_text('\\ndef hello():\\n    \"\"\"Say hello.\"\"\"\\n    return \"Hello, World!\"\\n')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b3823f05",
      "test_name": "test_analyze_quick_preset",
      "category": "workflow",
      "code": "'Test quick analysis preset (real execution).'\noutput_dir = self.test_dir / 'output_quick'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Quick analysis failed:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}')\nself.assertTrue(output_dir.exists(), 'Output directory not created')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not generated')\nskill_content = skill_file.read_text()\nself.assertGreater(len(skill_content), 100, 'SKILL.md is too short')\nself.assertIn('Codebase', skill_content, 'Missing codebase header')\nself.assertIn('Analysis', skill_content, 'Missing analysis section')\nself.assertTrue(skill_content.startswith('---'), 'Missing YAML frontmatter')\nself.assertIn('name:', skill_content, 'Missing name in frontmatter')",
      "language": "Python",
      "description": "Workflow: Test quick analysis preset (real execution).",
      "expected_behavior": "self.assertIn('name:', skill_content, 'Missing name in frontmatter')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 106,
      "line_end": 138,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4db84019",
      "test_name": "test_analyze_output_structure",
      "category": "workflow",
      "code": "'Test that output has expected structure.'\noutput_dir = self.test_dir / 'output_structure'\nresult = self.run_command('analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick')\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nself.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')\nanalysis_file = output_dir / 'code_analysis.json'\nif analysis_file.exists():\n    with open(analysis_file) as f:\n        data = json.load(f)\n        self.assertIsInstance(data, (dict, list), 'code_analysis.json is not valid JSON')",
      "language": "Python",
      "description": "Workflow: Test that output has expected structure.",
      "expected_behavior": "self.assertTrue((output_dir / 'SKILL.md').exists(), 'SKILL.md missing')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 228,
      "line_end": 247,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c431e62b",
      "test_name": "test_analyze_then_check_output",
      "category": "workflow",
      "code": "'Test analyzing and verifying output can be read.'\noutput_dir = self.test_dir / 'output'\nresult = subprocess.run(['skill-seekers', 'analyze', '--directory', str(self.test_dir), '--output', str(output_dir), '--quick'], capture_output=True, text=True, timeout=120)\nself.assertEqual(result.returncode, 0, f'Analysis failed: {result.stderr}')\nskill_file = output_dir / 'SKILL.md'\nself.assertTrue(skill_file.exists(), 'SKILL.md not created')\ncontent = skill_file.read_text()\nself.assertGreater(len(content), 50, 'Output too short')\nself.assertIn('Codebase', content, 'Missing codebase header')\nself.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
      "language": "Python",
      "description": "Workflow: Test analyzing and verifying output can be read.",
      "expected_behavior": "self.assertTrue(content.startswith('---'), 'Missing YAML frontmatter')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 283,
      "line_end": 314,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4d0fe165",
      "test_name": "test_analyze_help_shows_command",
      "category": "method_call",
      "code": "self.assertEqual(result.returncode, 0, f'Help failed: {result.stderr}')\nself.assertIn('analyze', result.stdout)",
      "language": "Python",
      "description": "Test that analyze command appears in main help.",
      "expected_behavior": "self.assertIn('analyze', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 93,
      "line_end": 94,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e46d507b",
      "test_name": "test_analyze_help_shows_command",
      "category": "method_call",
      "code": "self.assertIn('analyze', result.stdout)\nself.assertIn('Analyze local codebase', result.stdout)",
      "language": "Python",
      "description": "Test that analyze command appears in main help.",
      "expected_behavior": "self.assertIn('Analyze local codebase', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 94,
      "line_end": 95,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d341e3e5",
      "test_name": "test_analyze_subcommand_help",
      "category": "method_call",
      "code": "self.assertEqual(result.returncode, 0, f'Analyze help failed: {result.stderr}')\nself.assertIn('--quick', result.stdout)",
      "language": "Python",
      "description": "Test that analyze subcommand has proper help.",
      "expected_behavior": "self.assertIn('--quick', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 100,
      "line_end": 101,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4d0d52ff",
      "test_name": "test_analyze_subcommand_help",
      "category": "method_call",
      "code": "self.assertIn('--quick', result.stdout)\nself.assertIn('--comprehensive', result.stdout)",
      "language": "Python",
      "description": "Test that analyze subcommand has proper help.",
      "expected_behavior": "self.assertIn('--comprehensive', result.stdout)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_e2e.py",
      "line_start": 101,
      "line_end": 102,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "json",
        "shutil",
        "subprocess",
        "sys",
        "tempfile",
        "unittest",
        "pathlib"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "91db06e1",
      "test_name": "test_e2e_all_platforms_from_same_skill",
      "category": "workflow",
      "code": "'Test that all platforms can package the same skill'\nplatforms = ['claude', 'gemini', 'openai', 'markdown']\npackages = {}\nfor platform in platforms:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    self.assertTrue(package_path.exists(), f'Package not created for {platform}')\n    packages[platform] = package_path\nself.assertEqual(len(packages), 4)\nself.assertTrue(str(packages['claude']).endswith('.zip'))\nself.assertTrue(str(packages['gemini']).endswith('.tar.gz'))\nself.assertTrue(str(packages['openai']).endswith('.zip'))\nself.assertTrue(str(packages['markdown']).endswith('.zip'))",
      "language": "Python",
      "description": "Workflow: Test that all platforms can package the same skill",
      "expected_behavior": "self.assertTrue(str(packages['markdown']).endswith('.zip'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 129,
      "line_end": 153,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "62dfc4ba",
      "test_name": "test_e2e_claude_workflow",
      "category": "workflow",
      "code": "'Test complete Claude workflow: package + verify structure'\nadaptor = get_adaptor('claude')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('SKILL.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    skill_content = zf.read('SKILL.md').decode('utf-8')\n    self.assertGreater(len(skill_content), 0)",
      "language": "Python",
      "description": "Workflow: Test complete Claude workflow: package + verify structure",
      "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 155,
      "line_end": 180,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7a17248a",
      "test_name": "test_e2e_gemini_workflow",
      "category": "workflow",
      "code": "'Test complete Gemini workflow: package + verify structure'\nadaptor = get_adaptor('gemini')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.tar.gz'))\nwith tarfile.open(package_path, 'r:gz') as tar:\n    names = tar.getnames()\n    self.assertIn('system_instructions.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    self.assertIn('gemini_metadata.json', names)\n    metadata_member = tar.getmember('gemini_metadata.json')\n    metadata_file = tar.extractfile(metadata_member)\n    metadata = json.loads(metadata_file.read().decode('utf-8'))\n    self.assertEqual(metadata['platform'], 'gemini')\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertIn('created_with', metadata)",
      "language": "Python",
      "description": "Workflow: Test complete Gemini workflow: package + verify structure",
      "expected_behavior": "self.assertTrue(str(package_path).endswith('.tar.gz'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 182,
      "line_end": 213,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "500562d5",
      "test_name": "test_e2e_openai_workflow",
      "category": "workflow",
      "code": "'Test complete OpenAI workflow: package + verify structure'\nadaptor = get_adaptor('openai')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('assistant_instructions.txt', names)\n    self.assertTrue(any(('vector_store_files/' in name for name in names)))\n    self.assertIn('openai_metadata.json', names)\n    metadata_content = zf.read('openai_metadata.json').decode('utf-8')\n    metadata = json.loads(metadata_content)\n    self.assertEqual(metadata['platform'], 'openai')\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertEqual(metadata['model'], 'gpt-4o')\n    self.assertIn('file_search', metadata['tools'])",
      "language": "Python",
      "description": "Workflow: Test complete OpenAI workflow: package + verify structure",
      "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 215,
      "line_end": 246,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dec94e70",
      "test_name": "test_e2e_markdown_workflow",
      "category": "workflow",
      "code": "'Test complete Markdown workflow: package + verify structure'\nadaptor = get_adaptor('markdown')\npackage_path = adaptor.package(self.skill_dir, self.output_dir)\nself.assertTrue(package_path.exists())\nself.assertTrue(str(package_path).endswith('.zip'))\nwith zipfile.ZipFile(package_path, 'r') as zf:\n    names = zf.namelist()\n    self.assertIn('README.md', names)\n    self.assertIn('DOCUMENTATION.md', names)\n    self.assertTrue(any(('references/' in name for name in names)))\n    self.assertIn('metadata.json', names)\n    doc_content = zf.read('DOCUMENTATION.md').decode('utf-8')\n    self.assertIn('Getting Started', doc_content)\n    self.assertIn('React Hooks', doc_content)\n    self.assertIn('Components', doc_content)",
      "language": "Python",
      "description": "Workflow: Test complete Markdown workflow: package + verify structure",
      "expected_behavior": "self.assertTrue(str(package_path).endswith('.zip'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 248,
      "line_end": 281,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "13e57c58",
      "test_name": "test_e2e_package_format_validation",
      "category": "workflow",
      "code": "'Test that each platform creates correct package format'\ntest_cases = [('claude', '.zip'), ('gemini', '.tar.gz'), ('openai', '.zip'), ('markdown', '.zip')]\nfor platform, expected_ext in test_cases:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if expected_ext == '.tar.gz':\n        self.assertTrue(str(package_path).endswith('.tar.gz'), f'{platform} should create .tar.gz file')\n    else:\n        self.assertTrue(str(package_path).endswith('.zip'), f'{platform} should create .zip file')",
      "language": "Python",
      "description": "Workflow: Test that each platform creates correct package format",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 283,
      "line_end": 304,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a20b3287",
      "test_name": "test_e2e_package_filename_convention",
      "category": "workflow",
      "code": "'Test that package filenames follow convention'\ntest_cases = [('claude', 'test-skill.zip'), ('gemini', 'test-skill-gemini.tar.gz'), ('openai', 'test-skill-openai.zip'), ('markdown', 'test-skill-markdown.zip')]\nfor platform, expected_name in test_cases:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    self.assertEqual(package_path.name, expected_name, f'{platform} package filename incorrect')",
      "language": "Python",
      "description": "Workflow: Test that package filenames follow convention",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 306,
      "line_end": 322,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7c83641e",
      "test_name": "test_e2e_all_platforms_preserve_references",
      "category": "workflow",
      "code": "'Test that all platforms preserve reference files'\nref_files = ['getting_started.md', 'hooks.md', 'components.md']\nfor platform in ['claude', 'gemini', 'openai', 'markdown']:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if platform == 'gemini':\n        with tarfile.open(package_path, 'r:gz') as tar:\n            names = tar.getnames()\n            for ref_file in ref_files:\n                self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')\n    else:\n        with zipfile.ZipFile(package_path, 'r') as zf:\n            names = zf.namelist()\n            for ref_file in ref_files:\n                if platform == 'openai':\n                    self.assertTrue(any((f'vector_store_files/{ref_file}' in name for name in names)), f'{platform}: {ref_file} not found in vector_store_files/')\n                else:\n                    self.assertTrue(any((ref_file in name for name in names)), f'{platform}: {ref_file} not found in package')",
      "language": "Python",
      "description": "Workflow: Test that all platforms preserve reference files",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 324,
      "line_end": 355,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "baaebdb2",
      "test_name": "test_e2e_metadata_consistency",
      "category": "workflow",
      "code": "'Test that metadata is consistent across platforms'\nplatforms_with_metadata = ['gemini', 'openai', 'markdown']\nfor platform in platforms_with_metadata:\n    adaptor = get_adaptor(platform)\n    package_path = adaptor.package(self.skill_dir, self.output_dir)\n    if platform == 'gemini':\n        with tarfile.open(package_path, 'r:gz') as tar:\n            metadata_member = tar.getmember('gemini_metadata.json')\n            metadata_file = tar.extractfile(metadata_member)\n            metadata = json.loads(metadata_file.read().decode('utf-8'))\n    else:\n        with zipfile.ZipFile(package_path, 'r') as zf:\n            metadata_filename = f'{platform}_metadata.json' if platform == 'openai' else 'metadata.json'\n            metadata_content = zf.read(metadata_filename).decode('utf-8')\n            metadata = json.loads(metadata_content)\n    self.assertEqual(metadata['platform'], platform)\n    self.assertEqual(metadata['name'], 'test-skill')\n    self.assertIn('created_with', metadata)",
      "language": "Python",
      "description": "Workflow: Test that metadata is consistent across platforms",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 357,
      "line_end": 382,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cd0700dc",
      "test_name": "test_e2e_format_skill_md_differences",
      "category": "workflow",
      "code": "'Test that each platform formats SKILL.md differently'\nmetadata = SkillMetadata(name='test-skill', description='Test skill for E2E testing')\nformats = {}\nfor platform in ['claude', 'gemini', 'openai', 'markdown']:\n    adaptor = get_adaptor(platform)\n    formatted = adaptor.format_skill_md(self.skill_dir, metadata)\n    formats[platform] = formatted\nself.assertTrue(formats['claude'].startswith('---'))\nself.assertFalse(formats['gemini'].startswith('---'))\nself.assertFalse(formats['markdown'].startswith('---'))\nfor platform, formatted in formats.items():\n    self.assertIn('react', formatted.lower(), f'{platform} should contain skill content')\n    self.assertGreater(len(formatted), 100, f'{platform} should have substantial content')",
      "language": "Python",
      "description": "Workflow: Test that each platform formats SKILL.md differently",
      "expected_behavior": "self.assertFalse(formats['markdown'].startswith('---'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_adaptors_e2e.py",
      "line_start": 384,
      "line_end": 406,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "'Set up test environment with sample skill directory'\nself.temp_dir = tempfile.TemporaryDirectory()\nself.skill_dir = Path(self.temp_dir.name) / 'test-skill'\nself.skill_dir.mkdir()\nself._create_sample_skill()\nself.output_dir = Path(self.temp_dir.name) / 'output'\nself.output_dir.mkdir()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "tarfile",
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "chromadb"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4bd3db24",
      "test_name": "test_comprehensive_preset_implies_full_depth",
      "category": "workflow",
      "code": "'Test that --comprehensive preset should trigger full depth.'\nargs = self.parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nself.assertTrue(args.comprehensive)",
      "language": "Python",
      "description": "Workflow: Test that --comprehensive preset should trigger full depth.",
      "expected_behavior": "self.assertTrue(args.comprehensive)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 170,
      "line_end": 173,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4bd3db24",
      "test_name": "test_comprehensive_preset_implies_full_depth",
      "category": "workflow",
      "code": "'Test that --comprehensive preset should trigger full depth.'\nargs = self.parser.parse_args(['analyze', '--directory', '.', '--comprehensive'])\nself.assertTrue(args.comprehensive)",
      "language": "Python",
      "description": "Workflow: Test that --comprehensive preset should trigger full depth.",
      "expected_behavior": "self.assertTrue(args.comprehensive)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 170,
      "line_end": 173,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5d6c6c65",
      "test_name": "test_analyze_subcommand_exists",
      "category": "method_call",
      "code": "self.assertEqual(args.command, 'analyze')\nself.assertEqual(args.directory, '.')",
      "language": "Python",
      "description": "Test that analyze subcommand is registered.",
      "expected_behavior": "self.assertEqual(args.directory, '.')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 23,
      "line_end": 24,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc89bd3a",
      "test_name": "test_quick_preset_flag",
      "category": "method_call",
      "code": "self.assertTrue(args.quick)\nself.assertFalse(args.comprehensive)",
      "language": "Python",
      "description": "Test --quick preset flag parsing.",
      "expected_behavior": "self.assertFalse(args.comprehensive)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 34,
      "line_end": 35,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8b4c057d",
      "test_name": "test_comprehensive_preset_flag",
      "category": "method_call",
      "code": "self.assertTrue(args.comprehensive)\nself.assertFalse(args.quick)",
      "language": "Python",
      "description": "Test --comprehensive preset flag parsing.",
      "expected_behavior": "self.assertFalse(args.quick)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 40,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d930d69e",
      "test_name": "test_quick_and_comprehensive_mutually_exclusive",
      "category": "method_call",
      "code": "self.assertTrue(args.quick)\nself.assertTrue(args.comprehensive)",
      "language": "Python",
      "description": "Test that both flags can be parsed (mutual exclusion enforced at runtime).",
      "expected_behavior": "self.assertTrue(args.comprehensive)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 47,
      "line_end": 48,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cc54116e",
      "test_name": "test_skip_flags_passed_through",
      "category": "method_call",
      "code": "self.assertTrue(args.skip_patterns)\nself.assertTrue(args.skip_test_examples)",
      "language": "Python",
      "description": "Test that skip flags are recognized.",
      "expected_behavior": "self.assertTrue(args.skip_test_examples)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 61,
      "line_end": 62,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ecd34bb6",
      "test_name": "test_all_skip_flags",
      "category": "method_call",
      "code": "self.assertTrue(args.skip_api_reference)\nself.assertTrue(args.skip_dependency_graph)",
      "language": "Python",
      "description": "Test all skip flags are properly parsed.",
      "expected_behavior": "self.assertTrue(args.skip_dependency_graph)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 80,
      "line_end": 81,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dd11d9cf",
      "test_name": "test_all_skip_flags",
      "category": "method_call",
      "code": "self.assertTrue(args.skip_dependency_graph)\nself.assertTrue(args.skip_patterns)",
      "language": "Python",
      "description": "Test all skip flags are properly parsed.",
      "expected_behavior": "self.assertTrue(args.skip_patterns)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 81,
      "line_end": 82,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cc54116e",
      "test_name": "test_all_skip_flags",
      "category": "method_call",
      "code": "self.assertTrue(args.skip_patterns)\nself.assertTrue(args.skip_test_examples)",
      "language": "Python",
      "description": "Test all skip flags are properly parsed.",
      "expected_behavior": "self.assertTrue(args.skip_test_examples)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_analyze_command.py",
      "line_start": 82,
      "line_end": 83,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Create parser for testing.'\nself.parser = create_parser()",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "sys",
        "unittest",
        "pathlib",
        "skill_seekers.cli.main"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7c0d7c39",
      "test_name": "test_health_check_endpoint",
      "category": "instantiation",
      "code": "response = client.get('/health')",
      "language": "Python",
      "description": "Instantiate get: Test that health check endpoint returns correct response.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_server_fastmcp_http.py",
      "line_start": 64,
      "line_end": 64,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pytest",
        "skill_seekers.mcp.server_fastmcp",
        "starlette.testclient",
        "starlette.responses",
        "starlette.routing",
        "starlette.middleware.cors",
        "skill_seekers.mcp.server_fastmcp",
        "skill_seekers.mcp.server_fastmcp",
        "skill_seekers.mcp.server_fastmcp"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e478eee2",
      "test_name": "test_cors_middleware",
      "category": "method_call",
      "code": "app.add_middleware(CORSMiddleware, allow_origins=['*'], allow_credentials=True, allow_methods=['*'], allow_headers=['*'])\nassert len(app.user_middleware) > 0",
      "language": "Python",
      "description": "Test that CORS middleware can be added.",
      "expected_behavior": "assert len(app.user_middleware) > 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_server_fastmcp_http.py",
      "line_start": 101,
      "line_end": 110,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "sys",
        "pytest",
        "skill_seekers.mcp.server_fastmcp",
        "starlette.testclient",
        "starlette.responses",
        "starlette.routing",
        "starlette.middleware.cors",
        "skill_seekers.mcp.server_fastmcp",
        "skill_seekers.mcp.server_fastmcp",
        "skill_seekers.mcp.server_fastmcp"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ad73a5fc",
      "test_name": "test_codebase_analysis_enabled_by_default",
      "category": "workflow",
      "code": "'Test that enable_codebase_analysis defaults to True.'\nconfig_without_flag = {'name': 'test', 'description': 'Test', 'sources': [{'type': 'github', 'repo': 'test/repo', 'local_repo_path': temp_dir}]}\nconfig_path = os.path.join(temp_dir, 'config.json')\nwith open(config_path, 'w') as f:\n    json.dump(config_without_flag, f)\nscraper = UnifiedScraper(config_path)\ngithub_source = scraper.config['sources'][0]\nassert github_source.get('enable_codebase_analysis', True)",
      "language": "Python",
      "description": "Workflow: Test that enable_codebase_analysis defaults to True.",
      "expected_behavior": "assert github_source.get('enable_codebase_analysis', True)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 139,
      "line_end": 158,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_config, temp_dir",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "999a84fb",
      "test_name": "test_skip_codebase_analysis_flag",
      "category": "workflow",
      "code": "'Test --skip-codebase-analysis CLI flag disables analysis.'\nconfig_path = os.path.join(temp_dir, 'config.json')\nwith open(config_path, 'w') as f:\n    json.dump(mock_config, f)\nscraper = UnifiedScraper(config_path)\nfor source in scraper.config.get('sources', []):\n    if source['type'] == 'github':\n        source['enable_codebase_analysis'] = False\ngithub_source = scraper.config['sources'][0]\nassert not github_source['enable_codebase_analysis']",
      "language": "Python",
      "description": "Workflow: Test --skip-codebase-analysis CLI flag disables analysis.",
      "expected_behavior": "assert not github_source['enable_codebase_analysis']",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 160,
      "line_end": 177,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_config, temp_dir",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eb6091e1",
      "test_name": "test_architecture_md_generation",
      "category": "workflow",
      "code": "'Test ARCHITECTURE.md is generated with all 8 sections.'\ngithub_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}\nscraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nc3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')\nos.makedirs(c3_dir, exist_ok=True)\nbuilder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)\narch_file = os.path.join(c3_dir, 'ARCHITECTURE.md')\nassert os.path.exists(arch_file)\nwith open(arch_file) as f:\n    content = f.read()\nassert '## 1. Overview' in content\nassert '## 2. Architectural Patterns' in content\nassert '## 3. Technology Stack' in content\nassert '## 4. Design Patterns' in content\nassert '## 5. Configuration Overview' in content\nassert '## 6. Common Workflows' in content\nassert '## 7. Usage Examples' in content\nassert '## 8. Entry Points & Directory Structure' in content\nassert 'MVC' in content\nassert 'Flask' in content\nassert 'Factory' in content\nassert '15 usage example(s)' in content or '15 total' in content\nassert 'Security Alert' in content",
      "language": "Python",
      "description": "Workflow: Test ARCHITECTURE.md is generated with all 8 sections.",
      "expected_behavior": "assert 'Security Alert' in content",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 179,
      "line_end": 218,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e20cfa94",
      "test_name": "test_c3_reference_directory_structure",
      "category": "workflow",
      "code": "'Test correct C3.x reference directory structure is created.'\ngithub_data = {'readme': 'Test README', 'c3_analysis': mock_c3_data}\nscraped_data = {'github': [{'repo': 'test/repo', 'repo_id': 'test_repo', 'idx': 0, 'data': github_data}]}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nc3_dir = os.path.join(temp_dir, 'references', 'codebase_analysis')\nos.makedirs(c3_dir, exist_ok=True)\nbuilder._generate_architecture_overview(c3_dir, mock_c3_data, github_data)\nbuilder._generate_pattern_references(c3_dir, mock_c3_data.get('patterns'))\nbuilder._generate_example_references(c3_dir, mock_c3_data.get('test_examples'))\nbuilder._generate_guide_references(c3_dir, mock_c3_data.get('how_to_guides'))\nbuilder._generate_config_references(c3_dir, mock_c3_data.get('config_patterns'))\nbuilder._copy_architecture_details(c3_dir, mock_c3_data.get('architecture'))\nassert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns'))\nassert os.path.exists(os.path.join(c3_dir, 'examples'))\nassert os.path.exists(os.path.join(c3_dir, 'guides'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration'))\nassert os.path.exists(os.path.join(c3_dir, 'architecture_details'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'examples', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'guides', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'architecture_details', 'index.md'))\nassert os.path.exists(os.path.join(c3_dir, 'patterns', 'detected_patterns.json'))\nassert os.path.exists(os.path.join(c3_dir, 'examples', 'test_examples.json'))\nassert os.path.exists(os.path.join(c3_dir, 'configuration', 'config_patterns.json'))",
      "language": "Python",
      "description": "Workflow: Test correct C3.x reference directory structure is created.",
      "expected_behavior": "assert os.path.exists(os.path.join(c3_dir, 'configuration', 'config_patterns.json'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 220,
      "line_end": 260,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3720510e",
      "test_name": "test_skill_md_includes_c3_summary",
      "category": "workflow",
      "code": "'Test SKILL.md includes C3.x architecture summary.'\nscraped_data = {'github': {'data': {'readme': 'Test README', 'c3_analysis': mock_c3_data}}}\nbuilder = UnifiedSkillBuilder(mock_config, scraped_data)\nbuilder.skill_dir = temp_dir\nbuilder._generate_skill_md()\nskill_file = os.path.join(temp_dir, 'SKILL.md')\nwith open(skill_file) as f:\n    content = f.read()\nassert '## \ud83c\udfd7\ufe0f Architecture & Code Analysis' in content\nassert 'Primary Architecture' in content\nassert 'MVC' in content\nassert 'Design Patterns' in content\nassert 'Factory' in content\nassert 'references/codebase_analysis/ARCHITECTURE.md' in content",
      "language": "Python",
      "description": "Workflow: Test SKILL.md includes C3.x architecture summary.",
      "expected_behavior": "assert 'references/codebase_analysis/ARCHITECTURE.md' in content",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 339,
      "line_end": 358,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
      "tags": [
        "mock",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4d7a211d",
      "test_name": "test_c3_reference_directory_structure",
      "category": "method_call",
      "code": "builder._copy_architecture_details(c3_dir, mock_c3_data.get('architecture'))\nassert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))",
      "language": "Python",
      "description": "Test correct C3.x reference directory structure is created.",
      "expected_behavior": "assert os.path.exists(os.path.join(c3_dir, 'ARCHITECTURE.md'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 240,
      "line_end": 243,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "# Fixtures: mock_config, mock_c3_data, temp_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a9ce99a0",
      "test_name": "test_codebase_analysis_enabled_by_default",
      "category": "instantiation",
      "code": "config_path = os.path.join(temp_dir, 'config.json')",
      "language": "Python",
      "description": "Instantiate join: Test that enable_codebase_analysis defaults to True.",
      "expected_behavior": "assert github_source.get('enable_codebase_analysis', True)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 149,
      "line_end": 149,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_config, temp_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e0dbaafa",
      "test_name": "test_codebase_analysis_enabled_by_default",
      "category": "instantiation",
      "code": "scraper = UnifiedScraper(config_path)",
      "language": "Python",
      "description": "Instantiate UnifiedScraper: Test that enable_codebase_analysis defaults to True.",
      "expected_behavior": "assert github_source.get('enable_codebase_analysis', True)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 154,
      "line_end": 154,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_config, temp_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a9ce99a0",
      "test_name": "test_skip_codebase_analysis_flag",
      "category": "instantiation",
      "code": "config_path = os.path.join(temp_dir, 'config.json')",
      "language": "Python",
      "description": "Instantiate join: Test --skip-codebase-analysis CLI flag disables analysis.",
      "expected_behavior": "assert not github_source['enable_codebase_analysis']",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 163,
      "line_end": 163,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_config, temp_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e0dbaafa",
      "test_name": "test_skip_codebase_analysis_flag",
      "category": "instantiation",
      "code": "scraper = UnifiedScraper(config_path)",
      "language": "Python",
      "description": "Instantiate UnifiedScraper: Test --skip-codebase-analysis CLI flag disables analysis.",
      "expected_behavior": "assert not github_source['enable_codebase_analysis']",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_c3_integration.py",
      "line_start": 168,
      "line_end": 168,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_config, temp_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "os",
        "shutil",
        "tempfile",
        "unittest.mock",
        "pytest",
        "skill_seekers.cli.config_validator",
        "skill_seekers.cli.unified_scraper",
        "skill_seekers.cli.unified_skill_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2885431f",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as Chroma collection data.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for Chroma format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\ncollection_json = adaptor.format_skill_md(skill_dir, metadata)\ncollection = json.loads(collection_json)\nassert 'documents' in collection\nassert 'metadatas' in collection\nassert 'ids' in collection\nassert len(collection['documents']) == 3\nassert len(collection['metadatas']) == 3\nassert len(collection['ids']) == 3\nfor meta in collection['metadatas']:\n    assert meta['source'] == 'test_skill'\n    assert meta['version'] == '1.0.0'\n    assert 'category' in meta\n    assert 'file' in meta\n    assert 'type' in meta\ncategories = {meta['category'] for meta in collection['metadatas']}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as Chroma collection data.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 23,
      "line_end": 67,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e68be240",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('chroma')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'chroma' in output_path.name\nwith open(output_path) as f:\n    collection = json.load(f)\nassert 'documents' in collection\nassert 'metadatas' in collection\nassert 'ids' in collection\nassert len(collection['documents']) > 0",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert len(collection['documents']) > 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 69,
      "line_end": 92,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3db0e912",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('chroma')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-chroma.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'chroma' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'chroma' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 94,
      "line_end": 109,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eed4b1d6",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\ncollection_json = adaptor.format_skill_md(skill_dir, metadata)\ncollection = json.loads(collection_json)\nassert collection['documents'] == []\nassert collection['metadatas'] == []\nassert collection['ids'] == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert collection['ids'] == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 153,
      "line_end": 167,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cef1616e",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('chroma')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\ncollection_json = adaptor.format_skill_md(skill_dir, metadata)\ncollection = json.loads(collection_json)\nassert len(collection['documents']) == 1\nassert collection['metadatas'][0]['category'] == 'test'\nassert collection['metadatas'][0]['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert collection['metadatas'][0]['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 169,
      "line_end": 186,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ac42b59",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('chroma')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that Chroma adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'chroma'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ac42b59",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('chroma')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as Chroma collection data.",
      "expected_behavior": "assert 'documents' in collection",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as Chroma collection data.",
      "expected_behavior": "assert 'documents' in collection",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ca16b271",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "collection_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as Chroma collection data.",
      "expected_behavior": "assert 'documents' in collection",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e7bb0a6d",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "collection = json.loads(collection_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as Chroma collection data.",
      "expected_behavior": "assert 'documents' in collection",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_chroma_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9c566935",
      "test_name": "test_get_config_in_subdir",
      "category": "workflow",
      "code": "'Test loading config from subdirectory.'\nrepo_path = temp_cache_dir / 'test-repo'\nconfigs_dir = repo_path / 'configs'\nconfigs_dir.mkdir(parents=True)\nconfig_data = {'name': 'nestjs'}\n(configs_dir / 'nestjs.json').write_text(json.dumps(config_data))\nresult = git_repo.get_config(repo_path, 'nestjs')\nassert result == config_data",
      "language": "Python",
      "description": "Workflow: Test loading config from subdirectory.",
      "expected_behavior": "assert result == config_data",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 370,
      "line_end": 381,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: git_repo, temp_cache_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "eadb894d",
      "test_name": "test_force_refresh_deletes_cache",
      "category": "method_call",
      "code": "git_repo.clone_or_pull(source_name='test-source', git_url='https://github.com/org/repo.git', force_refresh=True)\nmock_clone.assert_called_once()",
      "language": "Python",
      "description": "Test force refresh deletes existing cache.",
      "expected_behavior": "mock_clone.assert_called_once()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 207,
      "line_end": 212,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "# Fixtures: mock_clone, git_repo, temp_cache_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "17f3d565",
      "test_name": "test_init_with_custom_cache_dir",
      "category": "instantiation",
      "code": "repo = GitConfigRepo(cache_dir=str(temp_cache_dir))",
      "language": "Python",
      "description": "Instantiate GitConfigRepo: Test initialization with custom cache directory.",
      "expected_behavior": "assert repo.cache_dir == temp_cache_dir",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 35,
      "line_end": 35,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: temp_cache_dir",
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "08b30196",
      "test_name": "test_inject_token_https",
      "category": "instantiation",
      "code": "result = GitConfigRepo.inject_token(url, token)",
      "language": "Python",
      "description": "Instantiate inject_token: Test token injection into HTTPS URL.",
      "expected_behavior": "assert result == 'https://ghp_testtoken123@github.com/org/repo.git'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 101,
      "line_end": 101,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "08b30196",
      "test_name": "test_inject_token_ssh_to_https",
      "category": "instantiation",
      "code": "result = GitConfigRepo.inject_token(url, token)",
      "language": "Python",
      "description": "Instantiate inject_token: Test SSH URL conversion to HTTPS with token.",
      "expected_behavior": "assert result == 'https://ghp_testtoken123@github.com/org/repo.git'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 109,
      "line_end": 109,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "08b30196",
      "test_name": "test_inject_token_with_port",
      "category": "instantiation",
      "code": "result = GitConfigRepo.inject_token(url, token)",
      "language": "Python",
      "description": "Instantiate inject_token: Test token injection with custom port.",
      "expected_behavior": "assert result == 'https://token123@gitlab.example.com:8443/org/repo.git'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 117,
      "line_end": 117,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "08b30196",
      "test_name": "test_inject_token_gitlab_ssh",
      "category": "instantiation",
      "code": "result = GitConfigRepo.inject_token(url, token)",
      "language": "Python",
      "description": "Instantiate inject_token: Test GitLab SSH URL conversion.",
      "expected_behavior": "assert result == 'https://glpat-token123@gitlab.com/group/project.git'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 125,
      "line_end": 125,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8996e8f0",
      "test_name": "test_clone_new_repo",
      "category": "instantiation",
      "code": "result = git_repo.clone_or_pull(source_name='test-source', git_url='https://github.com/org/repo.git')",
      "language": "Python",
      "description": "Instantiate clone_or_pull: Test cloning a new repository.",
      "expected_behavior": "assert result == git_repo.cache_dir / 'test-source'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 137,
      "line_end": 139,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_clone, git_repo",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8996e8f0",
      "test_name": "test_pull_existing_repo",
      "category": "instantiation",
      "code": "result = git_repo.clone_or_pull(source_name='test-source', git_url='https://github.com/org/repo.git')",
      "language": "Python",
      "description": "Instantiate clone_or_pull: Test pulling updates to existing repository.",
      "expected_behavior": "assert result == repo_path",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 164,
      "line_end": 166,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_repo_class, git_repo, temp_cache_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3f221349",
      "test_name": "test_pull_with_token_update",
      "category": "instantiation",
      "code": "_result = git_repo.clone_or_pull(source_name='test-source', git_url='https://github.com/org/repo.git', token='ghp_token123')",
      "language": "Python",
      "description": "Instantiate clone_or_pull: Test pulling with token updates remote URL.",
      "expected_behavior": "mock_origin.set_url.assert_called_once()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_git_repo.py",
      "line_start": 185,
      "line_end": 189,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: mock_repo_class, git_repo, temp_cache_dir",
      "tags": [
        "mock"
      ],
      "dependencies": [
        "json",
        "pathlib",
        "unittest.mock",
        "pytest",
        "git.exc",
        "skill_seekers.mcp.git_repo"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "32f8dabf",
      "test_name": "test_valid_complete_config",
      "category": "workflow",
      "code": "'Test valid complete configuration'\nconfig = {'name': 'godot', 'base_url': 'https://docs.godotengine.org/en/stable/', 'description': 'Godot Engine documentation', 'selectors': {'main_content': 'div[role=\"main\"]', 'title': 'title', 'code_blocks': 'pre code'}, 'url_patterns': {'include': ['/guide/', '/api/'], 'exclude': ['/blog/']}, 'categories': {'getting_started': ['intro', 'tutorial'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 500}\nerrors, _ = validate_config(config)\nself.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
      "language": "Python",
      "description": "Workflow: Test valid complete configuration",
      "expected_behavior": "self.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 27,
      "line_end": 44,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a6fc1ff6",
      "test_name": "test_valid_name_formats",
      "category": "workflow",
      "code": "'Test various valid name formats'\nvalid_names = ['test', 'test-skill', 'test_skill', 'TestSkill123', 'my-awesome-skill_v2']\nfor name in valid_names:\n    config = {'name': name, 'base_url': 'https://example.com/'}\n    errors, _ = validate_config(config)\n    name_errors = [e for e in errors if 'invalid name' in e.lower()]\n    self.assertEqual(len(name_errors), 0, f\"Name '{name}' should be valid\")",
      "language": "Python",
      "description": "Workflow: Test various valid name formats",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 64,
      "line_end": 71,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "32f8dabf",
      "test_name": "test_valid_complete_config",
      "category": "workflow",
      "code": "'Test valid complete configuration'\nconfig = {'name': 'godot', 'base_url': 'https://docs.godotengine.org/en/stable/', 'description': 'Godot Engine documentation', 'selectors': {'main_content': 'div[role=\"main\"]', 'title': 'title', 'code_blocks': 'pre code'}, 'url_patterns': {'include': ['/guide/', '/api/'], 'exclude': ['/blog/']}, 'categories': {'getting_started': ['intro', 'tutorial'], 'api': ['api', 'reference']}, 'rate_limit': 0.5, 'max_pages': 500}\nerrors, _ = validate_config(config)\nself.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
      "language": "Python",
      "description": "Workflow: Test valid complete configuration",
      "expected_behavior": "self.assertEqual(len(errors), 0, f'Valid config should have no errors, got: {errors}')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 27,
      "line_end": 44,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a6fc1ff6",
      "test_name": "test_valid_name_formats",
      "category": "workflow",
      "code": "'Test various valid name formats'\nvalid_names = ['test', 'test-skill', 'test_skill', 'TestSkill123', 'my-awesome-skill_v2']\nfor name in valid_names:\n    config = {'name': name, 'base_url': 'https://example.com/'}\n    errors, _ = validate_config(config)\n    name_errors = [e for e in errors if 'invalid name' in e.lower()]\n    self.assertEqual(len(name_errors), 0, f\"Name '{name}' should be valid\")",
      "language": "Python",
      "description": "Workflow: Test various valid name formats",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 64,
      "line_end": 71,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7921fb1f",
      "test_name": "test_missing_recommended_selectors",
      "category": "method_call",
      "code": "self.assertTrue(any(('title' in warning.lower() for warning in warnings)))\nself.assertTrue(any(('code_blocks' in warning.lower() for warning in warnings)))",
      "language": "Python",
      "description": "Test warning for missing recommended selectors",
      "expected_behavior": "self.assertTrue(any(('code_blocks' in warning.lower() for warning in warnings)))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 106,
      "line_end": 107,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6b139286",
      "test_name": "test_config_with_skip_llms_txt",
      "category": "method_call",
      "code": "self.assertEqual(errors, [])\nself.assertTrue(config.get('skip_llms_txt'))",
      "language": "Python",
      "description": "Test config validation accepts skip_llms_txt",
      "expected_behavior": "self.assertTrue(config.get('skip_llms_txt'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 257,
      "line_end": 258,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fca01aa2",
      "test_name": "test_config_with_skip_llms_txt_false",
      "category": "method_call",
      "code": "self.assertEqual(errors, [])\nself.assertFalse(config.get('skip_llms_txt'))",
      "language": "Python",
      "description": "Test config validation accepts skip_llms_txt as False",
      "expected_behavior": "self.assertFalse(config.get('skip_llms_txt'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 265,
      "line_end": 266,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7921fb1f",
      "test_name": "test_missing_recommended_selectors",
      "category": "method_call",
      "code": "self.assertTrue(any(('title' in warning.lower() for warning in warnings)))\nself.assertTrue(any(('code_blocks' in warning.lower() for warning in warnings)))",
      "language": "Python",
      "description": "Test warning for missing recommended selectors",
      "expected_behavior": "self.assertTrue(any(('code_blocks' in warning.lower() for warning in warnings)))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 106,
      "line_end": 107,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6b139286",
      "test_name": "test_config_with_skip_llms_txt",
      "category": "method_call",
      "code": "self.assertEqual(errors, [])\nself.assertTrue(config.get('skip_llms_txt'))",
      "language": "Python",
      "description": "Test config validation accepts skip_llms_txt",
      "expected_behavior": "self.assertTrue(config.get('skip_llms_txt'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 257,
      "line_end": 258,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fca01aa2",
      "test_name": "test_config_with_skip_llms_txt_false",
      "category": "method_call",
      "code": "self.assertEqual(errors, [])\nself.assertFalse(config.get('skip_llms_txt'))",
      "language": "Python",
      "description": "Test config validation accepts skip_llms_txt as False",
      "expected_behavior": "self.assertFalse(config.get('skip_llms_txt'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_config_validation.py",
      "line_start": 265,
      "line_end": 266,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cb8d825e",
      "test_name": "test_class_formatting",
      "category": "workflow",
      "code": "'Test markdown formatting for class signatures.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'docstring': 'A simple calculator class.', 'base_classes': ['object'], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'int', 'default': None}, {'name': 'b', 'type_hint': 'int', 'default': None}], 'return_type': 'int', 'docstring': 'Add two numbers.', 'is_async': False, 'is_method': True, 'decorators': []}]}], 'functions': []}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 1)\noutput_file = list(generated.values())[0]\nself.assertTrue(output_file.exists())\ncontent = output_file.read_text()\nself.assertIn('### Calculator', content)\nself.assertIn('A simple calculator class', content)\nself.assertIn('**Inherits from**: object', content)\nself.assertIn('##### add', content)\nself.assertIn('Add two numbers', content)",
      "language": "Python",
      "description": "Workflow: Test markdown formatting for class signatures.",
      "expected_behavior": "self.assertIn('Add two numbers', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 38,
      "line_end": 85,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0ccbbef2",
      "test_name": "test_function_formatting",
      "category": "workflow",
      "code": "'Test markdown formatting for function signatures.'\ncode_analysis = {'files': [{'file': 'utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'calculate_sum', 'parameters': [{'name': 'numbers', 'type_hint': 'list', 'default': None}], 'return_type': 'int', 'docstring': 'Calculate sum of numbers.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('## Functions', content)\nself.assertIn('### calculate_sum', content)\nself.assertIn('Calculate sum of numbers', content)\nself.assertIn('**Returns**: `int`', content)",
      "language": "Python",
      "description": "Workflow: Test markdown formatting for function signatures.",
      "expected_behavior": "self.assertIn('**Returns**: `int`', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 87,
      "line_end": 122,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "176f53b5",
      "test_name": "test_parameter_table_generation",
      "category": "workflow",
      "code": "'Test parameter table formatting.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'create_user', 'parameters': [{'name': 'name', 'type_hint': 'str', 'default': None}, {'name': 'age', 'type_hint': 'int', 'default': '18'}, {'name': 'active', 'type_hint': 'bool', 'default': 'True'}], 'return_type': 'dict', 'docstring': 'Create a user object.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Parameters**:', content)\nself.assertIn('| Name | Type | Default | Description |', content)\nself.assertIn('| name | str | - |', content)\nself.assertIn('| age | int | 18 |', content)\nself.assertIn('| active | bool | True |', content)",
      "language": "Python",
      "description": "Workflow: Test parameter table formatting.",
      "expected_behavior": "self.assertIn('| active | bool | True |', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 124,
      "line_end": 162,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "002fab06",
      "test_name": "test_markdown_output_structure",
      "category": "workflow",
      "code": "'Test overall markdown document structure.'\ncode_analysis = {'files': [{'file': 'module.py', 'language': 'Python', 'classes': [{'name': 'TestClass', 'docstring': 'Test class.', 'base_classes': [], 'methods': []}], 'functions': [{'name': 'test_func', 'parameters': [], 'return_type': None, 'docstring': 'Test function.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('# API Reference: module.py', content)\nself.assertIn('**Language**: Python', content)\nself.assertIn('**Source**: `module.py`', content)\nclasses_pos = content.find('## Classes')\nfunctions_pos = content.find('## Functions')\nself.assertNotEqual(classes_pos, -1)\nself.assertNotEqual(functions_pos, -1)\nself.assertLess(classes_pos, functions_pos)",
      "language": "Python",
      "description": "Workflow: Test overall markdown document structure.",
      "expected_behavior": "self.assertLess(classes_pos, functions_pos)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 164,
      "line_end": 212,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8dba195d",
      "test_name": "test_integration_with_code_analyzer",
      "category": "workflow",
      "code": "'Test integration with actual code analyzer output format.'\ncode_analysis = {'files': [{'file': 'calculator.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'base_classes': [], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'float', 'default': None}, {'name': 'b', 'type_hint': 'float', 'default': None}], 'return_type': 'float', 'docstring': 'Add two numbers.', 'decorators': [], 'is_async': False, 'is_method': True}], 'docstring': 'Calculator class.', 'line_number': 1}], 'functions': []}, {'file': 'utils.js', 'language': 'JavaScript', 'classes': [], 'functions': [{'name': 'formatDate', 'parameters': [{'name': 'date', 'type_hint': None, 'default': None}], 'return_type': None, 'docstring': None, 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 2)\nfilenames = [f.name for f in generated.values()]\nself.assertIn('calculator.md', filenames)\nself.assertIn('utils.md', filenames)\npy_file = next((f for f in generated.values() if f.name == 'calculator.md'))\npy_content = py_file.read_text()\nself.assertIn('Calculator class', py_content)\nself.assertIn('add(a: float, b: float) \u2192 float', py_content)\njs_file = next((f for f in generated.values() if f.name == 'utils.md'))\njs_content = js_file.read_text()\nself.assertIn('formatDate', js_content)\nself.assertIn('**Language**: JavaScript', js_content)",
      "language": "Python",
      "description": "Workflow: Test integration with actual code analyzer output format.",
      "expected_behavior": "self.assertIn('**Language**: JavaScript', js_content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 214,
      "line_end": 286,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a2d82022",
      "test_name": "test_async_function_indicator",
      "category": "workflow",
      "code": "'Test that async functions are marked in output.'\ncode_analysis = {'files': [{'file': 'async_utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'fetch_data', 'parameters': [{'name': 'url', 'type_hint': 'str', 'default': None}], 'return_type': 'dict', 'docstring': 'Fetch data from URL.', 'is_async': True, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Async function**', content)\nself.assertIn('fetch_data', content)",
      "language": "Python",
      "description": "Workflow: Test that async functions are marked in output.",
      "expected_behavior": "self.assertIn('fetch_data', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 288,
      "line_end": 319,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "'Set up test environment'\nself.temp_dir = tempfile.mkdtemp()\nself.output_dir = Path(self.temp_dir) / 'api_reference'",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "cb8d825e",
      "test_name": "test_class_formatting",
      "category": "workflow",
      "code": "'Test markdown formatting for class signatures.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [{'name': 'Calculator', 'docstring': 'A simple calculator class.', 'base_classes': ['object'], 'methods': [{'name': 'add', 'parameters': [{'name': 'a', 'type_hint': 'int', 'default': None}, {'name': 'b', 'type_hint': 'int', 'default': None}], 'return_type': 'int', 'docstring': 'Add two numbers.', 'is_async': False, 'is_method': True, 'decorators': []}]}], 'functions': []}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\nself.assertEqual(len(generated), 1)\noutput_file = list(generated.values())[0]\nself.assertTrue(output_file.exists())\ncontent = output_file.read_text()\nself.assertIn('### Calculator', content)\nself.assertIn('A simple calculator class', content)\nself.assertIn('**Inherits from**: object', content)\nself.assertIn('##### add', content)\nself.assertIn('Add two numbers', content)",
      "language": "Python",
      "description": "Workflow: Test markdown formatting for class signatures.",
      "expected_behavior": "self.assertIn('Add two numbers', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 38,
      "line_end": 85,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0ccbbef2",
      "test_name": "test_function_formatting",
      "category": "workflow",
      "code": "'Test markdown formatting for function signatures.'\ncode_analysis = {'files': [{'file': 'utils.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'calculate_sum', 'parameters': [{'name': 'numbers', 'type_hint': 'list', 'default': None}], 'return_type': 'int', 'docstring': 'Calculate sum of numbers.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('## Functions', content)\nself.assertIn('### calculate_sum', content)\nself.assertIn('Calculate sum of numbers', content)\nself.assertIn('**Returns**: `int`', content)",
      "language": "Python",
      "description": "Workflow: Test markdown formatting for function signatures.",
      "expected_behavior": "self.assertIn('**Returns**: `int`', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 87,
      "line_end": 122,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "176f53b5",
      "test_name": "test_parameter_table_generation",
      "category": "workflow",
      "code": "'Test parameter table formatting.'\ncode_analysis = {'files': [{'file': 'test.py', 'language': 'Python', 'classes': [], 'functions': [{'name': 'create_user', 'parameters': [{'name': 'name', 'type_hint': 'str', 'default': None}, {'name': 'age', 'type_hint': 'int', 'default': '18'}, {'name': 'active', 'type_hint': 'bool', 'default': 'True'}], 'return_type': 'dict', 'docstring': 'Create a user object.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('**Parameters**:', content)\nself.assertIn('| Name | Type | Default | Description |', content)\nself.assertIn('| name | str | - |', content)\nself.assertIn('| age | int | 18 |', content)\nself.assertIn('| active | bool | True |', content)",
      "language": "Python",
      "description": "Workflow: Test parameter table formatting.",
      "expected_behavior": "self.assertIn('| active | bool | True |', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 124,
      "line_end": 162,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "002fab06",
      "test_name": "test_markdown_output_structure",
      "category": "workflow",
      "code": "'Test overall markdown document structure.'\ncode_analysis = {'files': [{'file': 'module.py', 'language': 'Python', 'classes': [{'name': 'TestClass', 'docstring': 'Test class.', 'base_classes': [], 'methods': []}], 'functions': [{'name': 'test_func', 'parameters': [], 'return_type': None, 'docstring': 'Test function.', 'is_async': False, 'is_method': False, 'decorators': []}]}]}\nbuilder = APIReferenceBuilder(code_analysis)\ngenerated = builder.build_reference(self.output_dir)\noutput_file = list(generated.values())[0]\ncontent = output_file.read_text()\nself.assertIn('# API Reference: module.py', content)\nself.assertIn('**Language**: Python', content)\nself.assertIn('**Source**: `module.py`', content)\nclasses_pos = content.find('## Classes')\nfunctions_pos = content.find('## Functions')\nself.assertNotEqual(classes_pos, -1)\nself.assertNotEqual(functions_pos, -1)\nself.assertLess(classes_pos, functions_pos)",
      "language": "Python",
      "description": "Workflow: Test overall markdown document structure.",
      "expected_behavior": "self.assertLess(classes_pos, functions_pos)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_api_reference_builder.py",
      "line_start": 164,
      "line_end": 212,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.api_reference_builder"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "67934803",
      "test_name": "test_export_to_weaviate",
      "category": "workflow",
      "code": "'Test Weaviate export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_weaviate_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Weaviate Export Complete!' in text\nassert 'test_skill-weaviate.json' in text\nassert 'weaviate.Client' in text",
      "language": "Python",
      "description": "Workflow: Test Weaviate export tool.",
      "expected_behavior": "assert 'weaviate.Client' in text",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 60,
      "line_end": 80,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "03bf9106",
      "test_name": "test_export_to_chroma",
      "category": "workflow",
      "code": "'Test Chroma export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_chroma_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Chroma Export Complete!' in text\nassert 'test_skill-chroma.json' in text\nassert 'chromadb' in text",
      "language": "Python",
      "description": "Workflow: Test Chroma export tool.",
      "expected_behavior": "assert 'chromadb' in text",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 83,
      "line_end": 103,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d0cc1231",
      "test_name": "test_export_to_faiss",
      "category": "workflow",
      "code": "'Test FAISS export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_faiss_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 FAISS Export Complete!' in text\nassert 'test_skill-faiss.json' in text\nassert 'import faiss' in text",
      "language": "Python",
      "description": "Workflow: Test FAISS export tool.",
      "expected_behavior": "assert 'import faiss' in text",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 106,
      "line_end": 126,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d678d20a",
      "test_name": "test_export_to_qdrant",
      "category": "workflow",
      "code": "'Test Qdrant export tool.'\noutput_dir = test_skill_dir.parent\nargs = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\nresult = run_async(export_to_qdrant_impl(args))\nassert isinstance(result, list)\nassert len(result) == 1\nassert hasattr(result[0], 'text')\ntext = result[0].text\nassert '\u2705 Qdrant Export Complete!' in text\nassert 'test_skill-qdrant.json' in text\nassert 'QdrantClient' in text",
      "language": "Python",
      "description": "Workflow: Test Qdrant export tool.",
      "expected_behavior": "assert 'QdrantClient' in text",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 129,
      "line_end": 149,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a9129e6d",
      "test_name": "test_all_exports_create_files",
      "category": "workflow",
      "code": "'Test that all export tools create output files.'\noutput_dir = test_skill_dir.parent\nexports = [('weaviate', export_to_weaviate_impl), ('chroma', export_to_chroma_impl), ('faiss', export_to_faiss_impl), ('qdrant', export_to_qdrant_impl)]\nfor target, export_func in exports:\n    args = {'skill_dir': str(test_skill_dir), 'output_dir': str(output_dir)}\n    result = run_async(export_func(args))\n    assert isinstance(result, list)\n    text = result[0].text\n    assert '\u2705' in text\n    expected_file = output_dir / f'test_skill-{target}.json'\n    assert expected_file.exists(), f'{target} export file not created'\n    with open(expected_file) as f:\n        data = json.load(f)\n        assert isinstance(data, dict)",
      "language": "Python",
      "description": "Workflow: Test that all export tools create output files.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 179,
      "line_end": 211,
      "complexity_score": 0.4,
      "confidence": 0.9,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5b4cd96f",
      "test_name": "test_export_to_weaviate",
      "category": "instantiation",
      "code": "result = run_async(export_to_weaviate_impl(args))",
      "language": "Python",
      "description": "Instantiate run_async: Test Weaviate export tool.",
      "expected_behavior": "assert isinstance(result, list)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 69,
      "line_end": 69,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e2cec940",
      "test_name": "test_export_to_chroma",
      "category": "instantiation",
      "code": "result = run_async(export_to_chroma_impl(args))",
      "language": "Python",
      "description": "Instantiate run_async: Test Chroma export tool.",
      "expected_behavior": "assert isinstance(result, list)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 92,
      "line_end": 92,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2d649bfa",
      "test_name": "test_export_to_faiss",
      "category": "instantiation",
      "code": "result = run_async(export_to_faiss_impl(args))",
      "language": "Python",
      "description": "Instantiate run_async: Test FAISS export tool.",
      "expected_behavior": "assert isinstance(result, list)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 115,
      "line_end": 115,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a047f6f9",
      "test_name": "test_export_to_qdrant",
      "category": "instantiation",
      "code": "result = run_async(export_to_qdrant_impl(args))",
      "language": "Python",
      "description": "Instantiate run_async: Test Qdrant export tool.",
      "expected_behavior": "assert isinstance(result, list)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 138,
      "line_end": 138,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5b4cd96f",
      "test_name": "test_export_with_default_output_dir",
      "category": "instantiation",
      "code": "result = run_async(export_to_weaviate_impl(args))",
      "language": "Python",
      "description": "Instantiate run_async: Test export with default output directory.",
      "expected_behavior": "assert isinstance(result, list)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_mcp_vector_dbs.py",
      "line_start": 157,
      "line_end": 157,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: test_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "asyncio",
        "skill_seekers.mcp.tools.vector_db_tools"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4b6a2d8f",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as LlamaIndex Documents.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for LlamaIndex format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('llama-index')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert len(documents) == 3\nfor doc in documents:\n    assert 'text' in doc\n    assert 'metadata' in doc\n    assert doc['metadata']['source'] == 'test_skill'\n    assert doc['metadata']['version'] == '1.0.0'\n    assert 'category' in doc['metadata']\n    assert 'file' in doc['metadata']\n    assert 'type' in doc['metadata']\ncategories = {doc['metadata']['category'] for doc in documents}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as LlamaIndex Documents.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 23,
      "line_end": 63,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "08d54892",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('llama-index')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'llama' in output_path.name\nwith open(output_path) as f:\n    documents = json.load(f)\nassert isinstance(documents, list)\nassert len(documents) > 0\nassert 'text' in documents[0]\nassert 'metadata' in documents[0]",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert 'metadata' in documents[0]",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 65,
      "line_end": 88,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "431e69e6",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('llama-index')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-llama-index.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'llama' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'llama' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 90,
      "line_end": 105,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "551f0eac",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('llama-index')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert documents == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert documents == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 146,
      "line_end": 158,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "17e8219a",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('llama-index')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\ndocuments_json = adaptor.format_skill_md(skill_dir, metadata)\ndocuments = json.loads(documents_json)\nassert len(documents) == 1\nassert documents[0]['metadata']['category'] == 'test'\nassert documents[0]['metadata']['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert documents[0]['metadata']['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 160,
      "line_end": 177,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "abe5e7ba",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('llama-index')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that LlamaIndex adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'llama-index'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "abe5e7ba",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('llama-index')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as LlamaIndex Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as LlamaIndex Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ff9f3248",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "documents_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as LlamaIndex Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d9612045",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "documents = json.loads(documents_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as LlamaIndex Documents.",
      "expected_behavior": "assert len(documents) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_llama_index_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b0e0cc26",
      "test_name": "test_chroma_upload_without_chromadb_installed",
      "category": "workflow",
      "code": "'Test upload fails gracefully without chromadb installed.'\nadaptor = get_adaptor('chroma')\nimport sys\nchromadb_backup = sys.modules.get('chromadb')\nif 'chromadb' in sys.modules:\n    del sys.modules['chromadb']\ntry:\n    result = adaptor.upload(sample_chroma_package)\n    assert result['success'] is False\n    assert 'chromadb not installed' in result['message']\n    assert 'pip install chromadb' in result['message']\nfinally:\n    if chromadb_backup:\n        sys.modules['chromadb'] = chromadb_backup",
      "language": "Python",
      "description": "Workflow: Test upload fails gracefully without chromadb installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 79,
      "line_end": 98,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "# Fixtures: sample_chroma_package",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d7180035",
      "test_name": "test_weaviate_upload_without_weaviate_installed",
      "category": "workflow",
      "code": "'Test upload fails gracefully without weaviate-client installed.'\nadaptor = get_adaptor('weaviate')\nimport sys\nweaviate_backup = sys.modules.get('weaviate')\nif 'weaviate' in sys.modules:\n    del sys.modules['weaviate']\ntry:\n    result = adaptor.upload(sample_weaviate_package)\n    assert result['success'] is False\n    assert 'weaviate-client not installed' in result['message']\n    assert 'pip install weaviate-client' in result['message']\nfinally:\n    if weaviate_backup:\n        sys.modules['weaviate'] = weaviate_backup",
      "language": "Python",
      "description": "Workflow: Test upload fails gracefully without weaviate-client installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 121,
      "line_end": 140,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "# Fixtures: sample_weaviate_package",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ac42b59",
      "test_name": "test_chroma_adaptor_exists",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('chroma')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that ChromaDB adaptor can be loaded.",
      "expected_behavior": "assert adaptor is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 75,
      "line_end": 75,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ac42b59",
      "test_name": "test_chroma_upload_without_chromadb_installed",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('chroma')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test upload fails gracefully without chromadb installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 81,
      "line_end": 81,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_chroma_package",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4def4b3d",
      "test_name": "test_chroma_upload_without_chromadb_installed",
      "category": "instantiation",
      "code": "chromadb_backup = sys.modules.get('chromadb')",
      "language": "Python",
      "description": "Instantiate get: Test upload fails gracefully without chromadb installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 86,
      "line_end": 86,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_chroma_package",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "7c2654e2",
      "test_name": "test_chroma_upload_without_chromadb_installed",
      "category": "instantiation",
      "code": "result = adaptor.upload(sample_chroma_package)",
      "language": "Python",
      "description": "Instantiate upload: Test upload fails gracefully without chromadb installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 91,
      "line_end": 91,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_chroma_package",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ac42b59",
      "test_name": "test_chroma_upload_api_signature",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('chroma')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test ChromaDB upload has correct API signature.",
      "expected_behavior": "assert hasattr(adaptor, 'upload')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 102,
      "line_end": 102,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_chroma_package",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1da217a2",
      "test_name": "test_weaviate_adaptor_exists",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('weaviate')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that Weaviate adaptor can be loaded.",
      "expected_behavior": "assert adaptor is not None",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 117,
      "line_end": 117,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1da217a2",
      "test_name": "test_weaviate_upload_without_weaviate_installed",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('weaviate')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test upload fails gracefully without weaviate-client installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 123,
      "line_end": 123,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_weaviate_package",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "339c9517",
      "test_name": "test_weaviate_upload_without_weaviate_installed",
      "category": "instantiation",
      "code": "weaviate_backup = sys.modules.get('weaviate')",
      "language": "Python",
      "description": "Instantiate get: Test upload fails gracefully without weaviate-client installed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_upload_integration.py",
      "line_start": 128,
      "line_end": 128,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: sample_weaviate_package",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "sys",
        "sys",
        "skill_seekers.cli.upload_skill",
        "inspect"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a48c3dd0",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'markdown')\nself.assertEqual(self.adaptor.PLATFORM_NAME, 'Generic Markdown (Universal)')",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Generic Markdown (Universal)')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('markdown')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0ef73c03",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Generic Markdown (Universal)')\nself.assertIsNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('markdown')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "539d0884",
      "test_name": "test_validate_api_key",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('sk-ant-123'))\nself.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))",
      "language": "Python",
      "description": "Test that markdown export doesn't use API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 31,
      "line_end": 32,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('markdown')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e4fd1a5d",
      "test_name": "test_validate_api_key",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))\nself.assertFalse(self.adaptor.validate_api_key('any-key'))",
      "language": "Python",
      "description": "Test that markdown export doesn't use API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('any-key'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 32,
      "line_end": 33,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('markdown')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ea418e6a",
      "test_name": "test_validate_api_key",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('any-key'))\nself.assertFalse(self.adaptor.validate_api_key(''))",
      "language": "Python",
      "description": "Test that markdown export doesn't use API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key(''))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 33,
      "line_end": 34,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": "'Set up test adaptor'\nself.adaptor = get_adaptor('markdown')",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a48c3dd0",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM, 'markdown')\nself.assertEqual(self.adaptor.PLATFORM_NAME, 'Generic Markdown (Universal)')",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Generic Markdown (Universal)')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 24,
      "line_end": 25,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "0ef73c03",
      "test_name": "test_platform_info",
      "category": "method_call",
      "code": "self.assertEqual(self.adaptor.PLATFORM_NAME, 'Generic Markdown (Universal)')\nself.assertIsNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "language": "Python",
      "description": "Test platform identifiers",
      "expected_behavior": "self.assertIsNone(self.adaptor.DEFAULT_API_ENDPOINT)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 25,
      "line_end": 26,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "539d0884",
      "test_name": "test_validate_api_key",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('sk-ant-123'))\nself.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))",
      "language": "Python",
      "description": "Test that markdown export doesn't use API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 31,
      "line_end": 32,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e4fd1a5d",
      "test_name": "test_validate_api_key",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('AIzaSyABC123'))\nself.assertFalse(self.adaptor.validate_api_key('any-key'))",
      "language": "Python",
      "description": "Test that markdown export doesn't use API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key('any-key'))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 32,
      "line_end": 33,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ea418e6a",
      "test_name": "test_validate_api_key",
      "category": "method_call",
      "code": "self.assertFalse(self.adaptor.validate_api_key('any-key'))\nself.assertFalse(self.adaptor.validate_api_key(''))",
      "language": "Python",
      "description": "Test that markdown export doesn't use API keys",
      "expected_behavior": "self.assertFalse(self.adaptor.validate_api_key(''))",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_markdown_adaptor.py",
      "line_start": 33,
      "line_end": 34,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base",
        "json"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f7cb18da",
      "test_name": "test_chunk_document_single_chunk",
      "category": "workflow",
      "code": "'Test chunking when document fits in single chunk.'\ningester = StreamingIngester(chunk_size=1000, chunk_overlap=100)\ncontent = 'Small document'\nmetadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}\nchunks = list(ingester.chunk_document(content, metadata))\nassert len(chunks) == 1\nchunk_text, chunk_meta = chunks[0]\nassert chunk_text == content\nassert chunk_meta.chunk_index == 0\nassert chunk_meta.total_chunks == 1\nassert chunk_meta.source == 'test'",
      "language": "Python",
      "description": "Workflow: Test chunking when document fits in single chunk.",
      "expected_behavior": "assert chunk_meta.source == 'test'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 48,
      "line_end": 63,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2e944c86",
      "test_name": "test_chunk_document_multiple_chunks",
      "category": "workflow",
      "code": "'Test chunking with multiple chunks.'\ningester = StreamingIngester(chunk_size=100, chunk_overlap=20)\ncontent = 'A' * 250\nmetadata = {'source': 'test', 'file': 'test.md', 'category': 'overview'}\nchunks = list(ingester.chunk_document(content, metadata))\nassert len(chunks) > 1\nfor i in range(len(chunks) - 1):\n    chunk1_text, chunk1_meta = chunks[i]\n    chunk2_text, chunk2_meta = chunks[i + 1]\n    assert chunk2_meta.char_start < chunk1_meta.char_end",
      "language": "Python",
      "description": "Workflow: Test chunking with multiple chunks.",
      "expected_behavior": "assert len(chunks) > 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 66,
      "line_end": 84,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e804f7e6",
      "test_name": "test_chunk_document_metadata",
      "category": "workflow",
      "code": "'Test chunk metadata is correct.'\ningester = StreamingIngester(chunk_size=100, chunk_overlap=20)\ncontent = 'B' * 250\nmetadata = {'source': 'test_source', 'file': 'test_file.md', 'category': 'test_cat'}\nchunks = list(ingester.chunk_document(content, metadata))\nfor i, (chunk_text, chunk_meta) in enumerate(chunks):\n    assert chunk_meta.chunk_index == i\n    assert chunk_meta.total_chunks == len(chunks)\n    assert chunk_meta.source == 'test_source'\n    assert chunk_meta.file == 'test_file.md'\n    assert chunk_meta.category == 'test_cat'\n    assert len(chunk_meta.chunk_id) == 32",
      "language": "Python",
      "description": "Workflow: Test chunk metadata is correct.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 87,
      "line_end": 102,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "00f58fd0",
      "test_name": "test_stream_skill_directory",
      "category": "workflow",
      "code": "'Test streaming entire skill directory.'\ningester = StreamingIngester(chunk_size=500, chunk_overlap=50)\nchunks = list(ingester.stream_skill_directory(temp_skill_dir))\nassert len(chunks) > 0\nassert ingester.progress is not None\nassert ingester.progress.total_documents == 3\nassert ingester.progress.processed_documents == 3\nassert ingester.progress.total_chunks > 0\nassert ingester.progress.processed_chunks == len(chunks)\nsources = set()\ncategories = set()\nfor chunk_text, chunk_meta in chunks:\n    assert chunk_text\n    assert chunk_meta['chunk_id']\n    sources.add(chunk_meta['source'])\n    categories.add(chunk_meta['category'])\nassert 'test_skill' in sources\nassert 'overview' in categories",
      "language": "Python",
      "description": "Workflow: Test streaming entire skill directory.",
      "expected_behavior": "assert 'overview' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 105,
      "line_end": 132,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "facc692d",
      "test_name": "test_checkpoint_save_load",
      "category": "workflow",
      "code": "'Test checkpoint save and load.'\ningester = StreamingIngester()\nwith tempfile.TemporaryDirectory() as tmpdir:\n    checkpoint_path = Path(tmpdir) / 'checkpoint.json'\n    ingester.progress = IngestionProgress(total_documents=10, processed_documents=5, total_chunks=100, processed_chunks=50, failed_chunks=2, bytes_processed=10000, start_time=1234567890.0)\n    state = {'last_processed_file': 'test.md', 'batch_number': 3}\n    ingester.save_checkpoint(checkpoint_path, state)\n    assert checkpoint_path.exists()\n    loaded_state = ingester.load_checkpoint(checkpoint_path)\n    assert loaded_state == state",
      "language": "Python",
      "description": "Workflow: Test checkpoint save and load.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 178,
      "line_end": 205,
      "complexity_score": 0.3,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6531de8b",
      "test_name": "test_chunk_size_validation",
      "category": "workflow",
      "code": "'Test different chunk sizes.'\ncontent = 'X' * 1000\ningester_small = StreamingIngester(chunk_size=100, chunk_overlap=10)\nchunks_small = list(ingester_small.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))\ningester_large = StreamingIngester(chunk_size=500, chunk_overlap=50)\nchunks_large = list(ingester_large.chunk_document(content, {'source': 'test', 'file': 'test.md', 'category': 'test'}))\nassert len(chunks_small) > len(chunks_large)",
      "language": "Python",
      "description": "Workflow: Test different chunk sizes.",
      "expected_behavior": "assert len(chunks_small) > len(chunks_large)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 243,
      "line_end": 264,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "91934c47",
      "test_name": "test_progress_tracking",
      "category": "method_call",
      "code": "list(ingester.stream_skill_directory(temp_skill_dir, callback=callback))\nassert len(progress_updates) > 0",
      "language": "Python",
      "description": "Test progress tracking during streaming.",
      "expected_behavior": "assert len(progress_updates) > 0",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 166,
      "line_end": 169,
      "complexity_score": 0.3,
      "confidence": 0.85,
      "setup_code": "# Fixtures: temp_skill_dir",
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a0151bc6",
      "test_name": "test_chunk_document_single_chunk",
      "category": "instantiation",
      "code": "ingester = StreamingIngester(chunk_size=1000, chunk_overlap=100)",
      "language": "Python",
      "description": "Instantiate StreamingIngester: Test chunking when document fits in single chunk.",
      "expected_behavior": "assert len(chunks) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 50,
      "line_end": 50,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "80061fc0",
      "test_name": "test_chunk_document_single_chunk",
      "category": "instantiation",
      "code": "chunks = list(ingester.chunk_document(content, metadata))",
      "language": "Python",
      "description": "Instantiate list: Test chunking when document fits in single chunk.",
      "expected_behavior": "assert len(chunks) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 55,
      "line_end": 55,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a055fa87",
      "test_name": "test_chunk_document_multiple_chunks",
      "category": "instantiation",
      "code": "ingester = StreamingIngester(chunk_size=100, chunk_overlap=20)",
      "language": "Python",
      "description": "Instantiate StreamingIngester: Test chunking with multiple chunks.",
      "expected_behavior": "assert len(chunks) > 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_streaming_ingestion.py",
      "line_start": 68,
      "line_end": 68,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "skill_seekers.cli.streaming_ingest"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c1ebc59a",
      "test_name": "test_get_storage_adaptor_s3",
      "category": "instantiation",
      "code": "adaptor = get_storage_adaptor('s3', bucket='test-bucket')",
      "language": "Python",
      "description": "Instantiate get_storage_adaptor: Test S3 adaptor factory.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 53,
      "line_end": 53,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4da8159e",
      "test_name": "test_get_storage_adaptor_gcs",
      "category": "instantiation",
      "code": "adaptor = get_storage_adaptor('gcs', bucket='test-bucket')",
      "language": "Python",
      "description": "Instantiate get_storage_adaptor: Test GCS adaptor factory.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 62,
      "line_end": 62,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b0f580ad",
      "test_name": "test_get_storage_adaptor_azure",
      "category": "instantiation",
      "code": "adaptor = get_storage_adaptor('azure', container='test-container', connection_string='DefaultEndpointsProtocol=https;AccountName=test;AccountKey=key')",
      "language": "Python",
      "description": "Instantiate get_storage_adaptor: Test Azure adaptor factory.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 71,
      "line_end": 75,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50c95966",
      "test_name": "test_s3_upload_file",
      "category": "instantiation",
      "code": "adaptor = S3StorageAdaptor(bucket='test-bucket')",
      "language": "Python",
      "description": "Instantiate S3StorageAdaptor: Test S3 file upload.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 101,
      "line_end": 101,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9940709e",
      "test_name": "test_s3_upload_file",
      "category": "instantiation",
      "code": "result = adaptor.upload_file(tmp_path, 'test.txt')",
      "language": "Python",
      "description": "Instantiate upload_file: Test S3 file upload.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 110,
      "line_end": 110,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50c95966",
      "test_name": "test_s3_download_file",
      "category": "instantiation",
      "code": "adaptor = S3StorageAdaptor(bucket='test-bucket')",
      "language": "Python",
      "description": "Instantiate S3StorageAdaptor: Test S3 file download.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 129,
      "line_end": 129,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9422d63d",
      "test_name": "test_s3_download_file",
      "category": "instantiation",
      "code": "local_path = os.path.join(tmp_dir, 'downloaded.txt')",
      "language": "Python",
      "description": "Instantiate join: Test S3 file download.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 132,
      "line_end": 132,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50c95966",
      "test_name": "test_s3_list_files",
      "category": "instantiation",
      "code": "adaptor = S3StorageAdaptor(bucket='test-bucket')",
      "language": "Python",
      "description": "Instantiate S3StorageAdaptor: Test S3 file listing.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 167,
      "line_end": 167,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ea2fa478",
      "test_name": "test_s3_list_files",
      "category": "instantiation",
      "code": "files = adaptor.list_files('prefix/')",
      "language": "Python",
      "description": "Instantiate list_files: Test S3 file listing.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 170,
      "line_end": 170,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50c95966",
      "test_name": "test_s3_file_exists",
      "category": "instantiation",
      "code": "adaptor = S3StorageAdaptor(bucket='test-bucket')",
      "language": "Python",
      "description": "Instantiate S3StorageAdaptor: Test S3 file existence check.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_cloud_storage.py",
      "line_start": 190,
      "line_end": 190,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "mock"
      ],
      "dependencies": [
        "os",
        "pytest",
        "tempfile",
        "pathlib",
        "unittest.mock",
        "skill_seekers.cli.storage",
        "boto3",
        "google.cloud",
        "azure.storage.blob"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bccba00b",
      "test_name": "test_format_skill_md",
      "category": "workflow",
      "code": "'Test formatting SKILL.md as Qdrant points.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\nskill_md = skill_dir / 'SKILL.md'\nskill_md.write_text('# Test Skill\\n\\nThis is a test skill for Qdrant format.')\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'getting_started.md').write_text('# Getting Started\\n\\nQuick start.')\n(refs_dir / 'api.md').write_text('# API Reference\\n\\nAPI docs.')\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert 'collection_name' in result\nassert 'points' in result\nassert 'config' in result\nassert len(result['points']) == 3\nfor point in result['points']:\n    assert 'id' in point\n    assert 'vector' in point\n    assert 'payload' in point\n    payload = point['payload']\n    assert 'content' in payload\n    assert payload['source'] == 'test_skill'\n    assert payload['version'] == '1.0.0'\n    assert 'category' in payload\n    assert 'file' in payload\n    assert 'type' in payload\ncategories = {point['payload']['category'] for point in result['points']}\nassert 'overview' in categories\nassert 'getting started' in categories or 'api' in categories",
      "language": "Python",
      "description": "Workflow: Test formatting SKILL.md as Qdrant points.",
      "expected_behavior": "assert 'getting started' in categories or 'api' in categories",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 23,
      "line_end": 69,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f9fcbe20",
      "test_name": "test_package_creates_json",
      "category": "workflow",
      "code": "'Test packaging skill into JSON file.'\nskill_dir = tmp_path / 'test_skill'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('qdrant')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.exists()\nassert output_path.suffix == '.json'\nassert 'qdrant' in output_path.name\nwith open(output_path) as f:\n    result = json.load(f)\nassert isinstance(result, dict)\nassert 'points' in result\nassert len(result['points']) > 0\nassert 'id' in result['points'][0]\nassert 'payload' in result['points'][0]",
      "language": "Python",
      "description": "Workflow: Test packaging skill into JSON file.",
      "expected_behavior": "assert 'payload' in result['points'][0]",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 71,
      "line_end": 95,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "baec8673",
      "test_name": "test_package_output_filename",
      "category": "workflow",
      "code": "'Test package output filename generation.'\nskill_dir = tmp_path / 'react'\nskill_dir.mkdir()\n(skill_dir / 'SKILL.md').write_text('# React\\n\\nReact docs.')\nadaptor = get_adaptor('qdrant')\noutput_path = adaptor.package(skill_dir, tmp_path)\nassert output_path.name == 'react-qdrant.json'\noutput_path = adaptor.package(skill_dir, tmp_path / 'test.zip')\nassert output_path.suffix == '.json'\nassert 'qdrant' in output_path.name",
      "language": "Python",
      "description": "Workflow: Test package output filename generation.",
      "expected_behavior": "assert 'qdrant' in output_path.name",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 97,
      "line_end": 112,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ca3d402d",
      "test_name": "test_empty_skill_directory",
      "category": "workflow",
      "code": "'Test handling of empty skill directory.'\nskill_dir = tmp_path / 'empty_skill'\nskill_dir.mkdir()\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='empty_skill', description='Empty', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert 'points' in result\nassert result['points'] == []",
      "language": "Python",
      "description": "Workflow: Test handling of empty skill directory.",
      "expected_behavior": "assert result['points'] == []",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 153,
      "line_end": 166,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8566ae4f",
      "test_name": "test_references_only",
      "category": "workflow",
      "code": "'Test skill with references but no SKILL.md.'\nskill_dir = tmp_path / 'refs_only'\nskill_dir.mkdir()\nrefs_dir = skill_dir / 'references'\nrefs_dir.mkdir()\n(refs_dir / 'test.md').write_text('# Test\\n\\nTest content.')\nadaptor = get_adaptor('qdrant')\nmetadata = SkillMetadata(name='refs_only', description='Refs only', version='1.0.0')\npoints_json = adaptor.format_skill_md(skill_dir, metadata)\nresult = json.loads(points_json)\nassert len(result['points']) == 1\nassert result['points'][0]['payload']['category'] == 'test'\nassert result['points'][0]['payload']['type'] == 'reference'",
      "language": "Python",
      "description": "Workflow: Test skill with references but no SKILL.md.",
      "expected_behavior": "assert result['points'][0]['payload']['type'] == 'reference'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 168,
      "line_end": 185,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ef91c7ac",
      "test_name": "test_adaptor_registration",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('qdrant')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test that Qdrant adaptor is registered.",
      "expected_behavior": "assert adaptor.PLATFORM == 'qdrant'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 19,
      "line_end": 19,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ef91c7ac",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "adaptor = get_adaptor('qdrant')",
      "language": "Python",
      "description": "Instantiate get_adaptor: Test formatting SKILL.md as Qdrant points.",
      "expected_behavior": "assert 'collection_name' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 40,
      "line_end": 40,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "4969bda3",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "metadata = SkillMetadata(name='test_skill', description='Test skill', version='1.0.0')",
      "language": "Python",
      "description": "Instantiate SkillMetadata: Test formatting SKILL.md as Qdrant points.",
      "expected_behavior": "assert 'collection_name' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 41,
      "line_end": 41,
      "complexity_score": 0.25,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "f84d529b",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "points_json = adaptor.format_skill_md(skill_dir, metadata)",
      "language": "Python",
      "description": "Instantiate format_skill_md: Test formatting SKILL.md as Qdrant points.",
      "expected_behavior": "assert 'collection_name' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 43,
      "line_end": 43,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "43fb01ce",
      "test_name": "test_format_skill_md",
      "category": "instantiation",
      "code": "result = json.loads(points_json)",
      "language": "Python",
      "description": "Instantiate loads: Test formatting SKILL.md as Qdrant points.",
      "expected_behavior": "assert 'collection_name' in result",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_adaptors\\test_qdrant_adaptor.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "json",
        "pytest",
        "skill_seekers.cli.adaptors",
        "skill_seekers.cli.adaptors.base"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e89f472c",
      "test_name": "test_categorize_by_keywords",
      "category": "workflow",
      "code": "'Test categorization using keyword matching'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf', 'categories': {'getting_started': ['introduction', 'getting started'], 'api': ['api', 'reference', 'function']}}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Introduction to the API', 'chapter': 'Chapter 1: Getting Started'}, {'page_number': 2, 'text': 'API reference for functions', 'chapter': None}]}\ncategories = converter.categorize_content()\nself.assertIn('test', categories)\nself.assertEqual(len(categories), 1)\nself.assertEqual(len(categories['test']['pages']), 2)",
      "language": "Python",
      "description": "Workflow: Test categorization using keyword matching",
      "expected_behavior": "self.assertEqual(len(categories['test']['pages']), 2)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 90,
      "line_end": 121,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "bf742326",
      "test_name": "test_categorize_by_chapters",
      "category": "workflow",
      "code": "'Test categorization using chapter information'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Content here', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 2, 'text': 'More content', 'chapter': 'Chapter 1: Introduction'}, {'page_number': 3, 'text': 'New chapter', 'chapter': 'Chapter 2: Advanced Topics'}]}\ncategories = converter.categorize_content()\nself.assertIsInstance(categories, dict)\nself.assertGreater(len(categories), 0)",
      "language": "Python",
      "description": "Workflow: Test categorization using chapter information",
      "expected_behavior": "self.assertGreater(len(categories), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 123,
      "line_end": 141,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "06381c0f",
      "test_name": "test_categorize_handles_no_chapters",
      "category": "workflow",
      "code": "'Test categorization when no chapters are detected'\nconfig = {'name': 'test', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Some content', 'chapter': None}]}\ncategories = converter.categorize_content()\nself.assertIsInstance(categories, dict)",
      "language": "Python",
      "description": "Workflow: Test categorization when no chapters are detected",
      "expected_behavior": "self.assertIsInstance(categories, dict)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 143,
      "line_end": 156,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e4fdbc9d",
      "test_name": "test_build_skill_creates_structure",
      "category": "workflow",
      "code": "'Test that build_skill creates required directory structure'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test content', 'code_blocks': [], 'images': []}], 'total_pages': 1}\nconverter.categories = {'getting_started': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nskill_dir = Path(self.temp_dir) / 'test_skill'\nself.assertTrue(skill_dir.exists())\nself.assertTrue((skill_dir / 'references').exists())\nself.assertTrue((skill_dir / 'scripts').exists())\nself.assertTrue((skill_dir / 'assets').exists())",
      "language": "Python",
      "description": "Workflow: Test that build_skill creates required directory structure",
      "expected_behavior": "self.assertTrue((skill_dir / 'assets').exists())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 173,
      "line_end": 197,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6ee4a77e",
      "test_name": "test_build_skill_creates_skill_md",
      "category": "workflow",
      "code": "'Test that SKILL.md is created'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf', 'description': 'Test description'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Test', 'code_blocks': [], 'images': []}], 'total_pages': 1}\nconverter.categories = {'test': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nskill_md = Path(self.temp_dir) / 'test_skill' / 'SKILL.md'\nself.assertTrue(skill_md.exists())\ncontent = skill_md.read_text()\nself.assertIn('test_skill', content)\nself.assertIn('Test description', content)",
      "language": "Python",
      "description": "Workflow: Test that SKILL.md is created",
      "expected_behavior": "self.assertIn('Test description', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 199,
      "line_end": 221,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e94d8fca",
      "test_name": "test_build_skill_creates_reference_files",
      "category": "workflow",
      "code": "'Test that reference files are created for categories'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Getting started', 'code_blocks': [], 'images': []}, {'page_number': 2, 'text': 'API reference', 'code_blocks': [], 'images': []}], 'total_pages': 2}\nconverter.build_skill()\nrefs_dir = Path(self.temp_dir) / 'test_skill' / 'references'\nself.assertTrue((refs_dir / 'test.md').exists())\nself.assertTrue((refs_dir / 'index.md').exists())",
      "language": "Python",
      "description": "Workflow: Test that reference files are created for categories",
      "expected_behavior": "self.assertTrue((refs_dir / 'index.md').exists())",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 223,
      "line_end": 245,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "85d89c03",
      "test_name": "test_code_blocks_included_in_references",
      "category": "workflow",
      "code": "'Test that code blocks are included in reference files'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Example code', 'code_blocks': [{'code': \"def hello():\\n    print('world')\", 'language': 'python', 'quality': 8.0}], 'images': []}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('```python', content)\nself.assertIn('def hello()', content)\nself.assertIn(\"print('world')\", content)",
      "language": "Python",
      "description": "Workflow: Test that code blocks are included in reference files",
      "expected_behavior": "self.assertIn(\"print('world')\", content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 262,
      "line_end": 298,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "69471952",
      "test_name": "test_high_quality_code_preferred",
      "category": "workflow",
      "code": "'Test that high-quality code blocks are prioritized'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Code examples', 'code_blocks': [{'code': 'x = 1', 'language': 'python', 'quality': 2.0}, {'code': 'def process():\\n    return result', 'language': 'python', 'quality': 9.0}], 'images': []}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('def process()', content)",
      "language": "Python",
      "description": "Workflow: Test that high-quality code blocks are prioritized",
      "expected_behavior": "self.assertIn('def process()', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 300,
      "line_end": 335,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "dbbdbb69",
      "test_name": "test_images_saved_to_assets",
      "category": "workflow",
      "code": "'Test that images are saved to assets directory'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nmock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'See diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 100, 'height': 100, 'data': mock_image_bytes}]}], 'total_pages': 1}\nconverter.categories = {'diagrams': [converter.extracted_data['pages'][0]]}\nconverter.build_skill()\nassets_dir = Path(self.temp_dir) / 'test_skill' / 'assets'\nimage_files = list(assets_dir.glob('*.png'))\nself.assertGreater(len(image_files), 0)",
      "language": "Python",
      "description": "Workflow: Test that images are saved to assets directory",
      "expected_behavior": "self.assertGreater(len(image_files), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 352,
      "line_end": 389,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e8478fb4",
      "test_name": "test_image_references_in_markdown",
      "category": "workflow",
      "code": "'Test that images are referenced in markdown files'\nconfig = {'name': 'test_skill', 'pdf_path': 'test.pdf'}\nconverter = self.PDFToSkillConverter(config)\nconverter.skill_dir = str(Path(self.temp_dir) / 'test_skill')\nmock_image_bytes = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\nIDATx\\x9cc\\x00\\x01\\x00\\x00\\x05\\x00\\x01\\r\\n-\\xb4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\nconverter.extracted_data = {'pages': [{'page_number': 1, 'text': 'Architecture diagram', 'code_blocks': [], 'images': [{'page': 1, 'index': 0, 'width': 200, 'height': 150, 'data': mock_image_bytes}]}], 'total_pages': 1}\nconverter.build_skill()\nref_file = Path(self.temp_dir) / 'test_skill' / 'references' / 'test.md'\ncontent = ref_file.read_text()\nself.assertIn('![', content)\nself.assertIn('../assets/', content)",
      "language": "Python",
      "description": "Workflow: Test that images are referenced in markdown files",
      "expected_behavior": "self.assertIn('../assets/', content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_pdf_scraper.py",
      "line_start": 391,
      "line_end": 429,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "if not PYMUPDF_AVAILABLE:\n    self.skipTest('PyMuPDF not installed')\nfrom skill_seekers.cli.pdf_scraper import PDFToSkillConverter\nself.PDFToSkillConverter = PDFToSkillConverter\nself.temp_dir = tempfile.mkdtemp()",
      "tags": [
        "mock",
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "json",
        "shutil",
        "tempfile",
        "unittest",
        "pathlib",
        "fitz",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper",
        "skill_seekers.cli.pdf_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5f8a4852",
      "test_name": "test_summarize_reference_basic",
      "category": "workflow",
      "code": "'Test basic summarization preserves structure'\nenhancer = LocalSkillEnhancer(tmp_path)\nsections = []\nfor i in range(20):\n    sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with detailed explanation that would benefit from summarization.\\nWe add multiple paragraphs to make the content more realistic and substantial.\\nThis content explains various aspects of the framework in detail.\\n\\nAnother paragraph with more information about this specific topic.\\nTechnical details and explanations continue here with examples and use cases.\\n\\n```python\\n# Example code for section {i}\\ndef function_{i}():\\n    print(\"Section {i}\")\\n    return {i}\\n```\\n\\nFinal paragraph wrapping up this section with concluding remarks.\\n')\ncontent = '# Introduction\\n\\nThis is the framework introduction.\\n' + '\\n'.join(sections)\nsummarized = enhancer.summarize_reference(content, target_ratio=0.3)\nassert '# Introduction' in summarized\nassert '```python' in summarized\nassert '[Content intelligently summarized' in summarized\nassert len(summarized) < len(content)",
      "language": "Python",
      "description": "Workflow: Test basic summarization preserves structure",
      "expected_behavior": "assert len(summarized) < len(content)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 16,
      "line_end": 53,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fecb1f6d",
      "test_name": "test_summarize_large_content",
      "category": "workflow",
      "code": "'Test summarization with very large content'\nenhancer = LocalSkillEnhancer(tmp_path)\nsections = []\nfor i in range(50):\n    sections.append(f'\\n## Section {i}\\n\\nThis is section {i} with lots of content that needs to be summarized.\\nWe add multiple paragraphs to make it realistic.\\n\\n```python\\n# Code example {i}\\ndef function_{i}():\\n    return {i}\\n```\\n\\nMore explanatory text follows here.\\nAnother paragraph of content.\\n')\ncontent = '\\n'.join(sections)\noriginal_size = len(content)\nsummarized = enhancer.summarize_reference(content, target_ratio=0.3)\nsummarized_size = len(summarized)\nassert summarized_size < original_size\nratio = summarized_size / original_size\nassert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
      "language": "Python",
      "description": "Workflow: Test summarization with very large content",
      "expected_behavior": "assert 0.2 <= ratio <= 0.5, f'Ratio {ratio:.2f} not in expected range'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 94,
      "line_end": 128,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [
        "workflow",
        "integration"
      ],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d589f37c",
      "test_name": "test_summarize_reference_basic",
      "category": "instantiation",
      "code": "enhancer = LocalSkillEnhancer(tmp_path)",
      "language": "Python",
      "description": "Instantiate LocalSkillEnhancer: Test basic summarization preserves structure",
      "expected_behavior": "assert '# Introduction' in summarized",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 18,
      "line_end": 18,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9e00d33e",
      "test_name": "test_summarize_reference_basic",
      "category": "instantiation",
      "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.3)",
      "language": "Python",
      "description": "Instantiate summarize_reference: Test basic summarization preserves structure",
      "expected_behavior": "assert '# Introduction' in summarized",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 46,
      "line_end": 46,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d589f37c",
      "test_name": "test_summarize_preserves_code_blocks",
      "category": "instantiation",
      "code": "enhancer = LocalSkillEnhancer(tmp_path)",
      "language": "Python",
      "description": "Instantiate LocalSkillEnhancer: Test that code blocks are prioritized and preserved",
      "expected_behavior": "assert summarized.count('```python') >= 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 57,
      "line_end": 57,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "004acdf2",
      "test_name": "test_summarize_preserves_code_blocks",
      "category": "instantiation",
      "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.5)",
      "language": "Python",
      "description": "Instantiate summarize_reference: Test that code blocks are prioritized and preserved",
      "expected_behavior": "assert summarized.count('```python') >= 2",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 88,
      "line_end": 88,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d589f37c",
      "test_name": "test_summarize_large_content",
      "category": "instantiation",
      "code": "enhancer = LocalSkillEnhancer(tmp_path)",
      "language": "Python",
      "description": "Instantiate LocalSkillEnhancer: Test summarization with very large content",
      "expected_behavior": "assert summarized_size < original_size",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 96,
      "line_end": 96,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c77ca7a8",
      "test_name": "test_summarize_large_content",
      "category": "instantiation",
      "code": "content = '\\n'.join(sections)",
      "language": "Python",
      "description": "Instantiate join: Test summarization with very large content",
      "expected_behavior": "assert summarized_size < original_size",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 117,
      "line_end": 117,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b3e912d5",
      "test_name": "test_summarize_large_content",
      "category": "instantiation",
      "code": "original_size = len(content)",
      "language": "Python",
      "description": "Instantiate len: Test summarization with very large content",
      "expected_behavior": "assert summarized_size < original_size",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 118,
      "line_end": 118,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9e00d33e",
      "test_name": "test_summarize_large_content",
      "category": "instantiation",
      "code": "summarized = enhancer.summarize_reference(content, target_ratio=0.3)",
      "language": "Python",
      "description": "Instantiate summarize_reference: Test summarization with very large content",
      "expected_behavior": "assert summarized_size < original_size",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_smart_summarization.py",
      "line_start": 121,
      "line_end": 121,
      "complexity_score": 0.2,
      "confidence": 0.8,
      "setup_code": "# Fixtures: tmp_path",
      "tags": [],
      "dependencies": [
        "pytest",
        "skill_seekers.cli.enhance_skill_local"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c8c19ef1",
      "test_name": "test_python_docstring_extraction",
      "category": "workflow",
      "code": "'Test docstring extraction for functions and classes.'\ncode = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'\nresult = self.analyzer.analyze_file('test.py', code, 'Python')\ncalc_class = result['classes'][0]\nself.assertIn('A simple calculator class', calc_class['docstring'])\nself.assertIn('Supports basic arithmetic operations', calc_class['docstring'])\nadd_method = calc_class['methods'][0]\nself.assertIn('Add two numbers', add_method['docstring'])\nself.assertIn('Args:', add_method['docstring'])\nself.assertIn('Returns:', add_method['docstring'])",
      "language": "Python",
      "description": "Workflow: Test docstring extraction for functions and classes.",
      "expected_behavior": "self.assertIn('Returns:', add_method['docstring'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 134,
      "line_end": 166,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a692fb42",
      "test_name": "test_javascript_class_methods",
      "category": "workflow",
      "code": "'Test ES6 class method extraction.\\n\\n        Note: Regex-based parser has limitations in extracting all methods.\\n        This test verifies basic method extraction works.\\n        '\ncode = \"\\nclass User {\\n    constructor(name, email) {\\n        this.name = name;\\n        this.email = email;\\n    }\\n\\n    getProfile() {\\n        return { name: this.name, email: this.email };\\n    }\\n\\n    async fetchData() {\\n        return await fetch('/api/user');\\n    }\\n}\\n\"\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\nself.assertIn('classes', result)\nuser_class = result['classes'][0]\nself.assertEqual(user_class['name'], 'User')\nself.assertGreaterEqual(len(user_class['methods']), 1)\nmethod_names = [m['name'] for m in user_class['methods']]\nself.assertGreater(len(method_names), 0)",
      "language": "Python",
      "description": "Workflow: Test ES6 class method extraction.\n\nNote: Regex-based parser has limitations in extracting all methods.\nThis test verifies basic method extraction works.",
      "expected_behavior": "self.assertGreater(len(method_names), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 253,
      "line_end": 286,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "39ad407d",
      "test_name": "test_typescript_type_annotations",
      "category": "workflow",
      "code": "'Test TypeScript type annotation extraction.\\n\\n        Note: Current regex-based parser extracts parameter type hints\\n        but NOT return types. Return type extraction requires a proper\\n        TypeScript parser (ts-morph or typescript library).\\n        '\ncode = '\\nfunction calculate(a: number, b: number): number {\\n    return a + b;\\n}\\n\\ninterface User {\\n    name: string;\\n    age: number;\\n}\\n\\nfunction createUser(name: string, age: number = 18): User {\\n    return { name, age };\\n}\\n'\nresult = self.analyzer.analyze_file('test.ts', code, 'TypeScript')\nself.assertIn('functions', result)\ncalc_func = result['functions'][0]\nself.assertEqual(calc_func['name'], 'calculate')\nself.assertEqual(calc_func['parameters'][0]['type_hint'], 'number')\nself.assertIsNone(calc_func['return_type'])\ncreate_func = result['functions'][1]\nself.assertEqual(create_func['name'], 'createUser')\nself.assertEqual(create_func['parameters'][1]['default'], '18')\nself.assertIsNone(create_func['return_type'])",
      "language": "Python",
      "description": "Workflow: Test TypeScript type annotation extraction.\n\nNote: Current regex-based parser extracts parameter type hints\nbut NOT return types. Return type extraction requires a proper\nTypeScript parser (ts-morph or typescript library).",
      "expected_behavior": "self.assertIsNone(create_func['return_type'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 288,
      "line_end": 325,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3d148051",
      "test_name": "test_cpp_class_extraction",
      "category": "workflow",
      "code": "'Test C++ class extraction with inheritance.'\ncode = '\\nclass Animal {\\npublic:\\n    virtual void makeSound() = 0;\\n};\\n\\nclass Dog : public Animal {\\npublic:\\n    void makeSound() override;\\n    void bark();\\nprivate:\\n    std::string breed;\\n};\\n'\nresult = self.analyzer.analyze_file('test.h', code, 'C++')\nself.assertIn('classes', result)\nself.assertEqual(len(result['classes']), 2)\nanimal_class = result['classes'][0]\nself.assertEqual(animal_class['name'], 'Animal')\ndog_class = result['classes'][1]\nself.assertEqual(dog_class['name'], 'Dog')\nself.assertIn('Animal', dog_class['base_classes'])",
      "language": "Python",
      "description": "Workflow: Test C++ class extraction with inheritance.",
      "expected_behavior": "self.assertIn('Animal', dog_class['base_classes'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 376,
      "line_end": 404,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fe9f26b5",
      "test_name": "test_deep_depth_extracts_signatures",
      "category": "workflow",
      "code": "'Test that deep depth extracts full signatures.'\nanalyzer = CodeAnalyzer(depth='deep')\ncode = '\\ndef calculate(x: int, y: int) -> int:\\n    \"\"\"Calculate sum.\"\"\"\\n    return x + y\\n'\nresult = analyzer.analyze_file('test.py', code, 'Python')\nself.assertIn('functions', result)\nself.assertEqual(len(result['functions']), 1)\nfunc = result['functions'][0]\nself.assertEqual(func['name'], 'calculate')\nself.assertEqual(func['return_type'], 'int')",
      "language": "Python",
      "description": "Workflow: Test that deep depth extracts full signatures.",
      "expected_behavior": "self.assertEqual(func['return_type'], 'int')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 459,
      "line_end": 474,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5c7f9d11",
      "test_name": "test_javascript_inline_comments",
      "category": "workflow",
      "code": "'Test JavaScript // comment extraction.'\ncode = '\\n// Top-level comment\\nfunction test() {\\n    // Inside function\\n    const x = 5; // Inline (not extracted)\\n    return x;\\n}\\n\\n// Another comment\\nconst y = 10;\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\nself.assertIn('comments', result)\ncomments = result['comments']\nself.assertGreaterEqual(len(comments), 3)\ninline_comments = [c for c in comments if c['type'] == 'inline']\nself.assertGreaterEqual(len(inline_comments), 3)",
      "language": "Python",
      "description": "Workflow: Test JavaScript // comment extraction.",
      "expected_behavior": "self.assertGreaterEqual(len(inline_comments), 3)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 627,
      "line_end": 650,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "885c9e6b",
      "test_name": "test_javascript_block_comments",
      "category": "workflow",
      "code": "'Test JavaScript /* */ block comment extraction.'\ncode = '\\n/* This is a\\n   multi-line\\n   block comment */\\nfunction test() {\\n    /* Another block comment */\\n    return 42;\\n}\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\ncomments = result['comments']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(block_comments), 2)\nfirst_block = next((c for c in comments if 'multi-line' in c['text']))\nself.assertIn('multi-line', first_block['text'])",
      "language": "Python",
      "description": "Workflow: Test JavaScript /* */ block comment extraction.",
      "expected_behavior": "self.assertIn('multi-line', first_block['text'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 652,
      "line_end": 673,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "86bdbb68",
      "test_name": "test_javascript_mixed_comments",
      "category": "workflow",
      "code": "'Test JavaScript mixed inline and block comments.'\ncode = '\\n// Inline comment\\n/* Block comment */\\nfunction test() {\\n    // Another inline\\n    /* Another block */\\n    return true;\\n}\\n'\nresult = self.analyzer.analyze_file('test.js', code, 'JavaScript')\ncomments = result['comments']\ninline_comments = [c for c in comments if c['type'] == 'inline']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(inline_comments), 2)\nself.assertGreaterEqual(len(block_comments), 2)",
      "language": "Python",
      "description": "Workflow: Test JavaScript mixed inline and block comments.",
      "expected_behavior": "self.assertGreaterEqual(len(block_comments), 2)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 675,
      "line_end": 695,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2e6f1fe6",
      "test_name": "test_cpp_comment_extraction",
      "category": "workflow",
      "code": "'Test C++ comment extraction (uses same logic as JavaScript).'\ncode = '\\n// Header comment\\nclass Node {\\npublic:\\n    // Method comment\\n    void update();\\n\\n    /* Block comment for data member */\\n    int value;\\n};\\n'\nresult = self.analyzer.analyze_file('test.h', code, 'C++')\nself.assertIn('comments', result)\ncomments = result['comments']\nself.assertGreaterEqual(len(comments), 3)\ninline_comments = [c for c in comments if c['type'] == 'inline']\nblock_comments = [c for c in comments if c['type'] == 'block']\nself.assertGreaterEqual(len(inline_comments), 2)\nself.assertGreaterEqual(len(block_comments), 1)",
      "language": "Python",
      "description": "Workflow: Test C++ comment extraction (uses same logic as JavaScript).",
      "expected_behavior": "self.assertGreaterEqual(len(block_comments), 1)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 697,
      "line_end": 723,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "'Set up test analyzer with deep analysis'\nself.analyzer = CodeAnalyzer(depth='deep')",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "c8c19ef1",
      "test_name": "test_python_docstring_extraction",
      "category": "workflow",
      "code": "'Test docstring extraction for functions and classes.'\ncode = '\\nclass Calculator:\\n    \"\"\"A simple calculator class.\\n\\n    Supports basic arithmetic operations.\\n    \"\"\"\\n\\n    def add(self, a, b):\\n        \"\"\"Add two numbers.\\n\\n        Args:\\n            a: First number\\n            b: Second number\\n\\n        Returns:\\n            Sum of a and b\\n        \"\"\"\\n        return a + b\\n'\nresult = self.analyzer.analyze_file('test.py', code, 'Python')\ncalc_class = result['classes'][0]\nself.assertIn('A simple calculator class', calc_class['docstring'])\nself.assertIn('Supports basic arithmetic operations', calc_class['docstring'])\nadd_method = calc_class['methods'][0]\nself.assertIn('Add two numbers', add_method['docstring'])\nself.assertIn('Args:', add_method['docstring'])\nself.assertIn('Returns:', add_method['docstring'])",
      "language": "Python",
      "description": "Workflow: Test docstring extraction for functions and classes.",
      "expected_behavior": "self.assertIn('Returns:', add_method['docstring'])",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_code_analyzer.py",
      "line_start": 134,
      "line_end": 166,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "sys",
        "unittest",
        "skill_seekers.cli.code_analyzer"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3f1ab790",
      "test_name": "test_package_nonexistent_directory",
      "category": "method_call",
      "code": "self.assertFalse(success)\nself.assertIsNone(zip_path)",
      "language": "Python",
      "description": "Test packaging a nonexistent directory",
      "expected_behavior": "self.assertIsNone(zip_path)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 101,
      "line_end": 102,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3f1ab790",
      "test_name": "test_package_nonexistent_directory",
      "category": "method_call",
      "code": "self.assertFalse(success)\nself.assertIsNone(zip_path)",
      "language": "Python",
      "description": "Test packaging a nonexistent directory",
      "expected_behavior": "self.assertIsNone(zip_path)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 101,
      "line_end": 102,
      "complexity_score": 0.25,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "95f7b420",
      "test_name": "test_package_valid_skill_directory",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill_directory(tmpdir)",
      "language": "Python",
      "description": "Instantiate create_test_skill_directory: Test packaging a valid skill directory",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 42,
      "line_end": 42,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6d777b5a",
      "test_name": "test_package_valid_skill_directory",
      "category": "instantiation",
      "code": "success, zip_path = package_skill(skill_dir, open_folder_after=False, skip_quality_check=True)",
      "language": "Python",
      "description": "Instantiate package_skill: Test packaging a valid skill directory",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 44,
      "line_end": 46,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "95f7b420",
      "test_name": "test_package_creates_correct_zip_structure",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill_directory(tmpdir)",
      "language": "Python",
      "description": "Instantiate create_test_skill_directory: Test that packaged zip contains correct files",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 57,
      "line_end": 57,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6d777b5a",
      "test_name": "test_package_creates_correct_zip_structure",
      "category": "instantiation",
      "code": "success, zip_path = package_skill(skill_dir, open_folder_after=False, skip_quality_check=True)",
      "language": "Python",
      "description": "Instantiate package_skill: Test that packaged zip contains correct files",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 59,
      "line_end": 61,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "95f7b420",
      "test_name": "test_package_excludes_backup_files",
      "category": "instantiation",
      "code": "skill_dir = self.create_test_skill_directory(tmpdir)",
      "language": "Python",
      "description": "Instantiate create_test_skill_directory: Test that .backup files are excluded from zip",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 79,
      "line_end": 79,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6d777b5a",
      "test_name": "test_package_excludes_backup_files",
      "category": "instantiation",
      "code": "success, zip_path = package_skill(skill_dir, open_folder_after=False, skip_quality_check=True)",
      "language": "Python",
      "description": "Instantiate package_skill: Test that .backup files are excluded from zip",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 84,
      "line_end": 86,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "e46277c0",
      "test_name": "test_package_nonexistent_directory",
      "category": "instantiation",
      "code": "success, zip_path = package_skill('/nonexistent/path', open_folder_after=False, skip_quality_check=True)",
      "language": "Python",
      "description": "Instantiate package_skill: Test packaging a nonexistent directory",
      "expected_behavior": "self.assertFalse(success)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 97,
      "line_end": 99,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "6d777b5a",
      "test_name": "test_package_directory_without_skill_md",
      "category": "instantiation",
      "code": "success, zip_path = package_skill(skill_dir, open_folder_after=False, skip_quality_check=True)",
      "language": "Python",
      "description": "Instantiate package_skill: Test packaging directory without SKILL.md",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_package_skill.py",
      "line_start": 110,
      "line_end": 112,
      "complexity_score": 0.3,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "tempfile",
        "unittest",
        "zipfile",
        "pathlib",
        "skill_seekers.cli.package_skill",
        "subprocess",
        "subprocess"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a7e11ae3",
      "test_name": "test_extract_instantiation",
      "category": "workflow",
      "code": "'Test extraction of object instantiation patterns'\ncode = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'\nexamples = self.analyzer.extract('test_db.py', code)\ninstantiations = [ex for ex in examples if ex.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\ninst = instantiations[0]\nself.assertIn('Database', inst.code)\nself.assertIn('host', inst.code)\nself.assertGreaterEqual(inst.confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test extraction of object instantiation patterns",
      "expected_behavior": "self.assertGreaterEqual(inst.confidence, 0.7)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 40,
      "line_end": 60,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.analyzer = PythonTestAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "04c960f6",
      "test_name": "test_extract_method_call_with_assertion",
      "category": "workflow",
      "code": "'Test extraction of method calls followed by assertions'\ncode = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'\nexamples = self.analyzer.extract('test_api.py', code)\nself.assertGreater(len(examples), 0)\nmethod_calls = [ex for ex in examples if ex.category == 'method_call']\nif method_calls:\n    call = method_calls[0]\n    self.assertIn('get', call.code)\n    self.assertGreaterEqual(call.confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test extraction of method calls followed by assertions",
      "expected_behavior": "self.assertGreater(len(examples), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 62,
      "line_end": 83,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "self.analyzer = PythonTestAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2107235c",
      "test_name": "test_extract_config_dict",
      "category": "workflow",
      "code": "'Test extraction of configuration dictionaries'\ncode = '\\ndef test_app_config():\\n    \"\"\"Test application configuration\"\"\"\\n    config = {\\n        \"debug\": True,\\n        \"database_url\": \"postgresql://localhost/test\",\\n        \"cache_enabled\": False,\\n        \"max_connections\": 100\\n    }\\n    app = Application(config)\\n    assert app.is_configured()\\n'\nexamples = self.analyzer.extract('test_config.py', code)\nconfigs = [ex for ex in examples if ex.category == 'config']\nself.assertGreater(len(configs), 0)\nconfig = configs[0]\nself.assertIn('debug', config.code)\nself.assertIn('database_url', config.code)\nself.assertGreaterEqual(config.confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test extraction of configuration dictionaries",
      "expected_behavior": "self.assertGreaterEqual(config.confidence, 0.7)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 85,
      "line_end": 108,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.analyzer = PythonTestAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "2bc519d6",
      "test_name": "test_confidence_scoring",
      "category": "workflow",
      "code": "'Test confidence scores are calculated correctly'\nsimple_code = '\\ndef test_simple():\\n    obj = MyClass()\\n    assert obj is not None\\n'\nsimple_examples = self.analyzer.extract('test_simple.py', simple_code)\ncomplex_code = '\\ndef test_complex():\\n    \"\"\"Test complex initialization\"\"\"\\n    obj = MyClass(\\n        param1=\"value1\",\\n        param2=\"value2\",\\n        param3={\"nested\": \"dict\"},\\n        param4=[1, 2, 3]\\n    )\\n    result = obj.process()\\n    assert result.status == \"success\"\\n'\ncomplex_examples = self.analyzer.extract('test_complex.py', complex_code)\nif simple_examples and complex_examples:\n    simple_complexity = max((ex.complexity_score for ex in simple_examples))\n    complex_complexity = max((ex.complexity_score for ex in complex_examples))\n    self.assertGreater(complex_complexity, simple_complexity)",
      "language": "Python",
      "description": "Workflow: Test confidence scores are calculated correctly",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 209,
      "line_end": 238,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": "self.analyzer = PythonTestAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3017fb5b",
      "test_name": "test_extract_gdscript_gut_tests",
      "category": "workflow",
      "code": "'Test GDScript GUT/gdUnit4 test extraction'\ncode = '\\nextends GutTest\\n\\n# GUT test framework example\\nfunc test_player_instantiation():\\n    \"\"\"Test player node creation\"\"\"\\n    var player = preload(\"res://Player.gd\").new()\\n    player.name = \"TestPlayer\"\\n    player.health = 100\\n\\n    assert_eq(player.name, \"TestPlayer\")\\n    assert_eq(player.health, 100)\\n    assert_true(player.is_alive())\\n\\nfunc test_signal_connections():\\n    \"\"\"Test signal connections\"\"\"\\n    var enemy = Enemy.new()\\n    enemy.connect(\"died\", self, \"_on_enemy_died\")\\n\\n    enemy.take_damage(100)\\n\\n    assert_signal_emitted(enemy, \"died\")\\n\\n@test\\nfunc test_gdunit4_annotation():\\n    \"\"\"Test with gdUnit4 @test annotation\"\"\"\\n    var inventory = load(\"res://Inventory.gd\").new()\\n    inventory.add_item(\"sword\", 1)\\n\\n    assert_contains(inventory.items, \"sword\")\\n    assert_eq(inventory.get_item_count(\"sword\"), 1)\\n\\nfunc test_game_state():\\n    \"\"\"Test game state management\"\"\"\\n    const MAX_HEALTH = 100\\n    var player = Player.new()\\n    var game_state = GameState.new()\\n\\n    game_state.initialize(player)\\n\\n    assert_not_null(game_state.player)\\n    assert_eq(game_state.player.health, MAX_HEALTH)\\n'\nexamples = self.analyzer.extract('test_game.gd', code, 'GDScript')\nself.assertGreater(len(examples), 0)\nself.assertEqual(examples[0].language, 'GDScript')\ninstantiations = [e for e in examples if e.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\nhas_preload = any(('preload' in e.code or 'load' in e.code for e in instantiations))\nself.assertTrue(has_preload or len(instantiations) > 0)",
      "language": "Python",
      "description": "Workflow: Test GDScript GUT/gdUnit4 test extraction",
      "expected_behavior": "self.assertTrue(has_preload or len(instantiations) > 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 386,
      "line_end": 443,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": "self.analyzer = GenericTestAnalyzer()",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "8286b6de",
      "test_name": "test_language_filtering",
      "category": "workflow",
      "code": "'Test filtering by programming language'\npy_file = self.temp_dir / 'test_py.py'\npy_file.write_text('\\ndef test_python():\\n    obj = MyClass(param=\"value\")\\n    assert obj is not None\\n')\njs_file = self.temp_dir / 'test_js.js'\njs_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')\npython_extractor = TestExampleExtractor(languages=['python'])\nreport = python_extractor.extract_from_directory(self.temp_dir)\nfor example in report.examples:\n    self.assertEqual(example.language, 'Python')",
      "language": "Python",
      "description": "Workflow: Test filtering by programming language",
      "expected_behavior": "js_file.write_text('\\ntest(\"javascript test\", () => {\\n    const obj = new MyClass();\\n    expect(obj).toBeDefined();\\n});\\n')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 622,
      "line_end": 647,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9784e155",
      "test_name": "test_max_examples_limit",
      "category": "workflow",
      "code": "'Test max examples per file limit'\ntest_file = self.temp_dir / 'test_many.py'\ntest_code = 'import unittest\\n\\nclass TestSuite(unittest.TestCase):\\n'\nfor i in range(20):\n    test_code += f'\\n    def test_example_{i}(self):\\n        \"\"\"Test {i}\"\"\"\\n        obj = MyClass(id={i}, name=\"test_{i}\")\\n        self.assertIsNotNone(obj)\\n'\ntest_file.write_text(test_code)\nlimited_extractor = TestExampleExtractor(max_per_file=5)\nexamples = limited_extractor.extract_from_file(test_file)\nself.assertLessEqual(len(examples), 5)",
      "language": "Python",
      "description": "Workflow: Test max examples per file limit",
      "expected_behavior": "self.assertLessEqual(len(examples), 5)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 649,
      "line_end": 668,
      "complexity_score": 0.8,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "5e3da05f",
      "test_name": "test_end_to_end_workflow",
      "category": "workflow",
      "code": "'Test complete extraction workflow'\n(self.temp_dir / 'tests').mkdir()\n(self.temp_dir / 'tests' / 'test_unit.py').write_text('\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test API connection\"\"\"\\n        api = APIClient(url=\"https://api.example.com\", timeout=30)\\n        self.assertTrue(api.connect())\\n')\n(self.temp_dir / 'tests' / 'test_integration.py').write_text('\\ndef test_workflow():\\n    \"\"\"Test complete workflow\"\"\"\\n    user = User(name=\"John\", email=\"john@example.com\")\\n    user.save()\\n    user.verify()\\n    assert user.is_active\\n')\nreport = self.extractor.extract_from_directory(self.temp_dir / 'tests')\nself.assertGreater(report.total_examples, 0)\nself.assertIsInstance(report.examples_by_category, dict)\nself.assertIsInstance(report.examples_by_language, dict)\nself.assertGreaterEqual(report.avg_complexity, 0.0)\nself.assertLessEqual(report.avg_complexity, 1.0)\nself.assertGreater(len(report.examples_by_category), 0)\nfor example in report.examples:\n    self.assertIsNotNone(example.example_id)\n    self.assertIsNotNone(example.test_name)\n    self.assertIsNotNone(example.category)\n    self.assertIsNotNone(example.code)\n    self.assertIsNotNone(example.language)\n    self.assertGreaterEqual(example.confidence, 0.0)\n    self.assertLessEqual(example.confidence, 1.0)",
      "language": "Python",
      "description": "Workflow: Test complete extraction workflow",
      "expected_behavior": "self.assertGreater(len(report.examples_by_category), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 670,
      "line_end": 717,
      "complexity_score": 1.0,
      "confidence": 0.9,
      "setup_code": "self.temp_dir = Path(tempfile.mkdtemp())\nself.extractor = TestExampleExtractor(min_confidence=0.5, max_per_file=10)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "a7e11ae3",
      "test_name": "test_extract_instantiation",
      "category": "workflow",
      "code": "'Test extraction of object instantiation patterns'\ncode = '\\nimport unittest\\n\\nclass TestDatabase(unittest.TestCase):\\n    def test_connection(self):\\n        \"\"\"Test database connection\"\"\"\\n        db = Database(host=\"localhost\", port=5432, user=\"admin\")\\n        self.assertTrue(db.connect())\\n'\nexamples = self.analyzer.extract('test_db.py', code)\ninstantiations = [ex for ex in examples if ex.category == 'instantiation']\nself.assertGreater(len(instantiations), 0)\ninst = instantiations[0]\nself.assertIn('Database', inst.code)\nself.assertIn('host', inst.code)\nself.assertGreaterEqual(inst.confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test extraction of object instantiation patterns",
      "expected_behavior": "self.assertGreaterEqual(inst.confidence, 0.7)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 40,
      "line_end": 60,
      "complexity_score": 0.9,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "04c960f6",
      "test_name": "test_extract_method_call_with_assertion",
      "category": "workflow",
      "code": "'Test extraction of method calls followed by assertions'\ncode = '\\nimport unittest\\n\\nclass TestAPI(unittest.TestCase):\\n    def test_api_response(self):\\n        \"\"\"Test API returns correct status\"\"\"\\n        response = self.client.get(\"/users/1\")\\n        self.assertEqual(response.status_code, 200)\\n'\nexamples = self.analyzer.extract('test_api.py', code)\nself.assertGreater(len(examples), 0)\nmethod_calls = [ex for ex in examples if ex.category == 'method_call']\nif method_calls:\n    call = method_calls[0]\n    self.assertIn('get', call.code)\n    self.assertGreaterEqual(call.confidence, 0.7)",
      "language": "Python",
      "description": "Workflow: Test extraction of method calls followed by assertions",
      "expected_behavior": "self.assertGreater(len(examples), 0)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_test_example_extractor.py",
      "line_start": 62,
      "line_end": 83,
      "complexity_score": 0.6,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "os",
        "shutil",
        "sys",
        "tempfile",
        "unittest",
        "pathlib",
        "skill_seekers.cli.test_example_extractor"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9bb44f09",
      "test_name": "test_issue_277_error_message_urls",
      "category": "workflow",
      "code": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '\nerror_urls_with_anchors = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization/index.html.md', 'https://mikro-orm.io/docs/defining-entities#formulas/index.html.md', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums/index.html.md']\ninput_urls = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization', 'https://mikro-orm.io/docs/propagation', 'https://mikro-orm.io/docs/defining-entities#formulas', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums']\nresult = self.converter._convert_to_md_urls(input_urls)\nfor error_url in error_urls_with_anchors:\n    self.assertNotIn(error_url, result, f'Should not generate the 404-causing URL: {error_url}')\ncorrect_urls = ['https://mikro-orm.io/docs/quick-start/index.html.md', 'https://mikro-orm.io/docs/propagation/index.html.md', 'https://mikro-orm.io/docs/defining-entities/index.html.md']\nfor correct_url in correct_urls:\n    self.assertIn(correct_url, result, f'Should generate the correct URL: {correct_url}')",
      "language": "Python",
      "description": "Workflow: Test the exact URLs that appeared in error messages from the issue report.\nThese were the actual 404-causing URLs that need to be fixed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 213,
      "line_end": 255,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "9bb44f09",
      "test_name": "test_issue_277_error_message_urls",
      "category": "workflow",
      "code": "'\\n        Test the exact URLs that appeared in error messages from the issue report.\\n        These were the actual 404-causing URLs that need to be fixed.\\n        '\nerror_urls_with_anchors = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization/index.html.md', 'https://mikro-orm.io/docs/defining-entities#formulas/index.html.md', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums/index.html.md']\ninput_urls = ['https://mikro-orm.io/docs/quick-start#synchronous-initialization', 'https://mikro-orm.io/docs/propagation', 'https://mikro-orm.io/docs/defining-entities#formulas', 'https://mikro-orm.io/docs/defining-entities#postgresql-native-enums']\nresult = self.converter._convert_to_md_urls(input_urls)\nfor error_url in error_urls_with_anchors:\n    self.assertNotIn(error_url, result, f'Should not generate the 404-causing URL: {error_url}')\ncorrect_urls = ['https://mikro-orm.io/docs/quick-start/index.html.md', 'https://mikro-orm.io/docs/propagation/index.html.md', 'https://mikro-orm.io/docs/defining-entities/index.html.md']\nfor correct_url in correct_urls:\n    self.assertIn(correct_url, result, f'Should generate the correct URL: {correct_url}')",
      "language": "Python",
      "description": "Workflow: Test the exact URLs that appeared in error messages from the issue report.\nThese were the actual 404-causing URLs that need to be fixed.",
      "expected_behavior": "",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 213,
      "line_end": 255,
      "complexity_score": 0.7,
      "confidence": 0.9,
      "setup_code": null,
      "tags": [
        "unittest",
        "workflow",
        "integration"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "07a2cb0a",
      "test_name": "test_mikro_orm_urls_from_issue_277",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 7, f'Should have 7 unique base URLs after deduplication, got {len(result)}')\nself.assertIn('https://mikro-orm.io/docs/quick-start/index.html.md', result, 'quick-start URL should be correctly transformed')",
      "language": "Python",
      "description": "Test the exact URLs that caused 404 errors in issue #277",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/quick-start/index.html.md', result, 'quick-start URL should be correctly transformed')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 67,
      "line_end": 78,
      "complexity_score": 0.5,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "350b0770",
      "test_name": "test_mikro_orm_urls_from_issue_277",
      "category": "method_call",
      "code": "self.assertIn('https://mikro-orm.io/docs/quick-start/index.html.md', result, 'quick-start URL should be correctly transformed')\nself.assertIn('https://mikro-orm.io/docs/propagation/index.html.md', result, 'propagation URL should be correctly transformed')",
      "language": "Python",
      "description": "Test the exact URLs that caused 404 errors in issue #277",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/propagation/index.html.md', result, 'propagation URL should be correctly transformed')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 74,
      "line_end": 83,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ab550515",
      "test_name": "test_mikro_orm_urls_from_issue_277",
      "category": "method_call",
      "code": "self.assertIn('https://mikro-orm.io/docs/propagation/index.html.md', result, 'propagation URL should be correctly transformed')\nself.assertIn('https://mikro-orm.io/docs/defining-entities.md', result, 'defining-entities.md should preserve .md extension')",
      "language": "Python",
      "description": "Test the exact URLs that caused 404 errors in issue #277",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/defining-entities.md', result, 'defining-entities.md should preserve .md extension')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 79,
      "line_end": 88,
      "complexity_score": 0.45,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "ba7da4c1",
      "test_name": "test_deduplication_prevents_multiple_requests",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 1, 'Multiple anchors on same page should deduplicate to single request')\nself.assertEqual(result[0], 'https://mikro-orm.io/docs/defining-entities/index.html.md')",
      "language": "Python",
      "description": "Verify that multiple anchors on same page don't create duplicate requests",
      "expected_behavior": "self.assertEqual(result[0], 'https://mikro-orm.io/docs/defining-entities/index.html.md')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 134,
      "line_end": 142,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "50bf9f3a",
      "test_name": "test_md_files_with_anchors_preserved",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 3)\nself.assertIn('https://mikro-orm.io/docs/repositories.md', result)",
      "language": "Python",
      "description": "Test that .md files with anchors are handled correctly",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/repositories.md', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 155,
      "line_end": 156,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "01625f59",
      "test_name": "test_md_files_with_anchors_preserved",
      "category": "method_call",
      "code": "self.assertIn('https://mikro-orm.io/docs/repositories.md', result)\nself.assertIn('https://mikro-orm.io/docs/defining-entities.md', result)",
      "language": "Python",
      "description": "Test that .md files with anchors are handled correctly",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/defining-entities.md', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 156,
      "line_end": 157,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "1517887b",
      "test_name": "test_md_files_with_anchors_preserved",
      "category": "method_call",
      "code": "self.assertIn('https://mikro-orm.io/docs/defining-entities.md', result)\nself.assertIn('https://mikro-orm.io/docs/inheritance-mapping.md', result)",
      "language": "Python",
      "description": "Test that .md files with anchors are handled correctly",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/inheritance-mapping.md', result)",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 157,
      "line_end": 158,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": "'Set up test converter with MikroORM-like configuration'\nself.config = {'name': 'MikroORM', 'description': 'ORM', 'base_url': 'https://mikro-orm.io/docs/', 'selectors': {'main_content': 'article'}, 'url_patterns': {'include': ['/docs'], 'exclude': []}}\nself.converter = DocToSkillConverter(self.config, dry_run=True)",
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "07a2cb0a",
      "test_name": "test_mikro_orm_urls_from_issue_277",
      "category": "method_call",
      "code": "self.assertEqual(len(result), 7, f'Should have 7 unique base URLs after deduplication, got {len(result)}')\nself.assertIn('https://mikro-orm.io/docs/quick-start/index.html.md', result, 'quick-start URL should be correctly transformed')",
      "language": "Python",
      "description": "Test the exact URLs that caused 404 errors in issue #277",
      "expected_behavior": "self.assertIn('https://mikro-orm.io/docs/quick-start/index.html.md', result, 'quick-start URL should be correctly transformed')",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_issue_277_real_world.py",
      "line_start": 67,
      "line_end": 78,
      "complexity_score": 0.5,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [
        "unittest"
      ],
      "dependencies": [
        "unittest",
        "unittest.mock",
        "skill_seekers.cli.doc_scraper"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d7fb127c",
      "test_name": "test_add_document_single_language",
      "category": "method_call",
      "code": "manager.add_document('README.md', 'This is an English document.', {'category': 'overview'})\nassert len(manager.get_languages()) == 1",
      "language": "Python",
      "description": "Test adding documents in single language.",
      "expected_behavior": "assert len(manager.get_languages()) == 1",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 118,
      "line_end": 120,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "b339d3e7",
      "test_name": "test_add_document_multiple_languages",
      "category": "method_call",
      "code": "manager.add_document('README.fr.md', 'Ceci est fran\u00e7ais.', {})\nassert len(manager.get_languages()) == 3",
      "language": "Python",
      "description": "Test adding documents in multiple languages.",
      "expected_behavior": "assert len(manager.get_languages()) == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 131,
      "line_end": 133,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "016efbab",
      "test_name": "test_force_language",
      "category": "method_call",
      "code": "manager.add_document('file.md', 'This is actually English content.', {}, force_language='es')\nassert 'es' in manager.get_languages()",
      "language": "Python",
      "description": "Test forcing language override.",
      "expected_behavior": "assert 'es' in manager.get_languages()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 144,
      "line_end": 146,
      "complexity_score": 0.4,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "3fcc9c80",
      "test_name": "test_filename_language_priority",
      "category": "method_call",
      "code": "manager.add_document('guide.es.md', 'This is English content.', {})\nassert 'es' in manager.get_languages()",
      "language": "Python",
      "description": "Test filename pattern takes priority over content detection.",
      "expected_behavior": "assert 'es' in manager.get_languages()",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 155,
      "line_end": 158,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d5b3e25d",
      "test_name": "test_document_count_all",
      "category": "method_call",
      "code": "manager.add_document('file3.es.md', 'Spanish doc', {})\nassert manager.get_document_count() == 3",
      "language": "Python",
      "description": "Test total document count.",
      "expected_behavior": "assert manager.get_document_count() == 3",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 167,
      "line_end": 169,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "d79e058b",
      "test_name": "test_primary_language",
      "category": "method_call",
      "code": "manager.add_document('file2.es.md', 'Spanish doc', {})\nassert manager.primary_language == 'en'",
      "language": "Python",
      "description": "Test primary language is set correctly.",
      "expected_behavior": "assert manager.primary_language == 'en'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 179,
      "line_end": 182,
      "complexity_score": 0.35,
      "confidence": 0.85,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc8b7118",
      "test_name": "test_detect_english",
      "category": "instantiation",
      "code": "lang_info = detector.detect(text)",
      "language": "Python",
      "description": "Instantiate detect: Test English language detection.",
      "expected_behavior": "assert lang_info.code == 'en'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 30,
      "line_end": 30,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc8b7118",
      "test_name": "test_detect_spanish",
      "category": "instantiation",
      "code": "lang_info = detector.detect(text)",
      "language": "Python",
      "description": "Instantiate detect: Test Spanish language detection.",
      "expected_behavior": "assert lang_info.code == 'es'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 42,
      "line_end": 42,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc8b7118",
      "test_name": "test_detect_french",
      "category": "instantiation",
      "code": "lang_info = detector.detect(text)",
      "language": "Python",
      "description": "Instantiate detect: Test French language detection.",
      "expected_behavior": "assert lang_info.code == 'fr'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 53,
      "line_end": 53,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    },
    {
      "example_id": "fc8b7118",
      "test_name": "test_detect_german",
      "category": "instantiation",
      "code": "lang_info = detector.detect(text)",
      "language": "Python",
      "description": "Instantiate detect: Test German language detection.",
      "expected_behavior": "assert lang_info.code == 'de'",
      "file_path": "C:\\Users\\Administrator\\Desktop\\MT5\\skill\\Skill_Seekers\\tests\\test_multilang_support.py",
      "line_start": 64,
      "line_end": 64,
      "complexity_score": 0.15,
      "confidence": 0.8,
      "setup_code": null,
      "tags": [],
      "dependencies": [
        "pytest",
        "pathlib",
        "sys",
        "tempfile",
        "json",
        "skill_seekers.cli.multilang_support"
      ],
      "ai_analysis": null
    }
  ]
}